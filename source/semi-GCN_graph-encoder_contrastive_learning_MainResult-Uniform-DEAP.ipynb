{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34fd2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from pytorch_model_summary import summary\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.special import iv\n",
    "from typing import Optional\n",
    "from matplotlib import cm\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx  # pakage for handling a graph\n",
    "import os.path as osp\n",
    "from tqdm import tqdm\n",
    "from scipy import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import easydict\n",
    "import natsort\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "from torch_geometric.utils import sort_edge_index, degree, add_remaining_self_loops, remove_self_loops, get_laplacian, \\\n",
    "    to_undirected, to_dense_adj, to_networkx\n",
    "from torch_geometric.nn import GCNConv, SGConv, SAGEConv, GATConv, GraphConv, GINConv\n",
    "from torch_geometric.transforms import LaplacianLambdaMax\n",
    "from torch_geometric.utils import degree, to_undirected\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import ChebConv, GCNConv\n",
    "from torch_geometric.datasets import KarateClub\n",
    "\n",
    "\n",
    "from torch_scatter import scatter\n",
    "import torch_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fda8e3",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e293ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed_args():\n",
    "    args = easydict.EasyDict({\n",
    "        # arguments for setting device\n",
    "        'bus_id' : 'PCI_BUS_ID',\n",
    "        'cuda_id' : ['0','1','2'],\n",
    "        \n",
    "        # arguments for path\n",
    "        'os_path' : './SSLGCN',\n",
    "        'seed_data_dir_path' : 'dataset/seed/SEED_EEG/ExtractedFeatures/data/',\n",
    "        'feature_name1' : 'de_LDS',\n",
    "        'feature_name2' : 'psd_LDS',\n",
    "        'seed_label_dir_path' : 'dataset/seed/SEED_EEG/ExtractedFeatures/label/',\n",
    "        'figure_save_path' : './SSLGCN/store/figure/',\n",
    "        'tensor_save_path' : './SSLGCN/store/tensor/',\n",
    "        'model_save_path' : './SSLGCN/store/model/',\n",
    "        \n",
    "        # arguments for counts\n",
    "        'n_subjects' : 15,\n",
    "        'n_sessions' : 3,\n",
    "        'n_trials' : 15,\n",
    "        'n_nodes' : 62,\n",
    "        'n_features' : 5,\n",
    "        'n_samples' : 10182,\n",
    "        'n_labels_by_trials1' : 4,\n",
    "        'n_labels_by_trials2' : 6,\n",
    "        'n_labels_by_trials3' : 8,\n",
    "\n",
    "        # arguments for running algorithm\n",
    "        'seed' : 2023,\n",
    "        'EEG_band' : None,\n",
    "        'pca_components1' : 9,\n",
    "        'pca_components2' : 6,\n",
    "        'essm_lambda' : 0.9,\n",
    "        'de_k' : 3394, #721\n",
    "        'psd_k' : 3394, #1861\n",
    "        'k1' : 30,\n",
    "        'k2' : 130,\n",
    "        't1' : 1,\n",
    "        't2' : 1,\n",
    "        'feature_dimension' : 620,\n",
    "        'gcn_hid_channels' : 64,\n",
    "        'gcn_out_channels' : 128,\n",
    "        'out_channels' : 3,\n",
    "        'learning_rate' : 0.005,\n",
    "        'l2_lambda' : 0.001,\n",
    "        'epochs' : 3000,\n",
    "        'proj_hid_channels' : 32,\n",
    "        'ptau' : 32,\n",
    "        'pf1' : 0.1,\n",
    "        'pf2' : 0.1,\n",
    "        'pe1' : 0.1,\n",
    "        'pe2' : 0.1,\n",
    "        'tpf1' : 0.7,\n",
    "        'tpf2' : 0.7,\n",
    "        'tpe1' : 0.7,\n",
    "        'tpe2' : 0.7,\n",
    "        'loss_lambda' : 0.01,\n",
    "        'patience' : 10,\n",
    "        'val_split' : 0.2\n",
    "    })\n",
    "    \n",
    "    return args\n",
    "\n",
    "def get_seedIV_args():\n",
    "    args = easydict.EasyDict({\n",
    "        # arguments for setting device\n",
    "        'bus_id' : 'PCI_BUS_ID',\n",
    "        'cuda_id' : ['0','1','2'],\n",
    "        \n",
    "        # arguments for path\n",
    "        'os_path' : '/home/neuroai/users/dhkim/eer/SSLGCN',\n",
    "        'feature_name1' : 'de_LDS',\n",
    "        'feature_name2' : 'psd_LDS',\n",
    "        'seedIV_data_dir_path' : 'dataset/seed_IV/eeg_feature_smooth/',\n",
    "        'figure_save_path' : 'store_seedIV/figure/',\n",
    "        'tensor_save_path' : 'store_seedIV/tensor/',\n",
    "        'model_save_path' : 'store_seedIV/model/',\n",
    "        \n",
    "        # arguments for counts\n",
    "        'n_subjects' : 15,\n",
    "        'n_sessions' : 3,\n",
    "        'n_trials' : 24,\n",
    "        'n_nodes' : 62,\n",
    "        'n_features' : 5,\n",
    "        'n_samples' : 2505,\n",
    "        'n_labels_by_class1' : 15,\n",
    "        'n_labels_by_class2' : 20,\n",
    "        'n_labels_by_class3' : 25,\n",
    "\n",
    "        # arguments for running algorithm\n",
    "        'seed' : 2023,\n",
    "        'EEG_band' : None,\n",
    "        'pca_components1' : 9,\n",
    "        'pca_components2' : 6,\n",
    "        'essm_lambda' : 0.9,\n",
    "        'de_k' : 626,\n",
    "        'psd_k' : 626,\n",
    "        'k1' : 30,\n",
    "        'k2' : 130,\n",
    "        't1' : 1,\n",
    "        't2' : 1,\n",
    "        'feature_dimension' : 620,\n",
    "        'gcn_hid_channels' : 256,\n",
    "        'gcn_out_channels' : 64,\n",
    "        'out_channels' : 4,\n",
    "        'learning_rate' : 0.005,\n",
    "        'l2_lambda' : 0.001,\n",
    "        'epochs' : 3000,\n",
    "        'proj_hid_channels' : 16,\n",
    "        'ptau' : 0.7,\n",
    "        'pf1' : 0.1,\n",
    "        'pf2' : 0.2,\n",
    "        'pe1' : 0.1,\n",
    "        'pe2' : 0.2,\n",
    "        'tpf1' : 0.7,\n",
    "        'tpf2' : 0.7,\n",
    "        'tpe1' : 0.7,\n",
    "        'tpe2' : 0.7,\n",
    "        'loss_lambda' : 0.01,\n",
    "        'patience' : 10,\n",
    "        'val_split' : 0.2\n",
    "    })\n",
    "    return args\n",
    "\n",
    "def get_deap_args():\n",
    "    args = easydict.EasyDict({\n",
    "        # arguments for setting device\n",
    "        'bus_id' : 'PCI_BUS_ID',\n",
    "        'cuda_id' : ['0','1','2'],\n",
    "        \n",
    "        # arguments for path\n",
    "        'os_path' : '/home/user/users/dhkim/eer/SSLGCN',\n",
    "        'feature_name1' : 'DE_LDS_data',\n",
    "        'feature_name2' : 'PSD_LDS_data',\n",
    "        'deap_label_dir_path' : 'dataset/deap/data_preprocessed_matlab/',\n",
    "        'deap_data_dir_path' : 'dataset/deap/extractedfeatures/de_psd_lds/',\n",
    "        'figure_save_path' : 'store_deap/figure/',\n",
    "        'tensor_save_path' : 'store_deap/tensor/',\n",
    "        'model_save_path' : 'store_deap/model/',\n",
    "        'valence' : 'Valence',\n",
    "        'arousal' : 'Arousal',\n",
    "\n",
    "        \n",
    "        # arguments for counts\n",
    "        'n_subjects' : 32,\n",
    "        'n_trials' : 40,\n",
    "        'n_nodes' : 32,\n",
    "        'n_features' : 4,\n",
    "        'n_samples' : 2520,\n",
    "        'n_labels_by_class1' : 60,\n",
    "        'n_labels_by_class2' : 90,\n",
    "        'n_labels_by_class3' : 120,\n",
    "        'n_labels' : 2,\n",
    "\n",
    "        # arguments for running algorithm\n",
    "        'seed' : 2023,\n",
    "        'EEG_band' : None,\n",
    "        'pca_components1' : 9,\n",
    "        'pca_components2' : 6,\n",
    "        'essm_lambda' : 0.9,\n",
    "        'de_k' : 1200,\n",
    "        'psd_k' : 1200,\n",
    "        'k1' : 30,\n",
    "        'k2' : 130,\n",
    "        't1' : 1,\n",
    "        't2' : 1,\n",
    "        'feature_dimension' : 256,\n",
    "        'gcn_hid_channels' : 128,\n",
    "        'gcn_out_channels' : 64,\n",
    "        'out_channels' : 2,\n",
    "        'learning_rate' : 0.005,\n",
    "        'l2_lambda' : 0.001,\n",
    "        'epochs' : 3000,\n",
    "        'proj_hid_channels' : 16,\n",
    "        'ptau' : 0.7,\n",
    "        'pf1' : 0.1,\n",
    "        'pf2' : 0.2,\n",
    "        'pe1' : 0.1,\n",
    "        'pe2' : 0.2,\n",
    "        'tpf1' : 0.7,\n",
    "        'tpf2' : 0.7,\n",
    "        'tpe1' : 0.7,\n",
    "        'tpe2' : 0.7,\n",
    "        'loss_lambda' : 0.01,\n",
    "        'patience' : 10,\n",
    "        'val_split' : 0.2\n",
    "    })\n",
    "    \n",
    "    return args\n",
    "\n",
    "def setting_os_path(path):\n",
    "    if os.getcwd() != path:\n",
    "        os.chdir(path)\n",
    "    return\n",
    "\n",
    "def get_device(bus_id, cuda_id):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]= bus_id  # Arrange GPU devices starting from 0\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= cuda_id  # Set the GPU 2 to use\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print('Device:', device)\n",
    "    print('Current cuda device:', torch.cuda.current_device())\n",
    "    print('Count of using GPUs:', torch.cuda.device_count())\n",
    "    \n",
    "    return device\n",
    "    \n",
    "def fix_random_variables(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    cp.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "    \n",
    "    return\n",
    "\n",
    "def model_summary(model, fake_input,device):\n",
    "    print(summary(model, fake_input.to(device), max_depth=True, show_parent_layers=True))\n",
    "    print(model)\n",
    "    return\n",
    "\n",
    "def get_graph_data(features, edge_weights, labels):\n",
    "    adj = normalize_adj(edge_weights)\n",
    "    adj = (adj - adj.min()) / (adj.max()-adj.min())\n",
    "    adj = torch.from_numpy(adj).to(torch.float64)\n",
    "    features = features[0]\n",
    "    features = torch.from_numpy(features).to(torch.float64)\n",
    "    sparse_graph = adj.to_sparse()\n",
    "    \n",
    "    labels = torch.from_numpy(labels).to(torch.long)\n",
    "    data = Data(x=features, edge_index = sparse_graph._indices().to(torch.long), edge_attr =sparse_graph._values(), y=labels)\n",
    "    return data\n",
    "\n",
    "def get_base_model(name: str):\n",
    "    def gat_wrapper(in_channels, out_channels):\n",
    "        return GATConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels // 4,\n",
    "            heads=4\n",
    "        )\n",
    "\n",
    "    def gin_wrapper(in_channels, out_channels):\n",
    "        mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels, 2 * out_channels),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(2 * out_channels, out_channels)\n",
    "        )\n",
    "        return GINConv(mlp)\n",
    "\n",
    "    base_models = {\n",
    "        'GCNConv': GCNConv,\n",
    "        'SGConv': SGConv,\n",
    "        'SAGEConv': SAGEConv,\n",
    "        'GATConv': gat_wrapper,\n",
    "        'GraphConv': GraphConv,\n",
    "        'GINConv': gin_wrapper\n",
    "    }\n",
    "\n",
    "    return base_models[name]\n",
    "\n",
    "\n",
    "def get_activation(name: str):\n",
    "    activations = {\n",
    "        'relu': F.relu,\n",
    "        'hardtanh': F.hardtanh,\n",
    "        'elu': F.elu,\n",
    "        'leakyrelu': F.leaky_relu,\n",
    "        'prelu': torch.nn.PReLU(),\n",
    "        'rrelu': F.rrelu,\n",
    "        'celu' : torch.nn.CELU(),\n",
    "        'selu' : torch.nn.SELU(),\n",
    "        'gelu' : torch.nn.GELU()\n",
    "    }\n",
    "\n",
    "    return activations[name]\n",
    "\n",
    "\n",
    "def compute_pr(edge_index, damp: float = 0.85, k: int = 10):\n",
    "    num_nodes = edge_index.max().item() + 1\n",
    "    deg_out = degree(edge_index[0])\n",
    "    x = torch.ones((num_nodes, )).to(edge_index.device).to(torch.float64)\n",
    "\n",
    "    for i in range(k):\n",
    "        edge_msg = x[edge_index[0]] / deg_out[edge_index[0]]\n",
    "        agg_msg = scatter(edge_msg, edge_index[1], reduce='sum')\n",
    "\n",
    "        x = (1 - damp) * x + damp * agg_msg\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def eigenvector_centrality(data):\n",
    "    graph = to_networkx(data)\n",
    "    x = nx.eigenvector_centrality_numpy(graph)\n",
    "    x = [x[i] for i in range(data.num_nodes)]\n",
    "    return torch.tensor(x, dtype=torch.float64).to(data.edge_index.device)\n",
    "\n",
    "\n",
    "def generate_split(num_samples: int, train_ratio: float, val_ratio: float):\n",
    "    train_len = int(num_samples * train_ratio)\n",
    "    val_len = int(num_samples * val_ratio)\n",
    "    test_len = num_samples - train_len - val_len\n",
    "\n",
    "    train_set, test_set, val_set = random_split(torch.arange(0, num_samples), (train_len, test_len, val_len))\n",
    "\n",
    "    idx_train, idx_test, idx_val = train_set.indices, test_set.indices, val_set.indices\n",
    "    train_mask = torch.zeros((num_samples,)).to(torch.bool)\n",
    "    test_mask = torch.zeros((num_samples,)).to(torch.bool)\n",
    "    val_mask = torch.zeros((num_samples,)).to(torch.bool)\n",
    "\n",
    "    train_mask[idx_train] = True\n",
    "    test_mask[idx_test] = True\n",
    "    val_mask[idx_val] = True\n",
    "\n",
    "    return train_mask, test_mask, val_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a3454",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1db1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_deap_data(data_dir_path : str, fname1 : str, fname2 : str, label_dir_path : str, n_columns = 2):\n",
    "    print(\"*********** Load features and labels ************\")\n",
    "    \n",
    "    subject_feature_list1  = np.array([], dtype = float)\n",
    "    subject_feature_list2  = np.array([], dtype = float)\n",
    "    subject_label_list = np.array([], dtype = float)\n",
    "    subject_sample_counts  = np.array([], dtype = int)\n",
    "    \n",
    "    feature_dir_list = natsort.natsorted(os.listdir(data_dir_path))\n",
    "\n",
    "    for feature_idx, feature_dir in enumerate(feature_dir_list):\n",
    "        feature_data_dir_path = data_dir_path + feature_dir +'/'\n",
    "        file_list = natsort.natsorted(os.listdir(feature_data_dir_path))\n",
    "        print(feature_dir)\n",
    "        feature_list = np.array([], dtype = float)\n",
    "        if feature_idx == 0:\n",
    "            feature_name = fname1\n",
    "        else:\n",
    "            feature_name = fname2\n",
    "        \n",
    "        for f_idx, file in enumerate(file_list):\n",
    "            print(file)\n",
    "            data = io.loadmat(feature_data_dir_path + file)\n",
    "            np_data = data[feature_name]\n",
    "            \n",
    "            swap_data = np_data.transpose(1,2,3,0)\n",
    "            shape = swap_data.shape\n",
    "            swap_data = swap_data.reshape((shape[0]*shape[1], shape[2], shape[3]))\n",
    "\n",
    "            if feature_list.size == 0:\n",
    "                feature_list = swap_data.copy()\n",
    "                feature_list = np.expand_dims(feature_list, axis=0)\n",
    "            else:\n",
    "                feature_list = np.vstack((feature_list, np.expand_dims(swap_data, axis=0)))\n",
    "                \n",
    "        if feature_idx == 0:\n",
    "            print(\"get data in {} ... done\".format(feature_name))\n",
    "            subject_feature_list1 = feature_list\n",
    "\n",
    "        else:\n",
    "            print(\"get data in {} ... done\".format(feature_name))\n",
    "            subject_feature_list2 = feature_list\n",
    "            \n",
    "    label_list = natsort.natsorted(os.listdir(label_dir_path))\n",
    "    \n",
    "    shape2 = subject_feature_list1.shape\n",
    "    print(\"get label ... \", end= '')\n",
    "    subject_label_list = np.zeros((shape2[0],shape2[1],n_columns))\n",
    "    for l_idx, file in enumerate(label_list):\n",
    "        print(file)\n",
    "        label = io.loadmat(label_dir_path + file)\n",
    "        np_label = label['labels'][:,:n_columns]\n",
    "        start, end = 0, 0\n",
    "        for row in np_label:\n",
    "            end += shape[1]\n",
    "            label_by_trial = np.full((shape[1],n_columns), row)\n",
    "            subject_label_list[l_idx][start:end,:] = label_by_trial\n",
    "\n",
    "            start = end   \n",
    "    print(\"done\")\n",
    "    return subject_feature_list1, subject_feature_list2, subject_label_list\n",
    "\n",
    "    \n",
    "# EEG_band : delta, theta, alpha, beta, gamma, all = 1,2,3,4,5,None\n",
    "# Feature_name : de_LDS, PSD_LDS, etc.\n",
    "def load_seedIV_data(data_dir_path : str, feature_name : str, trial : int, islabel=True):\n",
    "    print(\"*********** Load features and labels ************\")\n",
    "    print(\"Feature type : \", feature_name)\n",
    "    \n",
    "    subject_feature_list  = np.array([], dtype = float)\n",
    "    session_dir_list = os.listdir(data_dir_path)\n",
    "    \n",
    "    if islabel:\n",
    "        subject_label_list = np.array([], dtype = float)\n",
    "        subject_sample_counts  = np.array([], dtype = int)\n",
    "\n",
    "        label_order = np.array([[1,2,3,0,2,0,0,1,0,1,2,1,1,1,2,3,2,2,3,3,0,3,0,3],\n",
    "                           [2,1,3,0,0,2,0,2,3,3,2,3,2,0,1,1,2,1,0,3,0,1,3,1],\n",
    "                           [1,2,2,1,3,3,3,1,1,2,1,0,2,3,3,0,2,3,0,0,2,0,1,0]])\n",
    "        \n",
    "        for ses_idx, ses_dir in enumerate(session_dir_list):\n",
    "            session_feature_list, session_label_list, session_sample_counts = np.array([], dtype = float), np.array([], dtype = int), np.array([], dtype = int)\n",
    "            \n",
    "            ses_data_dir_path = data_dir_path + ses_dir +'/'\n",
    "            file_list = os.listdir(ses_data_dir_path)\n",
    "            \n",
    "            for f_idx, file in enumerate(file_list):\n",
    "                trial_feature_list, trial_label_list, trial_sample_counts = np.array([], dtype = float), np.array([], dtype = int), np.array([], dtype = int)\n",
    "                \n",
    "                data = io.loadmat(ses_data_dir_path + file)\n",
    "                \n",
    "                for trial_idx in range(1, trial+1):\n",
    "                    np_data = data[feature_name + str(trial_idx)][:,:,:]\n",
    "                    swap_data = np_data.transpose(1,2,0)\n",
    "                    \n",
    "                    if trial_feature_list.size == 0:\n",
    "                        trial_feature_list = swap_data.copy()\n",
    "                    else:\n",
    "                        trial_feature_list = np.vstack((trial_feature_list, swap_data))\n",
    "                    \n",
    "                    trial_label = np.full((swap_data.shape[0]), label_order[ses_idx][trial_idx-1])\n",
    "                    trial_label_list = np.hstack((trial_label_list, trial_label))\n",
    "                    \n",
    "                    trial_sample_counts = np.hstack((trial_sample_counts, swap_data.shape[0]))\n",
    "                \n",
    "                if session_feature_list.size == 0:\n",
    "                    session_feature_list = np.expand_dims(trial_feature_list.copy(), axis=0)\n",
    "                else:\n",
    "                    session_feature_list = np.vstack((session_feature_list, np.expand_dims(trial_feature_list, axis=0)))\n",
    "\n",
    "                if session_label_list.size ==0:\n",
    "                    session_label_list = np.expand_dims(trial_label_list.copy(), axis=0)\n",
    "                else:\n",
    "                    session_label_list = np.vstack((session_label_list, np.expand_dims(trial_label_list, axis=0)))\n",
    "\n",
    "                if session_sample_counts.size == 0:\n",
    "                    session_sample_counts = np.expand_dims(trial_sample_counts.copy(), axis=0)\n",
    "                else:\n",
    "                    session_sample_counts = np.vstack((session_sample_counts, trial_sample_counts))\n",
    "                    \n",
    "            if subject_feature_list.size == 0:\n",
    "                subject_feature_list = session_feature_list\n",
    "            else:\n",
    "                subject_feature_list = np.concatenate((subject_feature_list, session_feature_list),axis = 1)\n",
    "            \n",
    "            if subject_label_list.size == 0:\n",
    "                subject_label_list = session_label_list\n",
    "            else:\n",
    "                subject_label_list = np.concatenate((subject_label_list, session_label_list),axis = 1)\n",
    "                \n",
    "            if subject_sample_counts.size == 0:\n",
    "                subject_sample_counts = session_sample_counts\n",
    "            else:\n",
    "                subject_sample_counts= np.concatenate((subject_sample_counts, session_sample_counts),axis = 1)\n",
    "\n",
    "            print(\"get data in session {} ... done\".format(ses_idx+1))\n",
    "        return subject_feature_list, subject_label_list, subject_sample_counts\n",
    "    \n",
    "    else:\n",
    "        for ses_idx, ses_dir in enumerate(session_dir_list):\n",
    "            session_feature_list = np.array([], dtype = float)\n",
    "            \n",
    "            ses_data_dir_path = data_dir_path + ses_dir +'/'\n",
    "            file_list = os.listdir(ses_data_dir_path)\n",
    "            \n",
    "            for f_idx, file in enumerate(file_list):\n",
    "                trial_feature_list = np.array([], dtype = float)\n",
    "                \n",
    "                data = io.loadmat(ses_data_dir_path + file)\n",
    "                \n",
    "                for trial_idx in range(1, trial+1):\n",
    "                    np_data = data[feature_name + str(trial_idx)][:,:,:]\n",
    "                    swap_data = np_data.transpose(1,2,0)\n",
    "                    \n",
    "                    if trial_feature_list.size == 0:\n",
    "                        trial_feature_list = swap_data.copy()\n",
    "                    else:\n",
    "                        trial_feature_list = np.vstack((trial_feature_list, swap_data))\n",
    "                    \n",
    "                if session_feature_list.size == 0:\n",
    "                    session_feature_list = np.expand_dims(trial_feature_list.copy(), axis=0)\n",
    "                else:\n",
    "                    session_feature_list = np.vstack((session_feature_list, np.expand_dims(trial_feature_list, axis=0)))\n",
    "                    \n",
    "            if subject_feature_list.size == 0:\n",
    "                subject_feature_list = session_feature_list\n",
    "            else:\n",
    "                subject_feature_list = np.concatenate((subject_feature_list, session_feature_list),axis = 1)\n",
    "    \n",
    "            print(\"get data in session {} ... done\".format(ses_idx+1))\n",
    "        return subject_feature_list\n",
    "    \n",
    "    \n",
    "def load_seed_data(data_dir_path, trial:int, feature_name, label_dir_path = None, EEG_band=None): \n",
    "\n",
    "    print(\"*********** Load features and labels ************\")\n",
    "    print(\"Feature type : \", feature_name)\n",
    "    \n",
    "    subject_feature_list, sample_feature_list = np.arange(0, dtype = 'float64'), np.arange(0, dtype = 'float64')\n",
    "    file_list = os.listdir(data_dir_path)\n",
    "    \n",
    "    if label_dir_path != None:\n",
    "        label_order = io.loadmat(label_dir_path + 'label.mat')['label']\n",
    "        label_order = [1 + label_order[0][i] for i in range(trial)]\n",
    "\n",
    "        subject_label_list, sample_label_list= np.array([], dtype = float), np.array([], dtype = float)\n",
    "        subject_sample_counts, trial_sample_counts = np.array([], dtype = int), np.array([], dtype = int)\n",
    "\n",
    "        for idx, file in enumerate(file_list):\n",
    "            data = io.loadmat(data_dir_path + file)\n",
    "            \n",
    "            if EEG_band is None:\n",
    "                for trial_idx in range(1, trial+1):\n",
    "                    np_data = data[feature_name + str(trial_idx)][:, :, :]\n",
    "                    swap_data = np_data.transpose(1,2,0)\n",
    "\n",
    "                    if sample_feature_list.size == 0:\n",
    "                        sample_feature_list = swap_data.copy()\n",
    "                    else:\n",
    "                        sample_feature_list = np.vstack((sample_feature_list, swap_data))\n",
    "\n",
    "                    trial_label = np.full((swap_data.shape[0]), np.int_(label_order[trial_idx-1])) \n",
    "                    sample_label_list = np.hstack((sample_label_list,trial_label))\n",
    "\n",
    "                    trial_sample_counts = np.hstack((trial_sample_counts, swap_data.shape[0]))\n",
    "\n",
    "            else:\n",
    "                for trial_idx in range(1, trial+1):\n",
    "                    np_data = data[feature_name + str(trial_idx)][:, :, EEG_band]\n",
    "\n",
    "                    swap_data = np_data.transpose(1,2,0)\n",
    "\n",
    "                    if sample_feature_list.size == 0:\n",
    "                        sample_feature_list = swap_data.copy()\n",
    "                    else:\n",
    "                        sample_feature_list = np.vstack((sample_feature_list, swap_data))\n",
    "\n",
    "\n",
    "                    trial_label = np.full((swap_data.shape[0]), float(label_order[trial_idx-1])) \n",
    "                    sample_label_list = np.hstack((sample_label_list,trial_label))\n",
    "\n",
    "                    trial_sample_counts = np.hstack((trial_sample_counts, swap_data.shape[0]))\n",
    "\n",
    "            if (idx+1)%3 == 0:\n",
    "\n",
    "                if subject_feature_list.size == 0:\n",
    "                    subject_feature_list = np.expand_dims(sample_feature_list.copy(), axis=0)\n",
    "                else:\n",
    "                    subject_feature_list = np.vstack((subject_feature_list, np.expand_dims(sample_feature_list, axis=0)))\n",
    "\n",
    "                sample_feature_list = np.array([], dtype = 'float64')\n",
    "\n",
    "                if subject_label_list.size ==0:\n",
    "                    subject_label_list = np.expand_dims(sample_label_list.copy(), axis=0)\n",
    "                else:\n",
    "                    subject_label_list = np.vstack((subject_label_list, np.expand_dims(sample_label_list, axis=0)))\n",
    "                sample_label_list = np.array([],dtype = 'float64')\n",
    "\n",
    "                if subject_sample_counts.size == 0:\n",
    "                    subject_sample_counts = np.expand_dims(trial_sample_counts.copy(), axis=0)\n",
    "                else:\n",
    "                    subject_sample_counts = np.vstack((subject_sample_counts, trial_sample_counts))\n",
    "                trial_sample_counts = np.array([], dtype=int)\n",
    "\n",
    "                print(\"get data of subject {} ... done\".format(int((idx+1)/3)))\n",
    "            \n",
    "        print(\"\\n data loading complete\")\n",
    "        return subject_feature_list, subject_label_list, subject_sample_counts\n",
    "                \n",
    "    else:\n",
    "        for idx, file in enumerate(file_list):\n",
    "            data =io.loadmat(data_dir_path + file)\n",
    "            \n",
    "            if EEG_band is None:\n",
    "                for trial_idx in range(1, trial+1):\n",
    "                    np_data = data[feature_name + str(trial_idx)][:, :, :]\n",
    "                    swap_data = np_data.transpose(1,2,0)\n",
    "\n",
    "                    if sample_feature_list.size == 0:\n",
    "                        sample_feature_list = swap_data.copy()\n",
    "                    else:\n",
    "                        sample_feature_list = np.vstack((sample_feature_list, swap_data))\n",
    "\n",
    "            else:\n",
    "                for trial_idx in range(1, trial+1):\n",
    "                    np_data = data[feature_name + str(trial_idx)][:, :, EEG_band]\n",
    "                    swap_data = np_data.transpose(1,2,0)\n",
    "\n",
    "                    if sample_feature_list.size == 0:\n",
    "                        sample_feature_list = swap_data.copy()\n",
    "                    else:\n",
    "                        sample_feature_list = np.vstack((sample_feature_list, swap_data))\n",
    "\n",
    "\n",
    "            if (idx+1)%3 == 0:\n",
    "\n",
    "                if subject_feature_list.size == 0:\n",
    "                    subject_feature_list = np.expand_dims(sample_feature_list.copy(), axis=0)\n",
    "                else:\n",
    "                    subject_feature_list = np.vstack((subject_feature_list, np.expand_dims(sample_feature_list, axis=0)))\n",
    "\n",
    "                sample_feature_list = np.array([], dtype = 'float64')\n",
    "\n",
    "                print(\"get data of subject {} ... done\".format(int((idx+1)/3)))\n",
    "                    \n",
    "        print(\"\\n data loading complete\")\n",
    "        return subject_feature_list\n",
    "    \n",
    "    # label [-1, 1] --> [0, 2]\n",
    "    # subject_feature_list : num_subjects(15) × (num_sessions(3) * num_trials(15) * approximately(240)) x feature embedding dimension(5) * num_nodes(62)\n",
    "\n",
    "\n",
    "# edge attributes are composed of edge weights, the distance between all EEG channel pairs\n",
    "\n",
    "def flatten(arr, reshape_size):\n",
    "    if isinstance(arr, list):\n",
    "        flatten_feature = np.array(arr).reshape((-1, reshape_size))\n",
    "    elif isinstance(arr, np.ndarray):\n",
    "        flatten_feature = arr.reshape((-1, reshape_size))\n",
    "    else:\n",
    "        print(\"unavailable type\")\n",
    "    return flatten_feature\n",
    "\n",
    "\n",
    "def deap_label(label_list):\n",
    "        \n",
    "    def binary_label_generator(val):\n",
    "        if val < 5.:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "            \n",
    "    shape = label_list.shape\n",
    "    valence_values = label_list[:,0]\n",
    "    arousal_values = label_list[:,1]\n",
    "    \n",
    "    vlc_label = np.zeros(shape[0])\n",
    "    ars_label = np.zeros(shape[0])\n",
    "    \n",
    "    for i in range(shape[0]):\n",
    "        vlc_label[i] = binary_label_generator(valence_values[i])\n",
    "        ars_label[i] = binary_label_generator(arousal_values[i])\n",
    "    \n",
    "    print(\"************* The number of samples by class ***********\")\n",
    "    print(\"Threshold : 5.0\")\n",
    "    print(\"low valence : {},    high valence : {}\".format(np.where(vlc_label == 0)[0].shape, np.where(vlc_label == 1)[0].shape))\n",
    "    print(\"low arousal : {},    high arousal : {}\".format(np.where(ars_label == 0)[0].shape, np.where(ars_label == 1)[0].shape))\n",
    "    \n",
    "    return vlc_label, ars_label\n",
    "\n",
    "def preprocessing(feature_list, sample_count_list, n_samples, n_labels_by_trials, n_nodes, n_features, seed): # flattening and simultaneous random shuffling\n",
    "    labeled_data_identifier = np.zeros(n_samples)\n",
    "    start = 0\n",
    "    end = 0\n",
    "    random.seed(seed)\n",
    "    for num in sample_count_list:\n",
    "        end += num\n",
    "        idcs = random.sample(range(start,end-1), n_labels_by_trials)\n",
    "        labeled_data_identifier[idcs] = 1\n",
    "        start += num\n",
    "        \n",
    "    flattened_feature_list = flatten(feature_list, n_nodes*n_features)\n",
    "\n",
    "    return flattened_feature_list, labeled_data_identifier\n",
    "\n",
    "def other_preprocessing(f1, f2, label_list, n_labels_by_class, n_classes,seed, isdeap=False): # flattening and simultaneous random shuffling\n",
    "    shape = f1.shape\n",
    "    n_samples = shape[0]\n",
    "    n_features = shape[1]\n",
    "    n_nodes = shape[2]\n",
    "\n",
    "    ff1 = flatten(f1,n_features*n_nodes)\n",
    "    ff2 = flatten(f2,n_features*n_nodes)\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    if isdeap == True:\n",
    "        vlc_label = label_list[0]\n",
    "        ars_label = label_list[1]\n",
    "        \n",
    "        vlc_labeled_data_identifier = np.zeros(n_samples)\n",
    "        ars_labeled_data_identifier = np.zeros(n_samples)\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            indices = np.where(vlc_label == i)[0]\n",
    "            labeled_idx = random.sample(sorted(indices), n_labels_by_class)\n",
    "            vlc_labeled_data_identifier[labeled_idx] = 1\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            indices = np.where(ars_label == i)[0]\n",
    "            labeled_idx = random.sample(sorted(indices), n_labels_by_class)\n",
    "            ars_labeled_data_identifier[labeled_idx] = 1\n",
    "\n",
    "        return ff1,ff2,vlc_labeled_data_identifier, ars_labeled_data_identifier\n",
    "\n",
    "    else:\n",
    "        labeled_data_identifier = np.zeros(n_samples)\n",
    "        for i in range(n_classes):\n",
    "            indices = np.where(label_list == i)[0]\n",
    "            labeled_idx = random.sample(sorted(indices), n_labels_by_class)\n",
    "            labeled_data_identifier[labeled_idx] = 1\n",
    "\n",
    "        return ff1,ff2,labeled_data_identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81890241",
   "metadata": {},
   "source": [
    "# functionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e104577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PCA was already implemented, LDA and NCA will be implemented later.\n",
    "def dimensionality_reduction(feature_list, n_component, feature_name, sub_idx, date): # PCA\n",
    "    feature_list = StandardScaler().fit_transform(feature_list) # standardization\n",
    "\n",
    "    pca = PCA(n_components = n_component)\n",
    "    pComponents = pca.fit_transform(feature_list)\n",
    "    print(\"Explaned variance ratio by principal components :\", pca.explained_variance_ratio_, \"\\n Overall ratio: \",sum(pca.explained_variance_ratio_))\n",
    "\n",
    "#     save_pca_figure(pca.explained_variance_ratio_, n_component, feature_name, sub_idx, date)\n",
    "    \n",
    "    return pComponents, pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "def input_feature(f1, f2):\n",
    "    return np.concatenate((f1,f2), axis = 1)\n",
    "\n",
    "\n",
    "def distance_matrix(f1):\n",
    "    shape = f1.shape[0]\n",
    "    if shape>5000:\n",
    "        D = np.zeros((shape,shape),float)\n",
    "        for i in range(shape):\n",
    "            for j in range(i+1, shape):\n",
    "                dist = np.linalg.norm(f1[i,:] - f1[j,:])\n",
    "                D[i,j] = dist\n",
    "                D[j,i] = dist\n",
    "        return D\n",
    "    else:\n",
    "        pairwise_dist = np.sum((f1[:, np.newaxis, :] - f1[np.newaxis, :, :])**2, axis=-1)\n",
    "\n",
    "        # Return square root of pairwise distances to obtain Euclidean distance\n",
    "        euclidean_dist = np.sqrt(pairwise_dist)\n",
    "        return euclidean_dist\n",
    "\n",
    "\n",
    "# get indices of K-nearest neighbors based on Manhattan distance of pivotal element of ssm \n",
    "def kneighbors(distance_matrix, length, k):\n",
    "    neighbors = np.zeros((length, k), dtype = float)\n",
    "    \n",
    "    neigh = NearestNeighbors(n_neighbors = k, p=1)\n",
    "    for i, vector in enumerate(distance_matrix):\n",
    "        v = np.expand_dims(vector,axis = 1)\n",
    "        neigh.fit(v)\n",
    "        neighbor= neigh.kneighbors([[vector[i]]], return_distance=False)\n",
    "        neighbors[i] = neighbor.squeeze()\n",
    "    neighbors = neighbors.astype(dtype='int32')\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def ssm_construction(dm, neighbors):\n",
    "    print(\"\\n********** SSM construction start ***********\")\n",
    "    length=dm.shape[0]\n",
    "    ssm = np.zeros((length, length), dtype = 'float64')\n",
    "    normalized_sparse_ssm = np.zeros((length,length), dtype = 'float64')\n",
    "\n",
    "    scaled_distance_mean = -dm.mean()*0.05\n",
    "    print(\"Done\")\n",
    "    print(\"\\nSparse ssm and normalized sparse ssm construction start...\")\n",
    "    # construct sparse_ssm \n",
    "    for i in range(length):\n",
    "        ith_neigh = neighbors[i]\n",
    "        ssm_elements = np.exp(dm[i][ith_neigh]/scaled_distance_mean)\n",
    "        ssm[i,ith_neigh] = ssm_elements\n",
    "        ssm[ith_neigh,i] = ssm_elements\n",
    "        \n",
    "#         ssm_sum = 2.0*(np.sum(ssm_elements)-1.)\n",
    "#         if ssm_sum != 0:\n",
    "#             normalized_sparse_ssm[i][ith_neigh] = ssm_elements / ssm_sum\n",
    "#         normalized_sparse_ssm[i][i] = 0.5\n",
    "    \n",
    "#     print(\"Done\\n\")\n",
    "\n",
    "#     trium = np.triu(normalized_sparse_ssm, k=1)\n",
    "#     normalized_sparse_ssm = trium + trium.T + np.diag(normalized_sparse_ssm.diagonal())\n",
    "\n",
    "    normalized_sparse_ssm = normalize_ssm(ssm)\n",
    "    print(\"Done\\n\")\n",
    "    \n",
    "    return ssm, normalized_sparse_ssm\n",
    "\n",
    "# def ssm_construction(feature_list, length, k):\n",
    "#     print(\"\\n********** SSM construction start ***********\")\n",
    "#     ssm = np.zeros((length, length), dtype = 'float64')\n",
    "#     normalized_sparse_ssm = np.zeros((length,length), dtype = 'float64')\n",
    "    \n",
    "#     print(\"\\nDistance matrix construction start...\")\n",
    "#     dm = distance_matrix(feature_list)\n",
    "\n",
    "#     scaled_distance_mean = -dm.mean()*0.05\n",
    "#     neighbors = kneighbors(dm, length, k)\n",
    "#     print(\"Done\")\n",
    "#     print(\"\\nSparse ssm and normalized sparse ssm construction start...\")\n",
    "#     # construct sparse_ssm \n",
    "#     for i in range(length):\n",
    "#         ith_neigh = neighbors[i]\n",
    "#         ssm_elements = np.exp(dm[i][ith_neigh]/scaled_distance_mean)\n",
    "#         ssm[i,ith_neigh] = ssm_elements\n",
    "#         ssm[ith_neigh,i] = ssm_elements\n",
    "        \n",
    "#         ssm_sum = 2.0*(np.sum(ssm_elements)-1.)\n",
    "#         if ssm_sum != 0:\n",
    "#             normalized_sparse_ssm[i][ith_neigh] = ssm_elements / ssm_sum\n",
    "#         normalized_sparse_ssm[i][i] = 0.5\n",
    "#     normalize_adj(ssm)\n",
    "    \n",
    "#     print(\"Done\\n\")\n",
    "\n",
    "#     trium = np.triu(normalized_sparse_ssm, k=1)\n",
    "#     normalized_sparse_ssm = trium + trium.T + np.diag(normalized_sparse_ssm.diagonal())\n",
    "\n",
    "#     print(\"Done\\n\")\n",
    "    \n",
    "#     return ssm, normalized_sparse_ssm\n",
    "\n",
    "# def ssm_construction(feature_list, length, k):\n",
    "#     print(\"\\n********** SSM construction start ***********\")\n",
    "#     ssm = np.zeros((length, length), dtype = 'float64')\n",
    "#     normalized_sparse_ssm = np.zeros((length,length), dtype = 'float64')\n",
    "    \n",
    "#     print(\"\\nDistance matrix construction start...\")\n",
    "#     dm = distance_matrix(feature_list)\n",
    "\n",
    "#     scaled_distance_mean = -dm.mean()*0.05\n",
    "#     neighbors = kneighbors(dm, length, k)\n",
    "#     print(\"Done\")\n",
    "#     print(\"\\nSparse ssm and normalized sparse ssm construction start...\")\n",
    "#     # construct sparse_ssm \n",
    "#     for i in range(length):\n",
    "#         ith_neigh = neighbors[i]\n",
    "#         ssm_elements = np.exp(dm[i][ith_neigh]/scaled_distance_mean)\n",
    "#         ssm[i,ith_neigh] = ssm_elements\n",
    "        \n",
    "#         ssm_sum = 2.0*(np.sum(ssm_elements)-1.)\n",
    "#         if ssm_sum != 0:\n",
    "#             normalized_sparse_ssm[i][ith_neigh] = ssm_elements / ssm_sum\n",
    "#         normalized_sparse_ssm[i][i] = 0.5\n",
    "\n",
    "#     print(\"Done\\n\")\n",
    "    \n",
    "#     return ssm, normalized_sparse_ssm\n",
    "\n",
    "def ssm_fusion(ssm_1,ssm_2,nssm_1,nssm_2, k, t):\n",
    "    print(\"\\n********** SSM fusion start ***********\")\n",
    "    length = ssm_1.shape[0]\n",
    "    \n",
    "    skm_1 = np.zeros((length,length), dtype = 'float64') # km means kernel matrix\n",
    "    skm_2 = np.zeros((length,length), dtype = 'float64')\n",
    "    \n",
    "    f1_neighbors = kneighbors(ssm_1, length, k)\n",
    "    f2_neighbors = kneighbors(ssm_2, length, k)\n",
    "    \n",
    "    print(\"sparse kernel matrix construction start...\")\n",
    "    # 1st feature based sparse kernel matrix construction \n",
    "    for i in range(length):\n",
    "        f1_ith_neighs = f1_neighbors[i]\n",
    "        f1_elements = ssm_1[i][f1_ith_neighs]\n",
    "        skm_1[i,f1_ith_neighs] = f1_elements\n",
    "        skm_1[f1_ith_neighs, i] = f1_elements\n",
    "        \n",
    "        f2_ith_neighs = f2_neighbors[i]\n",
    "        f2_elements = ssm_2[i][f2_ith_neighs]\n",
    "        skm_2[i,f2_ith_neighs] = f2_elements\n",
    "        skm_2[f2_ith_neighs, i] = f2_elements\n",
    "        \n",
    "    skm_1 = normalize_ssm(skm_1)\n",
    "    skm_2 = normalize_ssm(skm_2)\n",
    "    print(\"1st feature based skm has been completed\")\n",
    "    print(\"2nd feature based skm has been completed\\n\")\n",
    "    \n",
    "    print(\"fused ssm construction start...\")\n",
    "    # make normalized weight matrices by iterating t times\n",
    "    \n",
    "    st=time.time()\n",
    "    \n",
    "    for _t in range(t):\n",
    "        print(\"time step : \",_t)\n",
    "        temp = nssm_1.copy()\n",
    "        nssm_1 = np.matmul(np.matmul(skm_1, nssm_2.copy()), skm_1)\n",
    "        nssm_2 = np.matmul(np.matmul(skm_2, temp), skm_2)\n",
    "        if(t>1 and _t<t-1):\n",
    "            nssm_1 = normalize_ssm(nssm_1)\n",
    "            nssm_2 = normalize_ssm(nssm_2)\n",
    "    \n",
    "    fused_ssm = (nssm_1 + nssm_2) / 2\n",
    "\n",
    "    print(f\"{time.time()-st:.4f} sec\") # 종료와 함께 수행시간 출력\n",
    "    print(\"Done\")\n",
    "    print(\"**********************************************\")\n",
    "    return fused_ssm\n",
    "\n",
    "# def ssm_fusion(ssm_1,ssm_2,nssm_1,nssm_2, k, t):\n",
    "#     print(\"\\n********** SSM fusion start ***********\")\n",
    "#     length = ssm_1.shape[0]\n",
    "    \n",
    "#     skm_1 = np.zeros((length,length), dtype = 'float64') # km means kernel matrix\n",
    "#     skm_2 = np.zeros((length,length), dtype = 'float64')\n",
    "    \n",
    "#     f1_neighbors = kneighbors(ssm_1, length, k)\n",
    "#     f2_neighbors = kneighbors(ssm_2, length, k)\n",
    "    \n",
    "#     print(\"sparse kernel matrix construction start...\")\n",
    "#     # 1st feature based sparse kernel matrix construction \n",
    "#     for i in range(length):\n",
    "#         f1_ith_neighs = f1_neighbors[i]\n",
    "#         skm_1[i][f1_ith_neighs] = ssm_1[i][f1_ith_neighs]/np.sum(ssm_1[i][f1_ith_neighs])\n",
    "        \n",
    "#         f2_ith_neighs = f2_neighbors[i]\n",
    "#         skm_2[i][f2_ith_neighs] = ssm_2[i][f2_ith_neighs]/np.sum(ssm_2[i][f2_ith_neighs])\n",
    "#     print(\"1st feature based skm has been completed\")\n",
    "#     print(\"2nd feature based skm has been completed\\n\")\n",
    "    \n",
    "#     print(\"fused ssm construction start...\")\n",
    "#     # make normalized weight matrices by iterating t times\n",
    "    \n",
    "#     st=time.time()\n",
    "    \n",
    "#     for _t in range(t):\n",
    "#         print(\"time step : \",_t)\n",
    "#         temp = nssm_1.copy()\n",
    "#         nssm_1 = np.matmul(np.matmul(skm_1, nssm_2.copy().T), skm_1.T)\n",
    "#         nssm_2 = np.matmul(np.matmul(skm_2, temp.T), skm_2.T)\n",
    "            \n",
    "#     fused_ssm = (nssm_1 + nssm_2) / 2\n",
    "\n",
    "#     print(f\"{time.time()-st:.4f} sec\") # 종료와 함께 수행시간 출력\n",
    "#     print(\"Done\")\n",
    "#     print(\"**********************************************\")\n",
    "#     return fused_ssm\n",
    "\n",
    "\n",
    "def neighbor_matrix(neighbors,length,n_neigh):\n",
    "    i_neigh = np.zeros((length,n_neigh**2), dtype=float)\n",
    "    j_neigh = np.zeros((length,n_neigh**2), dtype=float)\n",
    "    for i in range(length):\n",
    "        duplicate_neighbors = sorted(list(neighbors[i]))*n_neigh\n",
    "        j_neigh[i] = duplicate_neighbors\n",
    "        i_neigh[i] = sorted(duplicate_neighbors)\n",
    "    return i_neigh, j_neigh\n",
    "\n",
    "def process_diffusion(fused_ssm, dfssm, i_neigh, j_neigh, neighbors,k2,t2, rweight, length):\n",
    "    # construct enhanced ssm leveraging \"fused ssm (fused_ssm)\" and \"denoised fused ssm (dfssm)\"\n",
    "    print(\"\\nSSM enhancement start...\")\n",
    "    enhanced_ssm = cp.zeros((length, length), dtype = 'float64')\n",
    "\n",
    "    neighbors = neighbors.astype(dtype='int32')\n",
    "    neighbors = np.sort(neighbors, axis=1)\n",
    "    ci_neigh = cp.asarray(i_neigh, dtype='int32')\n",
    "    cj_neigh = cp.asarray(j_neigh, dtype='int32')\n",
    "\n",
    "    essm = fused_ssm.copy()\n",
    "\n",
    "    for _t2 in range(t2):\n",
    "        for i in range(length):\n",
    "            ith_neigh = neighbors[i]\n",
    "            Qi = dfssm[i,ith_neigh]\n",
    "            vstacks = cp.random.random((k2,), dtype=float)\n",
    "            c_ith_neigh = ci_neigh[i]\n",
    "            for j in range(length):\n",
    "                A = essm[c_ith_neigh,cj_neigh[j]].reshape((k2,k2))\n",
    "                Qj = dfssm[neighbors[j],j]\n",
    "                vstacks = cp.vstack((vstacks,cp.matmul(A,Qj)))\n",
    "            vstacks = vstacks[1:].T\n",
    "            ith_essm = cp.matmul(Qi, vstacks)\n",
    "            enhanced_ssm[i,:] = ith_essm\n",
    "        essm = (rweight*enhanced_ssm + (1.0-rweight)*dfssm).copy()\n",
    "\n",
    "    print(\"Done\")\n",
    "    print(\"*********************************************\")\n",
    "    essm = cp.asnumpy(essm)\n",
    "    return essm\n",
    "\n",
    "\n",
    "def ssm_enhancement(fused_ssm,k2, t2, rweight):\n",
    "    print(\"\\n********** SSM enhancement start ***********\")\n",
    "    length = fused_ssm.shape[0]\n",
    "    \n",
    "    neighbors = kneighbors(fused_ssm, length, k2)\n",
    "    \n",
    "    print(\"\\nLocalized fused ssm construction start...\")\n",
    "    # construct the localized fused ssm by using KNN\n",
    "    lfssm = cp.zeros((length, length), dtype = 'float64') # nfssm means knn based \"normalized fused ssm\"\n",
    "    fused_ssm = cp.asarray(fused_ssm)\n",
    "    for i in range(length):\n",
    "        ith_neighs = neighbors[i]\n",
    "        lfssm[i][ith_neighs] = fused_ssm[i][ith_neighs] / cp.sum(fused_ssm[i][ith_neighs])\n",
    "    \n",
    "    print(\"Done\\n\")\n",
    "    print(\"Denoised fused ssm construction start...\")\n",
    "    # construct the denoised fused ssm exploiting nfssm\n",
    "    dfssm = cp.zeros((length,length), dtype = 'float64') # dfssm means denoised fused ssm\n",
    "    \n",
    "    sum_lfssm = cp.sum(lfssm, axis = 0)\n",
    "    # upper trianluar matrix construction\n",
    "    for i in range(length):\n",
    "        for j in range(i,length):\n",
    "            dfssm[i][j] = cp.sum(lfssm[i,:]*lfssm[j,:]/sum_lfssm)\n",
    "    \n",
    "    # reconstruct above matrix to symmetric matrix\n",
    "    dfssm += dfssm.T - cp.diag(dfssm.diagonal())\n",
    "    \n",
    "    print(\"Done\\n\")\n",
    "    \n",
    "    print(\"\\n Generate table for neighbors ...\")\n",
    "    i_neigh, j_neigh = neighbor_matrix(neighbors,length,k2)\n",
    "    print(\"Done\\n\")\n",
    "    \n",
    "    essm = process_diffusion(fused_ssm, dfssm, i_neigh, j_neigh, neighbors,k2,t2,rweight,length)\n",
    "    return essm\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Consider a weight for identity elements later\n",
    "\"\"\"\n",
    "def normalize_ssm(matrix):\n",
    "    length = matrix.shape[0]\n",
    "    tilde_matrix = matrix#+np.identity(length)\n",
    "    deg = np.sum(tilde_matrix, axis=1)\n",
    "    norm_deg = np.power(deg,-0.5)\n",
    "    tilde_deg = np.diag(norm_deg) # degree matrix (D) tilde\n",
    "    nor_ssm = np.matmul(np.matmul(tilde_deg, tilde_matrix),tilde_deg)\n",
    "        \n",
    "    return nor_ssm\n",
    "\n",
    "def normalize_adj(adj, im):   \n",
    "    length = adj.size(0)\n",
    "    tilde_adj = adj + im # adjacency matrix (A) tilde\n",
    "    deg = torch.sum(tilde_adj, dim=1)\n",
    "    norm_deg = torch.pow(deg, -0.5)\n",
    "    tilde_deg = torch.diag(norm_deg)  # degree matrix (D) tilde\n",
    "    nor_adj = torch.mm(torch.mm(tilde_deg, tilde_adj), tilde_deg)\n",
    "\n",
    "    \n",
    "    return nor_adj\n",
    "\n",
    "\n",
    "def normalization(x:torch.Tensor, axis:int = 0, ntype:str = None) -> torch.Tensor:\n",
    "    if ntype == None:\n",
    "        print(\"ntype is missed -- original tensor is returned\")\n",
    "        return x\n",
    "    elif ntype == 'standardization':\n",
    "        return (x-x.mean(axis=axis))/x.std(axis=axis)\n",
    "    elif ntype == 'min-max':\n",
    "        return (x - x.min())/(x.max() - x.min())\n",
    "\n",
    "def drop_features(features, edges, p: float, threshold: float = 0.7):\n",
    "    x = torch.abs(features)\n",
    "    row_sum = torch.sum(edges, axis=0)\n",
    "    feature_weights = x.t() @ row_sum\n",
    "    feature_weights = feature_weights.log()\n",
    "    weight_max = feature_weights.max()\n",
    "    w = (weight_max-feature_weights)/(weight_max-feature_weights.mean())\n",
    "\n",
    "    probability_weights = w / w.mean() * p\n",
    "    probability_weights = probability_weights.where(probability_weights < threshold, torch.ones_like(probability_weights) * threshold) \n",
    "    drop_mask = torch.bernoulli(probability_weights).to(torch.bool)\n",
    "    \n",
    "    features_view = features.clone()\n",
    "    features_view[:,drop_mask] = 0.\n",
    "\n",
    "    return features_view\n",
    "\n",
    "def disc_rank(feature, label,identifier, n_classes ):\n",
    "\n",
    "    X = feature[identifier]\n",
    "    y = label[identifier]\n",
    "    n_dims = X.shape[1]\n",
    "\n",
    "    Sw = torch.zeros(n_dims)\n",
    "    Sb = torch.zeros(n_dims)\n",
    "    for i in range(n_dims):\n",
    "        w = 0\n",
    "        wa = 0\n",
    "\n",
    "        global_mean_x = torch.mean(X[:,i])\n",
    "        for j in range(n_classes):\n",
    "            xc = X[torch.where(y==j)[0],i]\n",
    "            mean_xc = torch.mean(xc)\n",
    "            a = xc - mean_xc\n",
    "            w+=torch.dot(a,a)\n",
    "\n",
    "            wa += torch.pow(mean_xc-global_mean_x,2)\n",
    "        Sb[i] = wa\n",
    "        Sw[i] = w/float(n_classes)\n",
    "\n",
    "    #Sw low, Sb high --> important feauture dimension\n",
    "    disc_power = Sb/Sw\n",
    "    #disc_power high --> important feature dimension\n",
    "#     print(\"Within-class variance: \", Sw)\n",
    "#     print(\"between-class variance: \", Sb)\n",
    "#     print(\"Discriminative power: \", disc_power)\n",
    "    max_power = disc_power.max()\n",
    "    average_power = disc_power.mean()\n",
    "    rank = (max_power-disc_power)/(max_power-average_power)\n",
    "    #rank high -> unimportant feature dimension --> can be masked by high probablity\n",
    "#     print(\"Power probaility: \", rank*0.2)\n",
    "    return rank\n",
    "\n",
    "def drop_features2(features, rank, p: float, threshold: float = 0.7):\n",
    "    probablity_weights = rank * p\n",
    "\n",
    "    probablity_weights = probablity_weights.where(probablity_weights < threshold, torch.ones_like(probablity_weights) * threshold) \n",
    "    drop_mask = torch.bernoulli(probablity_weights).to(torch.bool)\n",
    "    \n",
    "    features_view = features.clone()\n",
    "    features_view[:,drop_mask] = 0.\n",
    "\n",
    "    return features_view\n",
    "\n",
    "def edge_mean_norm(edge_weights):\n",
    "    weight_max = edge_weights.max()\n",
    "    weights = (weight_max-edge_weights)/(weight_max-edge_weights.mean())\n",
    "    return weights\n",
    "\n",
    "def drop_edges(edge_weights, p: float, threshold: float = 1.):\n",
    "#     alleviated_weights = torch.log(edge_weights\n",
    "\n",
    "    probability_weights = weights / weights.mean() * p\n",
    "    probability_weights = probability_weights.where(probability_weights < threshold, torch.ones_like(probability_weights) * threshold)\n",
    "    drop_mask = torch.bernoulli(1. - probability_weights).to(torch.bool)\n",
    "   \n",
    "    edge_weights_view = edge_weights.where(drop_mask == True, torch.zeros_like(edge_weights))\n",
    "\n",
    "    return edge_weights_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da6ebe6",
   "metadata": {},
   "source": [
    "\n",
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "34eb22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 seed = 2023,\n",
    "                 bias = False\n",
    "                ):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        cp.random.seed(seed)\n",
    "        os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)  # type: ignore\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "        torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(in_channels, out_channels))\n",
    "        self.bias = None\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.torch.empty(out_channels))\n",
    "#         else:\n",
    "#             self.register_parameter('bias',None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        out = torch.mm(x, self.weight)\n",
    "        out = torch.mm(adj, out)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        return out\n",
    "    \n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels: int, hid_channels: int, out_channels: int, activation, seed, base_model=GraphConvolution):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "        self.gcn1 = base_model(in_channels, hid_channels, seed, bias = True)\n",
    "        self.gcn2 = base_model(hid_channels, out_channels, seed, bias = True)\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edges: torch.Tensor):\n",
    "        x = x.squeeze()\n",
    "        x1 = self.activation(self.gcn1(x, edges))\n",
    "        x2 = self.activation(self.gcn2(x1, edges))\n",
    "        return x2\n",
    "#         return torch.cat((x1,x2),axis=1)\n",
    "\n",
    "\n",
    "class GRACE(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, num_in: int, num_hidden: int, num_proj_hidden: int, num_out: int, tau: float = 0.5):\n",
    "        super(GRACE, self).__init__()\n",
    "        self.encoder: Encoder = encoder\n",
    "        self.tau: float = tau\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_hidden, num_proj_hidden)\n",
    "        self.fc2 = nn.Linear(num_proj_hidden, num_hidden)\n",
    "\n",
    "        self.gcn_classifier = GraphConvolution(num_hidden, num_out, 2023, bias=False)\n",
    "        self.fc_classifier = nn.Linear(num_hidden, num_out)\n",
    "        self.activation = nn.CELU()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.norm1d = nn.BatchNorm1d(num_in)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edges:torch.Tensor) -> torch.Tensor:\n",
    "#         x = self.norm1d(x)\n",
    "        x = x.unsqueeze(dim=0)\n",
    "        return self.encoder(x, edges)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        return self.activation(torch.mm(z, z.t()))\n",
    "    \n",
    "    def classification(self, z: torch.Tensor) ->torch.Tensor:\n",
    "#         return self.gcn_classifier(self.activation(z), adj)\n",
    "        return self.fc_classifier(self.activation(z))\n",
    "    \n",
    "    def projection(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        z = self.activation(self.fc1(z))\n",
    "        return self.fc2(z)\n",
    "\n",
    "    def sim(self, z1: torch.Tensor, z2: torch.Tensor):\n",
    "        z1 = F.normalize(z1)\n",
    "        z2 = F.normalize(z2)\n",
    "        return torch.mm(z1, z2.t())\n",
    "\n",
    "    def semi_loss(self, z1: torch.Tensor, z2: torch.Tensor):\n",
    "        f = lambda x: torch.exp(x / self.tau)\n",
    "        refl_sim = f(self.sim(z1, z1))\n",
    "        between_sim = f(self.sim(z1, z2))\n",
    "\n",
    "        return -torch.log(between_sim.diag() / (refl_sim.sum(1) + between_sim.sum(1) - refl_sim.diag()))\n",
    "\n",
    "    def batched_semi_loss(self, z1: torch.Tensor, z2: torch.Tensor, batch_size: int):\n",
    "        # Space complexity: O(BN) (semi_loss: O(N^2))\n",
    "        device = z1.device\n",
    "        num_nodes = z1.size(0)\n",
    "        num_batches = (num_nodes - 1) // batch_size + 1\n",
    "        f = lambda x: torch.exp(x / self.tau)\n",
    "        indices = torch.arange(0, num_nodes).to(device)\n",
    "        losses = []\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            mask = indices[i * batch_size:(i + 1) * batch_size]\n",
    "            refl_sim = f(self.sim(z1[mask], z1))  # [B, N]\n",
    "            between_sim = f(self.sim(z1[mask], z2))  # [B, N]\n",
    "\n",
    "            losses.append(-torch.log(between_sim[:, i * batch_size:(i + 1) * batch_size].diag()\n",
    "                                     / (refl_sim.sum(1) + between_sim.sum(1)\n",
    "                                        - refl_sim[:, i * batch_size:(i + 1) * batch_size].diag())))\n",
    "\n",
    "        return torch.cat(losses)\n",
    "\n",
    "    def loss(self, h1: torch.Tensor, h2: torch.Tensor, mean: bool = True, batch_size: Optional[int] = None):\n",
    "\n",
    "        if batch_size is None:\n",
    "            l1 = self.semi_loss(h1, h2)\n",
    "            l2 = self.semi_loss(h2, h1)\n",
    "        else:\n",
    "            l1 = self.batched_semi_loss(h1, h2, batch_size)\n",
    "            l2 = self.batched_semi_loss(h2, h1, batch_size)\n",
    "\n",
    "        ret = (l1 + l2) * 0.5\n",
    "        ret = ret.mean() if mean else ret.sum()\n",
    "\n",
    "        return ret\n",
    "\n",
    "\n",
    "class LogReg(nn.Module):\n",
    "    def __init__(self, ft_in, nb_classes):\n",
    "        super(LogReg, self).__init__()\n",
    "        self.fc = nn.Linear(ft_in, nb_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        ret = self.fc(seq)\n",
    "        return ret\n",
    "\n",
    "# activation Relu, Gelu, leaky Relu, Elu 비교해보기\n",
    "\n",
    "\n",
    "class SSLGCN(nn.Module):\n",
    "    def __init__(self, args, adj):\n",
    "        super(SSLGCN, self).__init__()\n",
    "        torch.random.manual_seed(args.seed)\n",
    "        self.l2_lambda = args.l2_lambda\n",
    "        self.in_channels = args.pca_components1 + args.pca_components2\n",
    "        self.gcn_hid_channels = args.gcn_hid_channels\n",
    "        self.gcn_out_channels = args.gcn_out_channels\n",
    "        self.fc_in_channels = args.gcn_hid_channels + args.gcn_out_channels\n",
    "#         self.fc_hid_channels = args.fc_hid_channels\n",
    "        self.out_channels = args.out_channels\n",
    "        self.edges = adj\n",
    "        self.activation = nn.CELU()\n",
    "\n",
    "        self.norm1d = nn.BatchNorm1d(self.in_channels)\n",
    "        self.gcnlayer1 = GraphConvolution(self.in_channels, self.gcn_hid_channels,\n",
    "                             bias = False)\n",
    "        self.gcnlayer2 = GraphConvolution(self.gcn_hid_channels, self.gcn_out_channels,\n",
    "                             bias = False)\n",
    "#         self.gcnlayers = nn.Sequential(\n",
    "#             GraphConvolution(self.in_channels, self.gcn_hid_channels,\n",
    "#                              adj = self.edges,\n",
    "#                              bias = False),\n",
    "#             self.activation,\n",
    "            \n",
    "#             GraphConvolution(self.gcn_hid_channels, self.gcn_out_channels,\n",
    "#                              adj = self.edges,\n",
    "#                              bias = False),\n",
    "#             self.activation\n",
    "#         )\n",
    "        \n",
    "        self.fclayer = nn.Linear(self.fc_in_channels, self.out_channels)\n",
    "#         self.fc1 = nn.Linear(self.fc_in_channels, self.fc_hid_channels)\n",
    "#         self.fc2 = nn.Linear(self.fc_hid_channels, self.out_channels)\n",
    "#         self.fclayers = nn.Sequential(self.fc1,self.activation,self.fc2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.norm1d(x)\n",
    "        gcn_out1 = self.activation(self.gcnlayer1(x,self.edges))\n",
    "        gcn_out2 = self.activation(self.gcnlayer2(gcn_out1, self.edges))\n",
    "        gcn_out = torch.cat((gcn_out1, gcn_out2), axis = 1)\n",
    "        out = self.fclayer(gcn_out)\n",
    "        return out\n",
    "\n",
    "    def set_lambda(self, l2_lambda):\n",
    "        self.l2_lambda = l2_lamda\n",
    "        \n",
    "    def l2_regularization(self):\n",
    "#         gcn_layers = self.gcnlayers.children()\n",
    "#         gcn_layers = next(iter(gcn_layers)) # Allow parameters to be extracted iteratively\n",
    "        loss = None\n",
    "        \n",
    "        for p in self.gcnlayer1.parameters():\n",
    "            if loss is None:\n",
    "                loss = p.pow(2).sum()\n",
    "            else:\n",
    "                loss += p.pow(2).sum()\n",
    "                \n",
    "        for p in self.gcnlayer2.parameters():\n",
    "            loss += p.pow(2).sum()\n",
    "                \n",
    "#         fc_layers = self.fclayers.children()\n",
    "#         fc_layers = next(iter(fc_layers)) \n",
    "        \n",
    "        for p in self.fclayer.parameters():\n",
    "            loss += p.pow(2).sum()\n",
    " \n",
    "        return loss * self.l2_lambda\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c3829",
   "metadata": {},
   "source": [
    "# learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4cedf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "def criterion(out, label):\n",
    "    return nn.functional.cross_entropy(out, label)\n",
    "\n",
    "def accuracy(out, label, isbinary = False):\n",
    "    if isbinary == True:\n",
    "        out = torch.sigmoid(out)\n",
    "    else:\n",
    "        out = nn.functional.softmax(out, dim=1)\n",
    "    pred = out.argmax(dim=1)\n",
    "    iscorrect = torch.eq(pred,label).float()\n",
    "    return iscorrect.mean()*100\n",
    "    \n",
    "# Learning rate schedular will be added later\n",
    "\n",
    "def test(feature, label, test_identifier, model):\n",
    "    model.eval()\n",
    "    \n",
    "    result = model(feature)\n",
    "    \n",
    "    test_pred = result[test_identifier]\n",
    "    test_y = label[test_identifier]\n",
    "    \n",
    "    acc = accuracy(test_pred, test_y)\n",
    "    \n",
    "    print(\"Test Acc : \", round(acc.item(), 2))\n",
    "    \n",
    "    return result, round(acc.item(), 2)\n",
    "\n",
    "\n",
    "def GCA_train(model, otimizer, feature, orig_adj, label, train_identifier, test_identifier, args, device,date = None,sub_idx = None, isdeap=False ):\n",
    "#     save_path = args.model_save_path+'subject_dependent/'+date+'/'+sub_idx+'.pt'\n",
    "#     early_stopping = EarlyStopping(patience = args.patience, verbose = False, path=save_path)\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_model = None\n",
    "    best_z = None\n",
    "#     w = 0.5\n",
    "\n",
    "    rank = disc_rank(feature, label,train_identifier, args.out_channels)\n",
    "\n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x1 = drop_features2(feature, rank, p = args.pf1, threshold = args.tpf1)\n",
    "        x2 = drop_features2(feature, rank, p = args.pf2, threshold = args.tpf2)\n",
    "        e1 = drop_edges(orig_adj, p = args.pe1, threshold = args.tpe1)\n",
    "        e2 = drop_edges(orig_adj, p = args.pe2, threshold = args.tpe2)\n",
    "\n",
    "#         x1 = drop_features(feature, adj, p = 0.1, threshold = args.tpf1)\n",
    "#         x2 = drop_features(feature, adj, p = 0.2, threshold = args.tpf2)\n",
    "#         e1 = drop_edges(adj, p = 0.1, threshold = args.tpe1)\n",
    "#         e2 = drop_edges(adj, p = 0.2, threshold = args.tpe2)\n",
    "        \n",
    "        z1 = model(x1,e1) #,bias = True)\n",
    "#         z1 = model(feature,adj)\n",
    "        z1 = model.projection(z1)\n",
    "        z2 = model(x2,e2)\n",
    "        z2 = model.projection(z2)   \n",
    "        \n",
    "#         ne1 = model.decoder(z1)\n",
    "#         ne2 = model.decoder(z2)\n",
    " \n",
    "#         ne1 = (ne1-ne1.min())/(ne1.max()-ne1.min())\n",
    "#         ne2 = (ne2-ne2.min())/(ne2.max()-ne2.min())\n",
    "#         nadj1 = w*adj + (1.-w)*ne1\n",
    "#         nadj2 = w*adj + (1.-w)*ne2\n",
    "#         nadj = 0.5*(nadj1+nadj2)\n",
    "#         print(nadj)\n",
    " \n",
    "        r1 = model.classification(z1)\n",
    "        r1_pred = r1[train_identifier]\n",
    "        r1_y = label[train_identifier]\n",
    "        # L2 regularization is not implemented yet\n",
    "        labeled_loss1 = criterion(r1_pred, r1_y)\n",
    "        r1_acc = accuracy(r1_pred, r1_y, isdeap)\n",
    "\n",
    "        r2 = model.classification(z2)\n",
    "        r2_pred = r2[train_identifier]\n",
    "        r2_y = label[train_identifier]\n",
    "        # L2 regularization is not implemented yet\n",
    "        labeled_loss2 = criterion(r2_pred, r2_y)\n",
    "        r2_acc = accuracy(r2_pred, r2_y, isdeap)\n",
    "\n",
    "        \n",
    "        contrastive_loss = model.loss(z1,z2)\n",
    "#         print(contrastive_loss)\n",
    "        loss = (labeled_loss1 + labeled_loss2)/2. + contrastive_loss*args.loss_lambda\n",
    "#         loss = labeled_loss1 + contrastive_loss*args.loss_lambda\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         orig_adj = nadj.detach().clone().to(device)\n",
    "#         print(orig_adj)\n",
    "#         adj = nadj.detach().clone().cuda()\n",
    "        acc = (r1_acc + r2_acc)/2.\n",
    "#         acc = r1_acc\n",
    "        \n",
    "        tr1_pred = r1[test_identifier]\n",
    "        tr1_y = label[test_identifier]\n",
    "        tr1_loss = criterion(tr1_pred, tr1_y)\n",
    "        tr1_acc = accuracy(tr1_pred, tr1_y, isdeap)\n",
    "        \n",
    "        tr2_pred = r2[test_identifier]\n",
    "        tr2_y = label[test_identifier]\n",
    "        tr2_acc = accuracy(tr2_pred, tr2_y, isdeap)\n",
    "        tr2_loss = criterion(tr2_pred, tr2_y)\n",
    "        \n",
    "#         tr_acc = (tr1_acc + tr2_acc)/2.\n",
    "        if tr1_acc > tr2_acc:\n",
    "            result = r1\n",
    "            tr_acc = tr1_acc\n",
    "        else:\n",
    "            result = r2\n",
    "            tr_acc = tr2_acc\n",
    "        \n",
    "        tr_loss = (tr1_loss + tr2_loss)/2.\n",
    "        total_acc = (tr_acc + acc)/2.\n",
    "        \n",
    "        if tr_acc > best_acc :\n",
    "            best_acc = tr_acc\n",
    "            best_epoch = epoch\n",
    "            best_model = model\n",
    "            \n",
    "            best_result = result\n",
    "            best_z = z1 if tr1_acc > tr2_acc else z2\n",
    "\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch {} - Train Acc : {}    Train Loss : {},    Test Acc : {},    Test Loss :{},    Total Acc : {}\".format(epoch, round(acc.item(), 2), round(loss.item(),2), round(tr_acc.item(),2), round(tr_loss.item(),2), round(total_acc.item(), 2)))\n",
    "\n",
    "#         early_stopping(vloss, model)\n",
    "#         if early_stopping.early_stop:\n",
    "#             print('Epoch : {} - Ealry Stopping'.format(epoch))\n",
    "#             break\n",
    "#     model.load_state_dict(torch.load(save_path))\n",
    "    return model, best_acc, best_epoch, best_model, best_z, best_result\n",
    "\n",
    "def GCA_test(model, feature, adj, label, test_identifier):\n",
    "    model.eval()\n",
    "    t1 = model(feature, adj) #,bias = True)\n",
    "\n",
    "    t1 = model.projection(t1)\n",
    "    tr1 = model.classification(t1)\n",
    "    tr1_pred = tr1[test_identifier]\n",
    "    tr1_y = label[test_identifier]\n",
    "    # L2 regularization is not implemented yet\n",
    "\n",
    "    tacc = accuracy(tr1_pred, tr1_y)\n",
    "\n",
    "    print(\"Test Acc : {}\".format(round(tacc.item(), 2)))\n",
    "    \n",
    "    return tr1, round(tacc.item(), 2)\n",
    "\n",
    "\n",
    "def disc_rank(feature, label,identifier, n_classes ):\n",
    "\n",
    "    X = feature[identifier]\n",
    "    y = label[identifier]\n",
    "    n_dims = X.shape[1]\n",
    "\n",
    "    Sw = torch.zeros(n_dims)\n",
    "    Sb = torch.zeros(n_dims)\n",
    "    for i in range(n_dims):\n",
    "        w = 0\n",
    "        wa = 0\n",
    "\n",
    "        global_mean_x = torch.mean(X[:,i])\n",
    "        for j in range(n_classes):\n",
    "            xc = X[torch.where(y==j)[0],i]\n",
    "            mean_xc = torch.mean(xc)\n",
    "            a = xc - mean_xc\n",
    "            w+=torch.dot(a,a)\n",
    "\n",
    "            wa += torch.pow(mean_xc-global_mean_x,2)\n",
    "        Sb[i] = wa\n",
    "        Sw[i] = w/float(n_classes)\n",
    "\n",
    "    #Sw low, Sb high --> important feauture dimension\n",
    "    disc_power = Sb/Sw\n",
    "    #disc_power high --> important feature dimension\n",
    "#     print(\"Within-class variance: \", Sw)\n",
    "#     print(\"between-class variance: \", Sb)\n",
    "#     print(\"Discriminative power: \", disc_power)\n",
    "    max_power = disc_power.max()\n",
    "    average_power = disc_power.mean()\n",
    "    rank = (max_power-disc_power)/(max_power-average_power)\n",
    "    #rank high -> unimportant feature dimension --> can be masked by high probablity\n",
    "#     print(\"Power probaility: \", rank*0.2)\n",
    "    return rank\n",
    "\n",
    "\n",
    "def drop_features2(probability_weights, features, threshold: float = 1.):\n",
    "\n",
    "    probability_weights = probability_weights.where(probability_weights < threshold, torch.ones_like(probability_weights) * threshold) \n",
    "    drop_mask = torch.bernoulli(probability_weights).to(torch.bool)\n",
    "    \n",
    "    features_view = features.clone()\n",
    "    features_view[:,drop_mask] = 0.\n",
    "\n",
    "    return features_view\n",
    "\n",
    "def edge_rank(edge_weights):\n",
    "    weight_max = edge_weights.max()\n",
    "    weight_mean = edge_weights.mean()\n",
    "    weights = (weight_max-edge_weights)/(weight_max-edge_weights.mean())\n",
    "    return weights\n",
    "\n",
    "def drop_edges2(probability_weights, edge_weights, threshold: float = 1.):\n",
    "#     alleviated_weights = torch.log(edge_weights\n",
    "\n",
    "    probability_weights = probability_weights.where(probability_weights < threshold, torch.ones_like(probability_weights) * threshold)\n",
    "    drop_mask = torch.bernoulli(1. - probability_weights).to(torch.bool)\n",
    "   \n",
    "    edge_weights_view = edge_weights.where(drop_mask == True, torch.zeros_like(edge_weights))\n",
    "\n",
    "    return edge_weights_view\n",
    "\n",
    "\n",
    "def GCA_train2(model, otimizer, feature, orig_adj, label, train_identifier, test_identifier, args, device,date = None,sub_idx = None, isdeap=False ):\n",
    "#     save_path = args.model_save_path+'subject_dependent/'+date+'/'+sub_idx+'.pt'\n",
    "#     early_stopping = EarlyStopping(patience = args.patience, verbose = False, path=save_path)\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_model = None\n",
    "    best_z = None\n",
    "#     w = 0.5\n",
    "\n",
    "    rankf = disc_rank(feature, label,train_identifier, args.out_channels)\n",
    "    rankf1 = rankf*args.pf1\n",
    "    rankf2 = rankf*args.pf2\n",
    "    ranke = edge_rank(adj)\n",
    "    ranke1 = ranke*args.pe1\n",
    "    ranke2 = ranke*args.pe2\n",
    "    \n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x1 = drop_features2(rankf1, feature, threshold = args.tpf1)\n",
    "        x2 = drop_features2(rankf2, feature, threshold = args.tpf2)\n",
    "        e1 = drop_edges2(ranke1,orig_adj, threshold = args.tpe1)\n",
    "        e2 = drop_edges2(ranke2,orig_adj, threshold = args.tpe2)\n",
    "\n",
    "#         x1 = drop_features(feature, adj, p = 0.1, threshold = args.tpf1)\n",
    "#         x2 = drop_features(feature, adj, p = 0.2, threshold = args.tpf2)\n",
    "#         e1 = drop_edges(adj, p = 0.1, threshold = args.tpe1)\n",
    "#         e2 = drop_edges(adj, p = 0.2, threshold = args.tpe2)\n",
    "        \n",
    "        z1 = model(x1,e1) #,bias = True)\n",
    "#         z1 = model(feature,adj)\n",
    "        z1 = model.projection(z1)\n",
    "        z2 = model(x2,e2)\n",
    "        z2 = model.projection(z2)   \n",
    "        \n",
    "#         ne1 = model.decoder(z1)\n",
    "#         ne2 = model.decoder(z2)\n",
    " \n",
    "#         ne1 = (ne1-ne1.min())/(ne1.max()-ne1.min())\n",
    "#         ne2 = (ne2-ne2.min())/(ne2.max()-ne2.min())\n",
    "#         nadj1 = w*adj + (1.-w)*ne1\n",
    "#         nadj2 = w*adj + (1.-w)*ne2\n",
    "#         nadj = 0.5*(nadj1+nadj2)\n",
    "#         print(nadj)\n",
    " \n",
    "        r1 = model.classification(z1)\n",
    "        r1_pred = r1[train_identifier]\n",
    "        r1_y = label[train_identifier]\n",
    "        # L2 regularization is not implemented yet\n",
    "        labeled_loss1 = criterion(r1_pred, r1_y)\n",
    "        r1_acc = accuracy(r1_pred, r1_y, isdeap)\n",
    "\n",
    "        r2 = model.classification(z2)\n",
    "        r2_pred = r2[train_identifier]\n",
    "        r2_y = label[train_identifier]\n",
    "        # L2 regularization is not implemented yet\n",
    "        labeled_loss2 = criterion(r2_pred, r2_y)\n",
    "        r2_acc = accuracy(r2_pred, r2_y, isdeap)\n",
    "\n",
    "        \n",
    "        contrastive_loss = model.loss(z1,z2)\n",
    "#         print(contrastive_loss)\n",
    "        loss = (labeled_loss1 + labeled_loss2)/2. + contrastive_loss*args.loss_lambda\n",
    "#         loss = labeled_loss1 + contrastive_loss*args.loss_lambda\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         orig_adj = nadj.detach().clone().to(device)\n",
    "#         print(orig_adj)\n",
    "#         adj = nadj.detach().clone().cuda()\n",
    "        acc = (r1_acc + r2_acc)/2.\n",
    "#         acc = r1_acc\n",
    "        \n",
    "        tr1_pred = r1[test_identifier]\n",
    "        tr1_y = label[test_identifier]\n",
    "        tr1_loss = criterion(tr1_pred, tr1_y)\n",
    "        tr1_acc = accuracy(tr1_pred, tr1_y, isdeap)\n",
    "        \n",
    "        tr2_pred = r2[test_identifier]\n",
    "        tr2_y = label[test_identifier]\n",
    "        tr2_acc = accuracy(tr2_pred, tr2_y, isdeap)\n",
    "        tr2_loss = criterion(tr2_pred, tr2_y)\n",
    "        \n",
    "#         tr_acc = (tr1_acc + tr2_acc)/2.\n",
    "        if tr1_acc > tr2_acc:\n",
    "            result = r1\n",
    "            tr_acc = tr1_acc\n",
    "        else:\n",
    "            result = r2\n",
    "            tr_acc = tr2_acc\n",
    "        \n",
    "        tr_loss = (tr1_loss + tr2_loss)/2.\n",
    "        total_acc = (tr_acc + acc)/2.\n",
    "        \n",
    "        if tr_acc > best_acc :\n",
    "            best_acc = tr_acc\n",
    "            best_epoch = epoch\n",
    "            best_model = model\n",
    "            \n",
    "            best_result = result\n",
    "            best_z = z1 if tr1_acc > tr2_acc else z2\n",
    "\n",
    "\n",
    "#         if epoch % 10 == 0:\n",
    "#             print(\"Epoch {} - Train Acc : {}    Train Loss : {},    Test Acc : {},    Test Loss :{},    Total Acc : {}\".format(epoch, round(acc.item(), 2), round(loss.item(),2), round(tr_acc.item(),2), round(tr_loss.item(),2), round(total_acc.item(), 2)))\n",
    "\n",
    "#         early_stopping(vloss, model)\n",
    "#         if early_stopping.early_stop:\n",
    "#             print('Epoch : {} - Ealry Stopping'.format(epoch))\n",
    "#             break\n",
    "#     model.load_state_dict(torch.load(save_path))\n",
    "    return model, best_acc, best_epoch, best_model, best_z, best_result\n",
    "\n",
    "def uniform_GCA_train(model, otimizer, feature, orig_adj, label, train_identifier, test_identifier, args, device,date = None,sub_idx = None, isdeap=False, verbose=True):\n",
    "#     save_path = args.model_save_path+'subject_dependent/'+date+'/'+sub_idx+'.pt'\n",
    "#     early_stopping = EarlyStopping(patience = args.patience, verbose = False, path=save_path)\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_model = None\n",
    "    best_z = None\n",
    "#     w = 0.5\n",
    "\n",
    "    im = torch.eye(args.n_samples, device=device)\n",
    "    \n",
    "    f1probs = torch.full((feature.shape), 1-args.pf1).to(device)\n",
    "    f2probs = torch.full((feature.shape), 1-args.pf2).to(device)\n",
    "    e1probs = torch.triu(torch.full((orig_adj.shape), 1-args.pe1),diagonal=1).to(device)\n",
    "    e2probs = torch.triu(torch.full((orig_adj.shape), 1-args.pe2),diagonal=1).to(device)\n",
    "\n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x1 = uniform_drop_features(feature, f1probs)\n",
    "        x2 = uniform_drop_features(feature, f2probs)\n",
    "        e1 = uniform_drop_edges(orig_adj, e1probs, im)\n",
    "        e2 = uniform_drop_edges(orig_adj, e2probs, im)\n",
    "\n",
    "        e1 = normalize_adj(e1, im)\n",
    "        e2 = normalize_adj(e2, im)\n",
    "#         x1 = drop_features(feature, adj, p = 0.1, threshold = args.tpf1)\n",
    "#         x2 = drop_features(feature, adj, p = 0.2, threshold = args.tpf2)\n",
    "#         e1 = drop_edges(adj, p = 0.1, threshold = args.tpe1)\n",
    "#         e2 = drop_edges(adj, p = 0.2, threshold = args.tpe2)\n",
    "        \n",
    "        z1 = model(x1,e1) #,bias = True)\n",
    "#         z1 = model(feature,adj)\n",
    "        z1 = model.projection(z1)\n",
    "        z2 = model(x2,e2)\n",
    "        z2 = model.projection(z2)   \n",
    "        \n",
    "#         ne1 = model.decoder(z1)\n",
    "#         ne2 = model.decoder(z2)\n",
    " \n",
    "#         ne1 = (ne1-ne1.min())/(ne1.max()-ne1.min())\n",
    "#         ne2 = (ne2-ne2.min())/(ne2.max()-ne2.min())\n",
    "#         nadj1 = w*adj + (1.-w)*ne1\n",
    "#         nadj2 = w*adj + (1.-w)*ne2\n",
    "#         nadj = 0.5*(nadj1+nadj2)\n",
    "#         print(nadj)\n",
    "\n",
    "        r_y = label[train_identifier] \n",
    "        r1 = model.classification(z1)\n",
    "        r1_pred = r1[train_identifier]\n",
    "\n",
    "        # L2 regularization is not implemented yet\n",
    "        labeled_loss1 = criterion(r1_pred, r_y)\n",
    "        r1_acc = accuracy(r1_pred, r_y, isdeap)\n",
    "\n",
    "        r2 = model.classification(z2)\n",
    "        r2_pred = r2[train_identifier]\n",
    "        # L2 regularization is not implemented yet\n",
    "        labeled_loss2 = criterion(r2_pred, r_y)\n",
    "        r2_acc = accuracy(r2_pred, r_y, isdeap)\n",
    "\n",
    "        labeled_loss = (labeled_loss1 + labeled_loss2)/2.\n",
    "\n",
    "        contrastive_loss = model.loss(z1,z2)\n",
    "#         print(contrastive_loss)\n",
    "        loss = labeled_loss + contrastive_loss*args.loss_lambda\n",
    "#         loss = labeled_loss1 + contrastive_loss*args.loss_lambda\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         orig_adj = nadj.detach().clone().to(device)\n",
    "#         print(orig_adj)\n",
    "#         adj = nadj.detach().clone().cuda()\n",
    "        acc = (r1_acc + r2_acc)/2.\n",
    "#         acc = r1_acc\n",
    "        \n",
    "        tr_y = label[test_identifier]\n",
    "        tr1_pred = r1[test_identifier]\n",
    "        tr1_loss = criterion(tr1_pred, tr_y)\n",
    "        tr1_acc = accuracy(tr1_pred, tr_y, isdeap)\n",
    "        \n",
    "        tr2_pred = r2[test_identifier]\n",
    "        tr2_y = label[test_identifier]\n",
    "        tr2_acc = accuracy(tr2_pred, tr_y, isdeap)\n",
    "        tr2_loss = criterion(tr2_pred, tr_y)\n",
    "        \n",
    "        #tr_acc = (tr1_acc + tr2_acc)/2.\n",
    "        tr_acc = tr1_acc if tr1_acc > tr2_acc else tr2_acc\n",
    "        tr_loss = (tr1_loss + tr2_loss)/2.\n",
    "        total_acc = (tr_acc + acc)/2.\n",
    "        \n",
    "        if tr_acc > best_acc :\n",
    "            best_acc = tr_acc\n",
    "            best_epoch = epoch\n",
    "            best_model = model\n",
    "            best_z = z1 if tr1_acc > tr2_acc else z2\n",
    "            best_result = r1 if tr1_acc > tr2_acc else r2\n",
    "\n",
    "        if best_acc == 100.0:\n",
    "            return best_acc, best_epoch, best_z, best_result\n",
    "\n",
    "        if verbose == True:\n",
    "            if epoch % 100 == 0:\n",
    "                print(\"Epoch {} - Train Acc : {}    Train Loss : {},    Test Acc : {},    Test Loss :{},    Total Acc : {}\".format(epoch, round(acc.item(), 2), round(loss.item(),2), round(tr_acc.item(),2), round(tr_loss.item(),2), round(total_acc.item(), 2)))\n",
    "\n",
    "#         early_stopping(vloss, model)\n",
    "#         if early_stopping.early_stop:\n",
    "#             print('Epoch : {} - Ealry Stopping'.format(epoch))\n",
    "#             break\n",
    "#     model.load_state_dict(torch.load(save_path))\n",
    "    return best_acc, best_epoch, best_z, best_result\n",
    "\n",
    "# def uniform_drop_features(features, edges, p: float, threshold: float = 0.7):\n",
    "    \n",
    "#     drop_mask = torch.bernoulli(torch.rand(features.shape[-1])).to(torch.bool)\n",
    "    \n",
    "#     features_view = features.clone()\n",
    "#     features_view[:,drop_mask] = 0.\n",
    "\n",
    "#     return features_view\n",
    "\n",
    "def uniform_drop_features(features, probs):\n",
    "    drop_mask = torch.bernoulli(probs).to(torch.bool)\n",
    "    \n",
    "    return features.where(drop_mask == True, torch.zeros_like(features))\n",
    "\n",
    "def uniform_drop_edges(edge_weights, probs, im):\n",
    "    drop_mask = torch.bernoulli(probs)\n",
    "    drop_mask = drop_mask+drop_mask.T+im\n",
    "    \n",
    "    return edge_weights.where(drop_mask.to(torch.bool) == True, torch.zeros_like(edge_weights))\n",
    "\n",
    "def train(feature, label, train_identifier, test_identifier, model, optimizer, epochs):\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        result, graph = model(feature)\n",
    "        train_pred = result[train_identifier]\n",
    "        train_y = label[train_identifier]\n",
    "        loss = criterion(train_pred, train_y) \n",
    "        acc = accuracy(train_pred, train_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        test_pred = result[test_identifier]\n",
    "        test_y = label[test_identifier]\n",
    "        test_loss = criterion(test_pred, test_y)\n",
    "        test_acc = accuracy(test_pred, test_y)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch {} - Train Acc : {}    Train Loss : {},    Test Acc : {}    Test Loss : {}\".format(epoch, round(acc.item(), 2), round(loss.item(),2), round(test_acc.item(),2), round(test_loss.item(),2)))\n",
    "\n",
    "    return round(test_acc.item(), 2), graph\n",
    "\n",
    "def encoder_train(feature, adj, label, train_identifier, test_identifier, model, optimizer, epochs):\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        result = model(feature,adj)\n",
    "        graph = model.projection(result)\n",
    "        result = model.classification(graph)\n",
    "        train_pred = result[train_identifier] \n",
    "        train_y = label[train_identifier]\n",
    "        loss = criterion(train_pred, train_y)\n",
    "        acc = accuracy(train_pred, train_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        test_pred = result[test_identifier]\n",
    "        test_y = label[test_identifier]\n",
    "        test_loss = criterion(test_pred, test_y)\n",
    "        test_acc = accuracy(test_pred, test_y)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch {} - Train Acc : {}    Train Loss : {},    Test Acc : {}    Test Loss : {}\".format(epoch, round(acc.item(), 2), round(loss.item(),2), round(test_acc.item(),2), round(test_loss.item(),2)))\n",
    "\n",
    "    return round(test_acc.item(), 2), graph\n",
    "\n",
    "class compare_model(nn.Module):\n",
    "    def __init__(self, args, in_channels, adj):\n",
    "        super(compare_model, self).__init__()\n",
    "        torch.random.manual_seed(args.seed)\n",
    "        self.l2_lambda = args.l2_lambda\n",
    "        self.in_channels = in_channels\n",
    "        self.gcn_hid_channels = args.gcn_hid_channels\n",
    "        self.gcn_out_channels = args.gcn_out_channels\n",
    "        self.fc_in_channels = args.gcn_out_channels+self.gcn_hid_channels\n",
    "        self.out_channels = args.out_channels\n",
    "        self.edges = adj\n",
    "        self.activation = nn.CELU()\n",
    "\n",
    "        self.norm1d = nn.BatchNorm1d(self.in_channels)\n",
    "        self.gcnlayer1 = GraphConvolution(self.in_channels, self.gcn_hid_channels,\n",
    "                             bias = True)\n",
    "        self.gcnlayer2 = GraphConvolution(self.gcn_hid_channels, self.gcn_out_channels,\n",
    "                             bias = True)\n",
    "\n",
    "        \n",
    "        self.fclayer = nn.Linear(self.fc_in_channels, self.out_channels)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.norm1d(x)\n",
    "        gcn_out1 = self.activation(self.gcnlayer1(x,self.edges))\n",
    "        gcn_out2 = self.activation(self.gcnlayer2(gcn_out1, self.edges))\n",
    "        gcn_out = torch.cat((gcn_out1, gcn_out2), axis = 1)\n",
    "#         out = self.fclayer(gcn_out2)\n",
    "        out = self.fclayer(gcn_out)\n",
    "        return out, gcn_out\n",
    "\n",
    "    def set_lambda(self, l2_lambda):\n",
    "        self.l2_lambda = l2_lamda\n",
    "        \n",
    "    def l2_regularization(self):\n",
    "#         gcn_layers = self.gcnlayers.children()\n",
    "#         gcn_layers = next(iter(gcn_layers)) # Allow parameters to be extracted iteratively\n",
    "        loss = None\n",
    "        \n",
    "        for p in self.gcnlayer1.parameters():\n",
    "            if loss is None:\n",
    "                loss = p.pow(2).sum()\n",
    "            else:\n",
    "                loss += p.pow(2).sum()\n",
    "                \n",
    "        for p in self.gcnlayer2.parameters():\n",
    "            loss += p.pow(2).sum()\n",
    "                \n",
    "#         fc_layers = self.fclayers.children()\n",
    "#         fc_layers = next(iter(fc_layers)) \n",
    "        \n",
    "        for p in self.fclayer.parameters():\n",
    "            loss += p.pow(2).sum()\n",
    " \n",
    "        return loss * self.l2_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95df9e",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3ff1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_np(dir_path, file_name, np_data):\n",
    "    if os.path.exists(dir_path):\n",
    "        print(\"directory already exists\")\n",
    "    else:\n",
    "        os.mkdir(dir_path)\n",
    "    np.save(dir_path+'/'+file_name, np_data)\n",
    "    print(\"{} is saved successfully\".format(file_name))\n",
    "    return\n",
    "\n",
    "def load_subject_data(dir_path, isdeap=False):\n",
    "    de = np.load(args.tensor_save_path+ 'subject_de.npy')\n",
    "    psd = np.load(args.tensor_save_path+ 'subject_psd.npy')\n",
    "    label = np.load(args.tensor_save_path+ 'subject_label.npy')\n",
    "    sample_counts = None\n",
    "    \n",
    "    if isdeap == False:\n",
    "        sample_counts = np.load(args.tensor_save_path+ 'subject_sample_counts.npy')\n",
    "        \n",
    "    return de, psd, label, sample_counts\n",
    "\n",
    "def save_pca_figure(explained_variance_ratio_, n_component, feature_name, sub_idx, date, savepath = None):\n",
    "    xlabel = []\n",
    "    Ratio = explained_variance_ratio_ * 100\n",
    "    cumulative_Ratio = np.cumsum(Ratio)\n",
    "    Ratio = np.append(Ratio, 100 - cumulative_Ratio[-1])\n",
    "    cumulative_Ratio = np.append(cumulative_Ratio, 100.0)\n",
    "\n",
    "    for i in range(1, n_component+1):\n",
    "        xlabel.append(str(i))\n",
    "    xlabel.append('(' + str(n_component+1) +'~ 310)')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.bar(xlabel, Ratio, color ='blue')\n",
    "    plt.plot(xlabel, cumulative_Ratio, visible=True, marker = '*', linestyle = '-', color = 'red')\n",
    "    plt.title(\"PCA results of {} feature samples\".format(feature_name))\n",
    "    plt.xlabel(\"N_components\")\n",
    "    plt.ylabel(\"Explaned variance ratio (%)\")\n",
    "    plt.xticks(range(n_component+1), xlabel, fontsize=5)\n",
    "    plt.yticks(np.arange(0,101,20))\n",
    "    plt.ylim([0,101])\n",
    "    for i in range(n_component+1):\n",
    "        height = cumulative_Ratio[i]\n",
    "        if i > 0:\n",
    "            plt.text(xlabel[i], height - 8, '%.1f' %height, ha='center', va='bottom', size = 8)\n",
    "        height2 = Ratio[i]\n",
    "        plt.text(xlabel[i], height2, '%.1f' %height2, ha='center', va='bottom', size = 8, color = 'black')\n",
    "\n",
    "    plt.legend(['CDF', 'PDF'])\n",
    "    # plt.show()\n",
    "    if savepath != None:\n",
    "        os.chdir(savepath)\n",
    "    plt.savefig('./store/figure/pca_result/'+sub_idx+'/'+feature_name+'/'+feature_name+'_'+date+'.png', dpi=250, facecolor='#eeeeee')\n",
    "    \n",
    "    return\n",
    "\n",
    "    \n",
    "def save_heatmap(matrix, title, xlabel, ylabel, save_path,clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight'):\n",
    "    plt.clf()\n",
    "    plt.matshow(matrix)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.colorbar()\n",
    "    if clim_min != None and clim_max != None:\n",
    "        plt.clim(clim_min, clim_max)\n",
    "    plt.savefig(save_path, dpi = _dpi, facecolor=_facecolor, bbox_inches = _bbox_inches)\n",
    "    \n",
    "    return\n",
    "\n",
    "def save_pca_heatmap(feature, sample_counts, feature_name, n_sessions, n_trials, sub_idx, date, _save_path):\n",
    "    label_list = [1,0,-1,-1,0,1,-1,0,1,1,0,-1,0,1,-1]\n",
    "    s = 0\n",
    "    e = 0\n",
    "    idx = 0\n",
    "\n",
    "    pca_min = feature.min()\n",
    "    pca_max = feature.max()\n",
    "    for i in range(n_sessions):\n",
    "        for j in range(n_trials):\n",
    "            idx = n_trials*i + j\n",
    "            e += sample_counts[idx]\n",
    "            if label_list[j] == 1:\n",
    "                save_path = _save_path+'heatmap/'+sub_idx+'/'+feature_name+'/positive/'+ feature_name+'_positive_idx'+str(idx)+'_'+ date +'.png'\n",
    "                save_heatmap(de_pca[s:e], title = 'PCA_results - '+feature_name+'_positive', xlabel = \"feature dimension\",\n",
    "                        ylabel = \"sample counts\", clim_min = pca_min, clim_max = pca_max, save_path = save_path)\n",
    "            elif label_list[j] == 0:\n",
    "                save_path = _save_path+'heatmap/'+sub_idx+'/'+feature_name+'/neutral/'+ feature_name+'_neutral_idx'+str(idx)+'_'+date +'.png'\n",
    "                save_heatmap(de_pca[s:e], title = 'PCA_results - '+feature_name+'_netural', xlabel = \"feature dimension\",\n",
    "                        ylabel = \"sample counts\", clim_min = pca_min, clim_max = pca_max, save_path = save_path)\n",
    "            elif label_list[j] == -1:\n",
    "                save_path = _save_path+'heatmap/'+sub_idx+'/'+feature_name+'/negative/'+ feature_name+'_negative_idx'+str(idx)+'_'+date +'.png'\n",
    "                save_heatmap(de_pca[s:e], title = 'PCA_results - '+feature_name+'_negative', xlabel = \"feature dimension\",\n",
    "                        ylabel = \"sample counts\", clim_min = pca_min, clim_max = pca_max, save_path = save_path)\n",
    "            else:\n",
    "                print(\"Error - Invalid label number : \", label_list[j])\n",
    "\n",
    "            s = e\n",
    "    return\n",
    "\n",
    "\n",
    "def save_scatter(result, label, best_acc,sub_idx, date, save_path, dr_type, iden):\n",
    "\n",
    "    negw = np.where(label.cpu()==0)[0]\n",
    "    neuw = np.where(label.cpu()==1)[0]\n",
    "    posw = np.where(label.cpu()==2)[0]\n",
    "    if dr_type == 0:\n",
    "        dr_name = 'PCA'\n",
    "    elif dr_type == 1:\n",
    "        dr_name = 'TSNE'\n",
    "    else:\n",
    "        dr_name = ''\n",
    "    neg = result[negw]\n",
    "    neu = result[neuw]\n",
    "    pos = result[posw]\n",
    "\n",
    "    gts = np.where(iden.cpu().numpy() ==True)[0]\n",
    "\n",
    "    neggtw,neugtw,posgtw = [], [], []\n",
    "    \n",
    "    for i in gts:\n",
    "        if i in negw:\n",
    "            neggtw.append(i)\n",
    "        elif i in neuw:\n",
    "            neugtw.append(i)\n",
    "        elif i in posw:\n",
    "            posgtw.append(i)\n",
    "\n",
    "    neggt = result[ngtw,:]\n",
    "    neugt = result[sgtw,:]\n",
    "    posgt = result[fgtw,:]\n",
    "    \n",
    "    plt.clf()\n",
    "    c1 = plt.scatter(neg[:,0], neg[:,1], marker = \"o\", color='#FF6600',s=1.)\n",
    "    gt1 = plt.scatter(neggt[:,0], neggt[:,1], marker = \"x\", color='red',s=2.)\n",
    "    c2 = plt.scatter(neu[:,0], neu[:,1], marker = \"o\",color ='#CCFF66', s=1.)\n",
    "    gt2 = plt.scatter(neugt[:,0], neugt[:,1], marker = \"x\", color='green',s=2.)\n",
    "    c3 = plt.scatter(pos[:,0], pos[:,1], marker = \"o\",color ='#33CCFF', s=1.)\n",
    "    gt3 = plt.scatter(posgt[:,0], posgt[:,1], marker = \"x\", color='blue',s=2.)\n",
    "    \n",
    "    plt.title('Classfication result of '+sub_idx + ' - Acc : '+ str(best_acc) +'%')\n",
    "    plt.xlabel(\"Reduced axis - 1\")\n",
    "    plt.ylabel(\"Reduced axis - 2\")\n",
    "    plt.legend(handles = (c1,c2,c3, gt1,gt2,gt3),labels=(\"negative\",\"neutral\", \"positive\", \"negative-gt\", \"neutral-gt\", \"positive-gt\"))\n",
    "    plt.savefig(save_path+'test_result/'+sub_idx+'/'+dr_name+'_classification_result_scatter_'+date+'.png', dpi=300, facecolor = \"#eeeeee\", bbox_inches = 'tight')\n",
    "    return\n",
    "\n",
    "\n",
    "def save_scatter_seedIV(result, label, best_acc,sub_idx, date, save_path, dr_type, iden):\n",
    "    nw = np.where(label.cpu()==0)[0]\n",
    "    sw = np.where(label.cpu()==1)[0]\n",
    "    fw = np.where(label.cpu()==2)[0]\n",
    "    hw = np.where(label.cpu()==3)[0]\n",
    "    if dr_type == 0:\n",
    "        dr_name = 'PCA'\n",
    "    elif dr_type == 1:\n",
    "        dr_name = 'TSNE'\n",
    "    else:\n",
    "        dr_name = ''\n",
    "    \n",
    "    n = result[nw,:]\n",
    "    s = result[sw,:]\n",
    "    f = result[fw,:]\n",
    "    h = result[hw,:]\n",
    "\n",
    "    gts = np.where(iden.cpu().numpy() ==True)[0]\n",
    "\n",
    "    ngtw, sgtw, fgtw, hgtw = [], [], [], []\n",
    "    for i in gts:\n",
    "        if i in nw:\n",
    "            ngtw.append(i)\n",
    "        elif i in sw:\n",
    "            sgtw.append(i)\n",
    "        elif i in fw:\n",
    "            fgtw.append(i)\n",
    "        else:\n",
    "            hgtw.append(i)\n",
    "\n",
    "    ngt = result[ngtw,:]\n",
    "    sgt = result[sgtw,:]\n",
    "    fgt = result[fgtw,:]\n",
    "    hgt = result[hgtw,:]\n",
    "    \n",
    "    plt.clf()\n",
    "    c1 = plt.scatter(n[:,0], n[:,1], marker = \"o\", color='#999999',s=1.)\n",
    "    gt1 = plt.scatter(ngt[:,0], ngt[:,1], marker = \"x\", color='black',s=2.)\n",
    "    c2 = plt.scatter(s[:,0], s[:,1], marker = \"o\",color ='#CCFF66', s=1.)\n",
    "    gt2 = plt.scatter(sgt[:,0], sgt[:,1], marker = \"x\", color='green',s=2.)\n",
    "    c3 = plt.scatter(f[:,0], f[:,1], marker = \"o\",color ='#FF6600', s=1.)\n",
    "    gt3 = plt.scatter(fgt[:,0], fgt[:,1], marker = \"x\", color='red',s=2.)\n",
    "    c4 =plt.scatter(h[:,0], h[:,1], marker = \"o\",color ='#33CCFF', s=1.)\n",
    "    gt4 = plt.scatter(hgt[:,0], hgt[:,1], marker = \"x\", color='blue',s=2.)\n",
    "    plt.title('Classfication result of '+sub_idx + ' - Acc : '+ str(best_acc) +'%')\n",
    "    plt.xlabel(\"Reduced axis - 1\")\n",
    "    plt.ylabel(\"Reduced axis - 2\")\n",
    "    plt.legend(handles = (c1,c2,c3,c4, gt1,gt2,gt3,gt4),labels=(\"neutral\",\"sad\", \"fear\", \"happy\", \"neutral - gt\",\"sad - gt\", \"fear - gt\", \"happy - gt\"))\n",
    "    plt.savefig(save_path+'test_result/'+sub_idx+'/'+dr_name+'_classification_result_scatter_'+date+'.png', dpi=300, facecolor = \"#eeeeee\", bbox_inches = 'tight')\n",
    "    return\n",
    "\n",
    "def save_scatter_deap(result, label, best_acc,sub_idx, date, save_path, dr_type, iden, cf_type, fig_name):\n",
    "    if dr_type == 0:\n",
    "        dr_name = 'PCA'\n",
    "    elif dr_type == 1:\n",
    "        dr_name = 'TSNE'\n",
    "    else:\n",
    "        dr_name = ''\n",
    "    \n",
    "    lw = np.where(label.cpu()==0)[0]\n",
    "    hw = np.where(label.cpu()==1)[0]\n",
    "    l = result[lw,:]\n",
    "    h = result[hw,:]\n",
    "\n",
    "    gts = np.where(iden.cpu().numpy() ==True)[0]\n",
    "\n",
    "    lgtw, hgtw = [], []\n",
    "    \n",
    "    for i in gts:\n",
    "        if i in lw:\n",
    "            lgtw.append(i)\n",
    "        else:\n",
    "            hgtw.append(i)\n",
    "\n",
    "    lgt = result[lgtw,:]\n",
    "    hgt = result[hgtw,:]\n",
    "    \n",
    "    plt.clf()\n",
    "    c1 = plt.scatter(l[:,0], l[:,1], marker = \"o\",color ='#FF6600', s=1.)\n",
    "    gt1 = plt.scatter(lgt[:,0], lgt[:,1], marker = \"x\", color='red',s=2.)\n",
    "    c2 =plt.scatter(h[:,0], h[:,1], marker = \"o\",color ='#33CCFF', s=1.)\n",
    "    gt2 = plt.scatter(hgt[:,0], hgt[:,1], marker = \"x\", color='blue',s=2.)\n",
    "    plt.title('Classfication result of '+sub_idx + ' - Acc : '+ str(best_acc) +'%')\n",
    "    plt.xlabel(\"Reduced axis - 1\")\n",
    "    plt.ylabel(\"Reduced axis - 2\")\n",
    "    plt.legend(handles = (c1,c2, gt1,gt2),labels=(\"Low \" + cf_type, \"High \"+cf_type, \"Low \" + cf_type + \" - gt\", \"High \"+cf_type +\" - gt\"))\n",
    "    plt.savefig(save_path+'test_result/'+sub_idx+'/'+fig_name +'_'+ dr_name+'_classification_result_scatter_'+date+'.png', dpi=300, facecolor = \"#eeeeee\", bbox_inches = 'tight')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ebf308",
   "metadata": {},
   "source": [
    "# verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c42867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbors_verification(data,label,length,data_name):\n",
    "    pos = np.where(label==2)[0]\n",
    "    neu = np.where(label==1)[0]\n",
    "    neg = np.where(label==0)[0]\n",
    "    pos_data, neu_data, neg_data = None, None, None\n",
    "    if data.shape[1] != data.shape[0]:\n",
    "        pos_data = data[pos[0]]\n",
    "        neu_data = data[neg[0]]\n",
    "        neg_data = data[neg[0]]\n",
    "    else:\n",
    "        pos_data = np.where(data[pos[0]] !=0)\n",
    "        neu_data = np.where(data[neu[0]] !=0)\n",
    "        neg_data = np.where(data[neg[0]] !=0)\n",
    "    \n",
    "    cnt = 0\n",
    "        \n",
    "    for i in range(length):\n",
    "        if pos_data[i]in pos:\n",
    "            cnt+=1\n",
    "    print(\"The number of neighbors around a sample of {} in a class 'positive': {}\".format(data_name, cnt))\n",
    "    for i in range(length):\n",
    "        if neu_data[i]in neu:\n",
    "            cnt+=1\n",
    "    print(\"The number of neighbors around a sample of {} in a class 'neutral': {}\".format(data_name, cnt))\n",
    "    for i in range(length):\n",
    "        if neg_data[i]in neg:\n",
    "            cnt+=1\n",
    "    print(\"The number of neighbors around a sample of {} in a class 'negative': {}\".format(data_name, cnt))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ef005",
   "metadata": {},
   "source": [
    "# DEAP (label: 60,90,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b52467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bus_id': 'PCI_BUS_ID',\n",
       " 'cuda_id': ['0', '1', '2'],\n",
       " 'os_path': '/home/user/users/dhkim/eer/SSLGCN',\n",
       " 'feature_name1': 'DE_LDS_data',\n",
       " 'feature_name2': 'PSD_LDS_data',\n",
       " 'deap_label_dir_path': 'dataset/deap/data_preprocessed_matlab/',\n",
       " 'deap_data_dir_path': 'dataset/deap/extractedfeatures/de_psd_lds/',\n",
       " 'figure_save_path': 'store_deap/figure/',\n",
       " 'tensor_save_path': 'store_deap/tensor/',\n",
       " 'model_save_path': 'store_deap/model/',\n",
       " 'valence': 'Valence',\n",
       " 'arousal': 'Arousal',\n",
       " 'n_subjects': 32,\n",
       " 'n_trials': 40,\n",
       " 'n_nodes': 32,\n",
       " 'n_features': 4,\n",
       " 'n_samples': 2520,\n",
       " 'n_labels_by_class1': 60,\n",
       " 'n_labels_by_class2': 90,\n",
       " 'n_labels_by_class3': 120,\n",
       " 'n_labels': 2,\n",
       " 'seed': 2023,\n",
       " 'EEG_band': None,\n",
       " 'pca_components1': 9,\n",
       " 'pca_components2': 6,\n",
       " 'essm_lambda': 0.9,\n",
       " 'de_k': 1200,\n",
       " 'psd_k': 1200,\n",
       " 'k1': 30,\n",
       " 'k2': 130,\n",
       " 't1': 1,\n",
       " 't2': 1,\n",
       " 'feature_dimension': 256,\n",
       " 'gcn_hid_channels': 128,\n",
       " 'gcn_out_channels': 64,\n",
       " 'out_channels': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'l2_lambda': 0.001,\n",
       " 'epochs': 3000,\n",
       " 'proj_hid_channels': 16,\n",
       " 'ptau': 0.7,\n",
       " 'pf1': 0.1,\n",
       " 'pf2': 0.2,\n",
       " 'pe1': 0.1,\n",
       " 'pe2': 0.2,\n",
       " 'tpf1': 0.7,\n",
       " 'tpf2': 0.7,\n",
       " 'tpe1': 0.7,\n",
       " 'tpe2': 0.7,\n",
       " 'loss_lambda': 0.01,\n",
       " 'patience': 10,\n",
       " 'val_split': 0.2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = get_deap_args()\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48c337",
   "metadata": {},
   "source": [
    "# Main result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5b6943f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 1\n",
      "Count of using GPUs: 1\n",
      "========================================== DEAP Protocol 120 ==========================================\n",
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2979 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 98.33 ***\n",
      "*** Best ACC : 96.54 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 2 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2982 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 96.1 ***\n",
      "*** Best ACC : 96.93 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 3 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (2016,),    high arousal : (504,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2780 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 99.69 ***\n",
      "*** Best ACC : 99.12 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 4 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1512,),    high valence : (1008,)\n",
      "low arousal : (1512,),    high arousal : (1008,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2895 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 94.61 ***\n",
      "*** Best ACC : 94.91 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 5 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1323,),    high arousal : (1197,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2920 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 98.99 ***\n",
      "*** Best ACC : 95.7 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 6 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2725 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 96.1 ***\n",
      "*** Best ACC : 95.26 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 7 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (756,),    high valence : (1764,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2715 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 96.36 ***\n",
      "*** Best ACC : 98.2 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 8 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.5134 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 97.24 ***\n",
      "*** Best ACC : 95.7 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 9 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2886 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 97.06 ***\n",
      "*** Best ACC : 98.07 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 10 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1134,),    high arousal : (1386,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2967 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 96.45 ***\n",
      "*** Best ACC : 97.32 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 11 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1575,),    high arousal : (945,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2856 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 93.29 ***\n",
      "*** Best ACC : 97.94 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 12 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2964 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 96.89 ***\n",
      "*** Best ACC : 98.68 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 13 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1386,),    high valence : (1134,)\n",
      "low arousal : (378,),    high arousal : (2142,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2917 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 98.51 ***\n",
      "*** Best ACC : 99.3 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 14 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2836 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 97.72 ***\n",
      "*** Best ACC : 98.51 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 15 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1197,),    high arousal : (1323,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2809 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 98.16 ***\n",
      "*** Best ACC : 97.59 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 16 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1575,),    high valence : (945,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2841 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 94.34 ***\n",
      "*** Best ACC : 98.25 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 17 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2840 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 95.83 ***\n",
      "*** Best ACC : 96.4 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 18 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2798 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 95.31 ***\n",
      "*** Best ACC : 96.89 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 19 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5541 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 98.86 ***\n",
      "*** Best ACC : 97.94 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 20 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (567,),    high arousal : (1953,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2714 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 98.6 ***\n",
      "*** Best ACC : 98.9 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 21 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (504,),    high arousal : (2016,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2730 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 96.4 ***\n",
      "*** Best ACC : 97.68 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 22 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2711 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 94.91 ***\n",
      "*** Best ACC : 91.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 23 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1701,),    high arousal : (819,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2707 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 96.49 ***\n",
      "*** Best ACC : 98.42 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 24 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2799 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 98.46 ***\n",
      "*** Best ACC : 93.99 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 25 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (630,),    high arousal : (1890,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3076 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 95.31 ***\n",
      "*** Best ACC : 97.5 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 26 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2885 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 96.01 ***\n",
      "*** Best ACC : 96.93 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 27 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2923 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 98.95 ***\n",
      "*** Best ACC : 98.46 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 28 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2932 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 94.91 ***\n",
      "*** Best ACC : 96.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 29 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2921 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 97.81 ***\n",
      "*** Best ACC : 96.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 30 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.4410 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 96.23 ***\n",
      "*** Best ACC : 96.84 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 31 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2718 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 97.54 ***\n",
      "*** Best ACC : 98.03 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 32 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (756,),    high arousal : (1764,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2664 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 98.64 ***\n",
      "*** Best ACC : 97.81 ***\n",
      "\n",
      "**************** Valence *********************\n",
      "** Best ACC : [98.33, 96.1, 99.69, 94.61, 98.99, 96.1, 96.36, 97.24, 97.06, 96.45, 93.29, 96.89, 98.51, 97.72, 98.16, 94.34, 95.83, 95.31, 98.86, 98.6, 96.4, 94.91, 96.49, 98.46, 95.31, 96.01, 98.95, 94.91, 97.81, 96.23, 97.54, 98.64] **\n",
      " ** Avearge acc : 96.878125,    std : 1.5731386570722228 **\n",
      "\n",
      "\n",
      " Best Epochs : [2224, 1260, 2674, 1606, 2086, 733, 1890, 2429, 106, 1224, 1559, 2459, 2204, 1561, 1589, 1514, 2657, 1761, 2418, 144, 844, 2004, 251, 630, 1169, 935, 2981, 1634, 140, 2306, 1122, 438]\n",
      "**************** Arousal *********************\n",
      "** Best ACC : [96.54, 96.93, 99.12, 94.91, 95.7, 95.26, 98.2, 95.7, 98.07, 97.32, 97.94, 98.68, 99.3, 98.51, 97.59, 98.25, 96.4, 96.89, 97.94, 98.9, 97.68, 91.62, 98.42, 93.99, 97.5, 96.93, 98.46, 96.62, 96.75, 96.84, 98.03, 97.81] **\n",
      " ** Avearge acc : 97.15,    std : 1.5843531803231246 **\n",
      "\n",
      "\n",
      " Best Epochs : [142, 356, 2726, 1789, 483, 1567, 2417, 2118, 490, 2553, 2668, 2142, 228, 2520, 433, 2251, 1424, 149, 1561, 941, 241, 1414, 2008, 605, 760, 2370, 2583, 887, 2596, 2629, 1100, 2280]\n",
      "directory already exists\n",
      "protocol_120_vlc_best_acc_list_231016 is saved successfully\n",
      "directory already exists\n",
      "protocol_120_ars_best_acc_list_231016 is saved successfully\n",
      "========================================== DEAP Protocol 60 ==========================================\n",
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2704 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 92.63 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 88.75 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 2 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2711 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 90.96 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 88.67 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 3 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (2016,),    high arousal : (504,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2693 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 95.38 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 89.88 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 4 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1512,),    high valence : (1008,)\n",
      "low arousal : (1512,),    high arousal : (1008,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2827 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 90.08 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 87.33 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 5 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1323,),    high arousal : (1197,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2750 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 94.0 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 86.62 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 6 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2820 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 87.25 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 84.92 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 7 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (756,),    high valence : (1764,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2932 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 91.33 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 88.33 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 8 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2866 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 87.25 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 93.12 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 9 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.5599 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 91.5 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 92.58 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 10 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1134,),    high arousal : (1386,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2967 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 88.96 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 83.96 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 11 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1575,),    high arousal : (945,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2779 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 86.75 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 94.12 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 12 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2764 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 92.67 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 94.33 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 13 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1386,),    high valence : (1134,)\n",
      "low arousal : (378,),    high arousal : (2142,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2778 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 87.88 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 97.58 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 14 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2781 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 87.38 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 91.58 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 15 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1197,),    high arousal : (1323,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3042 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 93.25 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 95.75 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 16 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1575,),    high valence : (945,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2903 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 89.71 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 91.0 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 17 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2861 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 92.08 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 87.58 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 18 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2847 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 93.29 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 89.62 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 19 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2878 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 93.5 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 94.67 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 20 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (567,),    high arousal : (1953,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2895 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 94.88 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 94.38 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 21 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (504,),    high arousal : (2016,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2874 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 91.38 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 95.04 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 22 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2892 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 85.08 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 82.5 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 23 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1701,),    high arousal : (819,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2861 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 94.5 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 95.38 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 24 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2841 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 93.62 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 94.21 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 25 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (630,),    high arousal : (1890,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2877 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 87.67 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 94.08 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 26 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2842 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 89.08 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 90.58 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 27 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2958 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 92.88 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 91.08 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 28 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2940 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 90.33 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 86.33 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 29 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2883 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 90.96 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 93.08 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 30 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2940 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 91.12 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 91.92 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 31 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3042 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 93.5 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 90.92 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "\n",
      "******************* SUBJECT : 32 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (756,),    high arousal : (1764,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2941 sec\n",
      "Done\n",
      "**********************************************\n",
      "*** Best ACC : 92.29 ***\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL is saved successfully\n",
      "*** Best ACC : 92.33 ***\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL is saved successfully\n",
      "\n",
      "**************** Valence *********************\n",
      "** Best ACC : [92.63, 90.96, 95.38, 90.08, 94.0, 87.25, 91.33, 87.25, 91.5, 88.96, 86.75, 92.67, 87.88, 87.38, 93.25, 89.71, 92.08, 93.29, 93.5, 94.88, 91.38, 85.08, 94.5, 93.62, 87.67, 89.08, 92.88, 90.33, 90.96, 91.12, 93.5, 92.29] **\n",
      " ** Avearge acc : 91.035625,    std : 2.64232253129231 **\n",
      "\n",
      "\n",
      " Best Epochs : [2348, 2485, 1348, 1418, 460, 2785, 2400, 1336, 1115, 650, 2223, 906, 392, 2915, 2674, 2873, 536, 58, 1787, 451, 662, 217, 622, 2145, 123, 308, 335, 1403, 1335, 334, 1940, 342]\n",
      "**************** Arousal *********************\n",
      "** Best ACC : [88.75, 88.67, 89.88, 87.33, 86.62, 84.92, 88.33, 93.12, 92.58, 83.96, 94.12, 94.33, 97.58, 91.58, 95.75, 91.0, 87.58, 89.62, 94.67, 94.38, 95.04, 82.5, 95.38, 94.21, 94.08, 90.58, 91.08, 86.33, 93.08, 91.92, 90.92, 92.33] **\n",
      " ** Avearge acc : 91.006875,    std : 3.6530992300203127 **\n",
      "\n",
      "\n",
      " Best Epochs : [1628, 1902, 52, 542, 2978, 1297, 276, 309, 2497, 140, 2526, 124, 262, 1401, 2959, 1072, 1094, 702, 1839, 167, 1227, 2439, 281, 212, 45, 1385, 107, 2964, 204, 1104, 1514, 145]\n",
      "directory already exists\n",
      "protocol_60_vlc_best_acc_list_231016 is saved successfully\n",
      "directory already exists\n",
      "protocol_60_ars_best_acc_list_231016 is saved successfully\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GCL_protocol_60_vlc_best_acc_list_231016 is saved successfully\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GCL_protocol_60_ars_best_acc_list_231016 is saved successfully\n"
     ]
    }
   ],
   "source": [
    "cp.cuda.Device(1).use()\n",
    "\n",
    "args = get_deap_args()\n",
    "\n",
    "device = get_device(args.bus_id, args.cuda_id[1])\n",
    "setting_os_path(args.os_path)\n",
    "fix_random_variables(args.seed)\n",
    "\n",
    "\n",
    "subject_de, subject_psd, subject_label, _ = load_subject_data(args.tensor_save_path, isdeap=True)\n",
    "\n",
    "visualization_type = 1\n",
    "\n",
    "for p in range(0,3,2):\n",
    "    if p == 0:\n",
    "        n_labels_by_class = args.n_labels_by_class3\n",
    "    elif p == 1:\n",
    "        n_labels_by_class = args.n_labels_by_class2\n",
    "    else:\n",
    "        n_labels_by_class = args.n_labels_by_class1\n",
    "\n",
    "    vlc_best_epoch = []\n",
    "    vlc_orig_acc = []\n",
    "    vlc_best_acc = []\n",
    "    ars_best_epoch = []\n",
    "    ars_orig_acc = []\n",
    "    ars_best_acc = []\n",
    "    print(\"========================================== DEAP Protocol {} ==========================================\".format(int(n_labels_by_class)))\n",
    "\n",
    "    for i in range(32):\n",
    "        print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "        sub_idx = 'sub'+str(i+1)\n",
    "        date = '231016'\n",
    "\n",
    "        sub_de = subject_de[i]\n",
    "        sub_psd = subject_psd[i]\n",
    "        sub_label = subject_label[i]\n",
    "\n",
    "        valence_label, arousal_label = deap_label(sub_label)\n",
    "\n",
    "        de, psd, vlc_identifier, ars_identifier = other_preprocessing(sub_de,sub_psd, (valence_label,arousal_label), n_labels_by_class, args.out_channels, args.seed, isdeap=True)\n",
    "\n",
    "        de = normalization(de, axis = 0, ntype='standardization')\n",
    "        psd = normalization(psd, axis = 0, ntype='standardization')\n",
    "\n",
    "        print(\"\\nDistance matrix construction start...\")\n",
    "        de_dm = distance_matrix(de)\n",
    "        psd_dm = distance_matrix(psd)\n",
    "        print(\"\\nDistance matrix construction Done...\")\n",
    "\n",
    "        de_neighbors = kneighbors(de_dm, args.n_samples, args.de_k)\n",
    "        psd_neighbors = kneighbors(psd_dm, args.n_samples, args.psd_k)\n",
    "\n",
    "        de_ssm, de_nssm = ssm_construction(de_dm,de_neighbors)\n",
    "        psd_ssm, psd_nssm = ssm_construction(psd_dm,psd_neighbors)\n",
    "\n",
    "    #         de_ssm, de_nssm = ssm_construction(de,args.n_samples, args.de_k)\n",
    "    #         psd_ssm, psd_nssm = ssm_construction(psd,args.n_samples, args.psd_k)\n",
    "#                 save_np(args.tensor_save_path+sub_idx, 'de_ssm_'+date, de_ssm)\n",
    "#                 save_np(args.tensor_save_path+sub_idx, 'psd_ssm_'+date, psd_ssm)\n",
    "#                 save_np(args.tensor_save_path+sub_idx, 'de_nssm_'+date, de_nssm)\n",
    "#                 save_np(args.tensor_save_path+sub_idx, 'psd_nssm_'+date, psd_nssm)\n",
    "#                 save_heatmap(de_ssm, \"DE SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/DE_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "#                 save_heatmap(psd_ssm, \"PSD SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/PSD_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "#                 save_heatmap(de_nssm, \"DE NSSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/DE_NSSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "#                 save_heatmap(psd_nssm, \"PSD NSSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/PSD_NSSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "\n",
    "        fsm = ssm_fusion(de_ssm,psd_ssm, de_nssm, psd_nssm, args.k1, args.t1)\n",
    "#                 save_np(args.tensor_save_path+sub_idx, 'fused_ssm_'+date, fsm)\n",
    "#                 save_heatmap(fsm, \"Fused SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/fused_ssm/Fused_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "        feature = input_feature(de, psd)\n",
    "\n",
    "#                 save_heatmap(feature, \"Feature matrix\", \"Feature dimensions\", \"Sample index\", args.figure_save_path+'heatmap/'+sub_idx+'/feature/feature_matrix_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight') \n",
    "\n",
    "        feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "        adj = torch.from_numpy(fsm).to(torch.float32).to(device)\n",
    "        ars_label = torch.from_numpy(arousal_label).to(torch.long).to(device)\n",
    "        vlc_label = torch.from_numpy(valence_label).to(torch.long).to(device)\n",
    "\n",
    "        vlc_identifier = torch.from_numpy(vlc_identifier).bool()\n",
    "        vlc_train_identifier = vlc_identifier.to(device)\n",
    "        isunlabeled = ~vlc_identifier\n",
    "        vlc_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "        ars_identifier = torch.from_numpy(ars_identifier).bool()\n",
    "        ars_train_identifier = ars_identifier.to(device)\n",
    "        isunlabeled = ~ars_identifier\n",
    "        ars_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "\n",
    "        activation = get_activation('celu')\n",
    "        gcn = GraphConvolution\n",
    "\n",
    "        encoder = Encoder(args.feature_dimension, args.gcn_hid_channels, args.gcn_out_channels, activation, args.seed, base_model = gcn).to(device)\n",
    "        model = GRACE(encoder, args.feature_dimension, args.gcn_out_channels, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = args.learning_rate)\n",
    "\n",
    "        args.pe1 = .2\n",
    "        args.pe2 = .2\n",
    "        args.pf1 = .3\n",
    "        args.pf2 = .3\n",
    "        best_acc, best_epoch, best_z, result = uniform_GCA_train(model, optimizer, feature, adj, vlc_label,\n",
    "                                                                    vlc_train_identifier, vlc_test_identifier,\n",
    "                                                                    args,device,date,sub_idx, isdeap=True, verbose=False)\n",
    "\n",
    "        print(\"*** Best ACC : {} ***\".format(round(best_acc.item(), 2)))\n",
    "        vlc_best_acc.append(round(best_acc.item(), 2))\n",
    "        vlc_orig_acc.append(best_acc.item())\n",
    "        vlc_best_epoch.append(best_epoch)\n",
    "\n",
    "#                 experiment_type = 'subject_dependent'\n",
    "#                 model_save_name = sub_idx+'_model_valence'\n",
    "#                 model_path = args.model_save_path+experiment_type+'/'+date+'/'+model_save_name\n",
    "#                 torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        sample = best_z.cpu().detach().numpy().copy()\n",
    "\n",
    "    #     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "    #     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "    #     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "    #     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "\n",
    "        if p == 2:\n",
    "            save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'vlc_DE_PSD_SNF_GCL', sample)\n",
    "    \n",
    "    \n",
    "        encoder = Encoder(args.feature_dimension, args.gcn_hid_channels, args.gcn_out_channels, activation, args.seed, base_model = gcn).to(device)\n",
    "        model = GRACE(encoder, args.feature_dimension, args.gcn_out_channels, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = args.learning_rate)\n",
    "\n",
    "        args.pe1 = .4\n",
    "        args.pe2 = .4\n",
    "        args.pf1 = .2\n",
    "        args.pf2 = .2\n",
    "        best_acc, best_epoch, best_z, result = uniform_GCA_train(model, optimizer, feature, adj, ars_label,\n",
    "                                                                            ars_train_identifier, ars_test_identifier,\n",
    "                                                                            args,device,date,sub_idx, isdeap=True, verbose=False)\n",
    "\n",
    "        print(\"*** Best ACC : {} ***\".format(round(best_acc.item(), 2)))\n",
    "        ars_best_acc.append(round(best_acc.item(), 2))\n",
    "        ars_orig_acc.append(best_acc.item())\n",
    "        ars_best_epoch.append(best_epoch)\n",
    "\n",
    "#                 experiment_type = 'subject_dependent'\n",
    "#                 model_save_name = sub_idx+'_model_arousal'\n",
    "#                 model_path = args.model_save_path+experiment_type+'/'+date+'/'+model_save_name\n",
    "#                 torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        sample = best_z.cpu().detach().numpy().copy()\n",
    "\n",
    "    #     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "    #     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "    #     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "    #     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "\n",
    "        if p == 2:\n",
    "            save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'ars_DE_PSD_SNF_GCL', sample)\n",
    "    \n",
    "    print(\"\\n**************** Valence *********************\")\n",
    "    print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(vlc_best_acc, np.mean(vlc_best_acc), np.std(vlc_best_acc)))\n",
    "    print(\"\\n Best Epochs : {}\".format(vlc_best_epoch))\n",
    "    print(\"**************** Arousal *********************\")\n",
    "    print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(ars_best_acc, np.mean(ars_best_acc), np.std(ars_best_acc)))\n",
    "    print(\"\\n Best Epochs : {}\".format(ars_best_epoch))\n",
    "\n",
    "\n",
    "    vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "    save_np(args.tensor_save_path+'main/', 'protocol_'+str(n_labels_by_class)+'_vlc_best_acc_list_'+date, vlc_best_acc_list)\n",
    "    ars_best_acc_list = np.array(ars_best_acc)\n",
    "    save_np(args.tensor_save_path+'main/', 'protocol_'+str(n_labels_by_class)+'_ars_best_acc_list_'+date, ars_best_acc_list)\n",
    "\n",
    "    if p==2:\n",
    "        save_np(args.tensor_save_path+'ablation2/vlc/', 'DE_PSD_SNF_GCL_protocol_'+str(n_labels_by_class)+'_vlc_best_acc_list_'+date, vlc_best_acc_list)\n",
    "        save_np(args.tensor_save_path+'ablation2/ars/', 'DE_PSD_SNF_GCL_protocol_'+str(n_labels_by_class)+'_ars_best_acc_list_'+date, ars_best_acc_list)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2f008",
   "metadata": {},
   "source": [
    "# Ablation study 1 - Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58333925",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_deap_args()\n",
    "\n",
    "device = get_device(args.bus_id, args.cuda_id[0])\n",
    "setting_os_path(args.os_path)\n",
    "fix_random_variables(args.seed)\n",
    "\n",
    "\n",
    "subject_de, subject_psd, subject_label, _ = load_subject_data(args.tensor_save_path, isdeap=True)\n",
    "\n",
    "visualization_type = 1\n",
    "\n",
    "for p in range(1):\n",
    "    if p == 0:\n",
    "        n_labels_by_class = args.n_labels_by_class3\n",
    "    elif p == 1:\n",
    "        n_labels_by_class = args.n_labels_by_class2\n",
    "    else:\n",
    "        n_labels_by_class = args.n_labels_by_class1\n",
    "    \n",
    "    \n",
    "    Best_EF_vlc_acc = [[0 for _ in range(9)] for _ in range(9)]\n",
    "    Best_EF_vlc_std = [[0 for _ in range(9)] for _ in range(9)]\n",
    "\n",
    "    Best_EF_ars_acc = [[0 for _ in range(9)] for _ in range(9)]\n",
    "    Best_EF_ars_std = [[0 for _ in range(9)] for _ in range(9)]\n",
    "    \n",
    "    for e in range(1,10):\n",
    "        for f in range(1,10):\n",
    "                \n",
    "            print(\"+++++++++++++++++++++++++++ Pe: {}, Pf:{} +++++++++++++++++++++++++++++++++++\".format(e/10,f/10))\n",
    "\n",
    "            args.pe1 = e/10\n",
    "            args.pe2 = e/10\n",
    "            args.pf1 = f/10\n",
    "            args.pf2 = f/10\n",
    "           \n",
    "            vlc_best_epoch = []\n",
    "            vlc_orig_acc = []\n",
    "            vlc_best_acc = []\n",
    "            ars_best_epoch = []\n",
    "            ars_orig_acc = []\n",
    "            ars_best_acc = []\n",
    "            print(\"========================================== DEAP Protocol {} ==========================================\".format(int(n_labels_by_class)))\n",
    "\n",
    "            for i in range(32):\n",
    "                print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "                sub_idx = 'sub'+str(i+1)\n",
    "                date = '231016'\n",
    "\n",
    "                sub_de = subject_de[i]\n",
    "                sub_psd = subject_psd[i]\n",
    "                sub_label = subject_label[i]\n",
    "\n",
    "                valence_label, arousal_label = deap_label(sub_label)\n",
    "\n",
    "                de, psd, vlc_identifier, ars_identifier = other_preprocessing(sub_de,sub_psd, (valence_label,arousal_label), n_labels_by_class, args.out_channels, args.seed, isdeap=True)\n",
    "\n",
    "                de = normalization(de, axis = 0, ntype='standardization')\n",
    "                psd = normalization(psd, axis = 0, ntype='standardization')\n",
    "\n",
    "                print(\"\\nDistance matrix construction start...\")\n",
    "                de_dm = distance_matrix(de)\n",
    "                psd_dm = distance_matrix(psd)\n",
    "                print(\"\\nDistance matrix construction Done...\")\n",
    "                \n",
    "                de_neighbors = kneighbors(de_dm, args.n_samples, args.de_k)\n",
    "                psd_neighbors = kneighbors(psd_dm, args.n_samples, args.psd_k)\n",
    "\n",
    "                de_ssm, de_nssm = ssm_construction(de_dm,de_neighbors)\n",
    "                psd_ssm, psd_nssm = ssm_construction(psd_dm,psd_neighbors)\n",
    "\n",
    "            #         de_ssm, de_nssm = ssm_construction(de,args.n_samples, args.de_k)\n",
    "            #         psd_ssm, psd_nssm = ssm_construction(psd,args.n_samples, args.psd_k)\n",
    "#                 save_np(args.tensor_save_path+sub_idx, 'de_ssm_'+date, de_ssm)\n",
    "#                 save_np(args.tensor_save_path+sub_idx, 'psd_ssm_'+date, psd_ssm)\n",
    "#                 save_np(args.tensor_save_path+sub_idx, 'de_nssm_'+date, de_nssm)\n",
    "#                 save_np(args.tensor_save_path+sub_idx, 'psd_nssm_'+date, psd_nssm)\n",
    "#                 save_heatmap(de_ssm, \"DE SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/DE_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "#                 save_heatmap(psd_ssm, \"PSD SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/PSD_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "#                 save_heatmap(de_nssm, \"DE NSSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/DE_NSSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "#                 save_heatmap(psd_nssm, \"PSD NSSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/PSD_NSSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "\n",
    "                fsm = ssm_fusion(de_ssm,psd_ssm, de_nssm, psd_nssm, args.k1, args.t1)\n",
    "#                 save_np(args.tensor_save_path+sub_idx, 'fused_ssm_'+date, fsm)\n",
    "#                 save_heatmap(fsm, \"Fused SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/fused_ssm/Fused_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "                feature = input_feature(de, psd)\n",
    "\n",
    "#                 save_heatmap(feature, \"Feature matrix\", \"Feature dimensions\", \"Sample index\", args.figure_save_path+'heatmap/'+sub_idx+'/feature/feature_matrix_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight') \n",
    "\n",
    "                feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "                adj = torch.from_numpy(fsm).to(torch.float32).to(device)\n",
    "                ars_label = torch.from_numpy(arousal_label).to(torch.long).to(device)\n",
    "                vlc_label = torch.from_numpy(valence_label).to(torch.long).to(device)\n",
    "\n",
    "                vlc_identifier = torch.from_numpy(vlc_identifier).bool()\n",
    "                vlc_train_identifier = vlc_identifier.to(device)\n",
    "                isunlabeled = ~vlc_identifier\n",
    "                vlc_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "                ars_identifier = torch.from_numpy(ars_identifier).bool()\n",
    "                ars_train_identifier = ars_identifier.to(device)\n",
    "                isunlabeled = ~ars_identifier\n",
    "                ars_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "\n",
    "                activation = get_activation('celu')\n",
    "                gcn = GraphConvolution\n",
    "\n",
    "                encoder = Encoder(args.feature_dimension, args.gcn_hid_channels, args.gcn_out_channels, activation, args.seed, base_model = gcn).to(device)\n",
    "                model = GRACE(encoder, args.feature_dimension, args.gcn_out_channels, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr = args.learning_rate)\n",
    "\n",
    "                best_acc, best_epoch, best_z, result = uniform_GCA_train(model, optimizer, feature, adj, vlc_label,\n",
    "                                                                            vlc_train_identifier, vlc_test_identifier,\n",
    "                                                                            args,device,date,sub_idx, isdeap=True, verbose=False)\n",
    "\n",
    "                print(\"*** Best ACC : {} ***\".format(round(best_acc.item(), 2)))\n",
    "                vlc_best_acc.append(round(best_acc.item(), 2))\n",
    "                vlc_orig_acc.append(best_acc.item())\n",
    "                vlc_best_epoch.append(best_epoch)\n",
    "\n",
    "#                 experiment_type = 'subject_dependent'\n",
    "#                 model_save_name = sub_idx+'_model_valence'\n",
    "#                 model_path = args.model_save_path+experiment_type+'/'+date+'/'+model_save_name\n",
    "#                 torch.save(model.state_dict(), model_path)\n",
    "\n",
    "\n",
    "                encoder = Encoder(args.feature_dimension, args.gcn_hid_channels, args.gcn_out_channels, activation, args.seed, base_model = gcn).to(device)\n",
    "                model = GRACE(encoder, args.feature_dimension, args.gcn_out_channels, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr = args.learning_rate)\n",
    "\n",
    "                best_acc, best_epoch, best_z, result = uniform_GCA_train(model, optimizer, feature, adj, ars_label,\n",
    "                                                                                    ars_train_identifier, ars_test_identifier,\n",
    "                                                                                    args,device,date,sub_idx, isdeap=True, verbose=False)\n",
    "\n",
    "                print(\"*** Best ACC : {} ***\".format(round(best_acc.item(), 2)))\n",
    "                ars_best_acc.append(round(best_acc.item(), 2))\n",
    "                ars_orig_acc.append(best_acc.item())\n",
    "                ars_best_epoch.append(best_epoch)\n",
    "\n",
    "#                 experiment_type = 'subject_dependent'\n",
    "#                 model_save_name = sub_idx+'_model_arousal'\n",
    "#                 model_path = args.model_save_path+experiment_type+'/'+date+'/'+model_save_name\n",
    "#                 torch.save(model.state_dict(), model_path)\n",
    "\n",
    "            print(\"\\n**************** Valence *********************\")\n",
    "            print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(vlc_best_acc, np.mean(vlc_best_acc), np.std(vlc_best_acc)))\n",
    "            print(\"\\n Best Epochs : {}\".format(vlc_best_epoch))\n",
    "            print(\"**************** Arousal *********************\")\n",
    "            print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(ars_best_acc, np.mean(ars_best_acc), np.std(ars_best_acc)))\n",
    "            print(\"\\n Best Epochs : {}\".format(ars_best_epoch))\n",
    "\n",
    "\n",
    "            vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "#             save_np(args.tensor_save_path+sub_idx, 'protocol '+str(n_labels_by_class)+'_vlc_best_acc_list_'+date, vlc_best_acc_list)\n",
    "            ars_best_acc_list = np.array(ars_best_acc)\n",
    "#             save_np(args.tensor_save_path+sub_idx, 'protocol '+str(n_labels_by_class)+'_ars_best_acc_list_'+date, ars_best_acc_list)\n",
    "\n",
    "\n",
    "            vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "#             save_np(args.tensor_save_path+sub_idx, 'protocol '+str(n_labels_by_class)+'_vlc_best_acc_list_'+date, vlc_best_acc_list)\n",
    "            ars_best_acc_list = np.array(ars_best_acc)\n",
    "#             save_np(args.tensor_save_path+sub_idx, 'protocol '+str(n_labels_by_class)+'_ars_best_acc_list_'+date, ars_best_acc_list)\n",
    "\n",
    "            Best_EF_vlc_acc[e-1][f-1] = round(np.mean(vlc_orig_acc),2)\n",
    "            Best_EF_vlc_std[e-1][f-1] = round(np.std(vlc_orig_acc),2)\n",
    "\n",
    "            Best_EF_ars_acc[e-1][f-1] = round(np.mean(ars_orig_acc),2)\n",
    "            Best_EF_ars_std[e-1][f-1] = round(np.std(ars_orig_acc),2)\n",
    "            \n",
    "            np_Best_EF_vlc_acc = np.array(Best_EF_vlc_acc)\n",
    "            save_np(args.tensor_save_path,'ablation1/'+'results_vlc_acc_'+date, np_Best_EF_vlc_acc)\n",
    "\n",
    "            np_Best_EF_vlc_std = np.array(Best_EF_vlc_std)\n",
    "            save_np(args.tensor_save_path,'ablation1/'+'results_vlc_std_'+date, np_Best_EF_vlc_std)\n",
    "\n",
    "            np_Best_EF_ars_acc = np.array(Best_EF_ars_acc)\n",
    "            save_np(args.tensor_save_path,'ablation1/'+'results_ars_acc_'+date, np_Best_EF_ars_acc)\n",
    "\n",
    "            np_Best_EF_ars_std = np.array(Best_EF_ars_std)\n",
    "            save_np(args.tensor_save_path,'ablation1/'+'results_ars_std_'+date, np_Best_EF_ars_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c728f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists\n",
      "ablation1/results_vlc_acc_231016 is saved successfully\n",
      "directory already exists\n",
      "ablation1/results_vlc_std_231016 is saved successfully\n",
      "directory already exists\n",
      "ablation1/results_ars_acc_231016 is saved successfully\n",
      "directory already exists\n",
      "ablation1/results_ars_std_231016 is saved successfully\n"
     ]
    }
   ],
   "source": [
    "np_Best_EF_vlc_acc = np.array(Best_EF_vlc_acc)\n",
    "save_np(args.tensor_save_path,'ablation1/'+'results_vlc_acc_'+date, np_Best_EF_vlc_acc)\n",
    "\n",
    "np_Best_EF_vlc_std = np.array(Best_EF_vlc_std)\n",
    "save_np(args.tensor_save_path,'ablation1/'+'results_vlc_std_'+date, np_Best_EF_vlc_std)\n",
    "\n",
    "np_Best_EF_ars_acc = np.array(Best_EF_ars_acc)\n",
    "save_np(args.tensor_save_path,'ablation1/'+'results_ars_acc_'+date, np_Best_EF_ars_acc)\n",
    "\n",
    "np_Best_EF_ars_std = np.array(Best_EF_ars_std)\n",
    "save_np(args.tensor_save_path,'ablation1/'+'results_ars_std_'+date, np_Best_EF_ars_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26f0af34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[96.55, 96.72, 96.81, 96.81, 96.81, 96.64, 96.35, 95.88, 94.43],\n",
       " [96.51, 96.6, 96.88, 96.85, 96.72, 96.54, 96.26, 95.67, 94.11],\n",
       " [96.5, 96.64, 96.8, 96.8, 96.67, 96.52, 96.1, 95.42, 93.75],\n",
       " [96.48, 96.68, 96.81, 96.71, 96.59, 96.35, 95.96, 95.2, 93.3],\n",
       " [96.6, 96.59, 96.8, 96.72, 96.48, 96.23, 95.76, 94.87, 92.7],\n",
       " [96.47, 96.58, 96.7, 96.63, 96.42, 96.04, 95.54, 94.56, 91.93],\n",
       " [96.4, 96.67, 96.61, 96.49, 96.24, 95.89, 95.22, 94.1, 91.09],\n",
       " [96.51, 96.6, 96.5, 96.4, 96.1, 95.61, 94.91, 93.61, 89.97],\n",
       " [96.43, 96.44, 96.4, 96.18, 95.82, 95.24, 94.45, 92.9, 88.56]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_EF_vlc_acc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e706da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(96.8800)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(Best_EF_vlc_acc).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_EF_vlc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16341b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[96.85, 97.02, 97.03, 97.06, 96.94, 96.67, 96.4, 95.74, 94.34],\n",
       " [96.8, 96.96, 96.94, 96.98, 96.92, 96.59, 96.26, 95.69, 93.97],\n",
       " [96.85, 97.04, 97.02, 96.95, 96.79, 96.45, 96.19, 95.35, 93.65],\n",
       " [96.86, 97.15, 97.01, 96.92, 96.83, 96.41, 96.04, 95.13, 93.19],\n",
       " [96.81, 97.04, 97.01, 96.87, 96.7, 96.24, 95.81, 94.86, 92.57],\n",
       " [96.92, 96.83, 96.93, 96.82, 96.59, 96.17, 95.5, 94.51, 91.93],\n",
       " [96.73, 96.79, 96.9, 96.73, 96.38, 95.92, 95.23, 94.06, 91.07],\n",
       " [96.66, 96.77, 96.79, 96.6, 96.19, 95.71, 95.01, 93.5, 89.96],\n",
       " [96.6, 96.67, 96.67, 96.45, 96.03, 95.38, 94.45, 92.84, 88.63]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_EF_ars_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93386c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(97.1500)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(Best_EF_ars_acc).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df45a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_EF_ars_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3ea77",
   "metadata": {},
   "source": [
    "# Ablation 2 & 3 (Method ablation and node embedding scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e69cb76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "compare_args = easydict.EasyDict({\n",
    "\n",
    "        # arguments for running algorithm\n",
    "        'seed' : 2023,\n",
    "        'EEG_band' : None,\n",
    "        'pca_components1' : 9,\n",
    "        'pca_components2' : 6,\n",
    "        'essm_lambda' : 0.9,\n",
    "        'de_k' : 1200, #721\n",
    "        'psd_k' : 1200, #1861\n",
    "        'k1' : 30,\n",
    "        'k2' : 130,\n",
    "        't1' : 1,\n",
    "        't2' : 1,\n",
    "        'gcn_hid_channels' : 64,\n",
    "        'gcn_out_channels' : 128,\n",
    "        'out_channels' : 2,\n",
    "        'learning_rate' : 0.005,\n",
    "        'l2_lambda' : 0.001,\n",
    "        'epochs' : 200\n",
    "    })\n",
    "\n",
    "cp.cuda.Device(0).use()\n",
    "\n",
    "args = get_deap_args()\n",
    "\n",
    "device = get_device(args.bus_id, args.cuda_id[0])\n",
    "setting_os_path(args.os_path)\n",
    "fix_random_variables(args.seed)\n",
    "\n",
    "subject_de, subject_psd, subject_label, _ = load_subject_data(args.tensor_save_path, isdeap=True)\n",
    "\n",
    "visualization_type = 1\n",
    "\n",
    "n_labels_by_class = args.n_labels_by_class1\n",
    "\n",
    "im = torch.eye(args.n_samples).to(device)\n",
    "\n",
    "activation = get_activation('celu')\n",
    "gcn = GraphConvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8493a",
   "metadata": {},
   "source": [
    "## Ablation 2-1 (DE+ PCA + SNF + GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bbc57663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "Explaned variance ratio by principal components : [0.38294457 0.12664908 0.08462927 0.04550889 0.03510897 0.0316\n",
      " 0.02291766 0.01886277 0.01691676] \n",
      " Overall ratio:  0.7651379787806818\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 65.0    Train Loss : 0.63,    Test Acc : 63.04    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.55,    Test Acc : 65.46    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 71.67    Train Loss : 0.51,    Test Acc : 65.79    Test Loss : 0.69\n",
      "Epoch 40 - Train Acc : 75.0    Train Loss : 0.48,    Test Acc : 66.67    Test Loss : 0.7\n",
      "Epoch 50 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 69.29    Test Loss : 0.67\n",
      "Epoch 60 - Train Acc : 83.33    Train Loss : 0.39,    Test Acc : 71.67    Test Loss : 0.68\n",
      "Epoch 70 - Train Acc : 88.33    Train Loss : 0.33,    Test Acc : 73.79    Test Loss : 0.71\n",
      "Epoch 80 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 75.75    Test Loss : 0.79\n",
      "Epoch 90 - Train Acc : 90.0    Train Loss : 0.21,    Test Acc : 76.46    Test Loss : 0.93\n",
      "Epoch 100 - Train Acc : 92.5    Train Loss : 0.17,    Test Acc : 77.42    Test Loss : 1.1\n",
      "Epoch 110 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 76.62    Test Loss : 1.37\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 76.08    Test Loss : 1.73\n",
      "Epoch 130 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 75.25    Test Loss : 2.19\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 74.79    Test Loss : 2.67\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 74.75    Test Loss : 3.1\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 75.08    Test Loss : 3.47\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 75.04    Test Loss : 3.78\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 75.08    Test Loss : 4.03\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.08    Test Loss : 4.24\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.17    Test Loss : 4.41\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 75.17 ***\n",
      "Epoch 10 - Train Acc : 80.83    Train Loss : 0.57,    Test Acc : 70.62    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.48,    Test Acc : 72.25    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.45,    Test Acc : 74.17    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.42,    Test Acc : 74.5    Test Loss : 0.61\n",
      "Epoch 50 - Train Acc : 85.0    Train Loss : 0.38,    Test Acc : 75.75    Test Loss : 0.56\n",
      "Epoch 60 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 76.67    Test Loss : 0.53\n",
      "Epoch 70 - Train Acc : 86.67    Train Loss : 0.28,    Test Acc : 77.38    Test Loss : 0.52\n",
      "Epoch 80 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 79.42    Test Loss : 0.54\n",
      "Epoch 90 - Train Acc : 95.83    Train Loss : 0.15,    Test Acc : 79.71    Test Loss : 0.6\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 79.92    Test Loss : 0.7\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 79.83    Test Loss : 0.92\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 79.71    Test Loss : 1.18\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.42    Test Loss : 1.43\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.33    Test Loss : 1.62\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.25    Test Loss : 1.77\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.25    Test Loss : 1.89\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.25    Test Loss : 1.98\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.29    Test Loss : 2.05\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.29    Test Loss : 2.12\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.29    Test Loss : 2.17\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 2 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "Explaned variance ratio by principal components : [0.66499555 0.1259352  0.04828088 0.03524043 0.01820806 0.01657125\n",
      " 0.0123173  0.01038662 0.00710544] \n",
      " Overall ratio:  0.9390407176345893\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 74.17    Train Loss : 0.59,    Test Acc : 67.25    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.54,    Test Acc : 72.83    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 75.83    Train Loss : 0.5,    Test Acc : 73.5    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 81.67    Train Loss : 0.46,    Test Acc : 76.46    Test Loss : 0.5\n",
      "Epoch 50 - Train Acc : 86.67    Train Loss : 0.39,    Test Acc : 81.46    Test Loss : 0.45\n",
      "Epoch 60 - Train Acc : 90.83    Train Loss : 0.32,    Test Acc : 85.29    Test Loss : 0.38\n",
      "Epoch 70 - Train Acc : 95.0    Train Loss : 0.24,    Test Acc : 87.67    Test Loss : 0.33\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.17,    Test Acc : 88.54    Test Loss : 0.29\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 89.58    Test Loss : 0.28\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 89.21    Test Loss : 0.32\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 89.21    Test Loss : 0.36\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.96    Test Loss : 0.4\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.58    Test Loss : 0.44\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.58    Test Loss : 0.47\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 0.49\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 0.5\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.52\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.53\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 0.54\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.55\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 88.5 ***\n",
      "Epoch 10 - Train Acc : 62.5    Train Loss : 0.62,    Test Acc : 54.29    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.58,    Test Acc : 60.04    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 71.67    Train Loss : 0.55,    Test Acc : 64.29    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 74.17    Train Loss : 0.51,    Test Acc : 66.25    Test Loss : 0.61\n",
      "Epoch 50 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 67.25    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 70.12    Test Loss : 0.53\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 75.25    Test Loss : 0.56\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.15,    Test Acc : 76.5    Test Loss : 0.69\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 77.21    Test Loss : 0.85\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 78.17    Test Loss : 1.08\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.83    Test Loss : 1.33\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.92    Test Loss : 1.56\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.88    Test Loss : 1.72\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.17    Test Loss : 1.84\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.25    Test Loss : 1.93\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.33    Test Loss : 2.0\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.42    Test Loss : 2.06\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.5    Test Loss : 2.12\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.58    Test Loss : 2.16\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.58    Test Loss : 2.2\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.58 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 3 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (2016,),    high arousal : (504,)\n",
      "Explaned variance ratio by principal components : [0.52763226 0.15814157 0.05869493 0.04236887 0.03271043 0.02357153\n",
      " 0.02058458 0.01800425 0.01179096] \n",
      " Overall ratio:  0.8934993723004274\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.59,    Test Acc : 69.42    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.49,    Test Acc : 74.62    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.45,    Test Acc : 74.46    Test Loss : 0.48\n",
      "Epoch 40 - Train Acc : 75.83    Train Loss : 0.41,    Test Acc : 76.46    Test Loss : 0.45\n",
      "Epoch 50 - Train Acc : 80.83    Train Loss : 0.38,    Test Acc : 77.12    Test Loss : 0.43\n",
      "Epoch 60 - Train Acc : 86.67    Train Loss : 0.33,    Test Acc : 78.21    Test Loss : 0.42\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.28,    Test Acc : 81.0    Test Loss : 0.42\n",
      "Epoch 80 - Train Acc : 92.5    Train Loss : 0.24,    Test Acc : 82.04    Test Loss : 0.41\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.19,    Test Acc : 82.92    Test Loss : 0.41\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.15,    Test Acc : 83.38    Test Loss : 0.41\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.11,    Test Acc : 83.75    Test Loss : 0.43\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 84.12    Test Loss : 0.49\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 84.67    Test Loss : 0.58\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.88    Test Loss : 0.68\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.54    Test Loss : 0.76\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 0.82\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 0.87\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 0.91\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 0.94\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 0.96\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 86.0 ***\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.59,    Test Acc : 63.75    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 70.83    Train Loss : 0.5,    Test Acc : 64.38    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.44,    Test Acc : 68.12    Test Loss : 0.54\n",
      "Epoch 40 - Train Acc : 79.17    Train Loss : 0.39,    Test Acc : 69.5    Test Loss : 0.54\n",
      "Epoch 50 - Train Acc : 82.5    Train Loss : 0.31,    Test Acc : 72.96    Test Loss : 0.49\n",
      "Epoch 60 - Train Acc : 90.0    Train Loss : 0.23,    Test Acc : 77.96    Test Loss : 0.46\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.16,    Test Acc : 80.0    Test Loss : 0.52\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 80.96    Test Loss : 0.65\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 80.58    Test Loss : 0.86\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 80.29    Test Loss : 1.06\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 80.42    Test Loss : 1.24\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.17    Test Loss : 1.43\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.83    Test Loss : 1.59\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.63    Test Loss : 1.71\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.63    Test Loss : 1.81\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.46    Test Loss : 1.89\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.38    Test Loss : 1.96\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.33    Test Loss : 2.02\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.33    Test Loss : 2.08\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.46    Test Loss : 2.12\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.46 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 4 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1512,),    high valence : (1008,)\n",
      "low arousal : (1512,),    high arousal : (1008,)\n",
      "Explaned variance ratio by principal components : [0.53445228 0.35509932 0.03070409 0.0215785  0.01865784 0.00847595\n",
      " 0.00508507 0.0040492  0.00361606] \n",
      " Overall ratio:  0.9817182933767559\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.55,    Test Acc : 70.12    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.47,    Test Acc : 69.25    Test Loss : 0.55\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.44,    Test Acc : 73.58    Test Loss : 0.53\n",
      "Epoch 40 - Train Acc : 80.83    Train Loss : 0.41,    Test Acc : 75.54    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.38,    Test Acc : 75.92    Test Loss : 0.49\n",
      "Epoch 60 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 76.17    Test Loss : 0.48\n",
      "Epoch 70 - Train Acc : 86.67    Train Loss : 0.32,    Test Acc : 77.04    Test Loss : 0.47\n",
      "Epoch 80 - Train Acc : 91.67    Train Loss : 0.28,    Test Acc : 77.96    Test Loss : 0.46\n",
      "Epoch 90 - Train Acc : 92.5    Train Loss : 0.24,    Test Acc : 78.25    Test Loss : 0.46\n",
      "Epoch 100 - Train Acc : 93.33    Train Loss : 0.21,    Test Acc : 78.58    Test Loss : 0.46\n",
      "Epoch 110 - Train Acc : 95.0    Train Loss : 0.18,    Test Acc : 79.54    Test Loss : 0.48\n",
      "Epoch 120 - Train Acc : 95.83    Train Loss : 0.15,    Test Acc : 80.42    Test Loss : 0.5\n",
      "Epoch 130 - Train Acc : 97.5    Train Loss : 0.13,    Test Acc : 81.42    Test Loss : 0.49\n",
      "Epoch 140 - Train Acc : 98.33    Train Loss : 0.1,    Test Acc : 82.92    Test Loss : 0.49\n",
      "Epoch 150 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 84.88    Test Loss : 0.51\n",
      "Epoch 160 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 86.0    Test Loss : 0.57\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 86.25    Test Loss : 0.67\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.29    Test Loss : 0.79\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.21    Test Loss : 0.9\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.04    Test Loss : 1.0\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 86.04 ***\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.6,    Test Acc : 69.17    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 75.83    Train Loss : 0.53,    Test Acc : 69.17    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.49,    Test Acc : 70.38    Test Loss : 0.57\n",
      "Epoch 40 - Train Acc : 77.5    Train Loss : 0.46,    Test Acc : 71.75    Test Loss : 0.56\n",
      "Epoch 50 - Train Acc : 80.83    Train Loss : 0.41,    Test Acc : 72.08    Test Loss : 0.53\n",
      "Epoch 60 - Train Acc : 83.33    Train Loss : 0.36,    Test Acc : 74.88    Test Loss : 0.5\n",
      "Epoch 70 - Train Acc : 86.67    Train Loss : 0.28,    Test Acc : 78.29    Test Loss : 0.49\n",
      "Epoch 80 - Train Acc : 90.83    Train Loss : 0.21,    Test Acc : 78.92    Test Loss : 0.5\n",
      "Epoch 90 - Train Acc : 90.83    Train Loss : 0.17,    Test Acc : 79.08    Test Loss : 0.54\n",
      "Epoch 100 - Train Acc : 94.17    Train Loss : 0.14,    Test Acc : 79.79    Test Loss : 0.6\n",
      "Epoch 110 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 79.83    Test Loss : 0.66\n",
      "Epoch 120 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 80.33    Test Loss : 0.75\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 80.58    Test Loss : 0.85\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 79.92    Test Loss : 0.96\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 80.38    Test Loss : 1.05\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.12    Test Loss : 1.14\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.25    Test Loss : 1.22\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.33    Test Loss : 1.29\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 1.36\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.75    Test Loss : 1.41\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 81.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 5 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1323,),    high arousal : (1197,)\n",
      "Explaned variance ratio by principal components : [0.4627099  0.31465133 0.05692983 0.02745092 0.02393454 0.01988661\n",
      " 0.01821302 0.01250122 0.00716879] \n",
      " Overall ratio:  0.9434461680259075\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.64,    Test Acc : 61.04    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 60.83    Train Loss : 0.6,    Test Acc : 64.25    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 69.17    Train Loss : 0.55,    Test Acc : 69.62    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.47,    Test Acc : 75.62    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.38,    Test Acc : 77.96    Test Loss : 0.44\n",
      "Epoch 60 - Train Acc : 90.0    Train Loss : 0.31,    Test Acc : 80.04    Test Loss : 0.42\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.24,    Test Acc : 81.88    Test Loss : 0.42\n",
      "Epoch 80 - Train Acc : 95.0    Train Loss : 0.18,    Test Acc : 82.33    Test Loss : 0.46\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 82.0    Test Loss : 0.52\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 81.96    Test Loss : 0.6\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 81.46    Test Loss : 0.71\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 81.46    Test Loss : 0.83\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 81.67    Test Loss : 0.93\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.67    Test Loss : 1.04\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.83    Test Loss : 1.13\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.71    Test Loss : 1.21\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.79    Test Loss : 1.26\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.96    Test Loss : 1.31\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.08    Test Loss : 1.35\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.17    Test Loss : 1.38\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 82.17 ***\n",
      "Epoch 10 - Train Acc : 60.0    Train Loss : 0.64,    Test Acc : 65.08    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 69.17    Train Loss : 0.6,    Test Acc : 67.92    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 69.17    Train Loss : 0.57,    Test Acc : 67.63    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 70.83    Train Loss : 0.54,    Test Acc : 67.79    Test Loss : 0.62\n",
      "Epoch 50 - Train Acc : 73.33    Train Loss : 0.51,    Test Acc : 70.71    Test Loss : 0.61\n",
      "Epoch 60 - Train Acc : 77.5    Train Loss : 0.47,    Test Acc : 72.71    Test Loss : 0.58\n",
      "Epoch 70 - Train Acc : 80.83    Train Loss : 0.43,    Test Acc : 74.29    Test Loss : 0.56\n",
      "Epoch 80 - Train Acc : 80.83    Train Loss : 0.38,    Test Acc : 74.83    Test Loss : 0.56\n",
      "Epoch 90 - Train Acc : 84.17    Train Loss : 0.32,    Test Acc : 76.71    Test Loss : 0.56\n",
      "Epoch 100 - Train Acc : 88.33    Train Loss : 0.26,    Test Acc : 77.67    Test Loss : 0.58\n",
      "Epoch 110 - Train Acc : 94.17    Train Loss : 0.2,    Test Acc : 78.83    Test Loss : 0.64\n",
      "Epoch 120 - Train Acc : 97.5    Train Loss : 0.14,    Test Acc : 79.67    Test Loss : 0.71\n",
      "Epoch 130 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 79.63    Test Loss : 0.85\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 79.0    Test Loss : 1.06\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 79.17    Test Loss : 1.28\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 79.21    Test Loss : 1.48\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.92    Test Loss : 1.64\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.83    Test Loss : 1.78\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.83    Test Loss : 1.88\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.88    Test Loss : 1.96\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.88 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 6 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "Explaned variance ratio by principal components : [0.48868338 0.19968501 0.10765411 0.04434801 0.01845038 0.01594614\n",
      " 0.01341688 0.01212369 0.00993146] \n",
      " Overall ratio:  0.9102390639360006\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.65,    Test Acc : 52.04    Test Loss : 0.7\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.61,    Test Acc : 58.79    Test Loss : 0.69\n",
      "Epoch 30 - Train Acc : 72.5    Train Loss : 0.58,    Test Acc : 60.79    Test Loss : 0.7\n",
      "Epoch 40 - Train Acc : 75.83    Train Loss : 0.54,    Test Acc : 62.54    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 80.0    Train Loss : 0.48,    Test Acc : 66.08    Test Loss : 0.65\n",
      "Epoch 60 - Train Acc : 84.17    Train Loss : 0.4,    Test Acc : 68.54    Test Loss : 0.62\n",
      "Epoch 70 - Train Acc : 88.33    Train Loss : 0.31,    Test Acc : 71.54    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.23,    Test Acc : 71.04    Test Loss : 0.79\n",
      "Epoch 90 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 70.79    Test Loss : 0.99\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.11,    Test Acc : 71.88    Test Loss : 1.18\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 72.12    Test Loss : 1.41\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 72.17    Test Loss : 1.65\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 72.21    Test Loss : 1.87\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 72.62    Test Loss : 2.04\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 72.79    Test Loss : 2.18\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 72.75    Test Loss : 2.28\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 72.92    Test Loss : 2.36\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 72.79    Test Loss : 2.43\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 72.79    Test Loss : 2.48\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 72.92    Test Loss : 2.53\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 72.92 ***\n",
      "Epoch 10 - Train Acc : 72.5    Train Loss : 0.6,    Test Acc : 59.79    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 72.5    Train Loss : 0.57,    Test Acc : 60.92    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 73.33    Train Loss : 0.55,    Test Acc : 60.96    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 72.5    Train Loss : 0.52,    Test Acc : 61.88    Test Loss : 0.66\n",
      "Epoch 50 - Train Acc : 76.67    Train Loss : 0.48,    Test Acc : 62.96    Test Loss : 0.66\n",
      "Epoch 60 - Train Acc : 82.5    Train Loss : 0.43,    Test Acc : 66.58    Test Loss : 0.69\n",
      "Epoch 70 - Train Acc : 86.67    Train Loss : 0.35,    Test Acc : 69.54    Test Loss : 0.74\n",
      "Epoch 80 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 73.33    Test Loss : 0.78\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.15,    Test Acc : 75.67    Test Loss : 0.93\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 76.58    Test Loss : 1.22\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 77.33    Test Loss : 1.51\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 77.67    Test Loss : 1.74\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 77.62    Test Loss : 1.98\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.0    Test Loss : 2.18\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.0    Test Loss : 2.33\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.08    Test Loss : 2.46\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.08    Test Loss : 2.56\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.17    Test Loss : 2.64\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.17    Test Loss : 2.71\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.12    Test Loss : 2.76\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.12 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 7 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (756,),    high valence : (1764,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.42837935 0.16204537 0.09392059 0.08387523 0.03721251 0.02388047\n",
      " 0.01429398 0.01282698 0.01142974] \n",
      " Overall ratio:  0.8678642068786071\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.61,    Test Acc : 65.71    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 73.33    Train Loss : 0.54,    Test Acc : 67.92    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.49,    Test Acc : 71.12    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 74.29    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.39,    Test Acc : 74.33    Test Loss : 0.53\n",
      "Epoch 60 - Train Acc : 90.83    Train Loss : 0.33,    Test Acc : 74.88    Test Loss : 0.51\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 75.58    Test Loss : 0.52\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 78.54    Test Loss : 0.55\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.13,    Test Acc : 80.42    Test Loss : 0.58\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 82.38    Test Loss : 0.57\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 83.21    Test Loss : 0.62\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 83.83    Test Loss : 0.74\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.12    Test Loss : 0.82\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 0.88\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 0.92\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 0.96\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.58    Test Loss : 0.99\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 1.02\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.05\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.07\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 84.71 ***\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.62,    Test Acc : 67.63    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 73.33    Train Loss : 0.55,    Test Acc : 69.29    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 70.83    Train Loss : 0.49,    Test Acc : 71.08    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 76.67    Train Loss : 0.42,    Test Acc : 73.21    Test Loss : 0.53\n",
      "Epoch 50 - Train Acc : 85.0    Train Loss : 0.33,    Test Acc : 75.88    Test Loss : 0.53\n",
      "Epoch 60 - Train Acc : 88.33    Train Loss : 0.25,    Test Acc : 75.92    Test Loss : 0.55\n",
      "Epoch 70 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 76.71    Test Loss : 0.57\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 76.88    Test Loss : 0.68\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.08,    Test Acc : 77.75    Test Loss : 0.84\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 77.79    Test Loss : 1.01\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 77.38    Test Loss : 1.19\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.17    Test Loss : 1.33\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.12    Test Loss : 1.48\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.33    Test Loss : 1.6\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.54    Test Loss : 1.68\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.83    Test Loss : 1.75\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.96    Test Loss : 1.81\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.96    Test Loss : 1.86\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.88    Test Loss : 1.91\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.88    Test Loss : 1.95\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.88 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 8 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "Explaned variance ratio by principal components : [0.57410235 0.18386765 0.0693744  0.03691964 0.02279853 0.02059312\n",
      " 0.01146079 0.00695547 0.00625838] \n",
      " Overall ratio:  0.9323303226321229\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.6,    Test Acc : 63.58    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 70.83    Train Loss : 0.52,    Test Acc : 67.13    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.48,    Test Acc : 68.96    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 69.88    Test Loss : 0.62\n",
      "Epoch 50 - Train Acc : 82.5    Train Loss : 0.42,    Test Acc : 72.67    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 87.5    Train Loss : 0.36,    Test Acc : 76.88    Test Loss : 0.57\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.28,    Test Acc : 79.54    Test Loss : 0.56\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.22,    Test Acc : 80.46    Test Loss : 0.58\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.16,    Test Acc : 82.0    Test Loss : 0.61\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 83.0    Test Loss : 0.62\n",
      "Epoch 110 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 83.29    Test Loss : 0.68\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 83.38    Test Loss : 0.81\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 83.04    Test Loss : 0.98\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.79    Test Loss : 1.17\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.75    Test Loss : 1.33\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.0    Test Loss : 1.46\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.92    Test Loss : 1.56\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.0    Test Loss : 1.65\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.96    Test Loss : 1.73\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.96    Test Loss : 1.79\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 82.96 ***\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.64,    Test Acc : 62.88    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 70.83    Train Loss : 0.57,    Test Acc : 65.88    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 70.0    Train Loss : 0.54,    Test Acc : 65.67    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 75.83    Train Loss : 0.5,    Test Acc : 66.75    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 79.17    Train Loss : 0.46,    Test Acc : 68.96    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 85.0    Train Loss : 0.41,    Test Acc : 69.33    Test Loss : 0.66\n",
      "Epoch 70 - Train Acc : 84.17    Train Loss : 0.35,    Test Acc : 70.54    Test Loss : 0.69\n",
      "Epoch 80 - Train Acc : 85.0    Train Loss : 0.29,    Test Acc : 71.67    Test Loss : 0.74\n",
      "Epoch 90 - Train Acc : 88.33    Train Loss : 0.24,    Test Acc : 72.58    Test Loss : 0.79\n",
      "Epoch 100 - Train Acc : 90.83    Train Loss : 0.2,    Test Acc : 73.17    Test Loss : 0.83\n",
      "Epoch 110 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 74.5    Test Loss : 0.94\n",
      "Epoch 120 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 74.33    Test Loss : 1.1\n",
      "Epoch 130 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 75.08    Test Loss : 1.29\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 76.25    Test Loss : 1.54\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 76.5    Test Loss : 1.78\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.88    Test Loss : 1.99\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.88    Test Loss : 2.18\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.92    Test Loss : 2.33\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.96    Test Loss : 2.45\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.92    Test Loss : 2.54\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 76.92 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 9 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.44689249 0.23215275 0.08293975 0.05940864 0.03709554 0.02654815\n",
      " 0.01738888 0.01046536 0.00960569] \n",
      " Overall ratio:  0.9224972566317602\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 73.33    Train Loss : 0.59,    Test Acc : 63.54    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.5,    Test Acc : 64.96    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 80.0    Train Loss : 0.46,    Test Acc : 67.79    Test Loss : 0.67\n",
      "Epoch 40 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 69.21    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 81.67    Train Loss : 0.39,    Test Acc : 69.62    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 83.33    Train Loss : 0.34,    Test Acc : 71.42    Test Loss : 0.59\n",
      "Epoch 70 - Train Acc : 87.5    Train Loss : 0.28,    Test Acc : 72.62    Test Loss : 0.59\n",
      "Epoch 80 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 76.33    Test Loss : 0.61\n",
      "Epoch 90 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 78.25    Test Loss : 0.66\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 79.54    Test Loss : 0.7\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 79.83    Test Loss : 0.78\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 80.67    Test Loss : 0.93\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 81.04    Test Loss : 1.09\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.96    Test Loss : 1.24\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.79    Test Loss : 1.38\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.67    Test Loss : 1.5\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.67    Test Loss : 1.59\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.5    Test Loss : 1.66\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.5    Test Loss : 1.72\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.46    Test Loss : 1.77\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 80.46 ***\n",
      "Epoch 10 - Train Acc : 60.83    Train Loss : 0.63,    Test Acc : 54.46    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 63.33    Train Loss : 0.58,    Test Acc : 58.83    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 71.67    Train Loss : 0.52,    Test Acc : 62.92    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 71.33    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 83.33    Train Loss : 0.38,    Test Acc : 78.38    Test Loss : 0.49\n",
      "Epoch 60 - Train Acc : 87.5    Train Loss : 0.3,    Test Acc : 79.67    Test Loss : 0.45\n",
      "Epoch 70 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 82.58    Test Loss : 0.42\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 84.88    Test Loss : 0.44\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 85.83    Test Loss : 0.51\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 85.71    Test Loss : 0.61\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 85.79    Test Loss : 0.7\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.83    Test Loss : 0.77\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.08    Test Loss : 0.82\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 0.86\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 0.9\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 0.93\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 0.96\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 0.98\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 1.0\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.46    Test Loss : 1.02\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 86.46 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 10 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1134,),    high arousal : (1386,)\n",
      "Explaned variance ratio by principal components : [0.58781647 0.24072545 0.04508322 0.02492528 0.01498236 0.01297621\n",
      " 0.00901634 0.00552238 0.0054266 ] \n",
      " Overall ratio:  0.946474303597169\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.6,    Test Acc : 69.12    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.5,    Test Acc : 73.38    Test Loss : 0.53\n",
      "Epoch 30 - Train Acc : 78.33    Train Loss : 0.42,    Test Acc : 79.08    Test Loss : 0.45\n",
      "Epoch 40 - Train Acc : 85.0    Train Loss : 0.37,    Test Acc : 81.75    Test Loss : 0.41\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.34,    Test Acc : 82.42    Test Loss : 0.41\n",
      "Epoch 60 - Train Acc : 87.5    Train Loss : 0.3,    Test Acc : 84.0    Test Loss : 0.4\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.25,    Test Acc : 84.54    Test Loss : 0.41\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.2,    Test Acc : 84.92    Test Loss : 0.42\n",
      "Epoch 90 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 86.04    Test Loss : 0.44\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 87.25    Test Loss : 0.44\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 88.08    Test Loss : 0.45\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 88.92    Test Loss : 0.47\n",
      "Epoch 130 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 89.88    Test Loss : 0.52\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 89.46    Test Loss : 0.59\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 89.33    Test Loss : 0.67\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.54    Test Loss : 0.75\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.54    Test Loss : 0.82\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.62    Test Loss : 0.88\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 0.93\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 0.97\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 89.5 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.6,    Test Acc : 69.17    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 75.83    Train Loss : 0.53,    Test Acc : 71.5    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 75.83    Train Loss : 0.5,    Test Acc : 68.71    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 77.5    Train Loss : 0.47,    Test Acc : 67.5    Test Loss : 0.67\n",
      "Epoch 50 - Train Acc : 79.17    Train Loss : 0.44,    Test Acc : 68.79    Test Loss : 0.65\n",
      "Epoch 60 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 71.96    Test Loss : 0.63\n",
      "Epoch 70 - Train Acc : 88.33    Train Loss : 0.33,    Test Acc : 74.71    Test Loss : 0.61\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.27,    Test Acc : 77.54    Test Loss : 0.61\n",
      "Epoch 90 - Train Acc : 94.17    Train Loss : 0.21,    Test Acc : 80.33    Test Loss : 0.63\n",
      "Epoch 100 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 81.08    Test Loss : 0.68\n",
      "Epoch 110 - Train Acc : 97.5    Train Loss : 0.11,    Test Acc : 81.25    Test Loss : 0.73\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 81.12    Test Loss : 0.79\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 82.12    Test Loss : 0.87\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.38    Test Loss : 0.99\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.67    Test Loss : 1.11\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.71    Test Loss : 1.21\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.67    Test Loss : 1.29\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.79    Test Loss : 1.36\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 1.42\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 1.47\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 82.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 11 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1575,),    high arousal : (945,)\n",
      "Explaned variance ratio by principal components : [0.76568987 0.15526957 0.02279887 0.01203807 0.01051219 0.00946625\n",
      " 0.00745327 0.00338042 0.00209395] \n",
      " Overall ratio:  0.9887024671084861\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.6,    Test Acc : 64.88    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.52,    Test Acc : 68.54    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 77.5    Train Loss : 0.51,    Test Acc : 68.46    Test Loss : 0.68\n",
      "Epoch 40 - Train Acc : 79.17    Train Loss : 0.48,    Test Acc : 69.42    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 80.83    Train Loss : 0.46,    Test Acc : 70.58    Test Loss : 0.61\n",
      "Epoch 60 - Train Acc : 83.33    Train Loss : 0.42,    Test Acc : 71.04    Test Loss : 0.6\n",
      "Epoch 70 - Train Acc : 82.5    Train Loss : 0.38,    Test Acc : 72.58    Test Loss : 0.58\n",
      "Epoch 80 - Train Acc : 85.0    Train Loss : 0.33,    Test Acc : 74.54    Test Loss : 0.57\n",
      "Epoch 90 - Train Acc : 86.67    Train Loss : 0.28,    Test Acc : 77.0    Test Loss : 0.59\n",
      "Epoch 100 - Train Acc : 89.17    Train Loss : 0.23,    Test Acc : 76.88    Test Loss : 0.65\n",
      "Epoch 110 - Train Acc : 91.67    Train Loss : 0.18,    Test Acc : 78.25    Test Loss : 0.76\n",
      "Epoch 120 - Train Acc : 95.83    Train Loss : 0.12,    Test Acc : 79.08    Test Loss : 0.9\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 79.83    Test Loss : 1.08\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 80.04    Test Loss : 1.36\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 79.63    Test Loss : 1.65\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.21    Test Loss : 1.88\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.62    Test Loss : 2.07\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.96    Test Loss : 2.22\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.96    Test Loss : 2.35\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.92    Test Loss : 2.45\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 80.92 ***\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.58,    Test Acc : 70.83    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.48,    Test Acc : 70.25    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.4,    Test Acc : 74.58    Test Loss : 0.61\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.36,    Test Acc : 73.29    Test Loss : 0.66\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.32,    Test Acc : 75.04    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.27,    Test Acc : 77.58    Test Loss : 0.54\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.21,    Test Acc : 81.21    Test Loss : 0.49\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 82.62    Test Loss : 0.45\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 83.92    Test Loss : 0.42\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 85.83    Test Loss : 0.4\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.08,    Test Acc : 87.17    Test Loss : 0.37\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 88.04    Test Loss : 0.36\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 88.12    Test Loss : 0.34\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 89.17    Test Loss : 0.32\n",
      "Epoch 150 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 89.46    Test Loss : 0.32\n",
      "Epoch 160 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 90.42    Test Loss : 0.33\n",
      "Epoch 170 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 90.42    Test Loss : 0.36\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 90.71    Test Loss : 0.41\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 90.92    Test Loss : 0.46\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 90.83    Test Loss : 0.51\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 90.83 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 12 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "Explaned variance ratio by principal components : [0.54593117 0.20194585 0.0593412  0.02669286 0.01930209 0.01847726\n",
      " 0.01373326 0.01143359 0.00908909] \n",
      " Overall ratio:  0.905946380203934\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.61,    Test Acc : 69.62    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.54,    Test Acc : 71.33    Test Loss : 0.53\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.48,    Test Acc : 74.0    Test Loss : 0.5\n",
      "Epoch 40 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 76.12    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 86.67    Train Loss : 0.33,    Test Acc : 77.25    Test Loss : 0.51\n",
      "Epoch 60 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 79.17    Test Loss : 0.55\n",
      "Epoch 70 - Train Acc : 95.83    Train Loss : 0.18,    Test Acc : 80.08    Test Loss : 0.63\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 80.54    Test Loss : 0.73\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 80.58    Test Loss : 0.81\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 81.25    Test Loss : 0.92\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 81.04    Test Loss : 1.05\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 81.08    Test Loss : 1.18\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.21    Test Loss : 1.3\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.29    Test Loss : 1.4\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.38    Test Loss : 1.48\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.12    Test Loss : 1.55\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 1.61\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.08    Test Loss : 1.66\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.08    Test Loss : 1.71\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.12    Test Loss : 1.74\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 81.12 ***\n",
      "Epoch 10 - Train Acc : 65.0    Train Loss : 0.62,    Test Acc : 58.08    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 72.5    Train Loss : 0.55,    Test Acc : 65.92    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 75.83    Train Loss : 0.5,    Test Acc : 67.33    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 80.83    Train Loss : 0.46,    Test Acc : 71.25    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 83.33    Train Loss : 0.41,    Test Acc : 74.25    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 86.67    Train Loss : 0.33,    Test Acc : 76.71    Test Loss : 0.56\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.25,    Test Acc : 79.5    Test Loss : 0.54\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.18,    Test Acc : 80.88    Test Loss : 0.58\n",
      "Epoch 90 - Train Acc : 95.83    Train Loss : 0.14,    Test Acc : 82.0    Test Loss : 0.62\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 82.96    Test Loss : 0.68\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 83.5    Test Loss : 0.77\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 83.12    Test Loss : 0.87\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 82.75    Test Loss : 1.0\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.5    Test Loss : 1.12\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.46    Test Loss : 1.25\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.58    Test Loss : 1.36\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.46    Test Loss : 1.45\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.53\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.62    Test Loss : 1.59\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 1.64\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 82.67 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 13 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1386,),    high valence : (1134,)\n",
      "low arousal : (378,),    high arousal : (2142,)\n",
      "Explaned variance ratio by principal components : [0.43736414 0.31086054 0.04810466 0.04015608 0.02878613 0.01523213\n",
      " 0.01310141 0.01005132 0.00753943] \n",
      " Overall ratio:  0.9111958474949405\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 75.83    Train Loss : 0.56,    Test Acc : 70.46    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 75.83    Train Loss : 0.45,    Test Acc : 69.5    Test Loss : 0.55\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.37,    Test Acc : 72.5    Test Loss : 0.53\n",
      "Epoch 40 - Train Acc : 85.0    Train Loss : 0.32,    Test Acc : 76.17    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 87.5    Train Loss : 0.26,    Test Acc : 77.79    Test Loss : 0.56\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 79.67    Test Loss : 0.57\n",
      "Epoch 70 - Train Acc : 92.5    Train Loss : 0.19,    Test Acc : 79.67    Test Loss : 0.62\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 78.58    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 94.17    Train Loss : 0.16,    Test Acc : 78.88    Test Loss : 0.69\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.15,    Test Acc : 79.21    Test Loss : 0.7\n",
      "Epoch 110 - Train Acc : 96.67    Train Loss : 0.14,    Test Acc : 79.46    Test Loss : 0.72\n",
      "Epoch 120 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 79.63    Test Loss : 0.75\n",
      "Epoch 130 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 79.63    Test Loss : 0.78\n",
      "Epoch 140 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 79.5    Test Loss : 0.81\n",
      "Epoch 150 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 79.0    Test Loss : 0.85\n",
      "Epoch 160 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 78.79    Test Loss : 0.89\n",
      "Epoch 170 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 78.96    Test Loss : 0.96\n",
      "Epoch 180 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 78.5    Test Loss : 1.04\n",
      "Epoch 190 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 78.33    Test Loss : 1.14\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.5    Test Loss : 1.25\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.5 ***\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.59,    Test Acc : 61.79    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.5,    Test Acc : 65.83    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 67.0    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 80.0    Train Loss : 0.41,    Test Acc : 65.75    Test Loss : 0.6\n",
      "Epoch 50 - Train Acc : 81.67    Train Loss : 0.37,    Test Acc : 68.12    Test Loss : 0.58\n",
      "Epoch 60 - Train Acc : 85.0    Train Loss : 0.32,    Test Acc : 69.46    Test Loss : 0.56\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.25,    Test Acc : 71.5    Test Loss : 0.58\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.2,    Test Acc : 73.63    Test Loss : 0.64\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.17,    Test Acc : 75.92    Test Loss : 0.69\n",
      "Epoch 100 - Train Acc : 95.0    Train Loss : 0.14,    Test Acc : 77.96    Test Loss : 0.71\n",
      "Epoch 110 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 79.46    Test Loss : 0.71\n",
      "Epoch 120 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 80.79    Test Loss : 0.71\n",
      "Epoch 130 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 82.12    Test Loss : 0.71\n",
      "Epoch 140 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 83.33    Test Loss : 0.73\n",
      "Epoch 150 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 83.12    Test Loss : 0.76\n",
      "Epoch 160 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 83.33    Test Loss : 0.79\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.54    Test Loss : 0.84\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.0    Test Loss : 0.9\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.92    Test Loss : 0.96\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.12    Test Loss : 1.02\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 84.12 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 14 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.55342623 0.19145894 0.0527622  0.02522522 0.02398084 0.0177977\n",
      " 0.0158908  0.01216294 0.00907979] \n",
      " Overall ratio:  0.9017846534407353\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.58,    Test Acc : 70.67    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 79.17    Train Loss : 0.49,    Test Acc : 74.5    Test Loss : 0.56\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 75.12    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 84.17    Train Loss : 0.39,    Test Acc : 76.38    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 86.67    Train Loss : 0.35,    Test Acc : 78.0    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 89.17    Train Loss : 0.3,    Test Acc : 78.75    Test Loss : 0.63\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.25,    Test Acc : 78.75    Test Loss : 0.69\n",
      "Epoch 80 - Train Acc : 91.67    Train Loss : 0.2,    Test Acc : 79.04    Test Loss : 0.81\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 79.0    Test Loss : 0.98\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 78.12    Test Loss : 1.19\n",
      "Epoch 110 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 77.58    Test Loss : 1.46\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 77.67    Test Loss : 1.76\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 77.88    Test Loss : 2.07\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 77.75    Test Loss : 2.36\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.08    Test Loss : 2.63\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.33    Test Loss : 2.84\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.38    Test Loss : 3.01\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.46    Test Loss : 3.14\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.46    Test Loss : 3.24\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.46    Test Loss : 3.33\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.46 ***\n",
      "Epoch 10 - Train Acc : 61.67    Train Loss : 0.62,    Test Acc : 63.62    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 70.0    Train Loss : 0.58,    Test Acc : 68.54    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 66.67    Train Loss : 0.55,    Test Acc : 66.21    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 77.5    Train Loss : 0.49,    Test Acc : 70.62    Test Loss : 0.59\n",
      "Epoch 50 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 72.58    Test Loss : 0.56\n",
      "Epoch 60 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 72.25    Test Loss : 0.56\n",
      "Epoch 70 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 75.25    Test Loss : 0.57\n",
      "Epoch 80 - Train Acc : 95.0    Train Loss : 0.19,    Test Acc : 77.12    Test Loss : 0.6\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.11,    Test Acc : 78.75    Test Loss : 0.67\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 79.21    Test Loss : 0.8\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 79.71    Test Loss : 0.96\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.04    Test Loss : 1.12\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.21    Test Loss : 1.27\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.33    Test Loss : 1.38\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.42    Test Loss : 1.46\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.62    Test Loss : 1.53\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.67    Test Loss : 1.59\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.58    Test Loss : 1.64\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.58    Test Loss : 1.68\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.58    Test Loss : 1.72\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 80.58 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 15 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1197,),    high arousal : (1323,)\n",
      "Explaned variance ratio by principal components : [0.43428238 0.24875278 0.12255951 0.0456574  0.04287132 0.01604328\n",
      " 0.01161675 0.01012167 0.0079936 ] \n",
      " Overall ratio:  0.9398986900981424\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 79.17    Train Loss : 0.55,    Test Acc : 71.96    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.43,    Test Acc : 74.67    Test Loss : 0.47\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 80.0    Test Loss : 0.41\n",
      "Epoch 40 - Train Acc : 86.67    Train Loss : 0.31,    Test Acc : 80.83    Test Loss : 0.4\n",
      "Epoch 50 - Train Acc : 89.17    Train Loss : 0.28,    Test Acc : 83.5    Test Loss : 0.38\n",
      "Epoch 60 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 85.83    Test Loss : 0.34\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 87.71    Test Loss : 0.33\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 88.58    Test Loss : 0.36\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 89.0    Test Loss : 0.4\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 89.92    Test Loss : 0.46\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 90.75    Test Loss : 0.51\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 91.46    Test Loss : 0.56\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 92.13    Test Loss : 0.6\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 92.21    Test Loss : 0.64\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.46    Test Loss : 0.67\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 0.69\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.38    Test Loss : 0.71\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 0.73\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 0.75\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 0.76\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 92.42 ***\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.63,    Test Acc : 64.04    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 73.33    Train Loss : 0.57,    Test Acc : 67.21    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 77.5    Train Loss : 0.53,    Test Acc : 70.46    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 77.5    Train Loss : 0.51,    Test Acc : 70.88    Test Loss : 0.6\n",
      "Epoch 50 - Train Acc : 78.33    Train Loss : 0.47,    Test Acc : 71.21    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 70.75    Test Loss : 0.53\n",
      "Epoch 70 - Train Acc : 82.5    Train Loss : 0.35,    Test Acc : 73.83    Test Loss : 0.51\n",
      "Epoch 80 - Train Acc : 86.67    Train Loss : 0.29,    Test Acc : 77.92    Test Loss : 0.53\n",
      "Epoch 90 - Train Acc : 87.5    Train Loss : 0.23,    Test Acc : 79.5    Test Loss : 0.55\n",
      "Epoch 100 - Train Acc : 92.5    Train Loss : 0.19,    Test Acc : 81.04    Test Loss : 0.56\n",
      "Epoch 110 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 81.29    Test Loss : 0.59\n",
      "Epoch 120 - Train Acc : 97.5    Train Loss : 0.11,    Test Acc : 81.92    Test Loss : 0.64\n",
      "Epoch 130 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 82.08    Test Loss : 0.69\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 82.54    Test Loss : 0.77\n",
      "Epoch 150 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 83.58    Test Loss : 0.86\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 83.88    Test Loss : 0.94\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.04    Test Loss : 1.01\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.46    Test Loss : 1.07\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.62    Test Loss : 1.12\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.16\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 84.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 16 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1575,),    high valence : (945,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.51440021 0.20004677 0.04832673 0.03633426 0.02519057 0.01979191\n",
      " 0.01246149 0.01143357 0.00974675] \n",
      " Overall ratio:  0.8777322525766603\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.51,    Test Acc : 63.92    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 82.5    Train Loss : 0.42,    Test Acc : 70.96    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 84.17    Train Loss : 0.39,    Test Acc : 72.83    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.35,    Test Acc : 76.5    Test Loss : 0.57\n",
      "Epoch 50 - Train Acc : 86.67    Train Loss : 0.31,    Test Acc : 77.83    Test Loss : 0.54\n",
      "Epoch 60 - Train Acc : 87.5    Train Loss : 0.26,    Test Acc : 76.96    Test Loss : 0.55\n",
      "Epoch 70 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 78.0    Test Loss : 0.58\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.15,    Test Acc : 78.88    Test Loss : 0.67\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 80.25    Test Loss : 0.81\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.06,    Test Acc : 80.75    Test Loss : 1.01\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 80.38    Test Loss : 1.24\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 80.13    Test Loss : 1.49\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.38    Test Loss : 1.7\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.38    Test Loss : 1.87\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.5    Test Loss : 2.0\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.58    Test Loss : 2.11\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.54    Test Loss : 2.19\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.75    Test Loss : 2.27\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 2.33\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 2.38\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 80.79 ***\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.56,    Test Acc : 69.29    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.48,    Test Acc : 70.21    Test Loss : 0.55\n",
      "Epoch 30 - Train Acc : 80.0    Train Loss : 0.4,    Test Acc : 71.17    Test Loss : 0.51\n",
      "Epoch 40 - Train Acc : 84.17    Train Loss : 0.35,    Test Acc : 72.46    Test Loss : 0.53\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 73.17    Test Loss : 0.54\n",
      "Epoch 60 - Train Acc : 90.83    Train Loss : 0.25,    Test Acc : 73.83    Test Loss : 0.52\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.2,    Test Acc : 76.25    Test Loss : 0.54\n",
      "Epoch 80 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 77.96    Test Loss : 0.64\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 78.29    Test Loss : 0.82\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 78.12    Test Loss : 1.02\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 77.67    Test Loss : 1.24\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 77.71    Test Loss : 1.46\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 77.42    Test Loss : 1.67\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 77.5    Test Loss : 1.86\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 77.5    Test Loss : 2.03\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 77.42    Test Loss : 2.17\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.42    Test Loss : 2.29\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.42    Test Loss : 2.39\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.58    Test Loss : 2.48\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.5    Test Loss : 2.56\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 77.5 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 17 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.51062918 0.22961179 0.05328091 0.04976234 0.01945455 0.01380647\n",
      " 0.01330218 0.00980806 0.00856099] \n",
      " Overall ratio:  0.9082164721176522\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 68.33    Train Loss : 0.61,    Test Acc : 58.92    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 70.0    Train Loss : 0.57,    Test Acc : 60.08    Test Loss : 0.71\n",
      "Epoch 30 - Train Acc : 70.83    Train Loss : 0.56,    Test Acc : 60.12    Test Loss : 0.72\n",
      "Epoch 40 - Train Acc : 72.5    Train Loss : 0.54,    Test Acc : 60.67    Test Loss : 0.69\n",
      "Epoch 50 - Train Acc : 73.33    Train Loss : 0.53,    Test Acc : 61.46    Test Loss : 0.68\n",
      "Epoch 60 - Train Acc : 74.17    Train Loss : 0.49,    Test Acc : 62.21    Test Loss : 0.66\n",
      "Epoch 70 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 65.04    Test Loss : 0.62\n",
      "Epoch 80 - Train Acc : 82.5    Train Loss : 0.35,    Test Acc : 69.62    Test Loss : 0.58\n",
      "Epoch 90 - Train Acc : 87.5    Train Loss : 0.28,    Test Acc : 74.96    Test Loss : 0.63\n",
      "Epoch 100 - Train Acc : 89.17    Train Loss : 0.23,    Test Acc : 76.12    Test Loss : 0.73\n",
      "Epoch 110 - Train Acc : 91.67    Train Loss : 0.19,    Test Acc : 77.42    Test Loss : 0.8\n",
      "Epoch 120 - Train Acc : 94.17    Train Loss : 0.15,    Test Acc : 79.33    Test Loss : 0.87\n",
      "Epoch 130 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 79.79    Test Loss : 0.97\n",
      "Epoch 140 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 80.08    Test Loss : 1.12\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 79.71    Test Loss : 1.3\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 79.58    Test Loss : 1.49\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.08    Test Loss : 1.69\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.08    Test Loss : 1.85\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.29    Test Loss : 1.97\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.29    Test Loss : 2.06\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.29 ***\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.61,    Test Acc : 63.25    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.51,    Test Acc : 70.21    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 81.67    Train Loss : 0.42,    Test Acc : 73.12    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 85.83    Train Loss : 0.4,    Test Acc : 72.88    Test Loss : 0.66\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.35,    Test Acc : 73.33    Test Loss : 0.61\n",
      "Epoch 60 - Train Acc : 88.33    Train Loss : 0.31,    Test Acc : 74.29    Test Loss : 0.6\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 76.04    Test Loss : 0.64\n",
      "Epoch 80 - Train Acc : 90.0    Train Loss : 0.21,    Test Acc : 76.88    Test Loss : 0.74\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.17,    Test Acc : 77.42    Test Loss : 0.88\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 77.54    Test Loss : 1.05\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 78.46    Test Loss : 1.26\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 79.29    Test Loss : 1.44\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 79.42    Test Loss : 1.6\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 80.04    Test Loss : 1.76\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.17    Test Loss : 1.9\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.17    Test Loss : 2.02\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.46    Test Loss : 2.12\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.58    Test Loss : 2.2\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.46    Test Loss : 2.26\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.62    Test Loss : 2.32\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 80.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 18 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.39463138 0.30355925 0.09429425 0.05535936 0.0298884  0.02025116\n",
      " 0.01442286 0.00889498 0.00846107] \n",
      " Overall ratio:  0.9297627011520958\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 74.17    Train Loss : 0.6,    Test Acc : 64.25    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 80.0    Train Loss : 0.48,    Test Acc : 71.21    Test Loss : 0.55\n",
      "Epoch 30 - Train Acc : 87.5    Train Loss : 0.37,    Test Acc : 76.29    Test Loss : 0.51\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.32,    Test Acc : 79.42    Test Loss : 0.48\n",
      "Epoch 50 - Train Acc : 90.83    Train Loss : 0.3,    Test Acc : 80.92    Test Loss : 0.48\n",
      "Epoch 60 - Train Acc : 90.83    Train Loss : 0.27,    Test Acc : 82.29    Test Loss : 0.47\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 84.0    Test Loss : 0.44\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.21,    Test Acc : 86.38    Test Loss : 0.4\n",
      "Epoch 90 - Train Acc : 93.33    Train Loss : 0.18,    Test Acc : 87.54    Test Loss : 0.39\n",
      "Epoch 100 - Train Acc : 94.17    Train Loss : 0.15,    Test Acc : 87.33    Test Loss : 0.4\n",
      "Epoch 110 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 87.04    Test Loss : 0.43\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 87.29    Test Loss : 0.47\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 87.17    Test Loss : 0.5\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 86.62    Test Loss : 0.54\n",
      "Epoch 150 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 86.46    Test Loss : 0.59\n",
      "Epoch 160 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 86.08    Test Loss : 0.64\n",
      "Epoch 170 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 86.04    Test Loss : 0.7\n",
      "Epoch 180 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 86.29    Test Loss : 0.75\n",
      "Epoch 190 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 86.25    Test Loss : 0.82\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.29    Test Loss : 0.89\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 86.29 ***\n",
      "Epoch 10 - Train Acc : 63.33    Train Loss : 0.61,    Test Acc : 60.83    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.54,    Test Acc : 66.71    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 73.33    Train Loss : 0.48,    Test Acc : 67.71    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 76.67    Train Loss : 0.45,    Test Acc : 67.13    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 78.33    Train Loss : 0.42,    Test Acc : 68.38    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 80.83    Train Loss : 0.38,    Test Acc : 68.83    Test Loss : 0.64\n",
      "Epoch 70 - Train Acc : 82.5    Train Loss : 0.34,    Test Acc : 69.79    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 83.33    Train Loss : 0.3,    Test Acc : 70.62    Test Loss : 0.71\n",
      "Epoch 90 - Train Acc : 88.33    Train Loss : 0.25,    Test Acc : 71.42    Test Loss : 0.8\n",
      "Epoch 100 - Train Acc : 90.83    Train Loss : 0.2,    Test Acc : 72.46    Test Loss : 0.9\n",
      "Epoch 110 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 74.83    Test Loss : 1.03\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 77.21    Test Loss : 1.19\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.06,    Test Acc : 77.88    Test Loss : 1.4\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 78.08    Test Loss : 1.63\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.46    Test Loss : 1.84\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.46    Test Loss : 2.03\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.62    Test Loss : 2.18\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.5    Test Loss : 2.31\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.54    Test Loss : 2.41\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.38    Test Loss : 2.5\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 19 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.54074327 0.14616401 0.0587916  0.0435941  0.04350681 0.02031629\n",
      " 0.01615357 0.01535712 0.01122858] \n",
      " Overall ratio:  0.8958553525317096\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.6,    Test Acc : 67.58    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 69.17    Train Loss : 0.53,    Test Acc : 69.33    Test Loss : 0.53\n",
      "Epoch 30 - Train Acc : 74.17    Train Loss : 0.5,    Test Acc : 72.0    Test Loss : 0.52\n",
      "Epoch 40 - Train Acc : 75.83    Train Loss : 0.47,    Test Acc : 74.29    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 75.83    Train Loss : 0.44,    Test Acc : 76.83    Test Loss : 0.45\n",
      "Epoch 60 - Train Acc : 79.17    Train Loss : 0.39,    Test Acc : 80.0    Test Loss : 0.4\n",
      "Epoch 70 - Train Acc : 82.5    Train Loss : 0.34,    Test Acc : 82.42    Test Loss : 0.36\n",
      "Epoch 80 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 84.75    Test Loss : 0.34\n",
      "Epoch 90 - Train Acc : 95.83    Train Loss : 0.19,    Test Acc : 85.63    Test Loss : 0.35\n",
      "Epoch 100 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 87.17    Test Loss : 0.37\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 87.67    Test Loss : 0.44\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 88.17    Test Loss : 0.56\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.42    Test Loss : 0.69\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.21    Test Loss : 0.79\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.86\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.38    Test Loss : 0.91\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.95\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 0.98\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 1.01\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.38    Test Loss : 1.03\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 88.38 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.6,    Test Acc : 62.83    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.55,    Test Acc : 67.5    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 70.83    Train Loss : 0.52,    Test Acc : 68.58    Test Loss : 0.57\n",
      "Epoch 40 - Train Acc : 70.83    Train Loss : 0.49,    Test Acc : 68.83    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 75.83    Train Loss : 0.46,    Test Acc : 70.21    Test Loss : 0.54\n",
      "Epoch 60 - Train Acc : 82.5    Train Loss : 0.41,    Test Acc : 73.83    Test Loss : 0.52\n",
      "Epoch 70 - Train Acc : 87.5    Train Loss : 0.34,    Test Acc : 76.96    Test Loss : 0.52\n",
      "Epoch 80 - Train Acc : 86.67    Train Loss : 0.27,    Test Acc : 77.75    Test Loss : 0.57\n",
      "Epoch 90 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 77.83    Test Loss : 0.67\n",
      "Epoch 100 - Train Acc : 95.0    Train Loss : 0.16,    Test Acc : 79.04    Test Loss : 0.76\n",
      "Epoch 110 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 80.17    Test Loss : 0.85\n",
      "Epoch 120 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 80.25    Test Loss : 0.95\n",
      "Epoch 130 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 80.5    Test Loss : 1.05\n",
      "Epoch 140 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 80.67    Test Loss : 1.18\n",
      "Epoch 150 - Train Acc : 97.5    Train Loss : 0.04,    Test Acc : 80.42    Test Loss : 1.31\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 80.13    Test Loss : 1.46\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 79.46    Test Loss : 1.62\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.96    Test Loss : 1.79\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.25    Test Loss : 1.94\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 77.71    Test Loss : 2.08\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 77.71 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 20 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (567,),    high arousal : (1953,)\n",
      "Explaned variance ratio by principal components : [0.41146202 0.24929551 0.08454913 0.0409253  0.01957663 0.01841643\n",
      " 0.01496066 0.01237091 0.01122691] \n",
      " Overall ratio:  0.8627834894871749\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 68.33    Train Loss : 0.6,    Test Acc : 71.5    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 79.17    Train Loss : 0.46,    Test Acc : 75.21    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 81.67    Train Loss : 0.36,    Test Acc : 78.46    Test Loss : 0.43\n",
      "Epoch 40 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 78.54    Test Loss : 0.47\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.32,    Test Acc : 79.42    Test Loss : 0.45\n",
      "Epoch 60 - Train Acc : 85.0    Train Loss : 0.29,    Test Acc : 81.29    Test Loss : 0.42\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.25,    Test Acc : 83.29    Test Loss : 0.4\n",
      "Epoch 80 - Train Acc : 95.0    Train Loss : 0.2,    Test Acc : 86.58    Test Loss : 0.39\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.15,    Test Acc : 88.83    Test Loss : 0.39\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.1,    Test Acc : 89.38    Test Loss : 0.41\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 89.38    Test Loss : 0.45\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 89.79    Test Loss : 0.53\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 90.08    Test Loss : 0.61\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.83    Test Loss : 0.71\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.29    Test Loss : 0.8\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.17    Test Loss : 0.87\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 0.93\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 0.98\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.02\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 1.06\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 89.0 ***\n",
      "Epoch 10 - Train Acc : 62.5    Train Loss : 0.65,    Test Acc : 53.96    Test Loss : 0.69\n",
      "Epoch 20 - Train Acc : 70.83    Train Loss : 0.59,    Test Acc : 64.75    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 73.33    Train Loss : 0.53,    Test Acc : 69.54    Test Loss : 0.61\n",
      "Epoch 40 - Train Acc : 80.0    Train Loss : 0.47,    Test Acc : 74.0    Test Loss : 0.58\n",
      "Epoch 50 - Train Acc : 89.17    Train Loss : 0.35,    Test Acc : 77.0    Test Loss : 0.5\n",
      "Epoch 60 - Train Acc : 95.83    Train Loss : 0.21,    Test Acc : 81.96    Test Loss : 0.44\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 85.0    Test Loss : 0.41\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 86.67    Test Loss : 0.41\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 87.5    Test Loss : 0.46\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.75    Test Loss : 0.52\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.67    Test Loss : 0.57\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.12    Test Loss : 0.61\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 0.65\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 0.68\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 0.7\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 0.72\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 0.74\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 0.76\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 0.77\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 0.78\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 88.04 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 21 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (504,),    high arousal : (2016,)\n",
      "Explaned variance ratio by principal components : [0.55716619 0.17213443 0.05407688 0.03728339 0.02120906 0.01599675\n",
      " 0.01369203 0.01138043 0.0086399 ] \n",
      " Overall ratio:  0.8915790647572368\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.61,    Test Acc : 62.17    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 70.83    Train Loss : 0.58,    Test Acc : 62.71    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 72.5    Train Loss : 0.56,    Test Acc : 63.83    Test Loss : 0.65\n",
      "Epoch 40 - Train Acc : 70.83    Train Loss : 0.55,    Test Acc : 66.0    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 69.25    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 78.33    Train Loss : 0.5,    Test Acc : 71.42    Test Loss : 0.62\n",
      "Epoch 70 - Train Acc : 79.17    Train Loss : 0.47,    Test Acc : 70.62    Test Loss : 0.62\n",
      "Epoch 80 - Train Acc : 79.17    Train Loss : 0.44,    Test Acc : 69.33    Test Loss : 0.63\n",
      "Epoch 90 - Train Acc : 81.67    Train Loss : 0.4,    Test Acc : 70.21    Test Loss : 0.62\n",
      "Epoch 100 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 71.71    Test Loss : 0.61\n",
      "Epoch 110 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 73.21    Test Loss : 0.61\n",
      "Epoch 120 - Train Acc : 94.17    Train Loss : 0.18,    Test Acc : 75.96    Test Loss : 0.66\n",
      "Epoch 130 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 77.21    Test Loss : 0.8\n",
      "Epoch 140 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 77.58    Test Loss : 1.0\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 78.75    Test Loss : 1.22\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.88    Test Loss : 1.45\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.92    Test Loss : 1.63\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.92    Test Loss : 1.77\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.96    Test Loss : 1.88\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.29    Test Loss : 1.99\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.29 ***\n",
      "Epoch 10 - Train Acc : 66.67    Train Loss : 0.62,    Test Acc : 54.12    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.53,    Test Acc : 68.54    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.48,    Test Acc : 69.12    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.43,    Test Acc : 69.67    Test Loss : 0.58\n",
      "Epoch 50 - Train Acc : 83.33    Train Loss : 0.37,    Test Acc : 69.79    Test Loss : 0.56\n",
      "Epoch 60 - Train Acc : 85.0    Train Loss : 0.31,    Test Acc : 69.92    Test Loss : 0.58\n",
      "Epoch 70 - Train Acc : 92.5    Train Loss : 0.24,    Test Acc : 72.88    Test Loss : 0.68\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 75.58    Test Loss : 0.78\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 78.92    Test Loss : 0.86\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.06,    Test Acc : 80.0    Test Loss : 1.01\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 80.0    Test Loss : 1.23\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 80.04    Test Loss : 1.46\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.96    Test Loss : 1.67\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.63    Test Loss : 1.86\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.75    Test Loss : 1.99\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.88    Test Loss : 2.09\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.79    Test Loss : 2.17\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.67    Test Loss : 2.24\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.79    Test Loss : 2.29\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.96    Test Loss : 2.34\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 22 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.47730228 0.39914183 0.04861757 0.0220424  0.01639548 0.01143172\n",
      " 0.00696697 0.0041986  0.00237292] \n",
      " Overall ratio:  0.9884697733357491\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 64.17    Train Loss : 0.64,    Test Acc : 64.29    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.54,    Test Acc : 71.62    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.47,    Test Acc : 73.42    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 83.33    Train Loss : 0.41,    Test Acc : 77.83    Test Loss : 0.5\n",
      "Epoch 50 - Train Acc : 83.33    Train Loss : 0.36,    Test Acc : 77.33    Test Loss : 0.51\n",
      "Epoch 60 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 78.08    Test Loss : 0.55\n",
      "Epoch 70 - Train Acc : 88.33    Train Loss : 0.25,    Test Acc : 79.29    Test Loss : 0.53\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.18,    Test Acc : 80.96    Test Loss : 0.49\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 83.08    Test Loss : 0.49\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 84.58    Test Loss : 0.56\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 84.71    Test Loss : 0.69\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 84.38    Test Loss : 0.82\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 84.04    Test Loss : 0.97\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.25    Test Loss : 1.08\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.5    Test Loss : 1.19\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.46    Test Loss : 1.29\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.36\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 1.43\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.49\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.55\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 84.96 ***\n",
      "Epoch 10 - Train Acc : 62.5    Train Loss : 0.64,    Test Acc : 55.08    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 66.67    Train Loss : 0.57,    Test Acc : 63.0    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 75.83    Train Loss : 0.53,    Test Acc : 61.5    Test Loss : 0.71\n",
      "Epoch 40 - Train Acc : 75.83    Train Loss : 0.49,    Test Acc : 62.75    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 78.33    Train Loss : 0.45,    Test Acc : 64.62    Test Loss : 0.65\n",
      "Epoch 60 - Train Acc : 80.0    Train Loss : 0.39,    Test Acc : 65.29    Test Loss : 0.68\n",
      "Epoch 70 - Train Acc : 82.5    Train Loss : 0.33,    Test Acc : 67.63    Test Loss : 0.77\n",
      "Epoch 80 - Train Acc : 87.5    Train Loss : 0.28,    Test Acc : 68.92    Test Loss : 0.9\n",
      "Epoch 90 - Train Acc : 89.17    Train Loss : 0.25,    Test Acc : 69.92    Test Loss : 0.95\n",
      "Epoch 100 - Train Acc : 90.0    Train Loss : 0.22,    Test Acc : 71.08    Test Loss : 1.03\n",
      "Epoch 110 - Train Acc : 91.67    Train Loss : 0.18,    Test Acc : 71.25    Test Loss : 1.21\n",
      "Epoch 120 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 72.42    Test Loss : 1.46\n",
      "Epoch 130 - Train Acc : 95.83    Train Loss : 0.12,    Test Acc : 72.0    Test Loss : 1.79\n",
      "Epoch 140 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 72.5    Test Loss : 2.15\n",
      "Epoch 150 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 72.33    Test Loss : 2.53\n",
      "Epoch 160 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 72.67    Test Loss : 2.93\n",
      "Epoch 170 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 73.29    Test Loss : 3.28\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 73.46    Test Loss : 3.61\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 73.79    Test Loss : 3.95\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 73.17    Test Loss : 4.28\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 73.17 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 23 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1701,),    high arousal : (819,)\n",
      "Explaned variance ratio by principal components : [0.50728102 0.13796758 0.06711706 0.060446   0.03076925 0.02072436\n",
      " 0.01518572 0.01489597 0.0118421 ] \n",
      " Overall ratio:  0.8662290567593832\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 64.17    Train Loss : 0.64,    Test Acc : 60.17    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 72.5    Train Loss : 0.61,    Test Acc : 64.33    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 72.5    Train Loss : 0.59,    Test Acc : 67.33    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 74.17    Train Loss : 0.57,    Test Acc : 70.96    Test Loss : 0.58\n",
      "Epoch 50 - Train Acc : 75.0    Train Loss : 0.54,    Test Acc : 73.42    Test Loss : 0.55\n",
      "Epoch 60 - Train Acc : 78.33    Train Loss : 0.49,    Test Acc : 76.83    Test Loss : 0.5\n",
      "Epoch 70 - Train Acc : 81.67    Train Loss : 0.43,    Test Acc : 80.42    Test Loss : 0.44\n",
      "Epoch 80 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 84.38    Test Loss : 0.39\n",
      "Epoch 90 - Train Acc : 91.67    Train Loss : 0.27,    Test Acc : 88.21    Test Loss : 0.34\n",
      "Epoch 100 - Train Acc : 95.83    Train Loss : 0.17,    Test Acc : 89.62    Test Loss : 0.3\n",
      "Epoch 110 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 90.83    Test Loss : 0.26\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 91.12    Test Loss : 0.26\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 91.33    Test Loss : 0.29\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 90.92    Test Loss : 0.33\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 90.62    Test Loss : 0.36\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.39\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.4\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.42\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.43\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.44\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 90.54 ***\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.51,    Test Acc : 69.83    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 81.67    Train Loss : 0.4,    Test Acc : 69.88    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.36,    Test Acc : 71.08    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 81.67    Train Loss : 0.33,    Test Acc : 72.17    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 83.33    Train Loss : 0.29,    Test Acc : 75.04    Test Loss : 0.65\n",
      "Epoch 60 - Train Acc : 87.5    Train Loss : 0.24,    Test Acc : 76.67    Test Loss : 0.65\n",
      "Epoch 70 - Train Acc : 92.5    Train Loss : 0.17,    Test Acc : 80.13    Test Loss : 0.64\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 81.46    Test Loss : 0.67\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 81.17    Test Loss : 0.74\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 82.58    Test Loss : 0.85\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 84.04    Test Loss : 0.97\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 84.92    Test Loss : 1.07\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.5    Test Loss : 1.16\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.67    Test Loss : 1.22\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 1.27\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.92    Test Loss : 1.31\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 1.34\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.37\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 1.39\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 1.41\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 86.33 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 24 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "Explaned variance ratio by principal components : [0.56681254 0.17093498 0.05109744 0.03374641 0.02973686 0.01630758\n",
      " 0.01447047 0.01245046 0.01152172] \n",
      " Overall ratio:  0.9070784680945846\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.63,    Test Acc : 64.0    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.52,    Test Acc : 70.5    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 78.33    Train Loss : 0.46,    Test Acc : 73.21    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.45,    Test Acc : 73.5    Test Loss : 0.67\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.42,    Test Acc : 73.96    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 86.67    Train Loss : 0.38,    Test Acc : 74.54    Test Loss : 0.62\n",
      "Epoch 70 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 75.42    Test Loss : 0.62\n",
      "Epoch 80 - Train Acc : 87.5    Train Loss : 0.29,    Test Acc : 75.96    Test Loss : 0.64\n",
      "Epoch 90 - Train Acc : 91.67    Train Loss : 0.24,    Test Acc : 76.71    Test Loss : 0.66\n",
      "Epoch 100 - Train Acc : 91.67    Train Loss : 0.18,    Test Acc : 76.62    Test Loss : 0.72\n",
      "Epoch 110 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 76.54    Test Loss : 0.81\n",
      "Epoch 120 - Train Acc : 95.83    Train Loss : 0.09,    Test Acc : 76.96    Test Loss : 0.92\n",
      "Epoch 130 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 78.08    Test Loss : 1.02\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 79.88    Test Loss : 1.12\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 80.46    Test Loss : 1.25\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.13    Test Loss : 1.42\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.29    Test Loss : 1.59\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.5    Test Loss : 1.73\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.29    Test Loss : 1.85\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.25    Test Loss : 1.95\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.25 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.62,    Test Acc : 52.17    Test Loss : 0.7\n",
      "Epoch 20 - Train Acc : 80.0    Train Loss : 0.48,    Test Acc : 67.29    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 80.0    Train Loss : 0.37,    Test Acc : 75.54    Test Loss : 0.46\n",
      "Epoch 40 - Train Acc : 84.17    Train Loss : 0.32,    Test Acc : 75.54    Test Loss : 0.47\n",
      "Epoch 50 - Train Acc : 89.17    Train Loss : 0.3,    Test Acc : 75.96    Test Loss : 0.49\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.28,    Test Acc : 75.92    Test Loss : 0.5\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.25,    Test Acc : 76.54    Test Loss : 0.51\n",
      "Epoch 80 - Train Acc : 92.5    Train Loss : 0.22,    Test Acc : 77.5    Test Loss : 0.52\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.19,    Test Acc : 78.25    Test Loss : 0.53\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.16,    Test Acc : 78.92    Test Loss : 0.55\n",
      "Epoch 110 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 80.25    Test Loss : 0.57\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 82.46    Test Loss : 0.63\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 83.62    Test Loss : 0.73\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 84.25    Test Loss : 0.86\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.79    Test Loss : 0.98\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.21    Test Loss : 1.09\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.33    Test Loss : 1.17\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.25\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 1.3\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.35\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 85.33 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 25 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (630,),    high arousal : (1890,)\n",
      "Explaned variance ratio by principal components : [0.55520879 0.2837569  0.03858897 0.03071047 0.02578398 0.01260087\n",
      " 0.01050494 0.0082018  0.00602108] \n",
      " Overall ratio:  0.9713778100613129\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.63,    Test Acc : 62.38    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 67.5    Train Loss : 0.55,    Test Acc : 64.0    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 72.5    Train Loss : 0.52,    Test Acc : 63.33    Test Loss : 0.73\n",
      "Epoch 40 - Train Acc : 75.0    Train Loss : 0.49,    Test Acc : 62.46    Test Loss : 0.75\n",
      "Epoch 50 - Train Acc : 76.67    Train Loss : 0.46,    Test Acc : 63.25    Test Loss : 0.74\n",
      "Epoch 60 - Train Acc : 76.67    Train Loss : 0.42,    Test Acc : 65.42    Test Loss : 0.74\n",
      "Epoch 70 - Train Acc : 83.33    Train Loss : 0.37,    Test Acc : 68.96    Test Loss : 0.75\n",
      "Epoch 80 - Train Acc : 85.0    Train Loss : 0.31,    Test Acc : 71.5    Test Loss : 0.77\n",
      "Epoch 90 - Train Acc : 90.0    Train Loss : 0.25,    Test Acc : 72.88    Test Loss : 0.8\n",
      "Epoch 100 - Train Acc : 94.17    Train Loss : 0.18,    Test Acc : 74.21    Test Loss : 0.84\n",
      "Epoch 110 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 74.42    Test Loss : 0.98\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 75.0    Test Loss : 1.23\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 75.92    Test Loss : 1.52\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 75.88    Test Loss : 1.8\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.12    Test Loss : 2.05\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.12    Test Loss : 2.23\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.25    Test Loss : 2.36\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.38    Test Loss : 2.46\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.46    Test Loss : 2.54\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.42    Test Loss : 2.61\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 76.42 ***\n",
      "Epoch 10 - Train Acc : 64.17    Train Loss : 0.64,    Test Acc : 50.13    Test Loss : 0.7\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.55,    Test Acc : 64.12    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.46,    Test Acc : 72.83    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 85.0    Train Loss : 0.41,    Test Acc : 76.46    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.37,    Test Acc : 80.0    Test Loss : 0.51\n",
      "Epoch 60 - Train Acc : 89.17    Train Loss : 0.3,    Test Acc : 80.13    Test Loss : 0.5\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.22,    Test Acc : 81.04    Test Loss : 0.51\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 80.17    Test Loss : 0.58\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.11,    Test Acc : 79.42    Test Loss : 0.69\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 80.08    Test Loss : 0.8\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 79.83    Test Loss : 0.97\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 80.33    Test Loss : 1.16\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.17    Test Loss : 1.33\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.46    Test Loss : 1.46\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.71    Test Loss : 1.57\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 1.66\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.62    Test Loss : 1.73\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 1.79\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 1.84\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 1.89\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 81.54 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 26 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "Explaned variance ratio by principal components : [0.56050442 0.16106454 0.07318039 0.04436825 0.02512253 0.01573966\n",
      " 0.01420222 0.01224927 0.00876687] \n",
      " Overall ratio:  0.9151981526673507\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.58,    Test Acc : 72.58    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 81.67    Train Loss : 0.46,    Test Acc : 75.12    Test Loss : 0.51\n",
      "Epoch 30 - Train Acc : 84.17    Train Loss : 0.41,    Test Acc : 75.42    Test Loss : 0.51\n",
      "Epoch 40 - Train Acc : 84.17    Train Loss : 0.39,    Test Acc : 76.5    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 77.25    Test Loss : 0.46\n",
      "Epoch 60 - Train Acc : 88.33    Train Loss : 0.32,    Test Acc : 78.96    Test Loss : 0.45\n",
      "Epoch 70 - Train Acc : 91.67    Train Loss : 0.27,    Test Acc : 79.67    Test Loss : 0.44\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.22,    Test Acc : 81.21    Test Loss : 0.43\n",
      "Epoch 90 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 80.25    Test Loss : 0.43\n",
      "Epoch 100 - Train Acc : 95.0    Train Loss : 0.12,    Test Acc : 79.42    Test Loss : 0.48\n",
      "Epoch 110 - Train Acc : 95.83    Train Loss : 0.08,    Test Acc : 79.17    Test Loss : 0.56\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 78.71    Test Loss : 0.69\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 78.58    Test Loss : 0.85\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.42    Test Loss : 0.98\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.67    Test Loss : 1.09\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.54    Test Loss : 1.2\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.42    Test Loss : 1.29\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.29    Test Loss : 1.37\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.42    Test Loss : 1.44\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.38    Test Loss : 1.5\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.38 ***\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.61,    Test Acc : 60.21    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 72.5    Train Loss : 0.54,    Test Acc : 66.38    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 74.17    Train Loss : 0.49,    Test Acc : 68.58    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 78.33    Train Loss : 0.45,    Test Acc : 72.33    Test Loss : 0.58\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.4,    Test Acc : 72.75    Test Loss : 0.58\n",
      "Epoch 60 - Train Acc : 86.67    Train Loss : 0.35,    Test Acc : 73.12    Test Loss : 0.59\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.28,    Test Acc : 74.88    Test Loss : 0.62\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.2,    Test Acc : 76.38    Test Loss : 0.69\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 78.29    Test Loss : 0.79\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 78.79    Test Loss : 0.94\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 78.96    Test Loss : 1.15\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.58    Test Loss : 1.37\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.08    Test Loss : 1.55\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.17    Test Loss : 1.71\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.21    Test Loss : 1.84\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.25    Test Loss : 1.94\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.17    Test Loss : 2.02\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.29    Test Loss : 2.08\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.42    Test Loss : 2.14\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.5    Test Loss : 2.19\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.5 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 27 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.58000955 0.13132278 0.0637214  0.02914774 0.02316072 0.02158316\n",
      " 0.01780128 0.0150561  0.01009865] \n",
      " Overall ratio:  0.8919013886157956\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 70.83    Train Loss : 0.58,    Test Acc : 69.0    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 80.0    Train Loss : 0.48,    Test Acc : 71.12    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 76.12    Test Loss : 0.57\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.42,    Test Acc : 73.96    Test Loss : 0.62\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.4,    Test Acc : 73.75    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 87.5    Train Loss : 0.37,    Test Acc : 74.92    Test Loss : 0.61\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.33,    Test Acc : 75.17    Test Loss : 0.6\n",
      "Epoch 80 - Train Acc : 90.0    Train Loss : 0.29,    Test Acc : 76.25    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 91.67    Train Loss : 0.25,    Test Acc : 76.79    Test Loss : 0.59\n",
      "Epoch 100 - Train Acc : 90.83    Train Loss : 0.2,    Test Acc : 77.21    Test Loss : 0.59\n",
      "Epoch 110 - Train Acc : 91.67    Train Loss : 0.16,    Test Acc : 79.33    Test Loss : 0.6\n",
      "Epoch 120 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 80.08    Test Loss : 0.62\n",
      "Epoch 130 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 81.0    Test Loss : 0.68\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 81.21    Test Loss : 0.78\n",
      "Epoch 150 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 81.46    Test Loss : 0.88\n",
      "Epoch 160 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 82.25    Test Loss : 0.99\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.83    Test Loss : 1.09\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.17    Test Loss : 1.22\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.08    Test Loss : 1.33\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.08    Test Loss : 1.43\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 83.08 ***\n",
      "Epoch 10 - Train Acc : 74.17    Train Loss : 0.57,    Test Acc : 69.58    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.48,    Test Acc : 73.0    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 81.67    Train Loss : 0.43,    Test Acc : 74.0    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 86.67    Train Loss : 0.4,    Test Acc : 74.46    Test Loss : 0.58\n",
      "Epoch 50 - Train Acc : 87.5    Train Loss : 0.34,    Test Acc : 75.12    Test Loss : 0.54\n",
      "Epoch 60 - Train Acc : 90.0    Train Loss : 0.27,    Test Acc : 76.58    Test Loss : 0.5\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.2,    Test Acc : 78.46    Test Loss : 0.5\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.14,    Test Acc : 79.83    Test Loss : 0.56\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.11,    Test Acc : 80.38    Test Loss : 0.68\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 80.5    Test Loss : 0.8\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 80.75    Test Loss : 0.88\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 80.5    Test Loss : 0.94\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 80.58    Test Loss : 0.99\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 80.54    Test Loss : 1.03\n",
      "Epoch 150 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 80.54    Test Loss : 1.09\n",
      "Epoch 160 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 80.29    Test Loss : 1.16\n",
      "Epoch 170 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 80.38    Test Loss : 1.24\n",
      "Epoch 180 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 80.75    Test Loss : 1.34\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 80.62    Test Loss : 1.44\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.12    Test Loss : 1.56\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 81.12 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 28 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.51586344 0.2204086  0.06211284 0.0553274  0.02619596 0.01697069\n",
      " 0.01491086 0.01006063 0.00833603] \n",
      " Overall ratio:  0.9301864386446245\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 79.17    Train Loss : 0.56,    Test Acc : 69.46    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.45,    Test Acc : 69.5    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.39,    Test Acc : 72.25    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 73.29    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 87.5    Train Loss : 0.3,    Test Acc : 74.17    Test Loss : 0.56\n",
      "Epoch 60 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 75.38    Test Loss : 0.6\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 74.58    Test Loss : 0.65\n",
      "Epoch 80 - Train Acc : 90.83    Train Loss : 0.2,    Test Acc : 74.75    Test Loss : 0.67\n",
      "Epoch 90 - Train Acc : 92.5    Train Loss : 0.17,    Test Acc : 75.12    Test Loss : 0.71\n",
      "Epoch 100 - Train Acc : 95.0    Train Loss : 0.14,    Test Acc : 75.21    Test Loss : 0.78\n",
      "Epoch 110 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 76.04    Test Loss : 0.87\n",
      "Epoch 120 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 76.83    Test Loss : 0.98\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 76.92    Test Loss : 1.13\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 76.88    Test Loss : 1.31\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.75    Test Loss : 1.49\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.54    Test Loss : 1.65\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.5    Test Loss : 1.78\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.42    Test Loss : 1.88\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.54    Test Loss : 1.97\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.62    Test Loss : 2.04\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 76.62 ***\n",
      "Epoch 10 - Train Acc : 63.33    Train Loss : 0.64,    Test Acc : 66.54    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 67.5    Train Loss : 0.6,    Test Acc : 67.92    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 70.0    Train Loss : 0.58,    Test Acc : 69.12    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 71.67    Train Loss : 0.56,    Test Acc : 70.5    Test Loss : 0.59\n",
      "Epoch 50 - Train Acc : 74.17    Train Loss : 0.51,    Test Acc : 72.96    Test Loss : 0.55\n",
      "Epoch 60 - Train Acc : 81.67    Train Loss : 0.43,    Test Acc : 77.0    Test Loss : 0.51\n",
      "Epoch 70 - Train Acc : 86.67    Train Loss : 0.35,    Test Acc : 77.25    Test Loss : 0.5\n",
      "Epoch 80 - Train Acc : 91.67    Train Loss : 0.27,    Test Acc : 75.88    Test Loss : 0.51\n",
      "Epoch 90 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 77.88    Test Loss : 0.58\n",
      "Epoch 100 - Train Acc : 94.17    Train Loss : 0.15,    Test Acc : 77.96    Test Loss : 0.67\n",
      "Epoch 110 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 77.54    Test Loss : 0.79\n",
      "Epoch 120 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 77.54    Test Loss : 0.94\n",
      "Epoch 130 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 78.0    Test Loss : 1.11\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 78.08    Test Loss : 1.31\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.25    Test Loss : 1.52\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.38    Test Loss : 1.74\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.5    Test Loss : 1.93\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.58    Test Loss : 2.1\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.33    Test Loss : 2.23\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.21    Test Loss : 2.35\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.21 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 29 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.47039687 0.12674051 0.09903279 0.06471201 0.04196225 0.01985035\n",
      " 0.01652087 0.01484021 0.01090527] \n",
      " Overall ratio:  0.864961144923582\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.57,    Test Acc : 69.46    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 78.21    Test Loss : 0.46\n",
      "Epoch 30 - Train Acc : 84.17    Train Loss : 0.38,    Test Acc : 83.38    Test Loss : 0.39\n",
      "Epoch 40 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 83.46    Test Loss : 0.4\n",
      "Epoch 50 - Train Acc : 85.0    Train Loss : 0.33,    Test Acc : 84.29    Test Loss : 0.38\n",
      "Epoch 60 - Train Acc : 87.5    Train Loss : 0.31,    Test Acc : 86.0    Test Loss : 0.34\n",
      "Epoch 70 - Train Acc : 89.17    Train Loss : 0.27,    Test Acc : 86.58    Test Loss : 0.31\n",
      "Epoch 80 - Train Acc : 89.17    Train Loss : 0.22,    Test Acc : 87.25    Test Loss : 0.28\n",
      "Epoch 90 - Train Acc : 92.5    Train Loss : 0.17,    Test Acc : 88.42    Test Loss : 0.26\n",
      "Epoch 100 - Train Acc : 93.33    Train Loss : 0.13,    Test Acc : 88.5    Test Loss : 0.27\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 87.88    Test Loss : 0.31\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 87.5    Test Loss : 0.37\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 87.75    Test Loss : 0.44\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 88.12    Test Loss : 0.51\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.54    Test Loss : 0.59\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.42    Test Loss : 0.66\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.46    Test Loss : 0.73\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 0.78\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.83\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.38    Test Loss : 0.87\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 88.38 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.58,    Test Acc : 66.42    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 75.0    Train Loss : 0.47,    Test Acc : 75.33    Test Loss : 0.53\n",
      "Epoch 30 - Train Acc : 81.67    Train Loss : 0.4,    Test Acc : 76.04    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.38,    Test Acc : 75.71    Test Loss : 0.56\n",
      "Epoch 50 - Train Acc : 82.5    Train Loss : 0.34,    Test Acc : 76.83    Test Loss : 0.54\n",
      "Epoch 60 - Train Acc : 84.17    Train Loss : 0.3,    Test Acc : 77.83    Test Loss : 0.54\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 80.46    Test Loss : 0.56\n",
      "Epoch 80 - Train Acc : 95.0    Train Loss : 0.19,    Test Acc : 82.67    Test Loss : 0.62\n",
      "Epoch 90 - Train Acc : 95.83    Train Loss : 0.14,    Test Acc : 84.17    Test Loss : 0.69\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 85.71    Test Loss : 0.75\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 86.88    Test Loss : 0.8\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 87.5    Test Loss : 0.9\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 87.96    Test Loss : 1.06\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 87.71    Test Loss : 1.24\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.46    Test Loss : 1.41\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.12    Test Loss : 1.54\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 1.65\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.88    Test Loss : 1.73\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.67    Test Loss : 1.81\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 1.87\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 86.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 30 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.53860918 0.16210924 0.09211102 0.04900104 0.03490006 0.02038517\n",
      " 0.0107367  0.00976345 0.00721595] \n",
      " Overall ratio:  0.9248318079246926\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.61,    Test Acc : 61.5    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 73.33    Train Loss : 0.55,    Test Acc : 63.62    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 73.33    Train Loss : 0.52,    Test Acc : 63.62    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 73.33    Train Loss : 0.49,    Test Acc : 65.42    Test Loss : 0.62\n",
      "Epoch 50 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 68.33    Test Loss : 0.59\n",
      "Epoch 60 - Train Acc : 85.0    Train Loss : 0.37,    Test Acc : 73.67    Test Loss : 0.55\n",
      "Epoch 70 - Train Acc : 88.33    Train Loss : 0.29,    Test Acc : 75.75    Test Loss : 0.53\n",
      "Epoch 80 - Train Acc : 90.0    Train Loss : 0.22,    Test Acc : 77.96    Test Loss : 0.55\n",
      "Epoch 90 - Train Acc : 94.17    Train Loss : 0.15,    Test Acc : 80.08    Test Loss : 0.58\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 82.21    Test Loss : 0.62\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 82.96    Test Loss : 0.69\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 83.75    Test Loss : 0.79\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 84.17    Test Loss : 0.91\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 84.38    Test Loss : 1.06\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.96    Test Loss : 1.21\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.75    Test Loss : 1.33\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.67    Test Loss : 1.43\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 1.52\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.5    Test Loss : 1.59\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.42    Test Loss : 1.65\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 83.42 ***\n",
      "Epoch 10 - Train Acc : 66.67    Train Loss : 0.59,    Test Acc : 61.71    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 69.17    Train Loss : 0.54,    Test Acc : 65.58    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 72.5    Train Loss : 0.52,    Test Acc : 69.12    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 72.5    Train Loss : 0.5,    Test Acc : 69.71    Test Loss : 0.59\n",
      "Epoch 50 - Train Acc : 75.0    Train Loss : 0.47,    Test Acc : 71.42    Test Loss : 0.58\n",
      "Epoch 60 - Train Acc : 78.33    Train Loss : 0.43,    Test Acc : 72.88    Test Loss : 0.58\n",
      "Epoch 70 - Train Acc : 84.17    Train Loss : 0.37,    Test Acc : 73.54    Test Loss : 0.58\n",
      "Epoch 80 - Train Acc : 83.33    Train Loss : 0.3,    Test Acc : 74.42    Test Loss : 0.6\n",
      "Epoch 90 - Train Acc : 89.17    Train Loss : 0.23,    Test Acc : 75.25    Test Loss : 0.68\n",
      "Epoch 100 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 75.75    Test Loss : 0.76\n",
      "Epoch 110 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 76.96    Test Loss : 0.84\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 79.21    Test Loss : 0.89\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 81.08    Test Loss : 0.93\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.12    Test Loss : 0.99\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.79    Test Loss : 1.07\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.58    Test Loss : 1.14\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 1.2\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.25\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.62    Test Loss : 1.3\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 1.33\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 82.71 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 31 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.3954156  0.17461501 0.1050674  0.04231871 0.03093074 0.02988044\n",
      " 0.01595323 0.0152407  0.01360145] \n",
      " Overall ratio:  0.8230232901974354\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 72.5    Train Loss : 0.62,    Test Acc : 62.58    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 72.5    Train Loss : 0.52,    Test Acc : 69.08    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 77.5    Train Loss : 0.46,    Test Acc : 73.71    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 76.67    Train Loss : 0.43,    Test Acc : 74.58    Test Loss : 0.57\n",
      "Epoch 50 - Train Acc : 81.67    Train Loss : 0.39,    Test Acc : 75.62    Test Loss : 0.54\n",
      "Epoch 60 - Train Acc : 82.5    Train Loss : 0.34,    Test Acc : 77.54    Test Loss : 0.52\n",
      "Epoch 70 - Train Acc : 89.17    Train Loss : 0.28,    Test Acc : 78.75    Test Loss : 0.54\n",
      "Epoch 80 - Train Acc : 91.67    Train Loss : 0.22,    Test Acc : 78.46    Test Loss : 0.57\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 80.08    Test Loss : 0.64\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.11,    Test Acc : 80.92    Test Loss : 0.78\n",
      "Epoch 110 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 81.17    Test Loss : 0.91\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 81.25    Test Loss : 0.99\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 81.54    Test Loss : 1.07\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 81.96    Test Loss : 1.16\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.17    Test Loss : 1.28\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.21    Test Loss : 1.39\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.17    Test Loss : 1.47\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.29    Test Loss : 1.54\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.42    Test Loss : 1.59\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.5    Test Loss : 1.64\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 82.5 ***\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.57,    Test Acc : 67.08    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 80.83    Train Loss : 0.46,    Test Acc : 71.21    Test Loss : 0.55\n",
      "Epoch 30 - Train Acc : 80.0    Train Loss : 0.41,    Test Acc : 70.71    Test Loss : 0.57\n",
      "Epoch 40 - Train Acc : 80.0    Train Loss : 0.4,    Test Acc : 71.71    Test Loss : 0.59\n",
      "Epoch 50 - Train Acc : 81.67    Train Loss : 0.39,    Test Acc : 71.71    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 83.33    Train Loss : 0.37,    Test Acc : 71.92    Test Loss : 0.55\n",
      "Epoch 70 - Train Acc : 83.33    Train Loss : 0.34,    Test Acc : 73.17    Test Loss : 0.54\n",
      "Epoch 80 - Train Acc : 84.17    Train Loss : 0.29,    Test Acc : 73.67    Test Loss : 0.55\n",
      "Epoch 90 - Train Acc : 86.67    Train Loss : 0.25,    Test Acc : 74.46    Test Loss : 0.58\n",
      "Epoch 100 - Train Acc : 91.67    Train Loss : 0.19,    Test Acc : 75.62    Test Loss : 0.64\n",
      "Epoch 110 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 76.42    Test Loss : 0.75\n",
      "Epoch 120 - Train Acc : 97.5    Train Loss : 0.11,    Test Acc : 76.5    Test Loss : 0.9\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 76.75    Test Loss : 1.11\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 75.92    Test Loss : 1.41\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 75.25    Test Loss : 1.74\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 75.0    Test Loss : 2.05\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 75.17    Test Loss : 2.33\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 75.04    Test Loss : 2.54\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.0    Test Loss : 2.7\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.0    Test Loss : 2.83\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 75.0 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 32 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (756,),    high arousal : (1764,)\n",
      "Explaned variance ratio by principal components : [0.4395234  0.20457745 0.10251503 0.03879003 0.03528077 0.02465768\n",
      " 0.01909694 0.01638334 0.01427687] \n",
      " Overall ratio:  0.8951015054987324\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.63,    Test Acc : 62.96    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 75.0    Train Loss : 0.53,    Test Acc : 69.58    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 78.33    Train Loss : 0.47,    Test Acc : 72.12    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 85.83    Train Loss : 0.44,    Test Acc : 74.21    Test Loss : 0.56\n",
      "Epoch 50 - Train Acc : 85.0    Train Loss : 0.4,    Test Acc : 75.33    Test Loss : 0.52\n",
      "Epoch 60 - Train Acc : 85.83    Train Loss : 0.36,    Test Acc : 77.08    Test Loss : 0.49\n",
      "Epoch 70 - Train Acc : 89.17    Train Loss : 0.3,    Test Acc : 79.88    Test Loss : 0.44\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.22,    Test Acc : 83.54    Test Loss : 0.39\n",
      "Epoch 90 - Train Acc : 95.83    Train Loss : 0.15,    Test Acc : 85.25    Test Loss : 0.38\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 87.25    Test Loss : 0.42\n",
      "Epoch 110 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 87.96    Test Loss : 0.51\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 87.71    Test Loss : 0.61\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 87.62    Test Loss : 0.72\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.54    Test Loss : 0.82\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.38    Test Loss : 0.91\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 0.96\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.01\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 1.04\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.07\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.1\n",
      "directory already exists\n",
      "/vlc_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 87.25 ***\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.63,    Test Acc : 57.5    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 73.33    Train Loss : 0.58,    Test Acc : 69.54    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 75.0    Train Loss : 0.55,    Test Acc : 72.88    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 78.33    Train Loss : 0.52,    Test Acc : 74.46    Test Loss : 0.56\n",
      "Epoch 50 - Train Acc : 78.33    Train Loss : 0.49,    Test Acc : 74.08    Test Loss : 0.55\n",
      "Epoch 60 - Train Acc : 81.67    Train Loss : 0.44,    Test Acc : 76.58    Test Loss : 0.51\n",
      "Epoch 70 - Train Acc : 86.67    Train Loss : 0.37,    Test Acc : 82.17    Test Loss : 0.45\n",
      "Epoch 80 - Train Acc : 90.83    Train Loss : 0.27,    Test Acc : 86.33    Test Loss : 0.39\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.18,    Test Acc : 88.88    Test Loss : 0.36\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 88.79    Test Loss : 0.4\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 88.88    Test Loss : 0.49\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 88.12    Test Loss : 0.61\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 89.21    Test Loss : 0.76\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.12    Test Loss : 0.92\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.5    Test Loss : 1.05\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.25    Test Loss : 1.14\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 1.2\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.38    Test Loss : 1.25\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 1.29\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 1.32\n",
      "directory already exists\n",
      "/ars_DE_PCA_GCN is saved successfully\n",
      "*** Best ACC : 88.12 ***\n",
      "\n",
      "**************** Valence *********************\n",
      "** Best ACC : [75.17, 88.5, 86.0, 86.04, 82.17, 72.92, 84.71, 82.96, 80.46, 89.5, 80.92, 81.12, 78.5, 78.46, 92.42, 80.79, 79.29, 86.29, 88.38, 89.0, 79.29, 84.96, 90.54, 79.25, 76.42, 78.38, 83.08, 76.62, 88.38, 83.42, 82.5, 87.25] **\n",
      " ** Avearge acc : 82.9278125,    std : 4.7982306207438326 **\n",
      "\n",
      "**************** Arousal *********************\n",
      "** Best ACC : [79.29, 79.58, 79.46, 81.75, 78.88, 78.12, 78.88, 76.92, 86.46, 82.75, 90.83, 82.67, 84.12, 80.58, 84.75, 77.5, 80.62, 78.38, 77.71, 88.04, 79.96, 73.17, 86.33, 85.33, 81.54, 78.5, 81.12, 78.21, 86.75, 82.71, 75.0, 88.12] **\n",
      " ** Avearge acc : 81.37593749999999,    std : 4.030201498820345 **\n",
      "\n",
      "directory already exists\n",
      "vlc_DE_PCA_GCN_protocol_60_best_acc_list_231016 is saved successfully\n",
      "directory already exists\n",
      "ars_DE_PCA_GCN_protocol_60_best_acc_list_231016 is saved successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vlc_best_epoch = []\n",
    "vlc_orig_acc = []\n",
    "vlc_best_acc = []\n",
    "ars_best_epoch = []\n",
    "ars_orig_acc = []\n",
    "ars_best_acc = []\n",
    "\n",
    "compare_args.gcn_hid_channels = 9\n",
    "compare_args.gcn_out_channels = 18\n",
    "for i in range(32):\n",
    "\n",
    "    print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "    sub_idx = 'sub'+str(i+1)\n",
    "    date = '231016'\n",
    "\n",
    "    sub_de = subject_de[i]\n",
    "    sub_psd = subject_psd[i]\n",
    "    sub_label = subject_label[i]\n",
    "    valence_label, arousal_label = deap_label(sub_label)\n",
    "\n",
    "    de, psd, vlc_identifier, ars_identifier = other_preprocessing(sub_de,sub_psd, (valence_label,arousal_label), n_labels_by_class, args.out_channels, args.seed, isdeap=True)\n",
    "\n",
    "    de_pca,_ = dimensionality_reduction(de, compare_args.pca_components1, 'de_LDS', sub_idx, date)\n",
    "    \n",
    "    print(\"\\nDistance matrix construction start...\")\n",
    "    de_dm = distance_matrix(de_pca)\n",
    "    print(\"\\nDistance matrix construction Done...\")\n",
    "\n",
    "    de_neighbors = kneighbors(de_dm, args.n_samples, args.de_k)\n",
    "\n",
    "    de_ssm, de_nssm = ssm_construction(de_dm,de_neighbors)\n",
    "\n",
    "    feature = de_pca\n",
    "    \n",
    "    adj = de_nssm\n",
    "    \n",
    "    feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "    adj = torch.from_numpy(adj).to(torch.float32).to(device)\n",
    "    adj = normalize_adj(adj,im)\n",
    "    \n",
    "    ars_label = torch.from_numpy(arousal_label).to(torch.long).to(device)\n",
    "    vlc_label = torch.from_numpy(valence_label).to(torch.long).to(device)\n",
    "\n",
    "    vlc_identifier = torch.from_numpy(vlc_identifier).bool()\n",
    "    vlc_train_identifier = vlc_identifier.to(device)\n",
    "    isunlabeled = ~vlc_identifier\n",
    "    vlc_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "    ars_identifier = torch.from_numpy(ars_identifier).bool()\n",
    "    ars_train_identifier = ars_identifier.to(device)\n",
    "    isunlabeled = ~ars_identifier\n",
    "    ars_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "\n",
    "    model = compare_model(compare_args,compare_args.pca_components1,adj).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = train(feature, vlc_label, vlc_train_identifier, vlc_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    experiment_type = 'subject_dependent'\n",
    "    model_save_name = sub_idx+'_ablation3_DE_PCA_GCN_protocol_'+str(n_labels_by_class)\n",
    "    model_path = args.model_save_path+experiment_type+'/'+date+'/'+model_save_name\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'/vlc_DE_PCA_GCN', sample)\n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    vlc_best_acc.append(best_acc)\n",
    "    vlc_orig_acc.append(best_acc)\n",
    "    \n",
    "    model = compare_model(compare_args,compare_args.pca_components1,adj).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = train(feature, ars_label, ars_train_identifier, ars_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'/ars_DE_PCA_GCN', sample)\n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    \n",
    "    ars_best_acc.append(best_acc)\n",
    "    ars_orig_acc.append(best_acc)\n",
    "\n",
    "\n",
    "print(\"\\n**************** Valence *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(vlc_best_acc, np.mean(vlc_best_acc), np.std(vlc_best_acc)))\n",
    "\n",
    "print(\"**************** Arousal *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(ars_best_acc, np.mean(ars_best_acc), np.std(ars_best_acc)))\n",
    "\n",
    "vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "ars_best_acc_list = np.array(ars_best_acc)\n",
    "\n",
    "save_np(args.tensor_save_path+'ablation2/vlc/', 'vlc_DE_PCA_GCN_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, vlc_best_acc_list)\n",
    "save_np(args.tensor_save_path+'ablation2/ars/', 'ars_DE_PCA_GCN_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, ars_best_acc_list)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11618864",
   "metadata": {},
   "source": [
    "##  Ablation 2 (PSD+ PCA + SNF + GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f33da80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "Explaned variance ratio by principal components : [0.34124007 0.16573164 0.09901982 0.05144135 0.04170491 0.03432301] \n",
      " Overall ratio:  0.7334608071598483\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 55.83    Train Loss : 0.67,    Test Acc : 59.12    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 65.83    Train Loss : 0.64,    Test Acc : 62.88    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 65.83    Train Loss : 0.63,    Test Acc : 64.46    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 65.0    Train Loss : 0.63,    Test Acc : 65.08    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 66.67    Train Loss : 0.62,    Test Acc : 64.17    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 66.67    Train Loss : 0.62,    Test Acc : 64.58    Test Loss : 0.64\n",
      "Epoch 70 - Train Acc : 67.5    Train Loss : 0.62,    Test Acc : 65.12    Test Loss : 0.63\n",
      "Epoch 80 - Train Acc : 69.17    Train Loss : 0.61,    Test Acc : 64.71    Test Loss : 0.64\n",
      "Epoch 90 - Train Acc : 69.17    Train Loss : 0.6,    Test Acc : 64.08    Test Loss : 0.64\n",
      "Epoch 100 - Train Acc : 69.17    Train Loss : 0.59,    Test Acc : 62.58    Test Loss : 0.65\n",
      "Epoch 110 - Train Acc : 74.17    Train Loss : 0.57,    Test Acc : 59.79    Test Loss : 0.67\n",
      "Epoch 120 - Train Acc : 75.83    Train Loss : 0.54,    Test Acc : 58.71    Test Loss : 0.71\n",
      "Epoch 130 - Train Acc : 81.67    Train Loss : 0.49,    Test Acc : 60.17    Test Loss : 0.76\n",
      "Epoch 140 - Train Acc : 75.83    Train Loss : 0.46,    Test Acc : 59.5    Test Loss : 0.84\n",
      "Epoch 150 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 60.12    Test Loss : 0.94\n",
      "Epoch 160 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 60.83    Test Loss : 0.98\n",
      "Epoch 170 - Train Acc : 83.33    Train Loss : 0.39,    Test Acc : 62.38    Test Loss : 0.96\n",
      "Epoch 180 - Train Acc : 82.5    Train Loss : 0.36,    Test Acc : 63.88    Test Loss : 0.92\n",
      "Epoch 190 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 64.92    Test Loss : 0.9\n",
      "Epoch 200 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 65.62    Test Loss : 0.9\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 65.62 ***\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.64,    Test Acc : 65.71    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 66.67    Train Loss : 0.62,    Test Acc : 66.04    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 70.0    Train Loss : 0.61,    Test Acc : 66.67    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.6,    Test Acc : 66.54    Test Loss : 0.67\n",
      "Epoch 50 - Train Acc : 71.67    Train Loss : 0.59,    Test Acc : 67.0    Test Loss : 0.65\n",
      "Epoch 60 - Train Acc : 70.83    Train Loss : 0.58,    Test Acc : 67.21    Test Loss : 0.64\n",
      "Epoch 70 - Train Acc : 73.33    Train Loss : 0.55,    Test Acc : 66.33    Test Loss : 0.63\n",
      "Epoch 80 - Train Acc : 71.67    Train Loss : 0.53,    Test Acc : 65.21    Test Loss : 0.61\n",
      "Epoch 90 - Train Acc : 74.17    Train Loss : 0.5,    Test Acc : 67.5    Test Loss : 0.6\n",
      "Epoch 100 - Train Acc : 78.33    Train Loss : 0.46,    Test Acc : 67.33    Test Loss : 0.59\n",
      "Epoch 110 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 68.0    Test Loss : 0.6\n",
      "Epoch 120 - Train Acc : 81.67    Train Loss : 0.39,    Test Acc : 68.08    Test Loss : 0.63\n",
      "Epoch 130 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 67.58    Test Loss : 0.67\n",
      "Epoch 140 - Train Acc : 83.33    Train Loss : 0.34,    Test Acc : 67.46    Test Loss : 0.72\n",
      "Epoch 150 - Train Acc : 86.67    Train Loss : 0.32,    Test Acc : 67.54    Test Loss : 0.77\n",
      "Epoch 160 - Train Acc : 89.17    Train Loss : 0.3,    Test Acc : 66.75    Test Loss : 0.82\n",
      "Epoch 170 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 66.71    Test Loss : 0.91\n",
      "Epoch 180 - Train Acc : 87.5    Train Loss : 0.26,    Test Acc : 66.71    Test Loss : 1.0\n",
      "Epoch 190 - Train Acc : 88.33    Train Loss : 0.24,    Test Acc : 66.58    Test Loss : 1.09\n",
      "Epoch 200 - Train Acc : 89.17    Train Loss : 0.23,    Test Acc : 66.79    Test Loss : 1.16\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 66.79 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 2 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "Explaned variance ratio by principal components : [0.61604082 0.1939618  0.07572698 0.0373204  0.01817518 0.01082485] \n",
      " Overall ratio:  0.9520500331769884\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 61.67    Train Loss : 0.67,    Test Acc : 55.13    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 67.5    Train Loss : 0.64,    Test Acc : 60.38    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 66.67    Train Loss : 0.61,    Test Acc : 66.96    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 71.67    Train Loss : 0.59,    Test Acc : 70.29    Test Loss : 0.6\n",
      "Epoch 50 - Train Acc : 70.0    Train Loss : 0.57,    Test Acc : 69.71    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 75.0    Train Loss : 0.54,    Test Acc : 71.58    Test Loss : 0.55\n",
      "Epoch 70 - Train Acc : 77.5    Train Loss : 0.51,    Test Acc : 72.58    Test Loss : 0.53\n",
      "Epoch 80 - Train Acc : 79.17    Train Loss : 0.49,    Test Acc : 73.21    Test Loss : 0.51\n",
      "Epoch 90 - Train Acc : 79.17    Train Loss : 0.46,    Test Acc : 74.0    Test Loss : 0.5\n",
      "Epoch 100 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 74.42    Test Loss : 0.49\n",
      "Epoch 110 - Train Acc : 83.33    Train Loss : 0.4,    Test Acc : 76.21    Test Loss : 0.48\n",
      "Epoch 120 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 76.88    Test Loss : 0.48\n",
      "Epoch 130 - Train Acc : 82.5    Train Loss : 0.33,    Test Acc : 77.96    Test Loss : 0.47\n",
      "Epoch 140 - Train Acc : 85.83    Train Loss : 0.29,    Test Acc : 78.04    Test Loss : 0.48\n",
      "Epoch 150 - Train Acc : 88.33    Train Loss : 0.26,    Test Acc : 78.58    Test Loss : 0.49\n",
      "Epoch 160 - Train Acc : 91.67    Train Loss : 0.23,    Test Acc : 79.5    Test Loss : 0.52\n",
      "Epoch 170 - Train Acc : 92.5    Train Loss : 0.2,    Test Acc : 80.88    Test Loss : 0.55\n",
      "Epoch 180 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 81.04    Test Loss : 0.61\n",
      "Epoch 190 - Train Acc : 96.67    Train Loss : 0.15,    Test Acc : 81.46    Test Loss : 0.68\n",
      "Epoch 200 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 81.71    Test Loss : 0.75\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 81.71 ***\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.63,    Test Acc : 57.75    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 68.33    Train Loss : 0.59,    Test Acc : 56.79    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 70.0    Train Loss : 0.58,    Test Acc : 60.79    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 72.5    Train Loss : 0.57,    Test Acc : 60.67    Test Loss : 0.67\n",
      "Epoch 50 - Train Acc : 69.17    Train Loss : 0.56,    Test Acc : 60.04    Test Loss : 0.67\n",
      "Epoch 60 - Train Acc : 70.83    Train Loss : 0.54,    Test Acc : 60.62    Test Loss : 0.67\n",
      "Epoch 70 - Train Acc : 70.83    Train Loss : 0.51,    Test Acc : 60.83    Test Loss : 0.69\n",
      "Epoch 80 - Train Acc : 75.0    Train Loss : 0.48,    Test Acc : 62.13    Test Loss : 0.71\n",
      "Epoch 90 - Train Acc : 75.83    Train Loss : 0.45,    Test Acc : 64.54    Test Loss : 0.76\n",
      "Epoch 100 - Train Acc : 78.33    Train Loss : 0.43,    Test Acc : 64.75    Test Loss : 0.82\n",
      "Epoch 110 - Train Acc : 80.0    Train Loss : 0.41,    Test Acc : 64.92    Test Loss : 0.89\n",
      "Epoch 120 - Train Acc : 79.17    Train Loss : 0.39,    Test Acc : 65.83    Test Loss : 0.97\n",
      "Epoch 130 - Train Acc : 80.0    Train Loss : 0.38,    Test Acc : 66.42    Test Loss : 1.01\n",
      "Epoch 140 - Train Acc : 80.0    Train Loss : 0.37,    Test Acc : 66.58    Test Loss : 1.02\n",
      "Epoch 150 - Train Acc : 80.83    Train Loss : 0.36,    Test Acc : 66.17    Test Loss : 1.0\n",
      "Epoch 160 - Train Acc : 80.83    Train Loss : 0.34,    Test Acc : 67.0    Test Loss : 0.97\n",
      "Epoch 170 - Train Acc : 83.33    Train Loss : 0.33,    Test Acc : 68.33    Test Loss : 0.93\n",
      "Epoch 180 - Train Acc : 85.0    Train Loss : 0.31,    Test Acc : 69.5    Test Loss : 0.89\n",
      "Epoch 190 - Train Acc : 88.33    Train Loss : 0.29,    Test Acc : 71.46    Test Loss : 0.88\n",
      "Epoch 200 - Train Acc : 89.17    Train Loss : 0.27,    Test Acc : 72.54    Test Loss : 0.91\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 72.54 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 3 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (2016,),    high arousal : (504,)\n",
      "Explaned variance ratio by principal components : [0.46598131 0.19901457 0.08314002 0.07158681 0.03199032 0.03011813] \n",
      " Overall ratio:  0.8818311710929607\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.65,    Test Acc : 65.33    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 67.5    Train Loss : 0.61,    Test Acc : 63.62    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 67.5    Train Loss : 0.59,    Test Acc : 65.5    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.58,    Test Acc : 68.5    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 70.0    Train Loss : 0.57,    Test Acc : 68.25    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 70.83    Train Loss : 0.57,    Test Acc : 67.17    Test Loss : 0.62\n",
      "Epoch 70 - Train Acc : 73.33    Train Loss : 0.56,    Test Acc : 67.79    Test Loss : 0.61\n",
      "Epoch 80 - Train Acc : 74.17    Train Loss : 0.54,    Test Acc : 68.62    Test Loss : 0.6\n",
      "Epoch 90 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 68.58    Test Loss : 0.59\n",
      "Epoch 100 - Train Acc : 74.17    Train Loss : 0.51,    Test Acc : 68.29    Test Loss : 0.59\n",
      "Epoch 110 - Train Acc : 72.5    Train Loss : 0.49,    Test Acc : 67.42    Test Loss : 0.59\n",
      "Epoch 120 - Train Acc : 72.5    Train Loss : 0.48,    Test Acc : 66.75    Test Loss : 0.6\n",
      "Epoch 130 - Train Acc : 74.17    Train Loss : 0.46,    Test Acc : 67.13    Test Loss : 0.6\n",
      "Epoch 140 - Train Acc : 75.83    Train Loss : 0.44,    Test Acc : 67.33    Test Loss : 0.61\n",
      "Epoch 150 - Train Acc : 80.83    Train Loss : 0.43,    Test Acc : 68.33    Test Loss : 0.61\n",
      "Epoch 160 - Train Acc : 82.5    Train Loss : 0.41,    Test Acc : 68.71    Test Loss : 0.62\n",
      "Epoch 170 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 69.08    Test Loss : 0.63\n",
      "Epoch 180 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 70.17    Test Loss : 0.63\n",
      "Epoch 190 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 70.42    Test Loss : 0.65\n",
      "Epoch 200 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 70.21    Test Loss : 0.68\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 70.21 ***\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.64,    Test Acc : 55.46    Test Loss : 0.69\n",
      "Epoch 20 - Train Acc : 65.0    Train Loss : 0.6,    Test Acc : 58.29    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 69.17    Train Loss : 0.58,    Test Acc : 57.92    Test Loss : 0.73\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.56,    Test Acc : 62.13    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 71.67    Train Loss : 0.55,    Test Acc : 61.92    Test Loss : 0.68\n",
      "Epoch 60 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 62.38    Test Loss : 0.67\n",
      "Epoch 70 - Train Acc : 74.17    Train Loss : 0.51,    Test Acc : 63.0    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 75.83    Train Loss : 0.48,    Test Acc : 64.83    Test Loss : 0.64\n",
      "Epoch 90 - Train Acc : 75.83    Train Loss : 0.46,    Test Acc : 65.12    Test Loss : 0.64\n",
      "Epoch 100 - Train Acc : 79.17    Train Loss : 0.44,    Test Acc : 64.83    Test Loss : 0.64\n",
      "Epoch 110 - Train Acc : 80.0    Train Loss : 0.43,    Test Acc : 65.42    Test Loss : 0.62\n",
      "Epoch 120 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 66.25    Test Loss : 0.6\n",
      "Epoch 130 - Train Acc : 80.0    Train Loss : 0.4,    Test Acc : 66.88    Test Loss : 0.59\n",
      "Epoch 140 - Train Acc : 80.83    Train Loss : 0.39,    Test Acc : 67.5    Test Loss : 0.58\n",
      "Epoch 150 - Train Acc : 83.33    Train Loss : 0.38,    Test Acc : 67.83    Test Loss : 0.58\n",
      "Epoch 160 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 68.42    Test Loss : 0.58\n",
      "Epoch 170 - Train Acc : 86.67    Train Loss : 0.35,    Test Acc : 68.67    Test Loss : 0.58\n",
      "Epoch 180 - Train Acc : 87.5    Train Loss : 0.33,    Test Acc : 68.04    Test Loss : 0.59\n",
      "Epoch 190 - Train Acc : 87.5    Train Loss : 0.31,    Test Acc : 67.88    Test Loss : 0.61\n",
      "Epoch 200 - Train Acc : 88.33    Train Loss : 0.29,    Test Acc : 68.38    Test Loss : 0.65\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 68.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 4 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1512,),    high valence : (1008,)\n",
      "low arousal : (1512,),    high arousal : (1008,)\n",
      "Explaned variance ratio by principal components : [0.63702801 0.26856435 0.04607182 0.01842077 0.01113548 0.00622467] \n",
      " Overall ratio:  0.9874450986628706\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 57.5    Train Loss : 0.66,    Test Acc : 56.33    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 65.83    Train Loss : 0.64,    Test Acc : 59.5    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 61.67    Train Loss : 0.6,    Test Acc : 59.42    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 63.33    Train Loss : 0.56,    Test Acc : 66.29    Test Loss : 0.61\n",
      "Epoch 50 - Train Acc : 71.67    Train Loss : 0.54,    Test Acc : 69.38    Test Loss : 0.58\n",
      "Epoch 60 - Train Acc : 70.0    Train Loss : 0.52,    Test Acc : 70.58    Test Loss : 0.56\n",
      "Epoch 70 - Train Acc : 70.0    Train Loss : 0.52,    Test Acc : 68.04    Test Loss : 0.56\n",
      "Epoch 80 - Train Acc : 70.83    Train Loss : 0.51,    Test Acc : 68.75    Test Loss : 0.55\n",
      "Epoch 90 - Train Acc : 70.83    Train Loss : 0.5,    Test Acc : 70.25    Test Loss : 0.56\n",
      "Epoch 100 - Train Acc : 72.5    Train Loss : 0.49,    Test Acc : 70.5    Test Loss : 0.57\n",
      "Epoch 110 - Train Acc : 73.33    Train Loss : 0.48,    Test Acc : 71.79    Test Loss : 0.58\n",
      "Epoch 120 - Train Acc : 76.67    Train Loss : 0.47,    Test Acc : 73.17    Test Loss : 0.59\n",
      "Epoch 130 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 74.25    Test Loss : 0.6\n",
      "Epoch 140 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 75.46    Test Loss : 0.61\n",
      "Epoch 150 - Train Acc : 80.0    Train Loss : 0.42,    Test Acc : 75.46    Test Loss : 0.63\n",
      "Epoch 160 - Train Acc : 82.5    Train Loss : 0.4,    Test Acc : 74.96    Test Loss : 0.65\n",
      "Epoch 170 - Train Acc : 83.33    Train Loss : 0.37,    Test Acc : 73.5    Test Loss : 0.68\n",
      "Epoch 180 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 73.71    Test Loss : 0.72\n",
      "Epoch 190 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 75.38    Test Loss : 0.75\n",
      "Epoch 200 - Train Acc : 85.0    Train Loss : 0.32,    Test Acc : 75.33    Test Loss : 0.78\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 75.33 ***\n",
      "Epoch 10 - Train Acc : 48.33    Train Loss : 0.68,    Test Acc : 61.0    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 58.33    Train Loss : 0.65,    Test Acc : 62.33    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 64.17    Train Loss : 0.61,    Test Acc : 59.67    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 64.17    Train Loss : 0.58,    Test Acc : 61.96    Test Loss : 0.59\n",
      "Epoch 50 - Train Acc : 68.33    Train Loss : 0.56,    Test Acc : 63.54    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 70.83    Train Loss : 0.55,    Test Acc : 63.67    Test Loss : 0.57\n",
      "Epoch 70 - Train Acc : 73.33    Train Loss : 0.54,    Test Acc : 64.12    Test Loss : 0.57\n",
      "Epoch 80 - Train Acc : 75.83    Train Loss : 0.53,    Test Acc : 64.17    Test Loss : 0.56\n",
      "Epoch 90 - Train Acc : 75.83    Train Loss : 0.52,    Test Acc : 64.92    Test Loss : 0.56\n",
      "Epoch 100 - Train Acc : 76.67    Train Loss : 0.5,    Test Acc : 65.96    Test Loss : 0.56\n",
      "Epoch 110 - Train Acc : 80.0    Train Loss : 0.48,    Test Acc : 67.83    Test Loss : 0.56\n",
      "Epoch 120 - Train Acc : 81.67    Train Loss : 0.46,    Test Acc : 70.21    Test Loss : 0.56\n",
      "Epoch 130 - Train Acc : 81.67    Train Loss : 0.44,    Test Acc : 72.75    Test Loss : 0.56\n",
      "Epoch 140 - Train Acc : 84.17    Train Loss : 0.41,    Test Acc : 75.79    Test Loss : 0.57\n",
      "Epoch 150 - Train Acc : 85.0    Train Loss : 0.39,    Test Acc : 76.12    Test Loss : 0.59\n",
      "Epoch 160 - Train Acc : 85.0    Train Loss : 0.36,    Test Acc : 76.5    Test Loss : 0.62\n",
      "Epoch 170 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 76.29    Test Loss : 0.65\n",
      "Epoch 180 - Train Acc : 88.33    Train Loss : 0.32,    Test Acc : 75.67    Test Loss : 0.69\n",
      "Epoch 190 - Train Acc : 90.83    Train Loss : 0.3,    Test Acc : 75.17    Test Loss : 0.74\n",
      "Epoch 200 - Train Acc : 90.83    Train Loss : 0.28,    Test Acc : 73.92    Test Loss : 0.81\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 73.92 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 5 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1323,),    high arousal : (1197,)\n",
      "Explaned variance ratio by principal components : [0.43381391 0.31507221 0.06265232 0.05063084 0.03125649 0.02739416] \n",
      " Overall ratio:  0.9208199303277511\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 57.5    Train Loss : 0.65,    Test Acc : 60.67    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 68.33    Train Loss : 0.62,    Test Acc : 68.46    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 66.67    Train Loss : 0.59,    Test Acc : 66.71    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 69.17    Train Loss : 0.57,    Test Acc : 68.62    Test Loss : 0.62\n",
      "Epoch 50 - Train Acc : 70.83    Train Loss : 0.54,    Test Acc : 68.42    Test Loss : 0.59\n",
      "Epoch 60 - Train Acc : 72.5    Train Loss : 0.51,    Test Acc : 72.25    Test Loss : 0.58\n",
      "Epoch 70 - Train Acc : 77.5    Train Loss : 0.47,    Test Acc : 74.92    Test Loss : 0.57\n",
      "Epoch 80 - Train Acc : 76.67    Train Loss : 0.45,    Test Acc : 75.25    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 77.5    Train Loss : 0.43,    Test Acc : 75.79    Test Loss : 0.62\n",
      "Epoch 100 - Train Acc : 77.5    Train Loss : 0.42,    Test Acc : 75.83    Test Loss : 0.64\n",
      "Epoch 110 - Train Acc : 79.17    Train Loss : 0.41,    Test Acc : 75.5    Test Loss : 0.64\n",
      "Epoch 120 - Train Acc : 79.17    Train Loss : 0.39,    Test Acc : 75.62    Test Loss : 0.64\n",
      "Epoch 130 - Train Acc : 81.67    Train Loss : 0.38,    Test Acc : 75.79    Test Loss : 0.66\n",
      "Epoch 140 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 75.08    Test Loss : 0.69\n",
      "Epoch 150 - Train Acc : 82.5    Train Loss : 0.35,    Test Acc : 74.29    Test Loss : 0.73\n",
      "Epoch 160 - Train Acc : 83.33    Train Loss : 0.34,    Test Acc : 74.5    Test Loss : 0.78\n",
      "Epoch 170 - Train Acc : 83.33    Train Loss : 0.32,    Test Acc : 74.38    Test Loss : 0.83\n",
      "Epoch 180 - Train Acc : 86.67    Train Loss : 0.3,    Test Acc : 74.04    Test Loss : 0.89\n",
      "Epoch 190 - Train Acc : 90.0    Train Loss : 0.27,    Test Acc : 73.33    Test Loss : 0.96\n",
      "Epoch 200 - Train Acc : 90.83    Train Loss : 0.25,    Test Acc : 72.38    Test Loss : 1.04\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 72.38 ***\n",
      "Epoch 10 - Train Acc : 57.5    Train Loss : 0.68,    Test Acc : 55.88    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 58.33    Train Loss : 0.67,    Test Acc : 56.92    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 52.5    Train Loss : 0.65,    Test Acc : 55.54    Test Loss : 0.67\n",
      "Epoch 40 - Train Acc : 59.17    Train Loss : 0.64,    Test Acc : 55.83    Test Loss : 0.66\n",
      "Epoch 50 - Train Acc : 60.0    Train Loss : 0.62,    Test Acc : 59.38    Test Loss : 0.67\n",
      "Epoch 60 - Train Acc : 67.5    Train Loss : 0.6,    Test Acc : 61.92    Test Loss : 0.67\n",
      "Epoch 70 - Train Acc : 70.83    Train Loss : 0.57,    Test Acc : 62.0    Test Loss : 0.68\n",
      "Epoch 80 - Train Acc : 70.83    Train Loss : 0.55,    Test Acc : 62.29    Test Loss : 0.68\n",
      "Epoch 90 - Train Acc : 72.5    Train Loss : 0.52,    Test Acc : 62.46    Test Loss : 0.65\n",
      "Epoch 100 - Train Acc : 71.67    Train Loss : 0.5,    Test Acc : 63.96    Test Loss : 0.63\n",
      "Epoch 110 - Train Acc : 74.17    Train Loss : 0.47,    Test Acc : 64.12    Test Loss : 0.63\n",
      "Epoch 120 - Train Acc : 77.5    Train Loss : 0.44,    Test Acc : 64.79    Test Loss : 0.65\n",
      "Epoch 130 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 67.33    Test Loss : 0.68\n",
      "Epoch 140 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 68.58    Test Loss : 0.71\n",
      "Epoch 150 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 68.92    Test Loss : 0.74\n",
      "Epoch 160 - Train Acc : 87.5    Train Loss : 0.32,    Test Acc : 69.21    Test Loss : 0.73\n",
      "Epoch 170 - Train Acc : 87.5    Train Loss : 0.3,    Test Acc : 69.58    Test Loss : 0.75\n",
      "Epoch 180 - Train Acc : 86.67    Train Loss : 0.28,    Test Acc : 69.58    Test Loss : 0.81\n",
      "Epoch 190 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 69.08    Test Loss : 0.87\n",
      "Epoch 200 - Train Acc : 88.33    Train Loss : 0.25,    Test Acc : 68.54    Test Loss : 0.93\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 68.54 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 6 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "Explaned variance ratio by principal components : [0.48200144 0.21864702 0.09479407 0.06309359 0.02098429 0.0188701 ] \n",
      " Overall ratio:  0.8983905163990804\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 60.83    Train Loss : 0.66,    Test Acc : 69.29    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.62,    Test Acc : 60.25    Test Loss : 0.71\n",
      "Epoch 30 - Train Acc : 71.67    Train Loss : 0.6,    Test Acc : 63.75    Test Loss : 0.71\n",
      "Epoch 40 - Train Acc : 71.67    Train Loss : 0.59,    Test Acc : 63.0    Test Loss : 0.72\n",
      "Epoch 50 - Train Acc : 73.33    Train Loss : 0.58,    Test Acc : 63.83    Test Loss : 0.72\n",
      "Epoch 60 - Train Acc : 75.0    Train Loss : 0.56,    Test Acc : 63.92    Test Loss : 0.72\n",
      "Epoch 70 - Train Acc : 74.17    Train Loss : 0.54,    Test Acc : 65.5    Test Loss : 0.72\n",
      "Epoch 80 - Train Acc : 72.5    Train Loss : 0.52,    Test Acc : 67.38    Test Loss : 0.72\n",
      "Epoch 90 - Train Acc : 73.33    Train Loss : 0.49,    Test Acc : 67.29    Test Loss : 0.72\n",
      "Epoch 100 - Train Acc : 76.67    Train Loss : 0.46,    Test Acc : 66.25    Test Loss : 0.72\n",
      "Epoch 110 - Train Acc : 80.0    Train Loss : 0.43,    Test Acc : 67.54    Test Loss : 0.71\n",
      "Epoch 120 - Train Acc : 82.5    Train Loss : 0.38,    Test Acc : 68.0    Test Loss : 0.7\n",
      "Epoch 130 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 69.92    Test Loss : 0.72\n",
      "Epoch 140 - Train Acc : 86.67    Train Loss : 0.3,    Test Acc : 70.92    Test Loss : 0.75\n",
      "Epoch 150 - Train Acc : 86.67    Train Loss : 0.26,    Test Acc : 71.58    Test Loss : 0.77\n",
      "Epoch 160 - Train Acc : 89.17    Train Loss : 0.24,    Test Acc : 72.21    Test Loss : 0.8\n",
      "Epoch 170 - Train Acc : 90.83    Train Loss : 0.22,    Test Acc : 73.54    Test Loss : 0.83\n",
      "Epoch 180 - Train Acc : 92.5    Train Loss : 0.2,    Test Acc : 74.62    Test Loss : 0.86\n",
      "Epoch 190 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 75.25    Test Loss : 0.88\n",
      "Epoch 200 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 75.54    Test Loss : 0.91\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 75.54 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.65,    Test Acc : 54.75    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 64.17    Train Loss : 0.6,    Test Acc : 55.54    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 70.0    Train Loss : 0.58,    Test Acc : 56.33    Test Loss : 0.68\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.57,    Test Acc : 57.92    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 71.67    Train Loss : 0.56,    Test Acc : 57.83    Test Loss : 0.68\n",
      "Epoch 60 - Train Acc : 70.83    Train Loss : 0.55,    Test Acc : 57.21    Test Loss : 0.67\n",
      "Epoch 70 - Train Acc : 70.0    Train Loss : 0.54,    Test Acc : 57.17    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 72.5    Train Loss : 0.53,    Test Acc : 58.75    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 75.0    Train Loss : 0.51,    Test Acc : 60.71    Test Loss : 0.66\n",
      "Epoch 100 - Train Acc : 75.0    Train Loss : 0.49,    Test Acc : 62.42    Test Loss : 0.66\n",
      "Epoch 110 - Train Acc : 75.83    Train Loss : 0.47,    Test Acc : 63.25    Test Loss : 0.67\n",
      "Epoch 120 - Train Acc : 79.17    Train Loss : 0.45,    Test Acc : 64.38    Test Loss : 0.69\n",
      "Epoch 130 - Train Acc : 80.0    Train Loss : 0.43,    Test Acc : 65.21    Test Loss : 0.72\n",
      "Epoch 140 - Train Acc : 80.83    Train Loss : 0.4,    Test Acc : 64.62    Test Loss : 0.75\n",
      "Epoch 150 - Train Acc : 81.67    Train Loss : 0.37,    Test Acc : 63.08    Test Loss : 0.81\n",
      "Epoch 160 - Train Acc : 83.33    Train Loss : 0.33,    Test Acc : 62.38    Test Loss : 0.89\n",
      "Epoch 170 - Train Acc : 84.17    Train Loss : 0.3,    Test Acc : 62.29    Test Loss : 1.0\n",
      "Epoch 180 - Train Acc : 86.67    Train Loss : 0.27,    Test Acc : 62.42    Test Loss : 1.1\n",
      "Epoch 190 - Train Acc : 89.17    Train Loss : 0.24,    Test Acc : 64.29    Test Loss : 1.21\n",
      "Epoch 200 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 65.75    Test Loss : 1.35\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 65.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 7 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (756,),    high valence : (1764,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.40376323 0.16861429 0.10046353 0.07080645 0.05867564 0.02477164] \n",
      " Overall ratio:  0.8270947918654309\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 74.17    Train Loss : 0.63,    Test Acc : 68.21    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 68.33    Train Loss : 0.55,    Test Acc : 63.5    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 71.67    Train Loss : 0.51,    Test Acc : 65.0    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 72.5    Train Loss : 0.49,    Test Acc : 65.12    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 75.0    Train Loss : 0.47,    Test Acc : 65.33    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 76.67    Train Loss : 0.44,    Test Acc : 66.5    Test Loss : 0.59\n",
      "Epoch 70 - Train Acc : 75.0    Train Loss : 0.41,    Test Acc : 68.38    Test Loss : 0.59\n",
      "Epoch 80 - Train Acc : 76.67    Train Loss : 0.38,    Test Acc : 69.54    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 80.0    Train Loss : 0.34,    Test Acc : 71.0    Test Loss : 0.59\n",
      "Epoch 100 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 72.54    Test Loss : 0.62\n",
      "Epoch 110 - Train Acc : 88.33    Train Loss : 0.26,    Test Acc : 74.33    Test Loss : 0.68\n",
      "Epoch 120 - Train Acc : 89.17    Train Loss : 0.22,    Test Acc : 74.79    Test Loss : 0.72\n",
      "Epoch 130 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 76.42    Test Loss : 0.74\n",
      "Epoch 140 - Train Acc : 93.33    Train Loss : 0.15,    Test Acc : 77.25    Test Loss : 0.81\n",
      "Epoch 150 - Train Acc : 95.83    Train Loss : 0.12,    Test Acc : 78.17    Test Loss : 0.89\n",
      "Epoch 160 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 79.46    Test Loss : 0.98\n",
      "Epoch 170 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 80.42    Test Loss : 1.09\n",
      "Epoch 180 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 80.96    Test Loss : 1.22\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 81.17    Test Loss : 1.34\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 81.46    Test Loss : 1.44\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 81.46 ***\n",
      "Epoch 10 - Train Acc : 61.67    Train Loss : 0.68,    Test Acc : 65.33    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 75.83    Train Loss : 0.64,    Test Acc : 67.08    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 72.5    Train Loss : 0.61,    Test Acc : 66.62    Test Loss : 0.65\n",
      "Epoch 40 - Train Acc : 73.33    Train Loss : 0.59,    Test Acc : 66.38    Test Loss : 0.66\n",
      "Epoch 50 - Train Acc : 75.0    Train Loss : 0.55,    Test Acc : 66.42    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 78.33    Train Loss : 0.49,    Test Acc : 68.96    Test Loss : 0.61\n",
      "Epoch 70 - Train Acc : 79.17    Train Loss : 0.42,    Test Acc : 70.33    Test Loss : 0.59\n",
      "Epoch 80 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 71.62    Test Loss : 0.62\n",
      "Epoch 90 - Train Acc : 85.0    Train Loss : 0.3,    Test Acc : 72.25    Test Loss : 0.67\n",
      "Epoch 100 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 72.58    Test Loss : 0.7\n",
      "Epoch 110 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 72.5    Test Loss : 0.72\n",
      "Epoch 120 - Train Acc : 92.5    Train Loss : 0.2,    Test Acc : 72.92    Test Loss : 0.73\n",
      "Epoch 130 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 73.38    Test Loss : 0.74\n",
      "Epoch 140 - Train Acc : 94.17    Train Loss : 0.13,    Test Acc : 75.88    Test Loss : 0.78\n",
      "Epoch 150 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 76.5    Test Loss : 0.84\n",
      "Epoch 160 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 76.71    Test Loss : 0.94\n",
      "Epoch 170 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 77.25    Test Loss : 1.07\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.06,    Test Acc : 77.54    Test Loss : 1.22\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 78.0    Test Loss : 1.37\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 78.12    Test Loss : 1.53\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.12 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 8 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "Explaned variance ratio by principal components : [0.50283109 0.17028135 0.09160995 0.06098791 0.03742539 0.02652397] \n",
      " Overall ratio:  0.8896596660680502\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 49.17    Train Loss : 0.69,    Test Acc : 54.04    Test Loss : 0.69\n",
      "Epoch 20 - Train Acc : 60.0    Train Loss : 0.68,    Test Acc : 52.08    Test Loss : 0.69\n",
      "Epoch 30 - Train Acc : 58.33    Train Loss : 0.66,    Test Acc : 53.04    Test Loss : 0.69\n",
      "Epoch 40 - Train Acc : 61.67    Train Loss : 0.63,    Test Acc : 54.46    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 70.0    Train Loss : 0.59,    Test Acc : 60.92    Test Loss : 0.67\n",
      "Epoch 60 - Train Acc : 73.33    Train Loss : 0.54,    Test Acc : 63.83    Test Loss : 0.67\n",
      "Epoch 70 - Train Acc : 74.17    Train Loss : 0.49,    Test Acc : 64.42    Test Loss : 0.7\n",
      "Epoch 80 - Train Acc : 75.0    Train Loss : 0.45,    Test Acc : 65.62    Test Loss : 0.74\n",
      "Epoch 90 - Train Acc : 78.33    Train Loss : 0.42,    Test Acc : 67.13    Test Loss : 0.76\n",
      "Epoch 100 - Train Acc : 81.67    Train Loss : 0.39,    Test Acc : 68.29    Test Loss : 0.76\n",
      "Epoch 110 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 68.88    Test Loss : 0.77\n",
      "Epoch 120 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 69.42    Test Loss : 0.81\n",
      "Epoch 130 - Train Acc : 87.5    Train Loss : 0.31,    Test Acc : 70.17    Test Loss : 0.85\n",
      "Epoch 140 - Train Acc : 89.17    Train Loss : 0.3,    Test Acc : 70.21    Test Loss : 0.88\n",
      "Epoch 150 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 70.04    Test Loss : 0.91\n",
      "Epoch 160 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 70.29    Test Loss : 0.95\n",
      "Epoch 170 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 70.54    Test Loss : 0.98\n",
      "Epoch 180 - Train Acc : 90.83    Train Loss : 0.25,    Test Acc : 71.62    Test Loss : 1.01\n",
      "Epoch 190 - Train Acc : 91.67    Train Loss : 0.24,    Test Acc : 72.0    Test Loss : 1.04\n",
      "Epoch 200 - Train Acc : 91.67    Train Loss : 0.23,    Test Acc : 72.29    Test Loss : 1.06\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 72.29 ***\n",
      "Epoch 10 - Train Acc : 55.0    Train Loss : 0.67,    Test Acc : 57.17    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 63.33    Train Loss : 0.64,    Test Acc : 63.33    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 61.67    Train Loss : 0.63,    Test Acc : 63.29    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 65.83    Train Loss : 0.62,    Test Acc : 63.62    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 67.5    Train Loss : 0.61,    Test Acc : 64.62    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 69.17    Train Loss : 0.59,    Test Acc : 65.88    Test Loss : 0.62\n",
      "Epoch 70 - Train Acc : 69.17    Train Loss : 0.57,    Test Acc : 67.17    Test Loss : 0.61\n",
      "Epoch 80 - Train Acc : 72.5    Train Loss : 0.55,    Test Acc : 69.58    Test Loss : 0.62\n",
      "Epoch 90 - Train Acc : 74.17    Train Loss : 0.54,    Test Acc : 70.54    Test Loss : 0.64\n",
      "Epoch 100 - Train Acc : 75.0    Train Loss : 0.53,    Test Acc : 70.67    Test Loss : 0.65\n",
      "Epoch 110 - Train Acc : 75.83    Train Loss : 0.52,    Test Acc : 70.71    Test Loss : 0.65\n",
      "Epoch 120 - Train Acc : 76.67    Train Loss : 0.5,    Test Acc : 70.62    Test Loss : 0.66\n",
      "Epoch 130 - Train Acc : 78.33    Train Loss : 0.49,    Test Acc : 70.42    Test Loss : 0.66\n",
      "Epoch 140 - Train Acc : 75.83    Train Loss : 0.46,    Test Acc : 69.75    Test Loss : 0.65\n",
      "Epoch 150 - Train Acc : 77.5    Train Loss : 0.44,    Test Acc : 69.67    Test Loss : 0.68\n",
      "Epoch 160 - Train Acc : 77.5    Train Loss : 0.42,    Test Acc : 68.83    Test Loss : 0.75\n",
      "Epoch 170 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 69.04    Test Loss : 0.83\n",
      "Epoch 180 - Train Acc : 80.0    Train Loss : 0.39,    Test Acc : 69.21    Test Loss : 0.89\n",
      "Epoch 190 - Train Acc : 79.17    Train Loss : 0.38,    Test Acc : 67.63    Test Loss : 0.92\n",
      "Epoch 200 - Train Acc : 78.33    Train Loss : 0.36,    Test Acc : 67.13    Test Loss : 0.96\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 67.13 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 9 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.4608065  0.2726299  0.07459642 0.04230136 0.03007816 0.02421791] \n",
      " Overall ratio:  0.9046302491882179\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 59.17    Train Loss : 0.65,    Test Acc : 59.12    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 64.17    Train Loss : 0.61,    Test Acc : 63.08    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 65.83    Train Loss : 0.59,    Test Acc : 66.04    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.57,    Test Acc : 69.29    Test Loss : 0.62\n",
      "Epoch 50 - Train Acc : 71.67    Train Loss : 0.56,    Test Acc : 70.0    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 73.33    Train Loss : 0.53,    Test Acc : 71.88    Test Loss : 0.57\n",
      "Epoch 70 - Train Acc : 78.33    Train Loss : 0.49,    Test Acc : 73.5    Test Loss : 0.55\n",
      "Epoch 80 - Train Acc : 78.33    Train Loss : 0.45,    Test Acc : 74.62    Test Loss : 0.53\n",
      "Epoch 90 - Train Acc : 83.33    Train Loss : 0.4,    Test Acc : 74.75    Test Loss : 0.54\n",
      "Epoch 100 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 75.62    Test Loss : 0.57\n",
      "Epoch 110 - Train Acc : 85.0    Train Loss : 0.33,    Test Acc : 76.08    Test Loss : 0.6\n",
      "Epoch 120 - Train Acc : 84.17    Train Loss : 0.31,    Test Acc : 76.58    Test Loss : 0.61\n",
      "Epoch 130 - Train Acc : 85.83    Train Loss : 0.28,    Test Acc : 76.46    Test Loss : 0.62\n",
      "Epoch 140 - Train Acc : 85.83    Train Loss : 0.26,    Test Acc : 76.75    Test Loss : 0.62\n",
      "Epoch 150 - Train Acc : 87.5    Train Loss : 0.23,    Test Acc : 77.71    Test Loss : 0.64\n",
      "Epoch 160 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 78.17    Test Loss : 0.66\n",
      "Epoch 170 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 78.96    Test Loss : 0.69\n",
      "Epoch 180 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 79.75    Test Loss : 0.73\n",
      "Epoch 190 - Train Acc : 95.0    Train Loss : 0.14,    Test Acc : 79.83    Test Loss : 0.77\n",
      "Epoch 200 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 78.79    Test Loss : 0.84\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.79 ***\n",
      "Epoch 10 - Train Acc : 55.0    Train Loss : 0.65,    Test Acc : 55.46    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 52.5    Train Loss : 0.63,    Test Acc : 55.71    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 60.0    Train Loss : 0.62,    Test Acc : 60.42    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 58.33    Train Loss : 0.6,    Test Acc : 60.5    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 62.5    Train Loss : 0.58,    Test Acc : 62.21    Test Loss : 0.63\n",
      "Epoch 60 - Train Acc : 68.33    Train Loss : 0.55,    Test Acc : 64.21    Test Loss : 0.62\n",
      "Epoch 70 - Train Acc : 71.67    Train Loss : 0.52,    Test Acc : 64.12    Test Loss : 0.65\n",
      "Epoch 80 - Train Acc : 76.67    Train Loss : 0.5,    Test Acc : 66.29    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 77.5    Train Loss : 0.47,    Test Acc : 67.83    Test Loss : 0.65\n",
      "Epoch 100 - Train Acc : 78.33    Train Loss : 0.45,    Test Acc : 68.92    Test Loss : 0.64\n",
      "Epoch 110 - Train Acc : 78.33    Train Loss : 0.42,    Test Acc : 68.29    Test Loss : 0.67\n",
      "Epoch 120 - Train Acc : 81.67    Train Loss : 0.4,    Test Acc : 68.75    Test Loss : 0.72\n",
      "Epoch 130 - Train Acc : 85.0    Train Loss : 0.37,    Test Acc : 68.83    Test Loss : 0.75\n",
      "Epoch 140 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 69.5    Test Loss : 0.79\n",
      "Epoch 150 - Train Acc : 85.0    Train Loss : 0.31,    Test Acc : 70.79    Test Loss : 0.81\n",
      "Epoch 160 - Train Acc : 86.67    Train Loss : 0.27,    Test Acc : 72.0    Test Loss : 0.84\n",
      "Epoch 170 - Train Acc : 86.67    Train Loss : 0.24,    Test Acc : 73.0    Test Loss : 0.89\n",
      "Epoch 180 - Train Acc : 87.5    Train Loss : 0.22,    Test Acc : 73.71    Test Loss : 0.98\n",
      "Epoch 190 - Train Acc : 89.17    Train Loss : 0.2,    Test Acc : 74.29    Test Loss : 1.09\n",
      "Epoch 200 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 74.5    Test Loss : 1.2\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 74.5 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 10 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1134,),    high arousal : (1386,)\n",
      "Explaned variance ratio by principal components : [0.57386026 0.28138646 0.05949809 0.02266869 0.01138361 0.0101871 ] \n",
      " Overall ratio:  0.9589842152238082\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 66.67    Train Loss : 0.63,    Test Acc : 60.92    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 67.5    Train Loss : 0.59,    Test Acc : 61.71    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 68.33    Train Loss : 0.55,    Test Acc : 64.17    Test Loss : 0.68\n",
      "Epoch 40 - Train Acc : 73.33    Train Loss : 0.5,    Test Acc : 74.12    Test Loss : 0.7\n",
      "Epoch 50 - Train Acc : 81.67    Train Loss : 0.46,    Test Acc : 75.54    Test Loss : 0.76\n",
      "Epoch 60 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 76.79    Test Loss : 0.84\n",
      "Epoch 70 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 77.67    Test Loss : 0.91\n",
      "Epoch 80 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 77.46    Test Loss : 0.93\n",
      "Epoch 90 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 77.25    Test Loss : 0.91\n",
      "Epoch 100 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 76.67    Test Loss : 0.9\n",
      "Epoch 110 - Train Acc : 80.83    Train Loss : 0.4,    Test Acc : 76.54    Test Loss : 0.9\n",
      "Epoch 120 - Train Acc : 80.83    Train Loss : 0.39,    Test Acc : 76.88    Test Loss : 0.91\n",
      "Epoch 130 - Train Acc : 80.0    Train Loss : 0.38,    Test Acc : 77.25    Test Loss : 0.93\n",
      "Epoch 140 - Train Acc : 79.17    Train Loss : 0.38,    Test Acc : 77.21    Test Loss : 0.95\n",
      "Epoch 150 - Train Acc : 79.17    Train Loss : 0.37,    Test Acc : 77.17    Test Loss : 0.96\n",
      "Epoch 160 - Train Acc : 79.17    Train Loss : 0.36,    Test Acc : 76.92    Test Loss : 0.96\n",
      "Epoch 170 - Train Acc : 80.83    Train Loss : 0.35,    Test Acc : 77.08    Test Loss : 0.96\n",
      "Epoch 180 - Train Acc : 81.67    Train Loss : 0.34,    Test Acc : 77.25    Test Loss : 0.96\n",
      "Epoch 190 - Train Acc : 82.5    Train Loss : 0.33,    Test Acc : 76.88    Test Loss : 0.96\n",
      "Epoch 200 - Train Acc : 84.17    Train Loss : 0.31,    Test Acc : 76.96    Test Loss : 0.96\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 76.96 ***\n",
      "Epoch 10 - Train Acc : 62.5    Train Loss : 0.67,    Test Acc : 56.63    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 65.83    Train Loss : 0.64,    Test Acc : 57.62    Test Loss : 0.68\n",
      "Epoch 30 - Train Acc : 69.17    Train Loss : 0.61,    Test Acc : 57.58    Test Loss : 0.72\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.6,    Test Acc : 57.25    Test Loss : 0.76\n",
      "Epoch 50 - Train Acc : 75.0    Train Loss : 0.58,    Test Acc : 57.21    Test Loss : 0.78\n",
      "Epoch 60 - Train Acc : 75.83    Train Loss : 0.56,    Test Acc : 60.29    Test Loss : 0.77\n",
      "Epoch 70 - Train Acc : 77.5    Train Loss : 0.52,    Test Acc : 62.42    Test Loss : 0.76\n",
      "Epoch 80 - Train Acc : 77.5    Train Loss : 0.48,    Test Acc : 64.08    Test Loss : 0.81\n",
      "Epoch 90 - Train Acc : 77.5    Train Loss : 0.44,    Test Acc : 64.46    Test Loss : 0.89\n",
      "Epoch 100 - Train Acc : 83.33    Train Loss : 0.41,    Test Acc : 66.46    Test Loss : 0.99\n",
      "Epoch 110 - Train Acc : 85.0    Train Loss : 0.38,    Test Acc : 67.04    Test Loss : 1.09\n",
      "Epoch 120 - Train Acc : 85.83    Train Loss : 0.37,    Test Acc : 67.13    Test Loss : 1.15\n",
      "Epoch 130 - Train Acc : 86.67    Train Loss : 0.35,    Test Acc : 67.63    Test Loss : 1.18\n",
      "Epoch 140 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 69.0    Test Loss : 1.2\n",
      "Epoch 150 - Train Acc : 86.67    Train Loss : 0.33,    Test Acc : 69.38    Test Loss : 1.22\n",
      "Epoch 160 - Train Acc : 87.5    Train Loss : 0.32,    Test Acc : 68.96    Test Loss : 1.26\n",
      "Epoch 170 - Train Acc : 87.5    Train Loss : 0.3,    Test Acc : 69.08    Test Loss : 1.3\n",
      "Epoch 180 - Train Acc : 90.83    Train Loss : 0.29,    Test Acc : 68.46    Test Loss : 1.37\n",
      "Epoch 190 - Train Acc : 91.67    Train Loss : 0.27,    Test Acc : 68.46    Test Loss : 1.48\n",
      "Epoch 200 - Train Acc : 91.67    Train Loss : 0.25,    Test Acc : 68.29    Test Loss : 1.6\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 68.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 11 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1575,),    high arousal : (945,)\n",
      "Explaned variance ratio by principal components : [0.69510566 0.1854232  0.05276322 0.02060389 0.01388229 0.01110932] \n",
      " Overall ratio:  0.978887577565713\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 68.33    Train Loss : 0.64,    Test Acc : 61.29    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 68.33    Train Loss : 0.6,    Test Acc : 61.54    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 68.33    Train Loss : 0.58,    Test Acc : 64.71    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 66.67    Train Loss : 0.57,    Test Acc : 60.88    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 65.83    Train Loss : 0.56,    Test Acc : 61.71    Test Loss : 0.67\n",
      "Epoch 60 - Train Acc : 65.83    Train Loss : 0.56,    Test Acc : 61.38    Test Loss : 0.67\n",
      "Epoch 70 - Train Acc : 66.67    Train Loss : 0.55,    Test Acc : 62.58    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 68.33    Train Loss : 0.53,    Test Acc : 62.71    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 69.17    Train Loss : 0.52,    Test Acc : 64.58    Test Loss : 0.66\n",
      "Epoch 100 - Train Acc : 72.5    Train Loss : 0.5,    Test Acc : 66.42    Test Loss : 0.66\n",
      "Epoch 110 - Train Acc : 72.5    Train Loss : 0.49,    Test Acc : 66.96    Test Loss : 0.68\n",
      "Epoch 120 - Train Acc : 73.33    Train Loss : 0.48,    Test Acc : 67.17    Test Loss : 0.7\n",
      "Epoch 130 - Train Acc : 76.67    Train Loss : 0.47,    Test Acc : 67.88    Test Loss : 0.71\n",
      "Epoch 140 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 68.38    Test Loss : 0.73\n",
      "Epoch 150 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 68.29    Test Loss : 0.75\n",
      "Epoch 160 - Train Acc : 81.67    Train Loss : 0.43,    Test Acc : 68.25    Test Loss : 0.78\n",
      "Epoch 170 - Train Acc : 80.0    Train Loss : 0.42,    Test Acc : 68.33    Test Loss : 0.82\n",
      "Epoch 180 - Train Acc : 80.83    Train Loss : 0.41,    Test Acc : 68.54    Test Loss : 0.86\n",
      "Epoch 190 - Train Acc : 81.67    Train Loss : 0.4,    Test Acc : 68.42    Test Loss : 0.91\n",
      "Epoch 200 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 68.38    Test Loss : 0.97\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 68.38 ***\n",
      "Epoch 10 - Train Acc : 59.17    Train Loss : 0.66,    Test Acc : 49.96    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 72.5    Train Loss : 0.58,    Test Acc : 62.96    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 75.83    Train Loss : 0.49,    Test Acc : 64.46    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 76.67    Train Loss : 0.43,    Test Acc : 66.04    Test Loss : 0.57\n",
      "Epoch 50 - Train Acc : 80.0    Train Loss : 0.39,    Test Acc : 66.29    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 83.33    Train Loss : 0.36,    Test Acc : 68.38    Test Loss : 0.56\n",
      "Epoch 70 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 69.38    Test Loss : 0.56\n",
      "Epoch 80 - Train Acc : 85.0    Train Loss : 0.32,    Test Acc : 69.83    Test Loss : 0.58\n",
      "Epoch 90 - Train Acc : 85.0    Train Loss : 0.3,    Test Acc : 70.17    Test Loss : 0.6\n",
      "Epoch 100 - Train Acc : 85.83    Train Loss : 0.29,    Test Acc : 71.17    Test Loss : 0.62\n",
      "Epoch 110 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 72.33    Test Loss : 0.62\n",
      "Epoch 120 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 73.79    Test Loss : 0.62\n",
      "Epoch 130 - Train Acc : 87.5    Train Loss : 0.26,    Test Acc : 74.96    Test Loss : 0.62\n",
      "Epoch 140 - Train Acc : 88.33    Train Loss : 0.25,    Test Acc : 74.96    Test Loss : 0.61\n",
      "Epoch 150 - Train Acc : 88.33    Train Loss : 0.25,    Test Acc : 75.21    Test Loss : 0.61\n",
      "Epoch 160 - Train Acc : 88.33    Train Loss : 0.24,    Test Acc : 75.46    Test Loss : 0.62\n",
      "Epoch 170 - Train Acc : 88.33    Train Loss : 0.24,    Test Acc : 75.42    Test Loss : 0.63\n",
      "Epoch 180 - Train Acc : 89.17    Train Loss : 0.23,    Test Acc : 75.58    Test Loss : 0.64\n",
      "Epoch 190 - Train Acc : 90.0    Train Loss : 0.23,    Test Acc : 75.25    Test Loss : 0.65\n",
      "Epoch 200 - Train Acc : 90.83    Train Loss : 0.22,    Test Acc : 75.29    Test Loss : 0.66\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 75.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 12 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "Explaned variance ratio by principal components : [0.48495281 0.24186043 0.06941034 0.0314334  0.02605534 0.02267292] \n",
      " Overall ratio:  0.8763852404378948\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.66,    Test Acc : 71.21    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 66.67    Train Loss : 0.59,    Test Acc : 70.96    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 70.83    Train Loss : 0.55,    Test Acc : 72.46    Test Loss : 0.53\n",
      "Epoch 40 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 73.42    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 76.67    Train Loss : 0.52,    Test Acc : 73.92    Test Loss : 0.52\n",
      "Epoch 60 - Train Acc : 76.67    Train Loss : 0.5,    Test Acc : 73.17    Test Loss : 0.5\n",
      "Epoch 70 - Train Acc : 76.67    Train Loss : 0.49,    Test Acc : 73.29    Test Loss : 0.49\n",
      "Epoch 80 - Train Acc : 77.5    Train Loss : 0.47,    Test Acc : 74.33    Test Loss : 0.48\n",
      "Epoch 90 - Train Acc : 78.33    Train Loss : 0.46,    Test Acc : 74.04    Test Loss : 0.48\n",
      "Epoch 100 - Train Acc : 76.67    Train Loss : 0.45,    Test Acc : 74.0    Test Loss : 0.48\n",
      "Epoch 110 - Train Acc : 76.67    Train Loss : 0.44,    Test Acc : 73.83    Test Loss : 0.47\n",
      "Epoch 120 - Train Acc : 77.5    Train Loss : 0.43,    Test Acc : 73.96    Test Loss : 0.47\n",
      "Epoch 130 - Train Acc : 78.33    Train Loss : 0.42,    Test Acc : 74.25    Test Loss : 0.47\n",
      "Epoch 140 - Train Acc : 78.33    Train Loss : 0.41,    Test Acc : 74.08    Test Loss : 0.47\n",
      "Epoch 150 - Train Acc : 76.67    Train Loss : 0.4,    Test Acc : 73.92    Test Loss : 0.47\n",
      "Epoch 160 - Train Acc : 77.5    Train Loss : 0.39,    Test Acc : 73.75    Test Loss : 0.48\n",
      "Epoch 170 - Train Acc : 79.17    Train Loss : 0.37,    Test Acc : 73.92    Test Loss : 0.48\n",
      "Epoch 180 - Train Acc : 79.17    Train Loss : 0.36,    Test Acc : 73.96    Test Loss : 0.49\n",
      "Epoch 190 - Train Acc : 80.83    Train Loss : 0.34,    Test Acc : 73.79    Test Loss : 0.5\n",
      "Epoch 200 - Train Acc : 79.17    Train Loss : 0.33,    Test Acc : 73.46    Test Loss : 0.52\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 73.46 ***\n",
      "Epoch 10 - Train Acc : 62.5    Train Loss : 0.65,    Test Acc : 80.21    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 60.83    Train Loss : 0.6,    Test Acc : 61.29    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 70.83    Train Loss : 0.57,    Test Acc : 69.42    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 75.0    Train Loss : 0.54,    Test Acc : 68.58    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 72.5    Train Loss : 0.53,    Test Acc : 68.25    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 72.5    Train Loss : 0.51,    Test Acc : 67.29    Test Loss : 0.66\n",
      "Epoch 70 - Train Acc : 76.67    Train Loss : 0.49,    Test Acc : 69.21    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 78.33    Train Loss : 0.47,    Test Acc : 71.54    Test Loss : 0.64\n",
      "Epoch 90 - Train Acc : 79.17    Train Loss : 0.44,    Test Acc : 73.25    Test Loss : 0.62\n",
      "Epoch 100 - Train Acc : 83.33    Train Loss : 0.41,    Test Acc : 74.83    Test Loss : 0.59\n",
      "Epoch 110 - Train Acc : 85.83    Train Loss : 0.39,    Test Acc : 75.29    Test Loss : 0.58\n",
      "Epoch 120 - Train Acc : 87.5    Train Loss : 0.36,    Test Acc : 75.62    Test Loss : 0.57\n",
      "Epoch 130 - Train Acc : 88.33    Train Loss : 0.35,    Test Acc : 75.33    Test Loss : 0.58\n",
      "Epoch 140 - Train Acc : 89.17    Train Loss : 0.33,    Test Acc : 74.83    Test Loss : 0.59\n",
      "Epoch 150 - Train Acc : 90.83    Train Loss : 0.32,    Test Acc : 74.25    Test Loss : 0.59\n",
      "Epoch 160 - Train Acc : 90.83    Train Loss : 0.31,    Test Acc : 74.88    Test Loss : 0.59\n",
      "Epoch 170 - Train Acc : 90.83    Train Loss : 0.29,    Test Acc : 75.46    Test Loss : 0.6\n",
      "Epoch 180 - Train Acc : 90.83    Train Loss : 0.27,    Test Acc : 75.83    Test Loss : 0.61\n",
      "Epoch 190 - Train Acc : 90.83    Train Loss : 0.25,    Test Acc : 75.58    Test Loss : 0.63\n",
      "Epoch 200 - Train Acc : 92.5    Train Loss : 0.23,    Test Acc : 75.0    Test Loss : 0.64\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 75.0 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 13 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1386,),    high valence : (1134,)\n",
      "low arousal : (378,),    high arousal : (2142,)\n",
      "Explaned variance ratio by principal components : [0.43256084 0.30382503 0.06602212 0.05089246 0.03799757 0.01800114] \n",
      " Overall ratio:  0.909299153004343\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 73.33    Train Loss : 0.61,    Test Acc : 66.79    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 83.33    Train Loss : 0.49,    Test Acc : 76.33    Test Loss : 0.56\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.42,    Test Acc : 76.33    Test Loss : 0.54\n",
      "Epoch 40 - Train Acc : 83.33    Train Loss : 0.38,    Test Acc : 77.58    Test Loss : 0.54\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 76.92    Test Loss : 0.53\n",
      "Epoch 60 - Train Acc : 85.83    Train Loss : 0.35,    Test Acc : 76.62    Test Loss : 0.52\n",
      "Epoch 70 - Train Acc : 87.5    Train Loss : 0.33,    Test Acc : 76.83    Test Loss : 0.52\n",
      "Epoch 80 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 76.0    Test Loss : 0.51\n",
      "Epoch 90 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 74.92    Test Loss : 0.52\n",
      "Epoch 100 - Train Acc : 90.0    Train Loss : 0.27,    Test Acc : 75.04    Test Loss : 0.53\n",
      "Epoch 110 - Train Acc : 90.0    Train Loss : 0.25,    Test Acc : 75.58    Test Loss : 0.55\n",
      "Epoch 120 - Train Acc : 90.0    Train Loss : 0.23,    Test Acc : 76.83    Test Loss : 0.56\n",
      "Epoch 130 - Train Acc : 89.17    Train Loss : 0.22,    Test Acc : 77.75    Test Loss : 0.56\n",
      "Epoch 140 - Train Acc : 90.83    Train Loss : 0.21,    Test Acc : 78.5    Test Loss : 0.58\n",
      "Epoch 150 - Train Acc : 92.5    Train Loss : 0.2,    Test Acc : 78.88    Test Loss : 0.59\n",
      "Epoch 160 - Train Acc : 92.5    Train Loss : 0.19,    Test Acc : 79.58    Test Loss : 0.6\n",
      "Epoch 170 - Train Acc : 94.17    Train Loss : 0.18,    Test Acc : 80.21    Test Loss : 0.61\n",
      "Epoch 180 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 81.0    Test Loss : 0.61\n",
      "Epoch 190 - Train Acc : 95.0    Train Loss : 0.16,    Test Acc : 81.25    Test Loss : 0.62\n",
      "Epoch 200 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 81.92    Test Loss : 0.63\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 81.92 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.63,    Test Acc : 55.17    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.56,    Test Acc : 54.17    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 75.83    Train Loss : 0.51,    Test Acc : 62.5    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 73.33    Train Loss : 0.49,    Test Acc : 62.0    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 77.5    Train Loss : 0.47,    Test Acc : 64.12    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 75.83    Train Loss : 0.45,    Test Acc : 63.92    Test Loss : 0.59\n",
      "Epoch 70 - Train Acc : 80.0    Train Loss : 0.42,    Test Acc : 65.54    Test Loss : 0.58\n",
      "Epoch 80 - Train Acc : 82.5    Train Loss : 0.4,    Test Acc : 67.54    Test Loss : 0.57\n",
      "Epoch 90 - Train Acc : 84.17    Train Loss : 0.37,    Test Acc : 69.33    Test Loss : 0.56\n",
      "Epoch 100 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 70.79    Test Loss : 0.55\n",
      "Epoch 110 - Train Acc : 90.0    Train Loss : 0.3,    Test Acc : 71.96    Test Loss : 0.55\n",
      "Epoch 120 - Train Acc : 91.67    Train Loss : 0.28,    Test Acc : 73.33    Test Loss : 0.55\n",
      "Epoch 130 - Train Acc : 90.83    Train Loss : 0.26,    Test Acc : 74.25    Test Loss : 0.54\n",
      "Epoch 140 - Train Acc : 91.67    Train Loss : 0.24,    Test Acc : 75.17    Test Loss : 0.52\n",
      "Epoch 150 - Train Acc : 92.5    Train Loss : 0.22,    Test Acc : 76.88    Test Loss : 0.5\n",
      "Epoch 160 - Train Acc : 95.0    Train Loss : 0.2,    Test Acc : 77.12    Test Loss : 0.5\n",
      "Epoch 170 - Train Acc : 95.0    Train Loss : 0.19,    Test Acc : 77.92    Test Loss : 0.51\n",
      "Epoch 180 - Train Acc : 95.0    Train Loss : 0.18,    Test Acc : 79.12    Test Loss : 0.54\n",
      "Epoch 190 - Train Acc : 95.83    Train Loss : 0.17,    Test Acc : 80.21    Test Loss : 0.56\n",
      "Epoch 200 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 80.79    Test Loss : 0.58\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 80.79 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 14 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.50868337 0.26862834 0.05921244 0.02846371 0.02169384 0.01650261] \n",
      " Overall ratio:  0.9031843047404322\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.63,    Test Acc : 65.38    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 70.83    Train Loss : 0.56,    Test Acc : 67.75    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 70.83    Train Loss : 0.52,    Test Acc : 66.25    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 79.17    Train Loss : 0.49,    Test Acc : 71.67    Test Loss : 0.6\n",
      "Epoch 50 - Train Acc : 80.83    Train Loss : 0.48,    Test Acc : 73.63    Test Loss : 0.61\n",
      "Epoch 60 - Train Acc : 78.33    Train Loss : 0.46,    Test Acc : 73.67    Test Loss : 0.6\n",
      "Epoch 70 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 74.42    Test Loss : 0.59\n",
      "Epoch 80 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 75.58    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 83.33    Train Loss : 0.39,    Test Acc : 76.42    Test Loss : 0.59\n",
      "Epoch 100 - Train Acc : 85.83    Train Loss : 0.37,    Test Acc : 77.67    Test Loss : 0.6\n",
      "Epoch 110 - Train Acc : 89.17    Train Loss : 0.33,    Test Acc : 78.54    Test Loss : 0.6\n",
      "Epoch 120 - Train Acc : 90.83    Train Loss : 0.3,    Test Acc : 78.62    Test Loss : 0.61\n",
      "Epoch 130 - Train Acc : 90.83    Train Loss : 0.27,    Test Acc : 77.67    Test Loss : 0.65\n",
      "Epoch 140 - Train Acc : 91.67    Train Loss : 0.24,    Test Acc : 77.5    Test Loss : 0.72\n",
      "Epoch 150 - Train Acc : 90.83    Train Loss : 0.21,    Test Acc : 77.54    Test Loss : 0.78\n",
      "Epoch 160 - Train Acc : 90.0    Train Loss : 0.18,    Test Acc : 77.25    Test Loss : 0.85\n",
      "Epoch 170 - Train Acc : 92.5    Train Loss : 0.15,    Test Acc : 77.79    Test Loss : 0.92\n",
      "Epoch 180 - Train Acc : 93.33    Train Loss : 0.13,    Test Acc : 78.88    Test Loss : 0.99\n",
      "Epoch 190 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 78.96    Test Loss : 1.08\n",
      "Epoch 200 - Train Acc : 98.33    Train Loss : 0.08,    Test Acc : 79.88    Test Loss : 1.19\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.88 ***\n",
      "Epoch 10 - Train Acc : 61.67    Train Loss : 0.66,    Test Acc : 61.75    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 65.0    Train Loss : 0.62,    Test Acc : 58.75    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 67.5    Train Loss : 0.59,    Test Acc : 64.42    Test Loss : 0.61\n",
      "Epoch 40 - Train Acc : 66.67    Train Loss : 0.58,    Test Acc : 64.25    Test Loss : 0.62\n",
      "Epoch 50 - Train Acc : 65.0    Train Loss : 0.57,    Test Acc : 64.38    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 65.83    Train Loss : 0.56,    Test Acc : 64.21    Test Loss : 0.61\n",
      "Epoch 70 - Train Acc : 65.83    Train Loss : 0.55,    Test Acc : 64.38    Test Loss : 0.6\n",
      "Epoch 80 - Train Acc : 66.67    Train Loss : 0.54,    Test Acc : 65.29    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 70.83    Train Loss : 0.52,    Test Acc : 69.46    Test Loss : 0.58\n",
      "Epoch 100 - Train Acc : 71.67    Train Loss : 0.5,    Test Acc : 72.17    Test Loss : 0.56\n",
      "Epoch 110 - Train Acc : 72.5    Train Loss : 0.48,    Test Acc : 73.08    Test Loss : 0.57\n",
      "Epoch 120 - Train Acc : 72.5    Train Loss : 0.46,    Test Acc : 72.92    Test Loss : 0.6\n",
      "Epoch 130 - Train Acc : 73.33    Train Loss : 0.45,    Test Acc : 72.38    Test Loss : 0.62\n",
      "Epoch 140 - Train Acc : 77.5    Train Loss : 0.43,    Test Acc : 74.67    Test Loss : 0.62\n",
      "Epoch 150 - Train Acc : 80.0    Train Loss : 0.4,    Test Acc : 75.25    Test Loss : 0.62\n",
      "Epoch 160 - Train Acc : 83.33    Train Loss : 0.37,    Test Acc : 74.62    Test Loss : 0.63\n",
      "Epoch 170 - Train Acc : 83.33    Train Loss : 0.33,    Test Acc : 76.08    Test Loss : 0.66\n",
      "Epoch 180 - Train Acc : 87.5    Train Loss : 0.29,    Test Acc : 76.96    Test Loss : 0.69\n",
      "Epoch 190 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 77.0    Test Loss : 0.74\n",
      "Epoch 200 - Train Acc : 90.83    Train Loss : 0.21,    Test Acc : 77.75    Test Loss : 0.8\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 77.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 15 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1197,),    high arousal : (1323,)\n",
      "Explaned variance ratio by principal components : [0.41161407 0.24159887 0.10584548 0.06013956 0.05390225 0.03174993] \n",
      " Overall ratio:  0.9048501544111528\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.64,    Test Acc : 66.46    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 73.33    Train Loss : 0.55,    Test Acc : 68.12    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.47,    Test Acc : 68.62    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 80.83    Train Loss : 0.4,    Test Acc : 70.96    Test Loss : 0.57\n",
      "Epoch 50 - Train Acc : 82.5    Train Loss : 0.38,    Test Acc : 71.46    Test Loss : 0.63\n",
      "Epoch 60 - Train Acc : 81.67    Train Loss : 0.38,    Test Acc : 71.29    Test Loss : 0.68\n",
      "Epoch 70 - Train Acc : 81.67    Train Loss : 0.37,    Test Acc : 71.42    Test Loss : 0.68\n",
      "Epoch 80 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 71.67    Test Loss : 0.68\n",
      "Epoch 90 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 71.67    Test Loss : 0.67\n",
      "Epoch 100 - Train Acc : 81.67    Train Loss : 0.36,    Test Acc : 71.25    Test Loss : 0.66\n",
      "Epoch 110 - Train Acc : 81.67    Train Loss : 0.36,    Test Acc : 72.0    Test Loss : 0.66\n",
      "Epoch 120 - Train Acc : 82.5    Train Loss : 0.35,    Test Acc : 72.08    Test Loss : 0.66\n",
      "Epoch 130 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 72.08    Test Loss : 0.67\n",
      "Epoch 140 - Train Acc : 82.5    Train Loss : 0.34,    Test Acc : 72.38    Test Loss : 0.68\n",
      "Epoch 150 - Train Acc : 81.67    Train Loss : 0.34,    Test Acc : 72.62    Test Loss : 0.69\n",
      "Epoch 160 - Train Acc : 82.5    Train Loss : 0.33,    Test Acc : 73.42    Test Loss : 0.7\n",
      "Epoch 170 - Train Acc : 82.5    Train Loss : 0.32,    Test Acc : 73.79    Test Loss : 0.72\n",
      "Epoch 180 - Train Acc : 83.33    Train Loss : 0.32,    Test Acc : 74.29    Test Loss : 0.73\n",
      "Epoch 190 - Train Acc : 84.17    Train Loss : 0.31,    Test Acc : 74.88    Test Loss : 0.75\n",
      "Epoch 200 - Train Acc : 85.0    Train Loss : 0.3,    Test Acc : 75.83    Test Loss : 0.76\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 75.83 ***\n",
      "Epoch 10 - Train Acc : 65.0    Train Loss : 0.63,    Test Acc : 61.13    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 67.5    Train Loss : 0.61,    Test Acc : 62.13    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 67.5    Train Loss : 0.6,    Test Acc : 61.04    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 66.67    Train Loss : 0.59,    Test Acc : 61.13    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 67.5    Train Loss : 0.59,    Test Acc : 61.83    Test Loss : 0.63\n",
      "Epoch 60 - Train Acc : 70.0    Train Loss : 0.58,    Test Acc : 63.21    Test Loss : 0.63\n",
      "Epoch 70 - Train Acc : 70.0    Train Loss : 0.57,    Test Acc : 63.17    Test Loss : 0.63\n",
      "Epoch 80 - Train Acc : 70.83    Train Loss : 0.55,    Test Acc : 64.12    Test Loss : 0.63\n",
      "Epoch 90 - Train Acc : 70.83    Train Loss : 0.53,    Test Acc : 65.29    Test Loss : 0.62\n",
      "Epoch 100 - Train Acc : 71.67    Train Loss : 0.51,    Test Acc : 66.12    Test Loss : 0.61\n",
      "Epoch 110 - Train Acc : 74.17    Train Loss : 0.48,    Test Acc : 67.46    Test Loss : 0.6\n",
      "Epoch 120 - Train Acc : 75.83    Train Loss : 0.46,    Test Acc : 68.83    Test Loss : 0.59\n",
      "Epoch 130 - Train Acc : 76.67    Train Loss : 0.43,    Test Acc : 69.96    Test Loss : 0.58\n",
      "Epoch 140 - Train Acc : 77.5    Train Loss : 0.41,    Test Acc : 71.29    Test Loss : 0.58\n",
      "Epoch 150 - Train Acc : 80.0    Train Loss : 0.39,    Test Acc : 72.54    Test Loss : 0.57\n",
      "Epoch 160 - Train Acc : 80.83    Train Loss : 0.36,    Test Acc : 73.75    Test Loss : 0.57\n",
      "Epoch 170 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 72.79    Test Loss : 0.6\n",
      "Epoch 180 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 72.25    Test Loss : 0.66\n",
      "Epoch 190 - Train Acc : 87.5    Train Loss : 0.28,    Test Acc : 72.12    Test Loss : 0.75\n",
      "Epoch 200 - Train Acc : 88.33    Train Loss : 0.26,    Test Acc : 72.25    Test Loss : 0.82\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 72.25 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 16 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1575,),    high valence : (945,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.52968023 0.20454603 0.05797728 0.03185913 0.02534341 0.02045039] \n",
      " Overall ratio:  0.8698564693432603\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 68.33    Train Loss : 0.62,    Test Acc : 63.33    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.59,    Test Acc : 67.96    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 74.17    Train Loss : 0.56,    Test Acc : 66.12    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 71.67    Train Loss : 0.54,    Test Acc : 69.25    Test Loss : 0.61\n",
      "Epoch 50 - Train Acc : 73.33    Train Loss : 0.54,    Test Acc : 68.46    Test Loss : 0.61\n",
      "Epoch 60 - Train Acc : 73.33    Train Loss : 0.53,    Test Acc : 69.88    Test Loss : 0.61\n",
      "Epoch 70 - Train Acc : 74.17    Train Loss : 0.52,    Test Acc : 69.67    Test Loss : 0.61\n",
      "Epoch 80 - Train Acc : 72.5    Train Loss : 0.51,    Test Acc : 68.96    Test Loss : 0.6\n",
      "Epoch 90 - Train Acc : 74.17    Train Loss : 0.49,    Test Acc : 70.04    Test Loss : 0.59\n",
      "Epoch 100 - Train Acc : 78.33    Train Loss : 0.46,    Test Acc : 71.38    Test Loss : 0.57\n",
      "Epoch 110 - Train Acc : 80.0    Train Loss : 0.43,    Test Acc : 72.67    Test Loss : 0.55\n",
      "Epoch 120 - Train Acc : 80.83    Train Loss : 0.39,    Test Acc : 73.79    Test Loss : 0.53\n",
      "Epoch 130 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 75.46    Test Loss : 0.5\n",
      "Epoch 140 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 76.58    Test Loss : 0.51\n",
      "Epoch 150 - Train Acc : 90.83    Train Loss : 0.26,    Test Acc : 78.17    Test Loss : 0.55\n",
      "Epoch 160 - Train Acc : 91.67    Train Loss : 0.23,    Test Acc : 77.88    Test Loss : 0.63\n",
      "Epoch 170 - Train Acc : 91.67    Train Loss : 0.2,    Test Acc : 78.25    Test Loss : 0.74\n",
      "Epoch 180 - Train Acc : 93.33    Train Loss : 0.18,    Test Acc : 77.83    Test Loss : 0.83\n",
      "Epoch 190 - Train Acc : 94.17    Train Loss : 0.16,    Test Acc : 78.42    Test Loss : 0.91\n",
      "Epoch 200 - Train Acc : 95.0    Train Loss : 0.14,    Test Acc : 79.04    Test Loss : 0.97\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.04 ***\n",
      "Epoch 10 - Train Acc : 63.33    Train Loss : 0.64,    Test Acc : 64.58    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 67.5    Train Loss : 0.59,    Test Acc : 65.29    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.54,    Test Acc : 69.58    Test Loss : 0.57\n",
      "Epoch 40 - Train Acc : 80.0    Train Loss : 0.49,    Test Acc : 71.96    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 80.0    Train Loss : 0.46,    Test Acc : 71.12    Test Loss : 0.58\n",
      "Epoch 60 - Train Acc : 81.67    Train Loss : 0.44,    Test Acc : 71.58    Test Loss : 0.58\n",
      "Epoch 70 - Train Acc : 82.5    Train Loss : 0.43,    Test Acc : 70.79    Test Loss : 0.59\n",
      "Epoch 80 - Train Acc : 84.17    Train Loss : 0.41,    Test Acc : 70.58    Test Loss : 0.6\n",
      "Epoch 90 - Train Acc : 84.17    Train Loss : 0.39,    Test Acc : 71.25    Test Loss : 0.61\n",
      "Epoch 100 - Train Acc : 86.67    Train Loss : 0.37,    Test Acc : 72.12    Test Loss : 0.61\n",
      "Epoch 110 - Train Acc : 86.67    Train Loss : 0.35,    Test Acc : 72.33    Test Loss : 0.6\n",
      "Epoch 120 - Train Acc : 86.67    Train Loss : 0.34,    Test Acc : 72.38    Test Loss : 0.6\n",
      "Epoch 130 - Train Acc : 85.83    Train Loss : 0.32,    Test Acc : 73.25    Test Loss : 0.61\n",
      "Epoch 140 - Train Acc : 86.67    Train Loss : 0.3,    Test Acc : 73.75    Test Loss : 0.62\n",
      "Epoch 150 - Train Acc : 87.5    Train Loss : 0.28,    Test Acc : 73.75    Test Loss : 0.64\n",
      "Epoch 160 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 74.46    Test Loss : 0.67\n",
      "Epoch 170 - Train Acc : 92.5    Train Loss : 0.25,    Test Acc : 74.71    Test Loss : 0.72\n",
      "Epoch 180 - Train Acc : 92.5    Train Loss : 0.23,    Test Acc : 75.08    Test Loss : 0.8\n",
      "Epoch 190 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 75.96    Test Loss : 0.87\n",
      "Epoch 200 - Train Acc : 92.5    Train Loss : 0.19,    Test Acc : 75.96    Test Loss : 0.96\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 75.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 17 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.51133997 0.18998672 0.05204487 0.04464509 0.03271103 0.02685497] \n",
      " Overall ratio:  0.8575826465968573\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.62,    Test Acc : 64.12    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 70.83    Train Loss : 0.56,    Test Acc : 61.92    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 70.83    Train Loss : 0.55,    Test Acc : 63.92    Test Loss : 0.72\n",
      "Epoch 40 - Train Acc : 69.17    Train Loss : 0.54,    Test Acc : 63.42    Test Loss : 0.72\n",
      "Epoch 50 - Train Acc : 70.83    Train Loss : 0.53,    Test Acc : 63.75    Test Loss : 0.69\n",
      "Epoch 60 - Train Acc : 71.67    Train Loss : 0.52,    Test Acc : 63.29    Test Loss : 0.7\n",
      "Epoch 70 - Train Acc : 71.67    Train Loss : 0.51,    Test Acc : 63.92    Test Loss : 0.71\n",
      "Epoch 80 - Train Acc : 72.5    Train Loss : 0.49,    Test Acc : 64.29    Test Loss : 0.71\n",
      "Epoch 90 - Train Acc : 75.0    Train Loss : 0.48,    Test Acc : 64.88    Test Loss : 0.73\n",
      "Epoch 100 - Train Acc : 78.33    Train Loss : 0.46,    Test Acc : 65.42    Test Loss : 0.76\n",
      "Epoch 110 - Train Acc : 79.17    Train Loss : 0.44,    Test Acc : 66.12    Test Loss : 0.8\n",
      "Epoch 120 - Train Acc : 79.17    Train Loss : 0.42,    Test Acc : 66.92    Test Loss : 0.84\n",
      "Epoch 130 - Train Acc : 80.83    Train Loss : 0.41,    Test Acc : 67.88    Test Loss : 0.89\n",
      "Epoch 140 - Train Acc : 81.67    Train Loss : 0.4,    Test Acc : 69.0    Test Loss : 0.96\n",
      "Epoch 150 - Train Acc : 80.0    Train Loss : 0.38,    Test Acc : 68.71    Test Loss : 1.03\n",
      "Epoch 160 - Train Acc : 80.0    Train Loss : 0.37,    Test Acc : 68.46    Test Loss : 1.12\n",
      "Epoch 170 - Train Acc : 80.0    Train Loss : 0.36,    Test Acc : 67.79    Test Loss : 1.2\n",
      "Epoch 180 - Train Acc : 79.17    Train Loss : 0.36,    Test Acc : 67.42    Test Loss : 1.28\n",
      "Epoch 190 - Train Acc : 80.0    Train Loss : 0.35,    Test Acc : 67.33    Test Loss : 1.36\n",
      "Epoch 200 - Train Acc : 79.17    Train Loss : 0.34,    Test Acc : 66.71    Test Loss : 1.43\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 66.71 ***\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.64,    Test Acc : 68.25    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 70.0    Train Loss : 0.58,    Test Acc : 64.67    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 72.5    Train Loss : 0.54,    Test Acc : 66.67    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 67.13    Test Loss : 0.7\n",
      "Epoch 50 - Train Acc : 74.17    Train Loss : 0.52,    Test Acc : 67.17    Test Loss : 0.69\n",
      "Epoch 60 - Train Acc : 74.17    Train Loss : 0.51,    Test Acc : 66.71    Test Loss : 0.69\n",
      "Epoch 70 - Train Acc : 77.5    Train Loss : 0.5,    Test Acc : 66.83    Test Loss : 0.7\n",
      "Epoch 80 - Train Acc : 80.0    Train Loss : 0.49,    Test Acc : 67.0    Test Loss : 0.72\n",
      "Epoch 90 - Train Acc : 80.0    Train Loss : 0.49,    Test Acc : 66.71    Test Loss : 0.74\n",
      "Epoch 100 - Train Acc : 80.0    Train Loss : 0.48,    Test Acc : 67.21    Test Loss : 0.75\n",
      "Epoch 110 - Train Acc : 80.0    Train Loss : 0.47,    Test Acc : 67.79    Test Loss : 0.76\n",
      "Epoch 120 - Train Acc : 81.67    Train Loss : 0.46,    Test Acc : 67.79    Test Loss : 0.77\n",
      "Epoch 130 - Train Acc : 80.83    Train Loss : 0.44,    Test Acc : 67.71    Test Loss : 0.78\n",
      "Epoch 140 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 67.17    Test Loss : 0.79\n",
      "Epoch 150 - Train Acc : 81.67    Train Loss : 0.4,    Test Acc : 66.62    Test Loss : 0.81\n",
      "Epoch 160 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 67.08    Test Loss : 0.85\n",
      "Epoch 170 - Train Acc : 83.33    Train Loss : 0.34,    Test Acc : 67.75    Test Loss : 0.89\n",
      "Epoch 180 - Train Acc : 84.17    Train Loss : 0.32,    Test Acc : 68.33    Test Loss : 0.92\n",
      "Epoch 190 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 68.25    Test Loss : 0.95\n",
      "Epoch 200 - Train Acc : 85.83    Train Loss : 0.28,    Test Acc : 68.12    Test Loss : 0.99\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 68.12 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 18 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.45500856 0.27365644 0.08954509 0.05228638 0.04110322 0.02312372] \n",
      " Overall ratio:  0.934723412117562\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.62,    Test Acc : 63.96    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.53,    Test Acc : 66.04    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 80.0    Train Loss : 0.45,    Test Acc : 71.42    Test Loss : 0.53\n",
      "Epoch 40 - Train Acc : 80.83    Train Loss : 0.38,    Test Acc : 73.33    Test Loss : 0.53\n",
      "Epoch 50 - Train Acc : 81.67    Train Loss : 0.35,    Test Acc : 74.54    Test Loss : 0.52\n",
      "Epoch 60 - Train Acc : 81.67    Train Loss : 0.34,    Test Acc : 75.54    Test Loss : 0.52\n",
      "Epoch 70 - Train Acc : 84.17    Train Loss : 0.32,    Test Acc : 75.67    Test Loss : 0.53\n",
      "Epoch 80 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 75.46    Test Loss : 0.53\n",
      "Epoch 90 - Train Acc : 86.67    Train Loss : 0.3,    Test Acc : 75.5    Test Loss : 0.54\n",
      "Epoch 100 - Train Acc : 87.5    Train Loss : 0.29,    Test Acc : 75.88    Test Loss : 0.56\n",
      "Epoch 110 - Train Acc : 87.5    Train Loss : 0.28,    Test Acc : 76.92    Test Loss : 0.58\n",
      "Epoch 120 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 77.92    Test Loss : 0.59\n",
      "Epoch 130 - Train Acc : 90.0    Train Loss : 0.25,    Test Acc : 78.58    Test Loss : 0.6\n",
      "Epoch 140 - Train Acc : 92.5    Train Loss : 0.24,    Test Acc : 78.79    Test Loss : 0.62\n",
      "Epoch 150 - Train Acc : 93.33    Train Loss : 0.23,    Test Acc : 79.33    Test Loss : 0.65\n",
      "Epoch 160 - Train Acc : 94.17    Train Loss : 0.22,    Test Acc : 79.33    Test Loss : 0.67\n",
      "Epoch 170 - Train Acc : 94.17    Train Loss : 0.21,    Test Acc : 79.63    Test Loss : 0.7\n",
      "Epoch 180 - Train Acc : 95.0    Train Loss : 0.2,    Test Acc : 79.88    Test Loss : 0.72\n",
      "Epoch 190 - Train Acc : 94.17    Train Loss : 0.2,    Test Acc : 80.08    Test Loss : 0.73\n",
      "Epoch 200 - Train Acc : 95.0    Train Loss : 0.19,    Test Acc : 79.92    Test Loss : 0.75\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.92 ***\n",
      "Epoch 10 - Train Acc : 64.17    Train Loss : 0.65,    Test Acc : 51.83    Test Loss : 0.69\n",
      "Epoch 20 - Train Acc : 64.17    Train Loss : 0.63,    Test Acc : 53.0    Test Loss : 0.71\n",
      "Epoch 30 - Train Acc : 62.5    Train Loss : 0.6,    Test Acc : 56.0    Test Loss : 0.69\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.56,    Test Acc : 60.46    Test Loss : 0.7\n",
      "Epoch 50 - Train Acc : 73.33    Train Loss : 0.53,    Test Acc : 65.21    Test Loss : 0.72\n",
      "Epoch 60 - Train Acc : 76.67    Train Loss : 0.5,    Test Acc : 68.12    Test Loss : 0.69\n",
      "Epoch 70 - Train Acc : 80.83    Train Loss : 0.47,    Test Acc : 68.5    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 79.17    Train Loss : 0.46,    Test Acc : 68.96    Test Loss : 0.69\n",
      "Epoch 90 - Train Acc : 79.17    Train Loss : 0.45,    Test Acc : 68.54    Test Loss : 0.7\n",
      "Epoch 100 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 68.04    Test Loss : 0.72\n",
      "Epoch 110 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 67.0    Test Loss : 0.75\n",
      "Epoch 120 - Train Acc : 78.33    Train Loss : 0.43,    Test Acc : 66.46    Test Loss : 0.79\n",
      "Epoch 130 - Train Acc : 78.33    Train Loss : 0.42,    Test Acc : 66.67    Test Loss : 0.82\n",
      "Epoch 140 - Train Acc : 79.17    Train Loss : 0.41,    Test Acc : 67.33    Test Loss : 0.86\n",
      "Epoch 150 - Train Acc : 79.17    Train Loss : 0.39,    Test Acc : 68.54    Test Loss : 0.89\n",
      "Epoch 160 - Train Acc : 83.33    Train Loss : 0.38,    Test Acc : 69.83    Test Loss : 0.92\n",
      "Epoch 170 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 70.75    Test Loss : 0.95\n",
      "Epoch 180 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 70.29    Test Loss : 0.99\n",
      "Epoch 190 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 70.5    Test Loss : 1.05\n",
      "Epoch 200 - Train Acc : 85.0    Train Loss : 0.3,    Test Acc : 71.08    Test Loss : 1.11\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 71.08 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 19 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.51210075 0.20727576 0.05449805 0.04206374 0.03852601 0.02942513] \n",
      " Overall ratio:  0.8838894482023049\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 62.5    Train Loss : 0.65,    Test Acc : 58.08    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 67.5    Train Loss : 0.63,    Test Acc : 61.58    Test Loss : 0.68\n",
      "Epoch 30 - Train Acc : 65.0    Train Loss : 0.62,    Test Acc : 65.25    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 68.33    Train Loss : 0.6,    Test Acc : 65.79    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 71.67    Train Loss : 0.57,    Test Acc : 69.79    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 75.83    Train Loss : 0.53,    Test Acc : 72.08    Test Loss : 0.59\n",
      "Epoch 70 - Train Acc : 76.67    Train Loss : 0.5,    Test Acc : 73.25    Test Loss : 0.57\n",
      "Epoch 80 - Train Acc : 80.0    Train Loss : 0.48,    Test Acc : 73.63    Test Loss : 0.56\n",
      "Epoch 90 - Train Acc : 79.17    Train Loss : 0.46,    Test Acc : 73.33    Test Loss : 0.56\n",
      "Epoch 100 - Train Acc : 80.0    Train Loss : 0.46,    Test Acc : 74.04    Test Loss : 0.55\n",
      "Epoch 110 - Train Acc : 78.33    Train Loss : 0.45,    Test Acc : 74.12    Test Loss : 0.54\n",
      "Epoch 120 - Train Acc : 77.5    Train Loss : 0.44,    Test Acc : 74.42    Test Loss : 0.53\n",
      "Epoch 130 - Train Acc : 76.67    Train Loss : 0.43,    Test Acc : 75.38    Test Loss : 0.51\n",
      "Epoch 140 - Train Acc : 79.17    Train Loss : 0.41,    Test Acc : 76.29    Test Loss : 0.48\n",
      "Epoch 150 - Train Acc : 81.67    Train Loss : 0.38,    Test Acc : 78.0    Test Loss : 0.45\n",
      "Epoch 160 - Train Acc : 83.33    Train Loss : 0.36,    Test Acc : 79.88    Test Loss : 0.42\n",
      "Epoch 170 - Train Acc : 85.83    Train Loss : 0.33,    Test Acc : 81.54    Test Loss : 0.41\n",
      "Epoch 180 - Train Acc : 87.5    Train Loss : 0.31,    Test Acc : 82.5    Test Loss : 0.41\n",
      "Epoch 190 - Train Acc : 89.17    Train Loss : 0.28,    Test Acc : 82.38    Test Loss : 0.41\n",
      "Epoch 200 - Train Acc : 86.67    Train Loss : 0.26,    Test Acc : 80.88    Test Loss : 0.44\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 80.88 ***\n",
      "Epoch 10 - Train Acc : 64.17    Train Loss : 0.64,    Test Acc : 75.17    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 72.5    Train Loss : 0.58,    Test Acc : 72.21    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 71.67    Train Loss : 0.56,    Test Acc : 74.54    Test Loss : 0.53\n",
      "Epoch 40 - Train Acc : 73.33    Train Loss : 0.55,    Test Acc : 72.79    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 73.33    Train Loss : 0.53,    Test Acc : 73.63    Test Loss : 0.51\n",
      "Epoch 60 - Train Acc : 73.33    Train Loss : 0.52,    Test Acc : 72.71    Test Loss : 0.51\n",
      "Epoch 70 - Train Acc : 75.83    Train Loss : 0.51,    Test Acc : 72.96    Test Loss : 0.5\n",
      "Epoch 80 - Train Acc : 75.0    Train Loss : 0.49,    Test Acc : 73.88    Test Loss : 0.49\n",
      "Epoch 90 - Train Acc : 76.67    Train Loss : 0.47,    Test Acc : 73.83    Test Loss : 0.49\n",
      "Epoch 100 - Train Acc : 77.5    Train Loss : 0.44,    Test Acc : 73.71    Test Loss : 0.47\n",
      "Epoch 110 - Train Acc : 80.0    Train Loss : 0.41,    Test Acc : 73.25    Test Loss : 0.47\n",
      "Epoch 120 - Train Acc : 85.0    Train Loss : 0.36,    Test Acc : 74.08    Test Loss : 0.48\n",
      "Epoch 130 - Train Acc : 88.33    Train Loss : 0.31,    Test Acc : 75.67    Test Loss : 0.49\n",
      "Epoch 140 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 75.75    Test Loss : 0.49\n",
      "Epoch 150 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 77.08    Test Loss : 0.52\n",
      "Epoch 160 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 77.62    Test Loss : 0.55\n",
      "Epoch 170 - Train Acc : 93.33    Train Loss : 0.18,    Test Acc : 78.21    Test Loss : 0.57\n",
      "Epoch 180 - Train Acc : 93.33    Train Loss : 0.15,    Test Acc : 78.58    Test Loss : 0.62\n",
      "Epoch 190 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 79.0    Test Loss : 0.68\n",
      "Epoch 200 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 79.54    Test Loss : 0.73\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.54 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 20 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (567,),    high arousal : (1953,)\n",
      "Explaned variance ratio by principal components : [0.36508439 0.30190392 0.08544304 0.05024928 0.03448712 0.02076544] \n",
      " Overall ratio:  0.8579331886759762\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 74.17    Train Loss : 0.6,    Test Acc : 71.96    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 73.42    Test Loss : 0.53\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.48,    Test Acc : 77.0    Test Loss : 0.49\n",
      "Epoch 40 - Train Acc : 81.67    Train Loss : 0.46,    Test Acc : 77.25    Test Loss : 0.48\n",
      "Epoch 50 - Train Acc : 79.17    Train Loss : 0.44,    Test Acc : 77.88    Test Loss : 0.47\n",
      "Epoch 60 - Train Acc : 79.17    Train Loss : 0.42,    Test Acc : 77.5    Test Loss : 0.48\n",
      "Epoch 70 - Train Acc : 82.5    Train Loss : 0.41,    Test Acc : 78.04    Test Loss : 0.51\n",
      "Epoch 80 - Train Acc : 83.33    Train Loss : 0.39,    Test Acc : 79.04    Test Loss : 0.54\n",
      "Epoch 90 - Train Acc : 81.67    Train Loss : 0.38,    Test Acc : 79.12    Test Loss : 0.56\n",
      "Epoch 100 - Train Acc : 81.67    Train Loss : 0.36,    Test Acc : 79.17    Test Loss : 0.59\n",
      "Epoch 110 - Train Acc : 82.5    Train Loss : 0.35,    Test Acc : 78.83    Test Loss : 0.64\n",
      "Epoch 120 - Train Acc : 82.5    Train Loss : 0.34,    Test Acc : 79.79    Test Loss : 0.69\n",
      "Epoch 130 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 80.21    Test Loss : 0.74\n",
      "Epoch 140 - Train Acc : 85.83    Train Loss : 0.32,    Test Acc : 80.67    Test Loss : 0.77\n",
      "Epoch 150 - Train Acc : 86.67    Train Loss : 0.31,    Test Acc : 81.21    Test Loss : 0.79\n",
      "Epoch 160 - Train Acc : 86.67    Train Loss : 0.3,    Test Acc : 81.62    Test Loss : 0.8\n",
      "Epoch 170 - Train Acc : 87.5    Train Loss : 0.29,    Test Acc : 82.25    Test Loss : 0.79\n",
      "Epoch 180 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 82.83    Test Loss : 0.76\n",
      "Epoch 190 - Train Acc : 88.33    Train Loss : 0.25,    Test Acc : 83.17    Test Loss : 0.72\n",
      "Epoch 200 - Train Acc : 89.17    Train Loss : 0.24,    Test Acc : 83.83    Test Loss : 0.64\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 83.83 ***\n",
      "Epoch 10 - Train Acc : 60.83    Train Loss : 0.66,    Test Acc : 76.38    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 56.67    Train Loss : 0.62,    Test Acc : 52.96    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 67.5    Train Loss : 0.58,    Test Acc : 65.21    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 73.33    Train Loss : 0.56,    Test Acc : 64.12    Test Loss : 0.6\n",
      "Epoch 50 - Train Acc : 75.0    Train Loss : 0.54,    Test Acc : 65.67    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 72.5    Train Loss : 0.52,    Test Acc : 62.46    Test Loss : 0.59\n",
      "Epoch 70 - Train Acc : 75.83    Train Loss : 0.5,    Test Acc : 65.42    Test Loss : 0.59\n",
      "Epoch 80 - Train Acc : 76.67    Train Loss : 0.48,    Test Acc : 66.29    Test Loss : 0.61\n",
      "Epoch 90 - Train Acc : 75.83    Train Loss : 0.47,    Test Acc : 66.71    Test Loss : 0.62\n",
      "Epoch 100 - Train Acc : 72.5    Train Loss : 0.46,    Test Acc : 67.29    Test Loss : 0.61\n",
      "Epoch 110 - Train Acc : 73.33    Train Loss : 0.45,    Test Acc : 67.21    Test Loss : 0.6\n",
      "Epoch 120 - Train Acc : 75.0    Train Loss : 0.44,    Test Acc : 67.5    Test Loss : 0.6\n",
      "Epoch 130 - Train Acc : 77.5    Train Loss : 0.43,    Test Acc : 68.21    Test Loss : 0.59\n",
      "Epoch 140 - Train Acc : 79.17    Train Loss : 0.42,    Test Acc : 69.21    Test Loss : 0.58\n",
      "Epoch 150 - Train Acc : 80.0    Train Loss : 0.41,    Test Acc : 70.46    Test Loss : 0.57\n",
      "Epoch 160 - Train Acc : 80.0    Train Loss : 0.39,    Test Acc : 71.58    Test Loss : 0.56\n",
      "Epoch 170 - Train Acc : 81.67    Train Loss : 0.37,    Test Acc : 73.17    Test Loss : 0.56\n",
      "Epoch 180 - Train Acc : 82.5    Train Loss : 0.34,    Test Acc : 74.62    Test Loss : 0.58\n",
      "Epoch 190 - Train Acc : 88.33    Train Loss : 0.31,    Test Acc : 75.33    Test Loss : 0.63\n",
      "Epoch 200 - Train Acc : 89.17    Train Loss : 0.28,    Test Acc : 74.62    Test Loss : 0.7\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 74.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 21 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (504,),    high arousal : (2016,)\n",
      "Explaned variance ratio by principal components : [0.59388807 0.18322285 0.0644886  0.04110107 0.02115446 0.01426468] \n",
      " Overall ratio:  0.9181197212062803\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 60.83    Train Loss : 0.67,    Test Acc : 58.67    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 66.67    Train Loss : 0.63,    Test Acc : 62.33    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 64.17    Train Loss : 0.59,    Test Acc : 60.96    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 66.67    Train Loss : 0.56,    Test Acc : 61.92    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 67.5    Train Loss : 0.54,    Test Acc : 64.38    Test Loss : 0.65\n",
      "Epoch 60 - Train Acc : 70.0    Train Loss : 0.53,    Test Acc : 63.67    Test Loss : 0.66\n",
      "Epoch 70 - Train Acc : 70.83    Train Loss : 0.52,    Test Acc : 64.29    Test Loss : 0.67\n",
      "Epoch 80 - Train Acc : 70.83    Train Loss : 0.51,    Test Acc : 65.25    Test Loss : 0.67\n",
      "Epoch 90 - Train Acc : 70.0    Train Loss : 0.5,    Test Acc : 66.46    Test Loss : 0.66\n",
      "Epoch 100 - Train Acc : 73.33    Train Loss : 0.49,    Test Acc : 67.17    Test Loss : 0.67\n",
      "Epoch 110 - Train Acc : 73.33    Train Loss : 0.48,    Test Acc : 67.08    Test Loss : 0.68\n",
      "Epoch 120 - Train Acc : 70.0    Train Loss : 0.47,    Test Acc : 67.08    Test Loss : 0.7\n",
      "Epoch 130 - Train Acc : 70.83    Train Loss : 0.46,    Test Acc : 66.79    Test Loss : 0.72\n",
      "Epoch 140 - Train Acc : 70.83    Train Loss : 0.45,    Test Acc : 65.88    Test Loss : 0.75\n",
      "Epoch 150 - Train Acc : 70.83    Train Loss : 0.44,    Test Acc : 65.54    Test Loss : 0.79\n",
      "Epoch 160 - Train Acc : 71.67    Train Loss : 0.43,    Test Acc : 65.33    Test Loss : 0.83\n",
      "Epoch 170 - Train Acc : 75.0    Train Loss : 0.42,    Test Acc : 65.54    Test Loss : 0.89\n",
      "Epoch 180 - Train Acc : 78.33    Train Loss : 0.4,    Test Acc : 65.21    Test Loss : 0.96\n",
      "Epoch 190 - Train Acc : 81.67    Train Loss : 0.39,    Test Acc : 66.08    Test Loss : 1.04\n",
      "Epoch 200 - Train Acc : 85.0    Train Loss : 0.37,    Test Acc : 66.5    Test Loss : 1.12\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 66.5 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.66,    Test Acc : 69.04    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 74.17    Train Loss : 0.61,    Test Acc : 60.67    Test Loss : 0.7\n",
      "Epoch 30 - Train Acc : 70.83    Train Loss : 0.57,    Test Acc : 64.42    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.54,    Test Acc : 60.92    Test Loss : 0.67\n",
      "Epoch 50 - Train Acc : 70.83    Train Loss : 0.52,    Test Acc : 59.25    Test Loss : 0.65\n",
      "Epoch 60 - Train Acc : 70.83    Train Loss : 0.49,    Test Acc : 60.17    Test Loss : 0.63\n",
      "Epoch 70 - Train Acc : 74.17    Train Loss : 0.46,    Test Acc : 62.08    Test Loss : 0.61\n",
      "Epoch 80 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 64.71    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 68.38    Test Loss : 0.57\n",
      "Epoch 100 - Train Acc : 83.33    Train Loss : 0.38,    Test Acc : 70.17    Test Loss : 0.56\n",
      "Epoch 110 - Train Acc : 85.0    Train Loss : 0.36,    Test Acc : 71.08    Test Loss : 0.55\n",
      "Epoch 120 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 70.58    Test Loss : 0.56\n",
      "Epoch 130 - Train Acc : 83.33    Train Loss : 0.32,    Test Acc : 71.88    Test Loss : 0.58\n",
      "Epoch 140 - Train Acc : 84.17    Train Loss : 0.3,    Test Acc : 72.12    Test Loss : 0.61\n",
      "Epoch 150 - Train Acc : 86.67    Train Loss : 0.28,    Test Acc : 73.04    Test Loss : 0.63\n",
      "Epoch 160 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 74.46    Test Loss : 0.65\n",
      "Epoch 170 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 76.08    Test Loss : 0.67\n",
      "Epoch 180 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 77.38    Test Loss : 0.69\n",
      "Epoch 190 - Train Acc : 93.33    Train Loss : 0.19,    Test Acc : 79.21    Test Loss : 0.7\n",
      "Epoch 200 - Train Acc : 95.0    Train Loss : 0.16,    Test Acc : 79.67    Test Loss : 0.72\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.67 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 22 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.47119558 0.40222649 0.05971501 0.02436959 0.01386209 0.00802466] \n",
      " Overall ratio:  0.9793934171432365\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.6,    Test Acc : 69.0    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 73.33    Train Loss : 0.55,    Test Acc : 71.38    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 73.33    Train Loss : 0.54,    Test Acc : 70.96    Test Loss : 0.61\n",
      "Epoch 40 - Train Acc : 73.33    Train Loss : 0.54,    Test Acc : 71.75    Test Loss : 0.6\n",
      "Epoch 50 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 71.42    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 75.0    Train Loss : 0.53,    Test Acc : 71.54    Test Loss : 0.59\n",
      "Epoch 70 - Train Acc : 74.17    Train Loss : 0.52,    Test Acc : 71.46    Test Loss : 0.6\n",
      "Epoch 80 - Train Acc : 75.0    Train Loss : 0.5,    Test Acc : 71.5    Test Loss : 0.6\n",
      "Epoch 90 - Train Acc : 74.17    Train Loss : 0.48,    Test Acc : 71.92    Test Loss : 0.6\n",
      "Epoch 100 - Train Acc : 73.33    Train Loss : 0.46,    Test Acc : 71.79    Test Loss : 0.62\n",
      "Epoch 110 - Train Acc : 74.17    Train Loss : 0.44,    Test Acc : 70.96    Test Loss : 0.64\n",
      "Epoch 120 - Train Acc : 75.83    Train Loss : 0.42,    Test Acc : 71.71    Test Loss : 0.66\n",
      "Epoch 130 - Train Acc : 77.5    Train Loss : 0.39,    Test Acc : 72.75    Test Loss : 0.67\n",
      "Epoch 140 - Train Acc : 80.83    Train Loss : 0.36,    Test Acc : 73.5    Test Loss : 0.7\n",
      "Epoch 150 - Train Acc : 82.5    Train Loss : 0.34,    Test Acc : 74.58    Test Loss : 0.76\n",
      "Epoch 160 - Train Acc : 84.17    Train Loss : 0.31,    Test Acc : 74.04    Test Loss : 0.85\n",
      "Epoch 170 - Train Acc : 85.83    Train Loss : 0.29,    Test Acc : 74.0    Test Loss : 0.94\n",
      "Epoch 180 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 73.63    Test Loss : 1.04\n",
      "Epoch 190 - Train Acc : 87.5    Train Loss : 0.25,    Test Acc : 73.5    Test Loss : 1.14\n",
      "Epoch 200 - Train Acc : 92.5    Train Loss : 0.23,    Test Acc : 72.83    Test Loss : 1.23\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 72.83 ***\n",
      "Epoch 10 - Train Acc : 57.5    Train Loss : 0.67,    Test Acc : 57.58    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 67.5    Train Loss : 0.62,    Test Acc : 61.04    Test Loss : 0.69\n",
      "Epoch 30 - Train Acc : 63.33    Train Loss : 0.59,    Test Acc : 59.12    Test Loss : 0.7\n",
      "Epoch 40 - Train Acc : 66.67    Train Loss : 0.58,    Test Acc : 59.96    Test Loss : 0.72\n",
      "Epoch 50 - Train Acc : 69.17    Train Loss : 0.56,    Test Acc : 60.21    Test Loss : 0.71\n",
      "Epoch 60 - Train Acc : 68.33    Train Loss : 0.55,    Test Acc : 62.21    Test Loss : 0.68\n",
      "Epoch 70 - Train Acc : 69.17    Train Loss : 0.52,    Test Acc : 61.42    Test Loss : 0.68\n",
      "Epoch 80 - Train Acc : 71.67    Train Loss : 0.49,    Test Acc : 62.08    Test Loss : 0.67\n",
      "Epoch 90 - Train Acc : 78.33    Train Loss : 0.46,    Test Acc : 63.42    Test Loss : 0.66\n",
      "Epoch 100 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 64.54    Test Loss : 0.68\n",
      "Epoch 110 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 63.67    Test Loss : 0.72\n",
      "Epoch 120 - Train Acc : 80.83    Train Loss : 0.41,    Test Acc : 64.46    Test Loss : 0.74\n",
      "Epoch 130 - Train Acc : 80.83    Train Loss : 0.39,    Test Acc : 65.88    Test Loss : 0.74\n",
      "Epoch 140 - Train Acc : 82.5    Train Loss : 0.38,    Test Acc : 66.75    Test Loss : 0.75\n",
      "Epoch 150 - Train Acc : 82.5    Train Loss : 0.36,    Test Acc : 67.21    Test Loss : 0.77\n",
      "Epoch 160 - Train Acc : 80.0    Train Loss : 0.35,    Test Acc : 66.96    Test Loss : 0.8\n",
      "Epoch 170 - Train Acc : 81.67    Train Loss : 0.34,    Test Acc : 65.96    Test Loss : 0.82\n",
      "Epoch 180 - Train Acc : 82.5    Train Loss : 0.32,    Test Acc : 66.04    Test Loss : 0.82\n",
      "Epoch 190 - Train Acc : 85.0    Train Loss : 0.3,    Test Acc : 67.75    Test Loss : 0.82\n",
      "Epoch 200 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 68.58    Test Loss : 0.8\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 68.58 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 23 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1701,),    high arousal : (819,)\n",
      "Explaned variance ratio by principal components : [0.42449235 0.18976918 0.09371976 0.05809049 0.04000829 0.0259987 ] \n",
      " Overall ratio:  0.8320787702028869\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 68.33    Train Loss : 0.65,    Test Acc : 70.5    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 62.5    Train Loss : 0.61,    Test Acc : 59.17    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 67.5    Train Loss : 0.59,    Test Acc : 66.29    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 68.33    Train Loss : 0.58,    Test Acc : 68.58    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 71.67    Train Loss : 0.57,    Test Acc : 69.0    Test Loss : 0.63\n",
      "Epoch 60 - Train Acc : 73.33    Train Loss : 0.54,    Test Acc : 70.79    Test Loss : 0.61\n",
      "Epoch 70 - Train Acc : 75.83    Train Loss : 0.5,    Test Acc : 74.21    Test Loss : 0.58\n",
      "Epoch 80 - Train Acc : 81.67    Train Loss : 0.45,    Test Acc : 76.12    Test Loss : 0.56\n",
      "Epoch 90 - Train Acc : 80.0    Train Loss : 0.41,    Test Acc : 75.04    Test Loss : 0.56\n",
      "Epoch 100 - Train Acc : 81.67    Train Loss : 0.39,    Test Acc : 73.67    Test Loss : 0.57\n",
      "Epoch 110 - Train Acc : 83.33    Train Loss : 0.36,    Test Acc : 74.92    Test Loss : 0.56\n",
      "Epoch 120 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 74.42    Test Loss : 0.55\n",
      "Epoch 130 - Train Acc : 85.0    Train Loss : 0.32,    Test Acc : 75.83    Test Loss : 0.54\n",
      "Epoch 140 - Train Acc : 88.33    Train Loss : 0.29,    Test Acc : 76.83    Test Loss : 0.55\n",
      "Epoch 150 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 77.54    Test Loss : 0.57\n",
      "Epoch 160 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 78.04    Test Loss : 0.58\n",
      "Epoch 170 - Train Acc : 90.83    Train Loss : 0.25,    Test Acc : 78.42    Test Loss : 0.59\n",
      "Epoch 180 - Train Acc : 90.83    Train Loss : 0.23,    Test Acc : 78.54    Test Loss : 0.58\n",
      "Epoch 190 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 78.71    Test Loss : 0.57\n",
      "Epoch 200 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 79.54    Test Loss : 0.57\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.54 ***\n",
      "Epoch 10 - Train Acc : 57.5    Train Loss : 0.68,    Test Acc : 45.42    Test Loss : 0.71\n",
      "Epoch 20 - Train Acc : 61.67    Train Loss : 0.66,    Test Acc : 55.58    Test Loss : 0.69\n",
      "Epoch 30 - Train Acc : 63.33    Train Loss : 0.65,    Test Acc : 56.79    Test Loss : 0.7\n",
      "Epoch 40 - Train Acc : 66.67    Train Loss : 0.63,    Test Acc : 57.62    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 68.33    Train Loss : 0.6,    Test Acc : 59.46    Test Loss : 0.67\n",
      "Epoch 60 - Train Acc : 70.0    Train Loss : 0.56,    Test Acc : 61.33    Test Loss : 0.68\n",
      "Epoch 70 - Train Acc : 70.83    Train Loss : 0.53,    Test Acc : 61.04    Test Loss : 0.71\n",
      "Epoch 80 - Train Acc : 69.17    Train Loss : 0.52,    Test Acc : 61.46    Test Loss : 0.76\n",
      "Epoch 90 - Train Acc : 70.0    Train Loss : 0.51,    Test Acc : 61.75    Test Loss : 0.78\n",
      "Epoch 100 - Train Acc : 70.83    Train Loss : 0.49,    Test Acc : 61.79    Test Loss : 0.82\n",
      "Epoch 110 - Train Acc : 74.17    Train Loss : 0.46,    Test Acc : 63.38    Test Loss : 0.89\n",
      "Epoch 120 - Train Acc : 78.33    Train Loss : 0.42,    Test Acc : 66.04    Test Loss : 0.96\n",
      "Epoch 130 - Train Acc : 83.33    Train Loss : 0.38,    Test Acc : 69.54    Test Loss : 1.05\n",
      "Epoch 140 - Train Acc : 89.17    Train Loss : 0.33,    Test Acc : 70.54    Test Loss : 1.19\n",
      "Epoch 150 - Train Acc : 91.67    Train Loss : 0.28,    Test Acc : 73.17    Test Loss : 1.37\n",
      "Epoch 160 - Train Acc : 92.5    Train Loss : 0.25,    Test Acc : 74.46    Test Loss : 1.59\n",
      "Epoch 170 - Train Acc : 92.5    Train Loss : 0.22,    Test Acc : 75.12    Test Loss : 1.82\n",
      "Epoch 180 - Train Acc : 93.33    Train Loss : 0.19,    Test Acc : 75.62    Test Loss : 2.09\n",
      "Epoch 190 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 76.83    Test Loss : 2.39\n",
      "Epoch 200 - Train Acc : 95.83    Train Loss : 0.14,    Test Acc : 76.21    Test Loss : 2.76\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 76.21 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 24 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "Explaned variance ratio by principal components : [0.63743425 0.21249161 0.035946   0.02538881 0.01366706 0.00966347] \n",
      " Overall ratio:  0.9345912009273653\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 60.0    Train Loss : 0.67,    Test Acc : 58.54    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 65.0    Train Loss : 0.64,    Test Acc : 65.21    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 69.17    Train Loss : 0.61,    Test Acc : 65.42    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 71.67    Train Loss : 0.6,    Test Acc : 65.79    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 70.83    Train Loss : 0.59,    Test Acc : 65.08    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 68.33    Train Loss : 0.57,    Test Acc : 64.38    Test Loss : 0.65\n",
      "Epoch 70 - Train Acc : 69.17    Train Loss : 0.56,    Test Acc : 64.33    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 72.5    Train Loss : 0.54,    Test Acc : 63.17    Test Loss : 0.67\n",
      "Epoch 90 - Train Acc : 75.0    Train Loss : 0.51,    Test Acc : 61.63    Test Loss : 0.68\n",
      "Epoch 100 - Train Acc : 77.5    Train Loss : 0.47,    Test Acc : 61.33    Test Loss : 0.69\n",
      "Epoch 110 - Train Acc : 78.33    Train Loss : 0.43,    Test Acc : 61.13    Test Loss : 0.73\n",
      "Epoch 120 - Train Acc : 79.17    Train Loss : 0.38,    Test Acc : 60.17    Test Loss : 0.79\n",
      "Epoch 130 - Train Acc : 81.67    Train Loss : 0.35,    Test Acc : 60.88    Test Loss : 0.88\n",
      "Epoch 140 - Train Acc : 83.33    Train Loss : 0.33,    Test Acc : 61.67    Test Loss : 0.94\n",
      "Epoch 150 - Train Acc : 85.0    Train Loss : 0.31,    Test Acc : 62.38    Test Loss : 0.97\n",
      "Epoch 160 - Train Acc : 85.0    Train Loss : 0.29,    Test Acc : 62.79    Test Loss : 1.0\n",
      "Epoch 170 - Train Acc : 85.0    Train Loss : 0.28,    Test Acc : 62.63    Test Loss : 1.02\n",
      "Epoch 180 - Train Acc : 83.33    Train Loss : 0.27,    Test Acc : 62.5    Test Loss : 1.05\n",
      "Epoch 190 - Train Acc : 83.33    Train Loss : 0.27,    Test Acc : 62.58    Test Loss : 1.08\n",
      "Epoch 200 - Train Acc : 83.33    Train Loss : 0.26,    Test Acc : 63.08    Test Loss : 1.11\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 63.08 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.64,    Test Acc : 51.25    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.57,    Test Acc : 56.0    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 75.83    Train Loss : 0.52,    Test Acc : 67.38    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 76.67    Train Loss : 0.49,    Test Acc : 71.0    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 74.17    Train Loss : 0.48,    Test Acc : 73.33    Test Loss : 0.49\n",
      "Epoch 60 - Train Acc : 75.0    Train Loss : 0.47,    Test Acc : 72.92    Test Loss : 0.5\n",
      "Epoch 70 - Train Acc : 76.67    Train Loss : 0.46,    Test Acc : 73.25    Test Loss : 0.49\n",
      "Epoch 80 - Train Acc : 79.17    Train Loss : 0.45,    Test Acc : 73.63    Test Loss : 0.48\n",
      "Epoch 90 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 73.92    Test Loss : 0.48\n",
      "Epoch 100 - Train Acc : 79.17    Train Loss : 0.41,    Test Acc : 74.08    Test Loss : 0.49\n",
      "Epoch 110 - Train Acc : 80.83    Train Loss : 0.39,    Test Acc : 74.58    Test Loss : 0.5\n",
      "Epoch 120 - Train Acc : 80.83    Train Loss : 0.37,    Test Acc : 75.21    Test Loss : 0.52\n",
      "Epoch 130 - Train Acc : 82.5    Train Loss : 0.35,    Test Acc : 76.21    Test Loss : 0.53\n",
      "Epoch 140 - Train Acc : 85.83    Train Loss : 0.33,    Test Acc : 76.29    Test Loss : 0.53\n",
      "Epoch 150 - Train Acc : 86.67    Train Loss : 0.3,    Test Acc : 77.33    Test Loss : 0.54\n",
      "Epoch 160 - Train Acc : 90.0    Train Loss : 0.28,    Test Acc : 77.33    Test Loss : 0.55\n",
      "Epoch 170 - Train Acc : 91.67    Train Loss : 0.26,    Test Acc : 77.62    Test Loss : 0.58\n",
      "Epoch 180 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 78.21    Test Loss : 0.63\n",
      "Epoch 190 - Train Acc : 90.83    Train Loss : 0.22,    Test Acc : 78.58    Test Loss : 0.68\n",
      "Epoch 200 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 79.21    Test Loss : 0.72\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 79.21 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 25 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (630,),    high arousal : (1890,)\n",
      "Explaned variance ratio by principal components : [0.47178681 0.28829264 0.09576637 0.04040026 0.03346586 0.02253163] \n",
      " Overall ratio:  0.9522435601348437\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 72.5    Train Loss : 0.63,    Test Acc : 63.33    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 68.33    Train Loss : 0.56,    Test Acc : 62.96    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 65.5    Test Loss : 0.65\n",
      "Epoch 40 - Train Acc : 78.33    Train Loss : 0.51,    Test Acc : 66.0    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 76.67    Train Loss : 0.49,    Test Acc : 66.42    Test Loss : 0.67\n",
      "Epoch 60 - Train Acc : 76.67    Train Loss : 0.47,    Test Acc : 67.58    Test Loss : 0.66\n",
      "Epoch 70 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 68.5    Test Loss : 0.65\n",
      "Epoch 80 - Train Acc : 78.33    Train Loss : 0.41,    Test Acc : 69.21    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 80.0    Train Loss : 0.38,    Test Acc : 70.0    Test Loss : 0.67\n",
      "Epoch 100 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 71.88    Test Loss : 0.67\n",
      "Epoch 110 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 73.17    Test Loss : 0.66\n",
      "Epoch 120 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 74.08    Test Loss : 0.68\n",
      "Epoch 130 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 74.33    Test Loss : 0.74\n",
      "Epoch 140 - Train Acc : 91.67    Train Loss : 0.22,    Test Acc : 74.5    Test Loss : 0.82\n",
      "Epoch 150 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 74.88    Test Loss : 0.91\n",
      "Epoch 160 - Train Acc : 93.33    Train Loss : 0.2,    Test Acc : 75.0    Test Loss : 0.98\n",
      "Epoch 170 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 75.33    Test Loss : 1.03\n",
      "Epoch 180 - Train Acc : 94.17    Train Loss : 0.18,    Test Acc : 75.08    Test Loss : 1.07\n",
      "Epoch 190 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 75.08    Test Loss : 1.11\n",
      "Epoch 200 - Train Acc : 95.0    Train Loss : 0.16,    Test Acc : 75.21    Test Loss : 1.15\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 75.21 ***\n",
      "Epoch 10 - Train Acc : 54.17    Train Loss : 0.67,    Test Acc : 44.04    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 65.0    Train Loss : 0.65,    Test Acc : 52.29    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.61,    Test Acc : 66.08    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 76.67    Train Loss : 0.58,    Test Acc : 63.88    Test Loss : 0.61\n",
      "Epoch 50 - Train Acc : 78.33    Train Loss : 0.55,    Test Acc : 65.5    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 83.33    Train Loss : 0.51,    Test Acc : 65.54    Test Loss : 0.61\n",
      "Epoch 70 - Train Acc : 82.5    Train Loss : 0.47,    Test Acc : 67.17    Test Loss : 0.6\n",
      "Epoch 80 - Train Acc : 83.33    Train Loss : 0.44,    Test Acc : 69.46    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 81.67    Train Loss : 0.43,    Test Acc : 70.58    Test Loss : 0.59\n",
      "Epoch 100 - Train Acc : 80.83    Train Loss : 0.41,    Test Acc : 71.33    Test Loss : 0.58\n",
      "Epoch 110 - Train Acc : 81.67    Train Loss : 0.4,    Test Acc : 71.96    Test Loss : 0.59\n",
      "Epoch 120 - Train Acc : 83.33    Train Loss : 0.38,    Test Acc : 72.58    Test Loss : 0.58\n",
      "Epoch 130 - Train Acc : 84.17    Train Loss : 0.37,    Test Acc : 72.92    Test Loss : 0.58\n",
      "Epoch 140 - Train Acc : 85.0    Train Loss : 0.36,    Test Acc : 73.33    Test Loss : 0.57\n",
      "Epoch 150 - Train Acc : 86.67    Train Loss : 0.34,    Test Acc : 74.38    Test Loss : 0.56\n",
      "Epoch 160 - Train Acc : 88.33    Train Loss : 0.31,    Test Acc : 75.17    Test Loss : 0.56\n",
      "Epoch 170 - Train Acc : 90.0    Train Loss : 0.29,    Test Acc : 74.79    Test Loss : 0.62\n",
      "Epoch 180 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 74.5    Test Loss : 0.73\n",
      "Epoch 190 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 74.0    Test Loss : 0.84\n",
      "Epoch 200 - Train Acc : 90.0    Train Loss : 0.23,    Test Acc : 73.67    Test Loss : 0.91\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 73.67 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 26 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "Explaned variance ratio by principal components : [0.56648751 0.25244451 0.0436146  0.02954773 0.02000295 0.01559967] \n",
      " Overall ratio:  0.9276969694469024\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 66.67    Train Loss : 0.65,    Test Acc : 61.58    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.6,    Test Acc : 63.88    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 74.17    Train Loss : 0.54,    Test Acc : 69.75    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 77.5    Train Loss : 0.5,    Test Acc : 72.21    Test Loss : 0.54\n",
      "Epoch 50 - Train Acc : 77.5    Train Loss : 0.48,    Test Acc : 72.54    Test Loss : 0.55\n",
      "Epoch 60 - Train Acc : 78.33    Train Loss : 0.46,    Test Acc : 74.29    Test Loss : 0.53\n",
      "Epoch 70 - Train Acc : 79.17    Train Loss : 0.45,    Test Acc : 74.96    Test Loss : 0.51\n",
      "Epoch 80 - Train Acc : 80.0    Train Loss : 0.43,    Test Acc : 75.12    Test Loss : 0.5\n",
      "Epoch 90 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 75.0    Test Loss : 0.51\n",
      "Epoch 100 - Train Acc : 80.83    Train Loss : 0.41,    Test Acc : 75.17    Test Loss : 0.5\n",
      "Epoch 110 - Train Acc : 81.67    Train Loss : 0.39,    Test Acc : 75.62    Test Loss : 0.5\n",
      "Epoch 120 - Train Acc : 83.33    Train Loss : 0.37,    Test Acc : 76.08    Test Loss : 0.5\n",
      "Epoch 130 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 76.04    Test Loss : 0.5\n",
      "Epoch 140 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 76.04    Test Loss : 0.5\n",
      "Epoch 150 - Train Acc : 85.83    Train Loss : 0.33,    Test Acc : 76.12    Test Loss : 0.51\n",
      "Epoch 160 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 76.71    Test Loss : 0.53\n",
      "Epoch 170 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 76.88    Test Loss : 0.54\n",
      "Epoch 180 - Train Acc : 87.5    Train Loss : 0.28,    Test Acc : 77.04    Test Loss : 0.54\n",
      "Epoch 190 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 77.75    Test Loss : 0.55\n",
      "Epoch 200 - Train Acc : 88.33    Train Loss : 0.25,    Test Acc : 78.0    Test Loss : 0.56\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.0 ***\n",
      "Epoch 10 - Train Acc : 62.5    Train Loss : 0.65,    Test Acc : 60.96    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 63.33    Train Loss : 0.61,    Test Acc : 66.5    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 60.83    Train Loss : 0.58,    Test Acc : 68.17    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 65.83    Train Loss : 0.56,    Test Acc : 69.42    Test Loss : 0.57\n",
      "Epoch 50 - Train Acc : 67.5    Train Loss : 0.56,    Test Acc : 69.88    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 66.67    Train Loss : 0.54,    Test Acc : 70.62    Test Loss : 0.56\n",
      "Epoch 70 - Train Acc : 71.67    Train Loss : 0.53,    Test Acc : 72.04    Test Loss : 0.55\n",
      "Epoch 80 - Train Acc : 73.33    Train Loss : 0.51,    Test Acc : 72.12    Test Loss : 0.54\n",
      "Epoch 90 - Train Acc : 72.5    Train Loss : 0.49,    Test Acc : 72.29    Test Loss : 0.54\n",
      "Epoch 100 - Train Acc : 74.17    Train Loss : 0.47,    Test Acc : 72.58    Test Loss : 0.54\n",
      "Epoch 110 - Train Acc : 72.5    Train Loss : 0.45,    Test Acc : 73.25    Test Loss : 0.54\n",
      "Epoch 120 - Train Acc : 75.83    Train Loss : 0.42,    Test Acc : 74.08    Test Loss : 0.53\n",
      "Epoch 130 - Train Acc : 80.83    Train Loss : 0.39,    Test Acc : 75.33    Test Loss : 0.53\n",
      "Epoch 140 - Train Acc : 85.0    Train Loss : 0.36,    Test Acc : 76.83    Test Loss : 0.54\n",
      "Epoch 150 - Train Acc : 87.5    Train Loss : 0.33,    Test Acc : 77.38    Test Loss : 0.57\n",
      "Epoch 160 - Train Acc : 88.33    Train Loss : 0.3,    Test Acc : 78.33    Test Loss : 0.6\n",
      "Epoch 170 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 78.71    Test Loss : 0.65\n",
      "Epoch 180 - Train Acc : 88.33    Train Loss : 0.25,    Test Acc : 78.88    Test Loss : 0.73\n",
      "Epoch 190 - Train Acc : 86.67    Train Loss : 0.23,    Test Acc : 78.83    Test Loss : 0.82\n",
      "Epoch 200 - Train Acc : 85.83    Train Loss : 0.22,    Test Acc : 78.62    Test Loss : 0.88\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 78.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 27 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.60467016 0.19630067 0.05386153 0.04188624 0.03585332 0.01667116] \n",
      " Overall ratio:  0.9492430806813116\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 70.83    Train Loss : 0.63,    Test Acc : 79.58    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 68.33    Train Loss : 0.57,    Test Acc : 76.79    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 70.83    Train Loss : 0.54,    Test Acc : 77.62    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.53,    Test Acc : 78.21    Test Loss : 0.57\n",
      "Epoch 50 - Train Acc : 73.33    Train Loss : 0.52,    Test Acc : 78.0    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 72.5    Train Loss : 0.51,    Test Acc : 78.12    Test Loss : 0.56\n",
      "Epoch 70 - Train Acc : 74.17    Train Loss : 0.51,    Test Acc : 78.12    Test Loss : 0.56\n",
      "Epoch 80 - Train Acc : 75.0    Train Loss : 0.5,    Test Acc : 78.21    Test Loss : 0.56\n",
      "Epoch 90 - Train Acc : 75.83    Train Loss : 0.5,    Test Acc : 78.58    Test Loss : 0.55\n",
      "Epoch 100 - Train Acc : 76.67    Train Loss : 0.49,    Test Acc : 79.33    Test Loss : 0.55\n",
      "Epoch 110 - Train Acc : 77.5    Train Loss : 0.47,    Test Acc : 79.17    Test Loss : 0.54\n",
      "Epoch 120 - Train Acc : 80.83    Train Loss : 0.46,    Test Acc : 79.46    Test Loss : 0.53\n",
      "Epoch 130 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 78.75    Test Loss : 0.55\n",
      "Epoch 140 - Train Acc : 81.67    Train Loss : 0.43,    Test Acc : 80.08    Test Loss : 0.57\n",
      "Epoch 150 - Train Acc : 81.67    Train Loss : 0.42,    Test Acc : 79.79    Test Loss : 0.6\n",
      "Epoch 160 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 79.83    Test Loss : 0.63\n",
      "Epoch 170 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 80.0    Test Loss : 0.64\n",
      "Epoch 180 - Train Acc : 83.33    Train Loss : 0.4,    Test Acc : 80.38    Test Loss : 0.66\n",
      "Epoch 190 - Train Acc : 83.33    Train Loss : 0.4,    Test Acc : 80.58    Test Loss : 0.67\n",
      "Epoch 200 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 80.75    Test Loss : 0.67\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 80.75 ***\n",
      "Epoch 10 - Train Acc : 62.5    Train Loss : 0.67,    Test Acc : 69.04    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 64.17    Train Loss : 0.64,    Test Acc : 66.5    Test Loss : 0.68\n",
      "Epoch 30 - Train Acc : 64.17    Train Loss : 0.64,    Test Acc : 66.12    Test Loss : 0.69\n",
      "Epoch 40 - Train Acc : 62.5    Train Loss : 0.63,    Test Acc : 66.46    Test Loss : 0.67\n",
      "Epoch 50 - Train Acc : 64.17    Train Loss : 0.62,    Test Acc : 68.33    Test Loss : 0.65\n",
      "Epoch 60 - Train Acc : 65.83    Train Loss : 0.61,    Test Acc : 69.67    Test Loss : 0.64\n",
      "Epoch 70 - Train Acc : 69.17    Train Loss : 0.58,    Test Acc : 69.33    Test Loss : 0.62\n",
      "Epoch 80 - Train Acc : 70.0    Train Loss : 0.55,    Test Acc : 68.92    Test Loss : 0.6\n",
      "Epoch 90 - Train Acc : 71.67    Train Loss : 0.52,    Test Acc : 68.21    Test Loss : 0.6\n",
      "Epoch 100 - Train Acc : 74.17    Train Loss : 0.49,    Test Acc : 68.12    Test Loss : 0.6\n",
      "Epoch 110 - Train Acc : 80.0    Train Loss : 0.46,    Test Acc : 69.21    Test Loss : 0.59\n",
      "Epoch 120 - Train Acc : 80.0    Train Loss : 0.43,    Test Acc : 69.62    Test Loss : 0.59\n",
      "Epoch 130 - Train Acc : 80.0    Train Loss : 0.41,    Test Acc : 71.92    Test Loss : 0.57\n",
      "Epoch 140 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 72.04    Test Loss : 0.57\n",
      "Epoch 150 - Train Acc : 84.17    Train Loss : 0.37,    Test Acc : 71.96    Test Loss : 0.58\n",
      "Epoch 160 - Train Acc : 83.33    Train Loss : 0.36,    Test Acc : 72.62    Test Loss : 0.59\n",
      "Epoch 170 - Train Acc : 84.17    Train Loss : 0.35,    Test Acc : 73.17    Test Loss : 0.6\n",
      "Epoch 180 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 73.54    Test Loss : 0.61\n",
      "Epoch 190 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 73.42    Test Loss : 0.63\n",
      "Epoch 200 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 73.25    Test Loss : 0.64\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 73.25 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 28 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.4623089  0.23444884 0.10405433 0.04639846 0.03494082 0.01930008] \n",
      " Overall ratio:  0.9014514179217936\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.58,    Test Acc : 69.75    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.49,    Test Acc : 68.0    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 71.62    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 80.83    Train Loss : 0.43,    Test Acc : 74.42    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 74.83    Test Loss : 0.54\n",
      "Epoch 60 - Train Acc : 81.67    Train Loss : 0.4,    Test Acc : 74.67    Test Loss : 0.54\n",
      "Epoch 70 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 74.92    Test Loss : 0.54\n",
      "Epoch 80 - Train Acc : 84.17    Train Loss : 0.37,    Test Acc : 74.96    Test Loss : 0.54\n",
      "Epoch 90 - Train Acc : 85.83    Train Loss : 0.36,    Test Acc : 75.33    Test Loss : 0.55\n",
      "Epoch 100 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 75.83    Test Loss : 0.55\n",
      "Epoch 110 - Train Acc : 85.83    Train Loss : 0.33,    Test Acc : 75.67    Test Loss : 0.56\n",
      "Epoch 120 - Train Acc : 85.83    Train Loss : 0.32,    Test Acc : 76.33    Test Loss : 0.57\n",
      "Epoch 130 - Train Acc : 86.67    Train Loss : 0.31,    Test Acc : 76.58    Test Loss : 0.57\n",
      "Epoch 140 - Train Acc : 87.5    Train Loss : 0.3,    Test Acc : 76.58    Test Loss : 0.58\n",
      "Epoch 150 - Train Acc : 89.17    Train Loss : 0.29,    Test Acc : 76.79    Test Loss : 0.59\n",
      "Epoch 160 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 77.04    Test Loss : 0.59\n",
      "Epoch 170 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 77.21    Test Loss : 0.6\n",
      "Epoch 180 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 77.42    Test Loss : 0.6\n",
      "Epoch 190 - Train Acc : 88.33    Train Loss : 0.26,    Test Acc : 77.71    Test Loss : 0.6\n",
      "Epoch 200 - Train Acc : 87.5    Train Loss : 0.25,    Test Acc : 77.83    Test Loss : 0.61\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 77.83 ***\n",
      "Epoch 10 - Train Acc : 52.5    Train Loss : 0.67,    Test Acc : 58.58    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 61.67    Train Loss : 0.65,    Test Acc : 59.79    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 60.0    Train Loss : 0.64,    Test Acc : 62.29    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 63.33    Train Loss : 0.63,    Test Acc : 61.25    Test Loss : 0.66\n",
      "Epoch 50 - Train Acc : 62.5    Train Loss : 0.62,    Test Acc : 62.25    Test Loss : 0.65\n",
      "Epoch 60 - Train Acc : 65.0    Train Loss : 0.62,    Test Acc : 61.75    Test Loss : 0.65\n",
      "Epoch 70 - Train Acc : 63.33    Train Loss : 0.6,    Test Acc : 60.88    Test Loss : 0.65\n",
      "Epoch 80 - Train Acc : 65.0    Train Loss : 0.59,    Test Acc : 61.04    Test Loss : 0.64\n",
      "Epoch 90 - Train Acc : 68.33    Train Loss : 0.58,    Test Acc : 61.67    Test Loss : 0.64\n",
      "Epoch 100 - Train Acc : 70.83    Train Loss : 0.56,    Test Acc : 60.92    Test Loss : 0.64\n",
      "Epoch 110 - Train Acc : 71.67    Train Loss : 0.54,    Test Acc : 61.29    Test Loss : 0.65\n",
      "Epoch 120 - Train Acc : 70.0    Train Loss : 0.51,    Test Acc : 62.21    Test Loss : 0.66\n",
      "Epoch 130 - Train Acc : 73.33    Train Loss : 0.48,    Test Acc : 61.0    Test Loss : 0.67\n",
      "Epoch 140 - Train Acc : 75.83    Train Loss : 0.45,    Test Acc : 58.96    Test Loss : 0.72\n",
      "Epoch 150 - Train Acc : 75.83    Train Loss : 0.42,    Test Acc : 59.0    Test Loss : 0.78\n",
      "Epoch 160 - Train Acc : 80.83    Train Loss : 0.39,    Test Acc : 61.29    Test Loss : 0.86\n",
      "Epoch 170 - Train Acc : 83.33    Train Loss : 0.37,    Test Acc : 62.54    Test Loss : 0.95\n",
      "Epoch 180 - Train Acc : 83.33    Train Loss : 0.34,    Test Acc : 62.42    Test Loss : 1.04\n",
      "Epoch 190 - Train Acc : 83.33    Train Loss : 0.31,    Test Acc : 62.58    Test Loss : 1.12\n",
      "Epoch 200 - Train Acc : 85.0    Train Loss : 0.28,    Test Acc : 63.42    Test Loss : 1.18\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 63.42 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 29 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.46412404 0.18277874 0.09547397 0.06043198 0.04659027 0.0318616 ] \n",
      " Overall ratio:  0.8812605945724278\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 75.83    Train Loss : 0.58,    Test Acc : 73.0    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.52,    Test Acc : 74.38    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.49,    Test Acc : 76.04    Test Loss : 0.49\n",
      "Epoch 40 - Train Acc : 80.0    Train Loss : 0.48,    Test Acc : 75.17    Test Loss : 0.5\n",
      "Epoch 50 - Train Acc : 80.0    Train Loss : 0.47,    Test Acc : 75.96    Test Loss : 0.49\n",
      "Epoch 60 - Train Acc : 80.0    Train Loss : 0.46,    Test Acc : 75.83    Test Loss : 0.48\n",
      "Epoch 70 - Train Acc : 80.83    Train Loss : 0.45,    Test Acc : 76.33    Test Loss : 0.48\n",
      "Epoch 80 - Train Acc : 80.0    Train Loss : 0.45,    Test Acc : 76.38    Test Loss : 0.48\n",
      "Epoch 90 - Train Acc : 80.83    Train Loss : 0.44,    Test Acc : 76.25    Test Loss : 0.48\n",
      "Epoch 100 - Train Acc : 80.0    Train Loss : 0.43,    Test Acc : 76.21    Test Loss : 0.48\n",
      "Epoch 110 - Train Acc : 80.0    Train Loss : 0.42,    Test Acc : 75.96    Test Loss : 0.48\n",
      "Epoch 120 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 75.83    Test Loss : 0.49\n",
      "Epoch 130 - Train Acc : 80.0    Train Loss : 0.41,    Test Acc : 76.04    Test Loss : 0.49\n",
      "Epoch 140 - Train Acc : 80.0    Train Loss : 0.39,    Test Acc : 75.92    Test Loss : 0.5\n",
      "Epoch 150 - Train Acc : 80.0    Train Loss : 0.38,    Test Acc : 75.79    Test Loss : 0.51\n",
      "Epoch 160 - Train Acc : 80.83    Train Loss : 0.36,    Test Acc : 74.58    Test Loss : 0.54\n",
      "Epoch 170 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 74.17    Test Loss : 0.59\n",
      "Epoch 180 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 73.29    Test Loss : 0.64\n",
      "Epoch 190 - Train Acc : 86.67    Train Loss : 0.32,    Test Acc : 73.04    Test Loss : 0.67\n",
      "Epoch 200 - Train Acc : 87.5    Train Loss : 0.3,    Test Acc : 72.83    Test Loss : 0.72\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 72.83 ***\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.62,    Test Acc : 76.96    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 74.17    Train Loss : 0.56,    Test Acc : 74.33    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 75.0    Train Loss : 0.53,    Test Acc : 74.88    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 74.17    Train Loss : 0.5,    Test Acc : 74.08    Test Loss : 0.58\n",
      "Epoch 50 - Train Acc : 75.0    Train Loss : 0.48,    Test Acc : 73.75    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 74.29    Test Loss : 0.57\n",
      "Epoch 70 - Train Acc : 77.5    Train Loss : 0.41,    Test Acc : 75.62    Test Loss : 0.57\n",
      "Epoch 80 - Train Acc : 80.0    Train Loss : 0.37,    Test Acc : 76.0    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 81.67    Train Loss : 0.34,    Test Acc : 76.67    Test Loss : 0.63\n",
      "Epoch 100 - Train Acc : 83.33    Train Loss : 0.32,    Test Acc : 77.88    Test Loss : 0.64\n",
      "Epoch 110 - Train Acc : 85.0    Train Loss : 0.31,    Test Acc : 79.29    Test Loss : 0.62\n",
      "Epoch 120 - Train Acc : 86.67    Train Loss : 0.29,    Test Acc : 80.58    Test Loss : 0.59\n",
      "Epoch 130 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 81.46    Test Loss : 0.57\n",
      "Epoch 140 - Train Acc : 89.17    Train Loss : 0.27,    Test Acc : 82.0    Test Loss : 0.57\n",
      "Epoch 150 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 82.33    Test Loss : 0.57\n",
      "Epoch 160 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 82.33    Test Loss : 0.58\n",
      "Epoch 170 - Train Acc : 89.17    Train Loss : 0.25,    Test Acc : 82.71    Test Loss : 0.58\n",
      "Epoch 180 - Train Acc : 89.17    Train Loss : 0.25,    Test Acc : 82.33    Test Loss : 0.59\n",
      "Epoch 190 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 81.79    Test Loss : 0.61\n",
      "Epoch 200 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 81.62    Test Loss : 0.65\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 81.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 30 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.5011948  0.18725101 0.13573676 0.06151374 0.03823836 0.02731841] \n",
      " Overall ratio:  0.9512530820197236\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 54.17    Train Loss : 0.66,    Test Acc : 49.46    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 53.33    Train Loss : 0.66,    Test Acc : 49.0    Test Loss : 0.68\n",
      "Epoch 30 - Train Acc : 54.17    Train Loss : 0.66,    Test Acc : 51.17    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 52.5    Train Loss : 0.66,    Test Acc : 48.79    Test Loss : 0.67\n",
      "Epoch 50 - Train Acc : 53.33    Train Loss : 0.65,    Test Acc : 49.25    Test Loss : 0.67\n",
      "Epoch 60 - Train Acc : 54.17    Train Loss : 0.65,    Test Acc : 48.96    Test Loss : 0.67\n",
      "Epoch 70 - Train Acc : 53.33    Train Loss : 0.65,    Test Acc : 48.42    Test Loss : 0.67\n",
      "Epoch 80 - Train Acc : 52.5    Train Loss : 0.64,    Test Acc : 48.33    Test Loss : 0.67\n",
      "Epoch 90 - Train Acc : 54.17    Train Loss : 0.64,    Test Acc : 48.79    Test Loss : 0.67\n",
      "Epoch 100 - Train Acc : 55.0    Train Loss : 0.62,    Test Acc : 48.88    Test Loss : 0.67\n",
      "Epoch 110 - Train Acc : 65.83    Train Loss : 0.6,    Test Acc : 53.5    Test Loss : 0.69\n",
      "Epoch 120 - Train Acc : 69.17    Train Loss : 0.56,    Test Acc : 59.92    Test Loss : 0.75\n",
      "Epoch 130 - Train Acc : 70.83    Train Loss : 0.54,    Test Acc : 60.67    Test Loss : 0.85\n",
      "Epoch 140 - Train Acc : 73.33    Train Loss : 0.52,    Test Acc : 62.04    Test Loss : 0.86\n",
      "Epoch 150 - Train Acc : 75.0    Train Loss : 0.5,    Test Acc : 63.38    Test Loss : 0.88\n",
      "Epoch 160 - Train Acc : 75.83    Train Loss : 0.49,    Test Acc : 64.38    Test Loss : 0.96\n",
      "Epoch 170 - Train Acc : 75.83    Train Loss : 0.48,    Test Acc : 64.25    Test Loss : 1.04\n",
      "Epoch 180 - Train Acc : 75.0    Train Loss : 0.47,    Test Acc : 64.12    Test Loss : 1.14\n",
      "Epoch 190 - Train Acc : 75.83    Train Loss : 0.46,    Test Acc : 64.17    Test Loss : 1.27\n",
      "Epoch 200 - Train Acc : 75.83    Train Loss : 0.45,    Test Acc : 64.46    Test Loss : 1.41\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 64.46 ***\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.63,    Test Acc : 60.96    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 66.67    Train Loss : 0.62,    Test Acc : 62.46    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 66.67    Train Loss : 0.62,    Test Acc : 60.08    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 65.0    Train Loss : 0.62,    Test Acc : 61.08    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 66.67    Train Loss : 0.61,    Test Acc : 61.29    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 66.67    Train Loss : 0.61,    Test Acc : 60.62    Test Loss : 0.62\n",
      "Epoch 70 - Train Acc : 66.67    Train Loss : 0.61,    Test Acc : 60.79    Test Loss : 0.62\n",
      "Epoch 80 - Train Acc : 66.67    Train Loss : 0.61,    Test Acc : 61.25    Test Loss : 0.62\n",
      "Epoch 90 - Train Acc : 66.67    Train Loss : 0.61,    Test Acc : 61.5    Test Loss : 0.62\n",
      "Epoch 100 - Train Acc : 66.67    Train Loss : 0.6,    Test Acc : 62.58    Test Loss : 0.62\n",
      "Epoch 110 - Train Acc : 66.67    Train Loss : 0.6,    Test Acc : 63.21    Test Loss : 0.61\n",
      "Epoch 120 - Train Acc : 67.5    Train Loss : 0.59,    Test Acc : 64.29    Test Loss : 0.6\n",
      "Epoch 130 - Train Acc : 70.0    Train Loss : 0.58,    Test Acc : 66.17    Test Loss : 0.59\n",
      "Epoch 140 - Train Acc : 73.33    Train Loss : 0.57,    Test Acc : 68.21    Test Loss : 0.58\n",
      "Epoch 150 - Train Acc : 71.67    Train Loss : 0.55,    Test Acc : 68.08    Test Loss : 0.57\n",
      "Epoch 160 - Train Acc : 72.5    Train Loss : 0.53,    Test Acc : 69.17    Test Loss : 0.56\n",
      "Epoch 170 - Train Acc : 75.0    Train Loss : 0.51,    Test Acc : 69.25    Test Loss : 0.56\n",
      "Epoch 180 - Train Acc : 75.83    Train Loss : 0.5,    Test Acc : 68.92    Test Loss : 0.55\n",
      "Epoch 190 - Train Acc : 73.33    Train Loss : 0.48,    Test Acc : 69.25    Test Loss : 0.56\n",
      "Epoch 200 - Train Acc : 75.0    Train Loss : 0.46,    Test Acc : 68.96    Test Loss : 0.57\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 68.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 31 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.51965352 0.17437604 0.08535715 0.0393794  0.0328574  0.02538941] \n",
      " Overall ratio:  0.8770129201257615\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 60.0    Train Loss : 0.66,    Test Acc : 58.96    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 62.5    Train Loss : 0.64,    Test Acc : 55.92    Test Loss : 0.69\n",
      "Epoch 30 - Train Acc : 60.0    Train Loss : 0.62,    Test Acc : 61.67    Test Loss : 0.65\n",
      "Epoch 40 - Train Acc : 60.83    Train Loss : 0.61,    Test Acc : 62.75    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 60.83    Train Loss : 0.59,    Test Acc : 63.58    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 70.83    Train Loss : 0.57,    Test Acc : 67.42    Test Loss : 0.63\n",
      "Epoch 70 - Train Acc : 75.83    Train Loss : 0.53,    Test Acc : 68.75    Test Loss : 0.62\n",
      "Epoch 80 - Train Acc : 77.5    Train Loss : 0.5,    Test Acc : 69.21    Test Loss : 0.62\n",
      "Epoch 90 - Train Acc : 82.5    Train Loss : 0.47,    Test Acc : 69.75    Test Loss : 0.64\n",
      "Epoch 100 - Train Acc : 83.33    Train Loss : 0.44,    Test Acc : 70.25    Test Loss : 0.66\n",
      "Epoch 110 - Train Acc : 85.0    Train Loss : 0.42,    Test Acc : 70.71    Test Loss : 0.67\n",
      "Epoch 120 - Train Acc : 88.33    Train Loss : 0.4,    Test Acc : 71.71    Test Loss : 0.68\n",
      "Epoch 130 - Train Acc : 87.5    Train Loss : 0.37,    Test Acc : 72.21    Test Loss : 0.69\n",
      "Epoch 140 - Train Acc : 87.5    Train Loss : 0.34,    Test Acc : 73.33    Test Loss : 0.73\n",
      "Epoch 150 - Train Acc : 88.33    Train Loss : 0.31,    Test Acc : 72.75    Test Loss : 0.79\n",
      "Epoch 160 - Train Acc : 88.33    Train Loss : 0.29,    Test Acc : 72.79    Test Loss : 0.82\n",
      "Epoch 170 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 73.96    Test Loss : 0.82\n",
      "Epoch 180 - Train Acc : 89.17    Train Loss : 0.24,    Test Acc : 75.04    Test Loss : 0.8\n",
      "Epoch 190 - Train Acc : 90.83    Train Loss : 0.21,    Test Acc : 75.71    Test Loss : 0.8\n",
      "Epoch 200 - Train Acc : 91.67    Train Loss : 0.2,    Test Acc : 76.92    Test Loss : 0.84\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 76.92 ***\n",
      "Epoch 10 - Train Acc : 62.5    Train Loss : 0.65,    Test Acc : 57.0    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 68.33    Train Loss : 0.59,    Test Acc : 63.96    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 75.0    Train Loss : 0.52,    Test Acc : 65.25    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 79.17    Train Loss : 0.49,    Test Acc : 68.83    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 78.33    Train Loss : 0.49,    Test Acc : 68.58    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 78.33    Train Loss : 0.47,    Test Acc : 68.38    Test Loss : 0.62\n",
      "Epoch 70 - Train Acc : 80.0    Train Loss : 0.46,    Test Acc : 68.46    Test Loss : 0.61\n",
      "Epoch 80 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 68.83    Test Loss : 0.62\n",
      "Epoch 90 - Train Acc : 78.33    Train Loss : 0.43,    Test Acc : 69.12    Test Loss : 0.63\n",
      "Epoch 100 - Train Acc : 82.5    Train Loss : 0.41,    Test Acc : 69.62    Test Loss : 0.64\n",
      "Epoch 110 - Train Acc : 85.0    Train Loss : 0.39,    Test Acc : 71.0    Test Loss : 0.68\n",
      "Epoch 120 - Train Acc : 85.0    Train Loss : 0.37,    Test Acc : 72.33    Test Loss : 0.7\n",
      "Epoch 130 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 74.0    Test Loss : 0.7\n",
      "Epoch 140 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 74.71    Test Loss : 0.69\n",
      "Epoch 150 - Train Acc : 87.5    Train Loss : 0.33,    Test Acc : 75.42    Test Loss : 0.68\n",
      "Epoch 160 - Train Acc : 89.17    Train Loss : 0.31,    Test Acc : 76.42    Test Loss : 0.67\n",
      "Epoch 170 - Train Acc : 89.17    Train Loss : 0.3,    Test Acc : 76.62    Test Loss : 0.66\n",
      "Epoch 180 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 76.38    Test Loss : 0.65\n",
      "Epoch 190 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 76.54    Test Loss : 0.65\n",
      "Epoch 200 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 76.92    Test Loss : 0.65\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 76.92 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 32 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (756,),    high arousal : (1764,)\n",
      "Explaned variance ratio by principal components : [0.40379541 0.19594926 0.09724724 0.06942047 0.04882956 0.03339357] \n",
      " Overall ratio:  0.8486355048441747\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 59.17    Train Loss : 0.66,    Test Acc : 56.96    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 61.67    Train Loss : 0.64,    Test Acc : 59.46    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 63.33    Train Loss : 0.62,    Test Acc : 61.75    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.61,    Test Acc : 67.21    Test Loss : 0.61\n",
      "Epoch 50 - Train Acc : 70.83    Train Loss : 0.59,    Test Acc : 68.79    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 72.5    Train Loss : 0.56,    Test Acc : 70.92    Test Loss : 0.57\n",
      "Epoch 70 - Train Acc : 77.5    Train Loss : 0.52,    Test Acc : 72.67    Test Loss : 0.55\n",
      "Epoch 80 - Train Acc : 81.67    Train Loss : 0.47,    Test Acc : 75.83    Test Loss : 0.53\n",
      "Epoch 90 - Train Acc : 84.17    Train Loss : 0.43,    Test Acc : 76.71    Test Loss : 0.52\n",
      "Epoch 100 - Train Acc : 85.83    Train Loss : 0.39,    Test Acc : 77.96    Test Loss : 0.5\n",
      "Epoch 110 - Train Acc : 88.33    Train Loss : 0.36,    Test Acc : 79.08    Test Loss : 0.5\n",
      "Epoch 120 - Train Acc : 90.0    Train Loss : 0.32,    Test Acc : 78.88    Test Loss : 0.5\n",
      "Epoch 130 - Train Acc : 90.83    Train Loss : 0.29,    Test Acc : 79.42    Test Loss : 0.51\n",
      "Epoch 140 - Train Acc : 91.67    Train Loss : 0.26,    Test Acc : 78.25    Test Loss : 0.53\n",
      "Epoch 150 - Train Acc : 95.0    Train Loss : 0.23,    Test Acc : 79.33    Test Loss : 0.59\n",
      "Epoch 160 - Train Acc : 96.67    Train Loss : 0.2,    Test Acc : 79.67    Test Loss : 0.66\n",
      "Epoch 170 - Train Acc : 96.67    Train Loss : 0.17,    Test Acc : 80.58    Test Loss : 0.71\n",
      "Epoch 180 - Train Acc : 97.5    Train Loss : 0.15,    Test Acc : 81.38    Test Loss : 0.75\n",
      "Epoch 190 - Train Acc : 97.5    Train Loss : 0.13,    Test Acc : 81.79    Test Loss : 0.81\n",
      "Epoch 200 - Train Acc : 97.5    Train Loss : 0.11,    Test Acc : 81.88    Test Loss : 0.87\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 81.88 ***\n",
      "Epoch 10 - Train Acc : 68.33    Train Loss : 0.66,    Test Acc : 69.79    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 79.17    Train Loss : 0.61,    Test Acc : 66.46    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 74.17    Train Loss : 0.57,    Test Acc : 69.42    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 80.83    Train Loss : 0.55,    Test Acc : 69.92    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 80.0    Train Loss : 0.53,    Test Acc : 71.17    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 80.83    Train Loss : 0.51,    Test Acc : 72.83    Test Loss : 0.58\n",
      "Epoch 70 - Train Acc : 81.67    Train Loss : 0.49,    Test Acc : 73.54    Test Loss : 0.56\n",
      "Epoch 80 - Train Acc : 81.67    Train Loss : 0.47,    Test Acc : 75.08    Test Loss : 0.54\n",
      "Epoch 90 - Train Acc : 83.33    Train Loss : 0.45,    Test Acc : 75.33    Test Loss : 0.52\n",
      "Epoch 100 - Train Acc : 84.17    Train Loss : 0.43,    Test Acc : 75.42    Test Loss : 0.52\n",
      "Epoch 110 - Train Acc : 85.83    Train Loss : 0.41,    Test Acc : 75.71    Test Loss : 0.53\n",
      "Epoch 120 - Train Acc : 86.67    Train Loss : 0.39,    Test Acc : 76.33    Test Loss : 0.56\n",
      "Epoch 130 - Train Acc : 87.5    Train Loss : 0.37,    Test Acc : 76.17    Test Loss : 0.59\n",
      "Epoch 140 - Train Acc : 87.5    Train Loss : 0.34,    Test Acc : 74.42    Test Loss : 0.65\n",
      "Epoch 150 - Train Acc : 87.5    Train Loss : 0.31,    Test Acc : 73.33    Test Loss : 0.71\n",
      "Epoch 160 - Train Acc : 89.17    Train Loss : 0.28,    Test Acc : 72.29    Test Loss : 0.78\n",
      "Epoch 170 - Train Acc : 89.17    Train Loss : 0.25,    Test Acc : 71.71    Test Loss : 0.89\n",
      "Epoch 180 - Train Acc : 88.33    Train Loss : 0.23,    Test Acc : 71.38    Test Loss : 0.99\n",
      "Epoch 190 - Train Acc : 88.33    Train Loss : 0.21,    Test Acc : 71.25    Test Loss : 1.12\n",
      "Epoch 200 - Train Acc : 88.33    Train Loss : 0.19,    Test Acc : 71.42    Test Loss : 1.27\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN is saved successfully\n",
      "*** Best ACC : 71.42 ***\n",
      "\n",
      "**************** Valence *********************\n",
      "** Best ACC : [65.62, 81.71, 70.21, 75.33, 72.38, 75.54, 81.46, 72.29, 78.79, 76.96, 68.38, 73.46, 81.92, 79.88, 75.83, 79.04, 66.71, 79.92, 80.88, 83.83, 66.5, 72.83, 79.54, 63.08, 75.21, 78.0, 80.75, 77.83, 72.83, 64.46, 76.92, 81.88] **\n",
      " ** Avearge acc : 75.3115625,    std : 5.657869027610462 **\n",
      "\n",
      "**************** Arousal *********************\n",
      "** Best ACC : [66.79, 72.54, 68.38, 73.92, 68.54, 65.75, 78.12, 67.13, 74.5, 68.29, 75.29, 75.0, 80.79, 77.75, 72.25, 75.96, 68.12, 71.08, 79.54, 74.62, 79.67, 68.58, 76.21, 79.21, 73.67, 78.62, 73.25, 63.42, 81.62, 68.96, 76.92, 71.42] **\n",
      " ** Avearge acc : 73.30968750000001,    std : 4.793951582707501 **\n",
      "\n",
      "directory already exists\n",
      "vlc_PSD_PCA_GCN_protocol_60_best_acc_list_231016 is saved successfully\n",
      "directory already exists\n",
      "ars_PSD_PCA_GCN_protocol_60_best_acc_list_231016 is saved successfully\n"
     ]
    }
   ],
   "source": [
    "vlc_best_epoch = []\n",
    "vlc_orig_acc = []\n",
    "vlc_best_acc = []\n",
    "ars_best_epoch = []\n",
    "ars_orig_acc = []\n",
    "ars_best_acc = []\n",
    "\n",
    "compare_args.gcn_hid_channels = 6\n",
    "compare_args.gcn_out_channels = 12\n",
    "for i in range(32):\n",
    "\n",
    "    print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "    sub_idx = 'sub'+str(i+1)\n",
    "    date = '231016'\n",
    "\n",
    "    sub_de = subject_de[i]\n",
    "    sub_psd = subject_psd[i]\n",
    "    sub_label = subject_label[i]\n",
    "    valence_label, arousal_label = deap_label(sub_label)\n",
    "\n",
    "    de, psd, vlc_identifier, ars_identifier = other_preprocessing(sub_de,sub_psd, (valence_label,arousal_label), n_labels_by_class, args.out_channels, args.seed, isdeap=True)\n",
    "\n",
    "    psd_pca,_ = dimensionality_reduction(psd, compare_args.pca_components2, 'psd_LDS', sub_idx, date)\n",
    "    \n",
    "    print(\"\\nDistance matrix construction start...\")\n",
    "    psd_dm = distance_matrix(psd_pca)\n",
    "    print(\"\\nDistance matrix construction Done...\")\n",
    "\n",
    "    psd_neighbors = kneighbors(psd_dm, args.n_samples, args.psd_k)\n",
    "\n",
    "    psd_ssm, psd_nssm = ssm_construction(psd_dm,psd_neighbors)\n",
    "    adj = psd_nssm\n",
    "    \n",
    "    feature = psd_pca\n",
    "    \n",
    "    feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "    adj = torch.from_numpy(adj).to(torch.float32).to(device)\n",
    "    adj = normalize_adj(adj,im)\n",
    "    \n",
    "    \n",
    "    ars_label = torch.from_numpy(arousal_label).to(torch.long).to(device)\n",
    "    vlc_label = torch.from_numpy(valence_label).to(torch.long).to(device)\n",
    "\n",
    "    vlc_identifier = torch.from_numpy(vlc_identifier).bool()\n",
    "    vlc_train_identifier = vlc_identifier.to(device)\n",
    "    isunlabeled = ~vlc_identifier\n",
    "    vlc_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "    ars_identifier = torch.from_numpy(ars_identifier).bool()\n",
    "    ars_train_identifier = ars_identifier.to(device)\n",
    "    isunlabeled = ~ars_identifier\n",
    "    ars_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "\n",
    "    model = compare_model(compare_args,compare_args.pca_components2,adj).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = train(feature, vlc_label, vlc_train_identifier, vlc_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'vlc_PSD_PCA_GCN', sample)\n",
    "    \n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    vlc_best_acc.append(best_acc)\n",
    "    vlc_orig_acc.append(best_acc)\n",
    "    \n",
    "    model = compare_model(compare_args,compare_args.pca_components2,adj).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = train(feature, ars_label, ars_train_identifier, ars_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'ars_PSD_PCA_GCN', sample)\n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    ars_best_acc.append(best_acc)\n",
    "    ars_orig_acc.append(best_acc)\n",
    "\n",
    "\n",
    "print(\"\\n**************** Valence *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(vlc_best_acc, np.mean(vlc_best_acc), np.std(vlc_best_acc)))\n",
    "\n",
    "print(\"**************** Arousal *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(ars_best_acc, np.mean(ars_best_acc), np.std(ars_best_acc)))\n",
    "\n",
    "\n",
    "vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "ars_best_acc_list = np.array(ars_best_acc)\n",
    "\n",
    "save_np(args.tensor_save_path+'ablation2/vlc/', 'vlc_PSD_PCA_GCN_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, vlc_best_acc_list)\n",
    "save_np(args.tensor_save_path+'ablation2/ars/', 'ars_PSD_PCA_GCN_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, ars_best_acc_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a7edbb",
   "metadata": {},
   "source": [
    "##  Ablation 3 (DE;PSD + PCA + SNF + GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f004d3aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "Explaned variance ratio by principal components : [0.38294457 0.12664908 0.08462927 0.04550889 0.03510897 0.0316\n",
      " 0.02291766 0.01886277 0.01691676] \n",
      " Overall ratio:  0.7651379787806818\n",
      "Explaned variance ratio by principal components : [0.34124007 0.16573164 0.09901982 0.05144135 0.04170491 0.03432301] \n",
      " Overall ratio:  0.7334608066771695\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.34124007 0.16573164 0.09901982 0.05144135 0.04170491 0.03432301] \n",
      " Overall ratio:  0.7334608071681391\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2723 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.59,    Test Acc : 67.0    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.51,    Test Acc : 67.58    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 77.5    Train Loss : 0.47,    Test Acc : 68.38    Test Loss : 0.68\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.41,    Test Acc : 70.88    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 72.62    Test Loss : 0.63\n",
      "Epoch 60 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 73.96    Test Loss : 0.7\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.21,    Test Acc : 73.04    Test Loss : 0.86\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 73.54    Test Loss : 1.07\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.12,    Test Acc : 74.83    Test Loss : 1.24\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 76.42    Test Loss : 1.34\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 76.92    Test Loss : 1.47\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 77.17    Test Loss : 1.67\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 77.88    Test Loss : 1.89\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.62    Test Loss : 2.06\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.04    Test Loss : 2.23\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.04    Test Loss : 2.38\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.29    Test Loss : 2.5\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.42    Test Loss : 2.6\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.5    Test Loss : 2.68\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.67    Test Loss : 2.75\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 79.67 ***\n",
      "Epoch 10 - Train Acc : 71.67    Train Loss : 0.55,    Test Acc : 67.29    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.48,    Test Acc : 73.04    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.43,    Test Acc : 72.88    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 74.88    Test Loss : 0.58\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 77.29    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.19,    Test Acc : 77.5    Test Loss : 0.69\n",
      "Epoch 70 - Train Acc : 98.33    Train Loss : 0.11,    Test Acc : 79.29    Test Loss : 0.87\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 79.83    Test Loss : 1.2\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 79.42    Test Loss : 1.73\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.83    Test Loss : 2.2\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.92    Test Loss : 2.5\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.88    Test Loss : 2.73\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.96    Test Loss : 2.89\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.0    Test Loss : 3.0\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.0    Test Loss : 3.1\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.04    Test Loss : 3.17\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.12    Test Loss : 3.24\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.25    Test Loss : 3.31\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.42    Test Loss : 3.36\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.46    Test Loss : 3.42\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 79.46 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 2 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "Explaned variance ratio by principal components : [0.66499555 0.1259352  0.04828088 0.03524043 0.01820806 0.01657125\n",
      " 0.0123173  0.01038662 0.00710544] \n",
      " Overall ratio:  0.9390407176345893\n",
      "Explaned variance ratio by principal components : [0.61604082 0.1939618  0.07572698 0.0373204  0.01817518 0.01082485] \n",
      " Overall ratio:  0.9520500331769884\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.61604082 0.1939618  0.07572698 0.0373204  0.01817518 0.01082485] \n",
      " Overall ratio:  0.9520500331769899\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2717 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.59,    Test Acc : 73.96    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.51,    Test Acc : 75.58    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.44,    Test Acc : 77.08    Test Loss : 0.52\n",
      "Epoch 40 - Train Acc : 90.0    Train Loss : 0.35,    Test Acc : 79.96    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 92.5    Train Loss : 0.22,    Test Acc : 83.5    Test Loss : 0.43\n",
      "Epoch 60 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 86.42    Test Loss : 0.43\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 87.42    Test Loss : 0.47\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 87.54    Test Loss : 0.58\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.25    Test Loss : 0.67\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 0.73\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 0.78\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 0.81\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 0.84\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 0.87\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 0.89\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 0.91\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 0.92\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 0.94\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 0.96\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 87.88 ***\n",
      "Epoch 10 - Train Acc : 70.83    Train Loss : 0.56,    Test Acc : 66.12    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 69.17    Train Loss : 0.52,    Test Acc : 64.5    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 74.17    Train Loss : 0.47,    Test Acc : 67.54    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 78.33    Train Loss : 0.39,    Test Acc : 69.08    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.3,    Test Acc : 72.96    Test Loss : 0.63\n",
      "Epoch 60 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 78.5    Test Loss : 0.68\n",
      "Epoch 70 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 79.92    Test Loss : 0.9\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 81.04    Test Loss : 1.2\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.58    Test Loss : 1.49\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.25    Test Loss : 1.69\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.21    Test Loss : 1.84\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.25    Test Loss : 1.97\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.13    Test Loss : 2.07\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.0    Test Loss : 2.14\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.0    Test Loss : 2.2\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.04    Test Loss : 2.25\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.08    Test Loss : 2.29\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.04    Test Loss : 2.33\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.0    Test Loss : 2.36\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.0    Test Loss : 2.39\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 80.0 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 3 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (2016,),    high arousal : (504,)\n",
      "Explaned variance ratio by principal components : [0.52763226 0.15814157 0.05869493 0.04236887 0.03271043 0.02357153\n",
      " 0.02058458 0.01800425 0.01179096] \n",
      " Overall ratio:  0.8934993723004274\n",
      "Explaned variance ratio by principal components : [0.46598131 0.19901457 0.08314002 0.07158681 0.03199032 0.03011813] \n",
      " Overall ratio:  0.8818311710929604\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.46598131 0.19901457 0.08314002 0.07158681 0.03199032 0.03011813] \n",
      " Overall ratio:  0.8818311710929607\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2718 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.5,    Test Acc : 76.79    Test Loss : 0.52\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.43,    Test Acc : 76.46    Test Loss : 0.45\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.37,    Test Acc : 78.83    Test Loss : 0.42\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.29,    Test Acc : 80.5    Test Loss : 0.39\n",
      "Epoch 50 - Train Acc : 93.33    Train Loss : 0.2,    Test Acc : 82.17    Test Loss : 0.38\n",
      "Epoch 60 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 83.5    Test Loss : 0.39\n",
      "Epoch 70 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 85.67    Test Loss : 0.39\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 86.62    Test Loss : 0.44\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.5    Test Loss : 0.53\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.58    Test Loss : 0.62\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 0.67\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 0.72\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 0.76\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 0.78\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 0.81\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 0.83\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.83    Test Loss : 0.84\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.83    Test Loss : 0.86\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.88    Test Loss : 0.87\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 0.89\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 86.79 ***\n",
      "Epoch 10 - Train Acc : 70.83    Train Loss : 0.58,    Test Acc : 60.58    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 74.17    Train Loss : 0.45,    Test Acc : 62.75    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 77.5    Train Loss : 0.37,    Test Acc : 67.83    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 93.33    Train Loss : 0.24,    Test Acc : 74.67    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 98.33    Train Loss : 0.12,    Test Acc : 79.92    Test Loss : 0.59\n",
      "Epoch 60 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 82.17    Test Loss : 0.83\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.04    Test Loss : 1.16\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.62    Test Loss : 1.48\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.5    Test Loss : 1.7\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.5    Test Loss : 1.85\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 1.96\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.5    Test Loss : 2.04\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.33    Test Loss : 2.11\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.33    Test Loss : 2.17\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.29    Test Loss : 2.21\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.25    Test Loss : 2.26\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.25    Test Loss : 2.3\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.25    Test Loss : 2.34\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.21    Test Loss : 2.37\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 2.41\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 81.17 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 4 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1512,),    high valence : (1008,)\n",
      "low arousal : (1512,),    high arousal : (1008,)\n",
      "Explaned variance ratio by principal components : [0.53445228 0.35509932 0.03070409 0.0215785  0.01865784 0.00847595\n",
      " 0.00508507 0.0040492  0.00361606] \n",
      " Overall ratio:  0.9817182933767559\n",
      "Explaned variance ratio by principal components : [0.63702801 0.26856435 0.04607182 0.01842077 0.01113548 0.00622467] \n",
      " Overall ratio:  0.9874450986628709\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.63702801 0.26856435 0.04607182 0.01842077 0.01113548 0.00622467] \n",
      " Overall ratio:  0.9874450986628703\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2730 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.53,    Test Acc : 71.25    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 79.17    Train Loss : 0.42,    Test Acc : 75.38    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 80.0    Train Loss : 0.4,    Test Acc : 76.5    Test Loss : 0.51\n",
      "Epoch 40 - Train Acc : 81.67    Train Loss : 0.36,    Test Acc : 77.79    Test Loss : 0.46\n",
      "Epoch 50 - Train Acc : 80.83    Train Loss : 0.33,    Test Acc : 77.29    Test Loss : 0.45\n",
      "Epoch 60 - Train Acc : 83.33    Train Loss : 0.3,    Test Acc : 78.5    Test Loss : 0.46\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.27,    Test Acc : 78.75    Test Loss : 0.47\n",
      "Epoch 80 - Train Acc : 90.83    Train Loss : 0.23,    Test Acc : 78.75    Test Loss : 0.5\n",
      "Epoch 90 - Train Acc : 91.67    Train Loss : 0.19,    Test Acc : 77.46    Test Loss : 0.56\n",
      "Epoch 100 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 76.67    Test Loss : 0.65\n",
      "Epoch 110 - Train Acc : 94.17    Train Loss : 0.14,    Test Acc : 78.08    Test Loss : 0.71\n",
      "Epoch 120 - Train Acc : 95.0    Train Loss : 0.11,    Test Acc : 79.54    Test Loss : 0.79\n",
      "Epoch 130 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 80.71    Test Loss : 0.9\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 80.75    Test Loss : 1.14\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 81.46    Test Loss : 1.46\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.79    Test Loss : 1.72\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.54    Test Loss : 1.95\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.83    Test Loss : 2.13\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.92    Test Loss : 2.25\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.92    Test Loss : 2.36\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 81.92 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.61,    Test Acc : 60.42    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 74.17    Train Loss : 0.51,    Test Acc : 69.33    Test Loss : 0.54\n",
      "Epoch 30 - Train Acc : 75.0    Train Loss : 0.48,    Test Acc : 72.71    Test Loss : 0.53\n",
      "Epoch 40 - Train Acc : 79.17    Train Loss : 0.44,    Test Acc : 73.88    Test Loss : 0.53\n",
      "Epoch 50 - Train Acc : 81.67    Train Loss : 0.39,    Test Acc : 75.0    Test Loss : 0.52\n",
      "Epoch 60 - Train Acc : 86.67    Train Loss : 0.32,    Test Acc : 77.25    Test Loss : 0.5\n",
      "Epoch 70 - Train Acc : 91.67    Train Loss : 0.22,    Test Acc : 77.96    Test Loss : 0.5\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 80.71    Test Loss : 0.57\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 80.88    Test Loss : 0.74\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 81.21    Test Loss : 0.91\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 80.38    Test Loss : 1.1\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.04    Test Loss : 1.29\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.08    Test Loss : 1.43\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.96    Test Loss : 1.56\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.96    Test Loss : 1.67\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.25    Test Loss : 1.75\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.17    Test Loss : 1.81\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.17    Test Loss : 1.86\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.25    Test Loss : 1.91\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.25    Test Loss : 1.95\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 80.25 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 5 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1323,),    high arousal : (1197,)\n",
      "Explaned variance ratio by principal components : [0.4627099  0.31465133 0.05692983 0.02745092 0.02393454 0.01988661\n",
      " 0.01821302 0.01250122 0.00716879] \n",
      " Overall ratio:  0.9434461680259075\n",
      "Explaned variance ratio by principal components : [0.43381391 0.31507221 0.06265232 0.05063084 0.03125649 0.02739416] \n",
      " Overall ratio:  0.9208199303277511\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.43381391 0.31507221 0.06265232 0.05063084 0.03125649 0.02739416] \n",
      " Overall ratio:  0.9208199303277517\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2709 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.6,    Test Acc : 66.08    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 70.0    Train Loss : 0.55,    Test Acc : 66.83    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.46,    Test Acc : 72.42    Test Loss : 0.51\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.33,    Test Acc : 79.04    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 93.33    Train Loss : 0.22,    Test Acc : 81.25    Test Loss : 0.63\n",
      "Epoch 60 - Train Acc : 98.33    Train Loss : 0.12,    Test Acc : 82.75    Test Loss : 0.8\n",
      "Epoch 70 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 83.92    Test Loss : 1.03\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 84.54    Test Loss : 1.3\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.75    Test Loss : 1.53\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.58    Test Loss : 1.69\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 1.78\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.84\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.88\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.92\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.95\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.98\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 2.01\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 2.03\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 2.05\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 2.07\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 84.75 ***\n",
      "Epoch 10 - Train Acc : 62.5    Train Loss : 0.62,    Test Acc : 65.12    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 67.5    Train Loss : 0.56,    Test Acc : 65.62    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 72.5    Train Loss : 0.5,    Test Acc : 67.0    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 78.33    Train Loss : 0.43,    Test Acc : 69.29    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 82.5    Train Loss : 0.36,    Test Acc : 72.21    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 89.17    Train Loss : 0.27,    Test Acc : 75.04    Test Loss : 0.6\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 76.88    Test Loss : 0.64\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.14,    Test Acc : 79.33    Test Loss : 0.71\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.11,    Test Acc : 79.58    Test Loss : 0.85\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 79.12    Test Loss : 1.03\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 79.29    Test Loss : 1.21\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 79.5    Test Loss : 1.37\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 78.88    Test Loss : 1.54\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 78.46    Test Loss : 1.74\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.21    Test Loss : 2.0\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 77.96    Test Loss : 2.27\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.17    Test Loss : 2.47\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.42    Test Loss : 2.61\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.38    Test Loss : 2.72\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.38    Test Loss : 2.79\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 78.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 6 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "Explaned variance ratio by principal components : [0.48868338 0.19968501 0.10765411 0.04434801 0.01845038 0.01594614\n",
      " 0.01341688 0.01212369 0.00993146] \n",
      " Overall ratio:  0.9102390639360006\n",
      "Explaned variance ratio by principal components : [0.48200144 0.21864702 0.09479407 0.06309359 0.02098429 0.0188701 ] \n",
      " Overall ratio:  0.8983905163993074\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.48200144 0.21864702 0.09479407 0.06309359 0.02098429 0.0188701 ] \n",
      " Overall ratio:  0.8983905163993066\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2743 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.62,    Test Acc : 61.13    Test Loss : 0.69\n",
      "Epoch 20 - Train Acc : 73.33    Train Loss : 0.57,    Test Acc : 63.58    Test Loss : 0.7\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.53,    Test Acc : 62.92    Test Loss : 0.72\n",
      "Epoch 40 - Train Acc : 78.33    Train Loss : 0.47,    Test Acc : 64.04    Test Loss : 0.75\n",
      "Epoch 50 - Train Acc : 85.0    Train Loss : 0.38,    Test Acc : 67.83    Test Loss : 0.75\n",
      "Epoch 60 - Train Acc : 88.33    Train Loss : 0.3,    Test Acc : 66.62    Test Loss : 0.88\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.19,    Test Acc : 67.04    Test Loss : 1.09\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.1,    Test Acc : 70.08    Test Loss : 1.37\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 71.04    Test Loss : 1.68\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 71.62    Test Loss : 2.01\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 71.29    Test Loss : 2.34\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 71.54    Test Loss : 2.63\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 71.92    Test Loss : 2.85\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 72.08    Test Loss : 3.0\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 72.04    Test Loss : 3.12\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 71.92    Test Loss : 3.22\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 71.75    Test Loss : 3.3\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 71.88    Test Loss : 3.37\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 71.71    Test Loss : 3.44\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 71.58    Test Loss : 3.5\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 71.58 ***\n",
      "Epoch 10 - Train Acc : 60.83    Train Loss : 0.58,    Test Acc : 55.5    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 75.0    Train Loss : 0.55,    Test Acc : 62.38    Test Loss : 0.69\n",
      "Epoch 30 - Train Acc : 73.33    Train Loss : 0.51,    Test Acc : 62.17    Test Loss : 0.65\n",
      "Epoch 40 - Train Acc : 78.33    Train Loss : 0.45,    Test Acc : 63.04    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.35,    Test Acc : 69.12    Test Loss : 0.61\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.22,    Test Acc : 72.0    Test Loss : 0.66\n",
      "Epoch 70 - Train Acc : 97.5    Train Loss : 0.11,    Test Acc : 75.83    Test Loss : 0.79\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 75.04    Test Loss : 1.07\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 74.83    Test Loss : 1.34\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 75.33    Test Loss : 1.55\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.08    Test Loss : 1.71\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.17    Test Loss : 1.82\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 74.92    Test Loss : 1.89\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.0    Test Loss : 1.95\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.0    Test Loss : 2.0\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 74.92    Test Loss : 2.04\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.04    Test Loss : 2.08\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.0    Test Loss : 2.11\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.04    Test Loss : 2.14\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.04    Test Loss : 2.17\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 75.04 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 7 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (756,),    high valence : (1764,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.42837935 0.16204537 0.09392059 0.08387523 0.03721251 0.02388047\n",
      " 0.01429398 0.01282698 0.01142974] \n",
      " Overall ratio:  0.8678642068786071\n",
      "Explaned variance ratio by principal components : [0.40376323 0.16861429 0.10046353 0.07080645 0.05867564 0.02477164] \n",
      " Overall ratio:  0.8270947918649271\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.40376323 0.16861429 0.10046353 0.07080645 0.05867564 0.02477164] \n",
      " Overall ratio:  0.8270947918648724\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2723 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 72.5    Train Loss : 0.5,    Test Acc : 72.0    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 73.08    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 84.17    Train Loss : 0.35,    Test Acc : 74.38    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 89.17    Train Loss : 0.27,    Test Acc : 77.29    Test Loss : 0.47\n",
      "Epoch 50 - Train Acc : 91.67    Train Loss : 0.18,    Test Acc : 79.46    Test Loss : 0.39\n",
      "Epoch 60 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 85.71    Test Loss : 0.35\n",
      "Epoch 70 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 88.42    Test Loss : 0.39\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 87.54    Test Loss : 0.53\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 0.65\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 0.75\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 0.81\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 0.85\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.5    Test Loss : 0.88\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.46    Test Loss : 0.9\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.46    Test Loss : 0.92\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 0.94\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 0.95\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 0.97\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 0.98\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 1.0\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 86.21 ***\n",
      "Epoch 10 - Train Acc : 68.33    Train Loss : 0.57,    Test Acc : 71.62    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 69.17    Train Loss : 0.49,    Test Acc : 71.04    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.38,    Test Acc : 73.46    Test Loss : 0.53\n",
      "Epoch 40 - Train Acc : 91.67    Train Loss : 0.25,    Test Acc : 76.42    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 77.04    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 78.71    Test Loss : 0.64\n",
      "Epoch 70 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 81.67    Test Loss : 0.74\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 82.46    Test Loss : 0.88\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.08    Test Loss : 1.03\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.17    Test Loss : 1.19\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 1.31\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.42    Test Loss : 1.39\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 1.46\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.51\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.42    Test Loss : 1.55\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.38    Test Loss : 1.59\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.38    Test Loss : 1.62\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.38    Test Loss : 1.65\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 1.67\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.29    Test Loss : 1.7\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 82.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 8 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "Explaned variance ratio by principal components : [0.57410235 0.18386765 0.0693744  0.03691964 0.02279853 0.02059312\n",
      " 0.01146079 0.00695547 0.00625838] \n",
      " Overall ratio:  0.9323303226321229\n",
      "Explaned variance ratio by principal components : [0.50283109 0.17028135 0.09160995 0.06098791 0.03742539 0.02652397] \n",
      " Overall ratio:  0.8896596660680494\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.50283109 0.17028135 0.09160995 0.06098791 0.03742539 0.02652397] \n",
      " Overall ratio:  0.8896596660680489\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2706 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 75.83    Train Loss : 0.58,    Test Acc : 67.96    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 80.0    Train Loss : 0.42,    Test Acc : 70.71    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 73.54    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 93.33    Train Loss : 0.26,    Test Acc : 76.25    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 77.67    Test Loss : 0.71\n",
      "Epoch 60 - Train Acc : 95.0    Train Loss : 0.14,    Test Acc : 77.17    Test Loss : 0.86\n",
      "Epoch 70 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 76.71    Test Loss : 1.03\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 77.62    Test Loss : 1.15\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 77.96    Test Loss : 1.3\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 78.46    Test Loss : 1.43\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.58    Test Loss : 1.56\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.33    Test Loss : 1.71\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.54    Test Loss : 1.87\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.83    Test Loss : 2.03\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.67    Test Loss : 2.16\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.58    Test Loss : 2.28\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.79    Test Loss : 2.38\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.96    Test Loss : 2.46\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.0    Test Loss : 2.53\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.08    Test Loss : 2.59\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 79.08 ***\n",
      "Epoch 10 - Train Acc : 64.17    Train Loss : 0.59,    Test Acc : 62.67    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 70.83    Train Loss : 0.54,    Test Acc : 65.42    Test Loss : 0.68\n",
      "Epoch 30 - Train Acc : 73.33    Train Loss : 0.5,    Test Acc : 64.62    Test Loss : 0.69\n",
      "Epoch 40 - Train Acc : 75.83    Train Loss : 0.46,    Test Acc : 67.29    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 80.0    Train Loss : 0.39,    Test Acc : 69.5    Test Loss : 0.73\n",
      "Epoch 60 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 72.08    Test Loss : 0.79\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.22,    Test Acc : 72.12    Test Loss : 0.89\n",
      "Epoch 80 - Train Acc : 95.0    Train Loss : 0.14,    Test Acc : 72.42    Test Loss : 1.07\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 73.08    Test Loss : 1.32\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 73.96    Test Loss : 1.68\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 74.29    Test Loss : 2.07\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 74.12    Test Loss : 2.47\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 73.96    Test Loss : 2.78\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 73.58    Test Loss : 3.03\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 73.42    Test Loss : 3.23\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 73.58    Test Loss : 3.39\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 73.58    Test Loss : 3.52\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 73.5    Test Loss : 3.62\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 73.5    Test Loss : 3.71\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 73.54    Test Loss : 3.79\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 73.54 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 9 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.44689249 0.23215275 0.08293975 0.05940864 0.03709554 0.02654815\n",
      " 0.01738888 0.01046536 0.00960569] \n",
      " Overall ratio:  0.9224972566317602\n",
      "Explaned variance ratio by principal components : [0.4608065  0.2726299  0.07459642 0.04230136 0.03007816 0.02421791] \n",
      " Overall ratio:  0.9046302491882182\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.4608065  0.2726299  0.07459642 0.04230136 0.03007816 0.02421791] \n",
      " Overall ratio:  0.9046302491882163\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2731 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 72.5    Train Loss : 0.53,    Test Acc : 70.25    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.46,    Test Acc : 69.67    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.43,    Test Acc : 72.12    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 83.33    Train Loss : 0.39,    Test Acc : 74.17    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.33,    Test Acc : 76.21    Test Loss : 0.5\n",
      "Epoch 60 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 79.58    Test Loss : 0.45\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.14,    Test Acc : 83.79    Test Loss : 0.48\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 83.5    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 84.67    Test Loss : 0.83\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.5    Test Loss : 1.02\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.83    Test Loss : 1.16\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 1.25\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 1.32\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.37\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.42\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.46\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.49\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.52\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.55\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 1.58\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 86.17 ***\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.59,    Test Acc : 61.88    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 70.0    Train Loss : 0.51,    Test Acc : 66.62    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.42,    Test Acc : 72.67    Test Loss : 0.54\n",
      "Epoch 40 - Train Acc : 90.83    Train Loss : 0.28,    Test Acc : 81.38    Test Loss : 0.48\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.12,    Test Acc : 84.92    Test Loss : 0.45\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 86.38    Test Loss : 0.55\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.17    Test Loss : 0.69\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 0.8\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.88    Test Loss : 0.86\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 0.89\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 0.9\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 0.92\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 0.93\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.88    Test Loss : 0.94\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.88    Test Loss : 0.95\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 0.96\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 0.97\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 0.97\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 0.98\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 0.99\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 87.04 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 10 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1134,),    high arousal : (1386,)\n",
      "Explaned variance ratio by principal components : [0.58781647 0.24072545 0.04508322 0.02492528 0.01498236 0.01297621\n",
      " 0.00901634 0.00552238 0.0054266 ] \n",
      " Overall ratio:  0.946474303597169\n",
      "Explaned variance ratio by principal components : [0.57386026 0.28138646 0.05949809 0.02266869 0.01138361 0.0101871 ] \n",
      " Overall ratio:  0.9589842152238109\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.57386026 0.28138646 0.05949809 0.02266869 0.01138361 0.0101871 ] \n",
      " Overall ratio:  0.958984215223811\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1899 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 71.88    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 77.29    Test Loss : 0.48\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 79.63    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.29,    Test Acc : 80.17    Test Loss : 0.57\n",
      "Epoch 50 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 83.12    Test Loss : 0.61\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.2,    Test Acc : 83.29    Test Loss : 0.7\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.16,    Test Acc : 83.17    Test Loss : 0.77\n",
      "Epoch 80 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 83.21    Test Loss : 0.82\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 85.0    Test Loss : 0.87\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 85.21    Test Loss : 1.0\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 84.92    Test Loss : 1.2\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.58    Test Loss : 1.37\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.5\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.61\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.54    Test Loss : 1.69\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 1.75\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 1.81\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.42    Test Loss : 1.86\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.42    Test Loss : 1.9\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.38    Test Loss : 1.93\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 84.38 ***\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.63,    Test Acc : 64.04    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 72.5    Train Loss : 0.53,    Test Acc : 64.88    Test Loss : 0.68\n",
      "Epoch 30 - Train Acc : 77.5    Train Loss : 0.46,    Test Acc : 70.54    Test Loss : 0.7\n",
      "Epoch 40 - Train Acc : 81.67    Train Loss : 0.43,    Test Acc : 68.67    Test Loss : 0.78\n",
      "Epoch 50 - Train Acc : 81.67    Train Loss : 0.4,    Test Acc : 70.33    Test Loss : 0.76\n",
      "Epoch 60 - Train Acc : 82.5    Train Loss : 0.34,    Test Acc : 73.58    Test Loss : 0.72\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.25,    Test Acc : 76.54    Test Loss : 0.71\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 76.21    Test Loss : 0.74\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 76.92    Test Loss : 0.87\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 78.12    Test Loss : 1.03\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.42    Test Loss : 1.17\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.79    Test Loss : 1.32\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.88    Test Loss : 1.47\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.54    Test Loss : 1.58\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.75    Test Loss : 1.65\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.42    Test Loss : 1.71\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.33    Test Loss : 1.76\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.38    Test Loss : 1.81\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.25    Test Loss : 1.84\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.21    Test Loss : 1.88\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 78.21 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 11 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1575,),    high arousal : (945,)\n",
      "Explaned variance ratio by principal components : [0.76568987 0.15526957 0.02279887 0.01203807 0.01051219 0.00946625\n",
      " 0.00745327 0.00338042 0.00209395] \n",
      " Overall ratio:  0.9887024671084861\n",
      "Explaned variance ratio by principal components : [0.69510566 0.1854232  0.05276322 0.02060389 0.01388229 0.01110932] \n",
      " Overall ratio:  0.9788875775657132\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.69510566 0.1854232  0.05276322 0.02060389 0.01388229 0.01110932] \n",
      " Overall ratio:  0.9788875775657123\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1881 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.55,    Test Acc : 65.46    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 74.17    Train Loss : 0.5,    Test Acc : 66.12    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 72.5    Train Loss : 0.46,    Test Acc : 68.08    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 69.96    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.35,    Test Acc : 75.08    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.27,    Test Acc : 80.71    Test Loss : 0.56\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.18,    Test Acc : 82.71    Test Loss : 0.62\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 83.42    Test Loss : 0.84\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 83.79    Test Loss : 1.07\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.62    Test Loss : 1.41\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.29    Test Loss : 1.7\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.29    Test Loss : 1.88\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.58    Test Loss : 1.98\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 2.06\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.79    Test Loss : 2.12\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.79    Test Loss : 2.17\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.79    Test Loss : 2.2\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.92    Test Loss : 2.24\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.92    Test Loss : 2.27\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.92    Test Loss : 2.3\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 82.92 ***\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.51,    Test Acc : 70.62    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 85.83    Train Loss : 0.36,    Test Acc : 76.5    Test Loss : 0.54\n",
      "Epoch 30 - Train Acc : 90.0    Train Loss : 0.29,    Test Acc : 80.0    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 90.83    Train Loss : 0.25,    Test Acc : 79.21    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 90.83    Train Loss : 0.21,    Test Acc : 79.58    Test Loss : 0.61\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.18,    Test Acc : 82.21    Test Loss : 0.62\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.15,    Test Acc : 82.83    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 84.62    Test Loss : 0.73\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 85.46    Test Loss : 0.76\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 85.83    Test Loss : 0.77\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 87.5    Test Loss : 0.8\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 87.46    Test Loss : 0.89\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 87.42    Test Loss : 0.97\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.46    Test Loss : 1.05\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 1.15\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 1.24\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.32\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.37\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.41\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.45\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 87.21 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 12 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "Explaned variance ratio by principal components : [0.54593117 0.20194585 0.0593412  0.02669286 0.01930209 0.01847726\n",
      " 0.01373326 0.01143359 0.00908909] \n",
      " Overall ratio:  0.905946380203934\n",
      "Explaned variance ratio by principal components : [0.48495281 0.24186043 0.06941034 0.0314334  0.02605534 0.02267292] \n",
      " Overall ratio:  0.876385240437894\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.48495281 0.24186043 0.06941034 0.0314334  0.02605534 0.02267292] \n",
      " Overall ratio:  0.8763852404378931\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1918 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 66.67    Train Loss : 0.55,    Test Acc : 67.83    Test Loss : 0.54\n",
      "Epoch 20 - Train Acc : 73.33    Train Loss : 0.48,    Test Acc : 72.58    Test Loss : 0.51\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 75.67    Test Loss : 0.48\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 77.71    Test Loss : 0.46\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 79.38    Test Loss : 0.43\n",
      "Epoch 60 - Train Acc : 88.33    Train Loss : 0.23,    Test Acc : 81.67    Test Loss : 0.42\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.16,    Test Acc : 84.0    Test Loss : 0.46\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 86.42    Test Loss : 0.49\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 87.21    Test Loss : 0.54\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 88.0    Test Loss : 0.62\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.08    Test Loss : 0.72\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.8\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 0.86\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.25    Test Loss : 0.9\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 0.92\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 0.94\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.96\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.25    Test Loss : 0.98\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 0.99\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 1.0\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 88.17 ***\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.58,    Test Acc : 63.58    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.49,    Test Acc : 70.46    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 82.5    Train Loss : 0.42,    Test Acc : 73.42    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.31,    Test Acc : 77.58    Test Loss : 0.5\n",
      "Epoch 50 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 83.83    Test Loss : 0.4\n",
      "Epoch 60 - Train Acc : 95.83    Train Loss : 0.12,    Test Acc : 86.33    Test Loss : 0.38\n",
      "Epoch 70 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 88.0    Test Loss : 0.41\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 88.75    Test Loss : 0.49\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.79    Test Loss : 0.57\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.5    Test Loss : 0.66\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 0.7\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 0.73\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 0.75\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 0.77\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 0.79\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 0.8\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 0.81\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 0.82\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 0.83\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 0.84\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 88.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 13 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1386,),    high valence : (1134,)\n",
      "low arousal : (378,),    high arousal : (2142,)\n",
      "Explaned variance ratio by principal components : [0.43736414 0.31086054 0.04810466 0.04015608 0.02878613 0.01523213\n",
      " 0.01310141 0.01005132 0.00753943] \n",
      " Overall ratio:  0.9111958474949405\n",
      "Explaned variance ratio by principal components : [0.43256084 0.30382503 0.06602212 0.05089246 0.03799757 0.01800114] \n",
      " Overall ratio:  0.9092991530043638\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.43256084 0.30382503 0.06602212 0.05089246 0.03799757 0.01800114] \n",
      " Overall ratio:  0.9092991530043664\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2817 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 83.33    Train Loss : 0.42,    Test Acc : 75.54    Test Loss : 0.52\n",
      "Epoch 20 - Train Acc : 85.83    Train Loss : 0.33,    Test Acc : 76.46    Test Loss : 0.54\n",
      "Epoch 30 - Train Acc : 86.67    Train Loss : 0.25,    Test Acc : 76.67    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 94.17    Train Loss : 0.2,    Test Acc : 79.67    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 95.0    Train Loss : 0.17,    Test Acc : 79.83    Test Loss : 0.72\n",
      "Epoch 60 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 79.29    Test Loss : 0.74\n",
      "Epoch 70 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 79.75    Test Loss : 0.73\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 79.79    Test Loss : 0.76\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 80.04    Test Loss : 0.81\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 80.25    Test Loss : 0.91\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 81.96    Test Loss : 1.02\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 82.12    Test Loss : 1.15\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 81.96    Test Loss : 1.29\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 81.88    Test Loss : 1.44\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.42    Test Loss : 1.62\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.75    Test Loss : 1.78\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.67    Test Loss : 1.94\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.0    Test Loss : 2.08\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.0    Test Loss : 2.2\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.83    Test Loss : 2.3\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 81.83 ***\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.55,    Test Acc : 59.54    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 75.0    Train Loss : 0.43,    Test Acc : 66.83    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 81.67    Train Loss : 0.37,    Test Acc : 69.75    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 85.0    Train Loss : 0.31,    Test Acc : 75.33    Test Loss : 0.43\n",
      "Epoch 50 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 79.67    Test Loss : 0.4\n",
      "Epoch 60 - Train Acc : 93.33    Train Loss : 0.21,    Test Acc : 82.5    Test Loss : 0.4\n",
      "Epoch 70 - Train Acc : 95.0    Train Loss : 0.16,    Test Acc : 83.04    Test Loss : 0.41\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 84.38    Test Loss : 0.46\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 85.5    Test Loss : 0.55\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 85.71    Test Loss : 0.66\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 85.25    Test Loss : 0.83\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.5    Test Loss : 1.02\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.29    Test Loss : 1.14\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 1.22\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 1.28\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 1.34\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 1.38\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 1.41\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 1.45\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.33    Test Loss : 1.47\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 84.33 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 14 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.55342623 0.19145894 0.0527622  0.02522522 0.02398084 0.0177977\n",
      " 0.0158908  0.01216294 0.00907979] \n",
      " Overall ratio:  0.9017846534407353\n",
      "Explaned variance ratio by principal components : [0.50868337 0.26862834 0.05921244 0.02846371 0.02169384 0.01650261] \n",
      " Overall ratio:  0.9031843047409416\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.50868337 0.26862834 0.05921244 0.02846371 0.02169384 0.01650261] \n",
      " Overall ratio:  0.9031843047410273\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2800 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 73.33    Train Loss : 0.52,    Test Acc : 68.71    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 71.17    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.39,    Test Acc : 76.42    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.32,    Test Acc : 78.46    Test Loss : 0.72\n",
      "Epoch 50 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 79.12    Test Loss : 0.79\n",
      "Epoch 60 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 81.0    Test Loss : 1.0\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 81.0    Test Loss : 1.35\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 81.79    Test Loss : 1.61\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.58    Test Loss : 1.84\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.17    Test Loss : 2.08\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.75    Test Loss : 2.27\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 2.41\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 2.51\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.04    Test Loss : 2.59\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.12    Test Loss : 2.65\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.12    Test Loss : 2.7\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.25    Test Loss : 2.75\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.25    Test Loss : 2.79\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.21    Test Loss : 2.83\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 2.86\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 81.17 ***\n",
      "Epoch 10 - Train Acc : 64.17    Train Loss : 0.62,    Test Acc : 59.79    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 65.83    Train Loss : 0.58,    Test Acc : 65.46    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 65.83    Train Loss : 0.55,    Test Acc : 66.58    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 70.0    Train Loss : 0.49,    Test Acc : 68.25    Test Loss : 0.54\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.38,    Test Acc : 78.33    Test Loss : 0.47\n",
      "Epoch 60 - Train Acc : 90.83    Train Loss : 0.26,    Test Acc : 81.17    Test Loss : 0.44\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.14,    Test Acc : 80.96    Test Loss : 0.56\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.06,    Test Acc : 81.25    Test Loss : 0.79\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 81.17    Test Loss : 1.11\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.08    Test Loss : 1.44\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.42    Test Loss : 1.67\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.38    Test Loss : 1.84\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.29    Test Loss : 1.95\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.38    Test Loss : 2.03\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.33    Test Loss : 2.09\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.5    Test Loss : 2.14\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.42    Test Loss : 2.18\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.38    Test Loss : 2.22\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.38    Test Loss : 2.25\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.29    Test Loss : 2.28\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 81.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 15 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1197,),    high arousal : (1323,)\n",
      "Explaned variance ratio by principal components : [0.43428238 0.24875278 0.12255951 0.0456574  0.04287132 0.01604328\n",
      " 0.01161675 0.01012167 0.0079936 ] \n",
      " Overall ratio:  0.9398986900981424\n",
      "Explaned variance ratio by principal components : [0.41161407 0.24159887 0.10584548 0.06013956 0.05390225 0.03174993] \n",
      " Overall ratio:  0.9048501544111535\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.41161407 0.24159887 0.10584548 0.06013956 0.05390225 0.03174993] \n",
      " Overall ratio:  0.9048501544111524\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2793 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 79.17    Train Loss : 0.48,    Test Acc : 74.42    Test Loss : 0.53\n",
      "Epoch 20 - Train Acc : 82.5    Train Loss : 0.35,    Test Acc : 77.42    Test Loss : 0.51\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.31,    Test Acc : 77.0    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 86.67    Train Loss : 0.27,    Test Acc : 77.79    Test Loss : 0.56\n",
      "Epoch 50 - Train Acc : 90.0    Train Loss : 0.23,    Test Acc : 80.17    Test Loss : 0.59\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.17,    Test Acc : 84.38    Test Loss : 0.61\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.12,    Test Acc : 85.88    Test Loss : 0.71\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 87.62    Test Loss : 0.89\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 88.71    Test Loss : 1.05\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 89.0    Test Loss : 1.18\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.5    Test Loss : 1.32\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.79    Test Loss : 1.45\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.55\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 1.62\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.68\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.72\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.76\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 1.79\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.82\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.84\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 90.12 ***\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.58,    Test Acc : 66.62    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 71.67    Train Loss : 0.51,    Test Acc : 67.21    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.45,    Test Acc : 72.08    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 77.5    Train Loss : 0.38,    Test Acc : 74.83    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.3,    Test Acc : 76.33    Test Loss : 0.51\n",
      "Epoch 60 - Train Acc : 89.17    Train Loss : 0.22,    Test Acc : 77.79    Test Loss : 0.55\n",
      "Epoch 70 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 80.71    Test Loss : 0.57\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 83.96    Test Loss : 0.62\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 85.79    Test Loss : 0.7\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 86.33    Test Loss : 0.82\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.38    Test Loss : 0.94\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.54    Test Loss : 1.06\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.67    Test Loss : 1.16\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.58    Test Loss : 1.24\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.46    Test Loss : 1.31\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.46    Test Loss : 1.37\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.58    Test Loss : 1.41\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.54    Test Loss : 1.45\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.62    Test Loss : 1.49\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.67    Test Loss : 1.52\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 86.67 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 16 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1575,),    high valence : (945,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.51440021 0.20004677 0.04832673 0.03633426 0.02519057 0.01979191\n",
      " 0.01246149 0.01143357 0.00974675] \n",
      " Overall ratio:  0.8777322525766603\n",
      "Explaned variance ratio by principal components : [0.52968023 0.20454603 0.05797728 0.03185913 0.02534341 0.02045039] \n",
      " Overall ratio:  0.8698564693515246\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.52968023 0.20454603 0.05797728 0.03185913 0.02534341 0.02045039] \n",
      " Overall ratio:  0.8698564693515286\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2818 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 79.17    Train Loss : 0.48,    Test Acc : 73.46    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 85.83    Train Loss : 0.39,    Test Acc : 72.42    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 74.04    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.29,    Test Acc : 74.54    Test Loss : 0.59\n",
      "Epoch 50 - Train Acc : 93.33    Train Loss : 0.21,    Test Acc : 77.12    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 79.08    Test Loss : 0.76\n",
      "Epoch 70 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 81.29    Test Loss : 0.87\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 81.33    Test Loss : 1.1\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.83    Test Loss : 1.27\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 1.42\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.58    Test Loss : 1.51\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 1.55\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.62    Test Loss : 1.58\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 1.61\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 1.63\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 1.65\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.79    Test Loss : 1.67\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.68\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.7\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.71\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 82.83 ***\n",
      "Epoch 10 - Train Acc : 80.0    Train Loss : 0.51,    Test Acc : 73.12    Test Loss : 0.55\n",
      "Epoch 20 - Train Acc : 81.67    Train Loss : 0.38,    Test Acc : 71.83    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 74.12    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 86.67    Train Loss : 0.3,    Test Acc : 75.04    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 86.67    Train Loss : 0.26,    Test Acc : 75.58    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 89.17    Train Loss : 0.21,    Test Acc : 76.33    Test Loss : 0.65\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.15,    Test Acc : 78.04    Test Loss : 0.77\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 80.0    Test Loss : 0.96\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 80.92    Test Loss : 1.2\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 81.46    Test Loss : 1.51\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.08    Test Loss : 1.85\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.29    Test Loss : 2.13\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.08    Test Loss : 2.33\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.48\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.6\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.17    Test Loss : 2.69\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.76\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.04    Test Loss : 2.83\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.04    Test Loss : 2.88\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.0    Test Loss : 2.93\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 82.0 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 17 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.51062918 0.22961179 0.05328091 0.04976234 0.01945455 0.01380647\n",
      " 0.01330218 0.00980806 0.00856099] \n",
      " Overall ratio:  0.9082164721176522\n",
      "Explaned variance ratio by principal components : [0.51133997 0.18998672 0.05204487 0.04464509 0.03271103 0.02685497] \n",
      " Overall ratio:  0.8575826465968562\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.51133997 0.18998672 0.05204487 0.04464509 0.03271103 0.02685497] \n",
      " Overall ratio:  0.8575826465968565\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2798 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 66.67    Train Loss : 0.56,    Test Acc : 59.25    Test Loss : 0.7\n",
      "Epoch 20 - Train Acc : 70.83    Train Loss : 0.5,    Test Acc : 60.96    Test Loss : 0.7\n",
      "Epoch 30 - Train Acc : 80.0    Train Loss : 0.45,    Test Acc : 66.54    Test Loss : 0.73\n",
      "Epoch 40 - Train Acc : 80.0    Train Loss : 0.4,    Test Acc : 65.71    Test Loss : 0.78\n",
      "Epoch 50 - Train Acc : 86.67    Train Loss : 0.32,    Test Acc : 67.54    Test Loss : 0.8\n",
      "Epoch 60 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 73.25    Test Loss : 0.83\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 73.88    Test Loss : 0.94\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 74.0    Test Loss : 1.15\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 75.88    Test Loss : 1.36\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 77.04    Test Loss : 1.59\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 77.62    Test Loss : 1.87\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.46    Test Loss : 2.11\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.46    Test Loss : 2.3\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.46    Test Loss : 2.44\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.46    Test Loss : 2.54\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.5    Test Loss : 2.62\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.58    Test Loss : 2.68\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.5    Test Loss : 2.74\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.5    Test Loss : 2.78\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.54    Test Loss : 2.83\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 78.54 ***\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.49,    Test Acc : 70.12    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 81.67    Train Loss : 0.45,    Test Acc : 71.42    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.41,    Test Acc : 71.75    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 85.0    Train Loss : 0.37,    Test Acc : 70.42    Test Loss : 0.6\n",
      "Epoch 50 - Train Acc : 89.17    Train Loss : 0.31,    Test Acc : 71.29    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 72.33    Test Loss : 0.61\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.21,    Test Acc : 74.79    Test Loss : 0.62\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 76.96    Test Loss : 0.68\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.1,    Test Acc : 79.79    Test Loss : 0.81\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 81.75    Test Loss : 1.13\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 81.67    Test Loss : 1.52\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.83    Test Loss : 1.86\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.54    Test Loss : 2.13\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.25    Test Loss : 2.32\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 2.46\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.29    Test Loss : 2.56\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.29    Test Loss : 2.64\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.21    Test Loss : 2.71\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 2.76\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 2.81\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 81.17 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 18 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.39463138 0.30355925 0.09429425 0.05535936 0.0298884  0.02025116\n",
      " 0.01442286 0.00889498 0.00846107] \n",
      " Overall ratio:  0.9297627011520958\n",
      "Explaned variance ratio by principal components : [0.45500856 0.27365644 0.08954509 0.05228638 0.04110322 0.02312372] \n",
      " Overall ratio:  0.9347234121175605\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.45500856 0.27365644 0.08954509 0.05228638 0.04110322 0.02312372] \n",
      " Overall ratio:  0.9347234121175619\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.4844 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.45,    Test Acc : 73.92    Test Loss : 0.52\n",
      "Epoch 20 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 77.0    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 81.04    Test Loss : 0.48\n",
      "Epoch 40 - Train Acc : 91.67    Train Loss : 0.23,    Test Acc : 81.46    Test Loss : 0.5\n",
      "Epoch 50 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 82.96    Test Loss : 0.49\n",
      "Epoch 60 - Train Acc : 96.67    Train Loss : 0.16,    Test Acc : 84.79    Test Loss : 0.5\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.14,    Test Acc : 85.25    Test Loss : 0.54\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 85.38    Test Loss : 0.58\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 85.12    Test Loss : 0.61\n",
      "Epoch 100 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 85.5    Test Loss : 0.66\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 86.08    Test Loss : 0.78\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 86.96    Test Loss : 0.88\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.62    Test Loss : 0.99\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.21    Test Loss : 1.08\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 1.16\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.22\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.27\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.31\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.34\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.37\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 88.96 ***\n",
      "Epoch 10 - Train Acc : 75.83    Train Loss : 0.58,    Test Acc : 66.75    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 75.83    Train Loss : 0.46,    Test Acc : 66.58    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 69.38    Test Loss : 0.72\n",
      "Epoch 40 - Train Acc : 79.17    Train Loss : 0.4,    Test Acc : 69.29    Test Loss : 0.69\n",
      "Epoch 50 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 71.46    Test Loss : 0.66\n",
      "Epoch 60 - Train Acc : 85.0    Train Loss : 0.29,    Test Acc : 73.58    Test Loss : 0.68\n",
      "Epoch 70 - Train Acc : 89.17    Train Loss : 0.22,    Test Acc : 75.88    Test Loss : 0.74\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 77.0    Test Loss : 0.84\n",
      "Epoch 90 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 77.79    Test Loss : 1.01\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 77.46    Test Loss : 1.26\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 77.38    Test Loss : 1.58\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 77.62    Test Loss : 1.91\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.0    Test Loss : 2.19\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.17    Test Loss : 2.47\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 77.96    Test Loss : 2.75\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 77.75    Test Loss : 3.0\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.62    Test Loss : 3.23\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.38    Test Loss : 3.41\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.29    Test Loss : 3.57\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.17    Test Loss : 3.7\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 77.17 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 19 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.54074327 0.14616401 0.0587916  0.0435941  0.04350681 0.02031629\n",
      " 0.01615357 0.01535712 0.01122858] \n",
      " Overall ratio:  0.8958553525317096\n",
      "Explaned variance ratio by principal components : [0.51210075 0.20727576 0.05449805 0.04206374 0.03852601 0.02942513] \n",
      " Overall ratio:  0.8838894482023038\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.51210075 0.20727576 0.05449805 0.04206374 0.03852601 0.02942513] \n",
      " Overall ratio:  0.8838894482023032\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.4994 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.55,    Test Acc : 72.29    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.49,    Test Acc : 74.88    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.44,    Test Acc : 75.25    Test Loss : 0.49\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 79.58    Test Loss : 0.4\n",
      "Epoch 50 - Train Acc : 90.83    Train Loss : 0.27,    Test Acc : 84.42    Test Loss : 0.31\n",
      "Epoch 60 - Train Acc : 95.83    Train Loss : 0.17,    Test Acc : 87.92    Test Loss : 0.28\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 89.17    Test Loss : 0.32\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 90.71    Test Loss : 0.34\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 91.33    Test Loss : 0.4\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 91.42    Test Loss : 0.47\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 91.42    Test Loss : 0.54\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 91.5    Test Loss : 0.6\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.65\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.17    Test Loss : 0.68\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.04    Test Loss : 0.71\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.04    Test Loss : 0.73\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.08    Test Loss : 0.75\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.08    Test Loss : 0.77\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.96    Test Loss : 0.78\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.92    Test Loss : 0.8\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 90.92 ***\n",
      "Epoch 10 - Train Acc : 70.83    Train Loss : 0.51,    Test Acc : 69.29    Test Loss : 0.55\n",
      "Epoch 20 - Train Acc : 75.0    Train Loss : 0.47,    Test Acc : 73.21    Test Loss : 0.51\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.43,    Test Acc : 72.58    Test Loss : 0.48\n",
      "Epoch 40 - Train Acc : 81.67    Train Loss : 0.36,    Test Acc : 76.67    Test Loss : 0.44\n",
      "Epoch 50 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 81.42    Test Loss : 0.41\n",
      "Epoch 60 - Train Acc : 97.5    Train Loss : 0.14,    Test Acc : 85.88    Test Loss : 0.4\n",
      "Epoch 70 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 87.12    Test Loss : 0.43\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 87.5    Test Loss : 0.53\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.88    Test Loss : 0.64\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.21    Test Loss : 0.75\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.83\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 0.9\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 0.95\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 0.99\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.06\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 1.08\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 1.11\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 1.13\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 1.15\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 88.5 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 20 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (567,),    high arousal : (1953,)\n",
      "Explaned variance ratio by principal components : [0.41146202 0.24929551 0.08454913 0.0409253  0.01957663 0.01841643\n",
      " 0.01496066 0.01237091 0.01122691] \n",
      " Overall ratio:  0.8627834894871749\n",
      "Explaned variance ratio by principal components : [0.36508439 0.30190392 0.08544304 0.05024928 0.03448712 0.02076544] \n",
      " Overall ratio:  0.8579331886757007\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.36508439 0.30190392 0.08544304 0.05024928 0.03448712 0.02076544] \n",
      " Overall ratio:  0.857933188676028\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2636 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.49,    Test Acc : 76.54    Test Loss : 0.49\n",
      "Epoch 20 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 77.71    Test Loss : 0.46\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.32,    Test Acc : 75.67    Test Loss : 0.49\n",
      "Epoch 40 - Train Acc : 85.83    Train Loss : 0.29,    Test Acc : 79.33    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 89.17    Train Loss : 0.24,    Test Acc : 81.96    Test Loss : 0.41\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 83.92    Test Loss : 0.42\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 85.08    Test Loss : 0.5\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 85.38    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 84.96    Test Loss : 0.7\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 85.58    Test Loss : 0.88\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 85.92    Test Loss : 1.12\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.92    Test Loss : 1.4\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.63\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.81\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 1.96\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 2.07\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 2.16\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 2.23\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 2.29\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.63    Test Loss : 2.35\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 85.63 ***\n",
      "Epoch 10 - Train Acc : 66.67    Train Loss : 0.58,    Test Acc : 64.33    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.46,    Test Acc : 68.33    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 80.0    Train Loss : 0.41,    Test Acc : 71.17    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 85.83    Train Loss : 0.33,    Test Acc : 73.92    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 94.17    Train Loss : 0.22,    Test Acc : 81.33    Test Loss : 0.45\n",
      "Epoch 60 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 85.04    Test Loss : 0.48\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 87.29    Test Loss : 0.58\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 87.79    Test Loss : 0.74\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.54    Test Loss : 0.9\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.01\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 1.1\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 1.15\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.88    Test Loss : 1.19\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 1.22\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 1.25\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.27\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.3\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.32\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.34\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.35\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 86.71 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 21 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (504,),    high arousal : (2016,)\n",
      "Explaned variance ratio by principal components : [0.55716619 0.17213443 0.05407688 0.03728339 0.02120906 0.01599675\n",
      " 0.01369203 0.01138043 0.0086399 ] \n",
      " Overall ratio:  0.8915790647572368\n",
      "Explaned variance ratio by principal components : [0.59388807 0.18322285 0.0644886  0.04110107 0.02115446 0.01426468] \n",
      " Overall ratio:  0.9181197212062884\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.59388807 0.18322285 0.0644886  0.04110107 0.02115446 0.01426468] \n",
      " Overall ratio:  0.9181197212054579\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2668 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.59,    Test Acc : 61.67    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 74.17    Train Loss : 0.55,    Test Acc : 64.62    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 73.33    Train Loss : 0.51,    Test Acc : 66.83    Test Loss : 0.61\n",
      "Epoch 40 - Train Acc : 77.5    Train Loss : 0.46,    Test Acc : 69.17    Test Loss : 0.58\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.39,    Test Acc : 72.58    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 88.33    Train Loss : 0.31,    Test Acc : 76.17    Test Loss : 0.56\n",
      "Epoch 70 - Train Acc : 92.5    Train Loss : 0.25,    Test Acc : 77.46    Test Loss : 0.58\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 76.54    Test Loss : 0.64\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 77.62    Test Loss : 0.76\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.08,    Test Acc : 78.96    Test Loss : 0.91\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 80.42    Test Loss : 1.06\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.25    Test Loss : 1.2\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.62    Test Loss : 1.33\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.67    Test Loss : 1.43\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 1.52\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 1.57\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 1.61\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 1.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 1.68\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.62    Test Loss : 1.71\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 82.62 ***\n",
      "Epoch 10 - Train Acc : 65.83    Train Loss : 0.6,    Test Acc : 62.96    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 69.17    Train Loss : 0.51,    Test Acc : 65.17    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 82.5    Train Loss : 0.43,    Test Acc : 70.54    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 86.67    Train Loss : 0.35,    Test Acc : 74.62    Test Loss : 0.5\n",
      "Epoch 50 - Train Acc : 92.5    Train Loss : 0.27,    Test Acc : 78.17    Test Loss : 0.45\n",
      "Epoch 60 - Train Acc : 94.17    Train Loss : 0.18,    Test Acc : 84.42    Test Loss : 0.37\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 89.46    Test Loss : 0.29\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 92.04    Test Loss : 0.26\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 91.83    Test Loss : 0.27\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 90.21    Test Loss : 0.27\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 89.67    Test Loss : 0.31\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 89.29    Test Loss : 0.37\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.29    Test Loss : 0.41\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.54    Test Loss : 0.45\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.46    Test Loss : 0.48\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.83    Test Loss : 0.5\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 0.52\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.92    Test Loss : 0.54\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.0    Test Loss : 0.56\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.92    Test Loss : 0.57\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 89.92 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 22 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "Explaned variance ratio by principal components : [0.47730228 0.39914183 0.04861757 0.0220424  0.01639548 0.01143172\n",
      " 0.00696697 0.0041986  0.00237292] \n",
      " Overall ratio:  0.9884697733357491\n",
      "Explaned variance ratio by principal components : [0.47119558 0.40222649 0.05971501 0.02436959 0.01386209 0.00802466] \n",
      " Overall ratio:  0.9793934171432369\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.47119558 0.40222649 0.05971501 0.02436959 0.01386209 0.00802466] \n",
      " Overall ratio:  0.9793934171432361\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2675 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.52,    Test Acc : 72.5    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 80.0    Train Loss : 0.45,    Test Acc : 75.71    Test Loss : 0.55\n",
      "Epoch 30 - Train Acc : 78.33    Train Loss : 0.41,    Test Acc : 71.92    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 73.96    Test Loss : 0.53\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 76.88    Test Loss : 0.49\n",
      "Epoch 60 - Train Acc : 93.33    Train Loss : 0.22,    Test Acc : 80.0    Test Loss : 0.46\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.15,    Test Acc : 81.17    Test Loss : 0.49\n",
      "Epoch 80 - Train Acc : 95.0    Train Loss : 0.11,    Test Acc : 82.38    Test Loss : 0.58\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 82.58    Test Loss : 0.7\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 83.08    Test Loss : 0.81\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 83.5    Test Loss : 0.88\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 83.42    Test Loss : 0.94\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.46    Test Loss : 1.01\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.79    Test Loss : 1.1\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.71    Test Loss : 1.19\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 1.27\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 1.34\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 1.39\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 1.44\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 1.49\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 83.46 ***\n",
      "Epoch 10 - Train Acc : 68.33    Train Loss : 0.6,    Test Acc : 62.04    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 75.0    Train Loss : 0.53,    Test Acc : 64.92    Test Loss : 0.75\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.48,    Test Acc : 65.88    Test Loss : 0.8\n",
      "Epoch 40 - Train Acc : 80.83    Train Loss : 0.43,    Test Acc : 66.92    Test Loss : 0.76\n",
      "Epoch 50 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 68.08    Test Loss : 0.74\n",
      "Epoch 60 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 68.58    Test Loss : 0.79\n",
      "Epoch 70 - Train Acc : 89.17    Train Loss : 0.23,    Test Acc : 71.79    Test Loss : 0.89\n",
      "Epoch 80 - Train Acc : 91.67    Train Loss : 0.17,    Test Acc : 73.42    Test Loss : 1.02\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 75.21    Test Loss : 1.14\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 75.38    Test Loss : 1.4\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 75.46    Test Loss : 1.82\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 76.0    Test Loss : 2.21\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.54    Test Loss : 2.54\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.75    Test Loss : 2.85\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.96    Test Loss : 3.1\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.67    Test Loss : 3.3\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.54    Test Loss : 3.47\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.67    Test Loss : 3.6\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.71    Test Loss : 3.71\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.75    Test Loss : 3.81\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 76.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 23 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1701,),    high arousal : (819,)\n",
      "Explaned variance ratio by principal components : [0.50728102 0.13796758 0.06711706 0.060446   0.03076925 0.02072436\n",
      " 0.01518572 0.01489597 0.0118421 ] \n",
      " Overall ratio:  0.8662290567593832\n",
      "Explaned variance ratio by principal components : [0.42449235 0.18976918 0.09371976 0.05809049 0.04000829 0.0259987 ] \n",
      " Overall ratio:  0.8320787702029635\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.42449235 0.18976918 0.09371976 0.05809049 0.04000829 0.0259987 ] \n",
      " Overall ratio:  0.8320787702030419\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2677 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 70.83    Train Loss : 0.58,    Test Acc : 69.17    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.55,    Test Acc : 73.33    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 77.5    Train Loss : 0.51,    Test Acc : 73.29    Test Loss : 0.54\n",
      "Epoch 40 - Train Acc : 80.83    Train Loss : 0.46,    Test Acc : 77.46    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 86.67    Train Loss : 0.37,    Test Acc : 81.12    Test Loss : 0.43\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.26,    Test Acc : 84.21    Test Loss : 0.4\n",
      "Epoch 70 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 86.46    Test Loss : 0.46\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 88.08    Test Loss : 0.5\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 89.5    Test Loss : 0.53\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 90.58    Test Loss : 0.58\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.83    Test Loss : 0.64\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.88    Test Loss : 0.68\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.5    Test Loss : 0.7\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.72\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.46    Test Loss : 0.73\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 0.75\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 0.76\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 0.77\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 0.77\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 0.78\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 90.42 ***\n",
      "Epoch 10 - Train Acc : 79.17    Train Loss : 0.48,    Test Acc : 70.58    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 82.5    Train Loss : 0.38,    Test Acc : 73.79    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.31,    Test Acc : 72.42    Test Loss : 0.75\n",
      "Epoch 40 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 77.62    Test Loss : 0.73\n",
      "Epoch 50 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 78.58    Test Loss : 0.7\n",
      "Epoch 60 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 80.0    Test Loss : 0.84\n",
      "Epoch 70 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 81.96    Test Loss : 1.01\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 84.38    Test Loss : 1.14\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 86.17    Test Loss : 1.25\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 86.75    Test Loss : 1.35\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.62    Test Loss : 1.46\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.71    Test Loss : 1.58\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.69\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.79\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.89\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.96\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 2.02\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 2.07\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 2.12\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 2.16\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 87.17 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 24 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "Explaned variance ratio by principal components : [0.56681254 0.17093498 0.05109744 0.03374641 0.02973686 0.01630758\n",
      " 0.01447047 0.01245046 0.01152172] \n",
      " Overall ratio:  0.9070784680945846\n",
      "Explaned variance ratio by principal components : [0.63743425 0.21249161 0.035946   0.02538881 0.01366706 0.00966347] \n",
      " Overall ratio:  0.9345912009270315\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.63743425 0.21249161 0.035946   0.02538881 0.01366706 0.00966347] \n",
      " Overall ratio:  0.9345912009271602\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2970 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.57,    Test Acc : 72.54    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.45,    Test Acc : 74.25    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.42,    Test Acc : 74.29    Test Loss : 0.67\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 75.58    Test Loss : 0.61\n",
      "Epoch 50 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 75.75    Test Loss : 0.59\n",
      "Epoch 60 - Train Acc : 89.17    Train Loss : 0.29,    Test Acc : 76.88    Test Loss : 0.58\n",
      "Epoch 70 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 79.21    Test Loss : 0.54\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 81.08    Test Loss : 0.54\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 82.67    Test Loss : 0.64\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 84.17    Test Loss : 0.78\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 84.46    Test Loss : 0.93\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 84.62    Test Loss : 1.06\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.71    Test Loss : 1.21\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.58    Test Loss : 1.34\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.38    Test Loss : 1.45\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 1.54\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 1.61\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.08    Test Loss : 1.68\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.08    Test Loss : 1.73\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.0    Test Loss : 1.78\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 84.0 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.57,    Test Acc : 61.58    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 83.33    Train Loss : 0.38,    Test Acc : 77.92    Test Loss : 0.41\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.34,    Test Acc : 79.96    Test Loss : 0.42\n",
      "Epoch 40 - Train Acc : 85.0    Train Loss : 0.32,    Test Acc : 78.71    Test Loss : 0.43\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 78.58    Test Loss : 0.4\n",
      "Epoch 60 - Train Acc : 86.67    Train Loss : 0.28,    Test Acc : 80.5    Test Loss : 0.39\n",
      "Epoch 70 - Train Acc : 86.67    Train Loss : 0.25,    Test Acc : 80.58    Test Loss : 0.39\n",
      "Epoch 80 - Train Acc : 88.33    Train Loss : 0.22,    Test Acc : 81.5    Test Loss : 0.38\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.16,    Test Acc : 84.0    Test Loss : 0.38\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 85.96    Test Loss : 0.42\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 86.33    Test Loss : 0.52\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.25    Test Loss : 0.66\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.46    Test Loss : 0.79\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.5    Test Loss : 0.88\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.63    Test Loss : 0.95\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 0.99\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 1.03\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 1.06\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.1\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 85.71 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 25 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (630,),    high arousal : (1890,)\n",
      "Explaned variance ratio by principal components : [0.55520879 0.2837569  0.03858897 0.03071047 0.02578398 0.01260087\n",
      " 0.01050494 0.0082018  0.00602108] \n",
      " Overall ratio:  0.9713778100613129\n",
      "Explaned variance ratio by principal components : [0.47178681 0.28829264 0.09576637 0.04040026 0.03346586 0.02253163] \n",
      " Overall ratio:  0.9522435601348439\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.47178681 0.28829264 0.09576637 0.04040026 0.03346586 0.02253163] \n",
      " Overall ratio:  0.9522435601348428\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2736 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.52,    Test Acc : 69.0    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 72.5    Train Loss : 0.47,    Test Acc : 64.79    Test Loss : 0.72\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.43,    Test Acc : 67.29    Test Loss : 0.67\n",
      "Epoch 40 - Train Acc : 85.0    Train Loss : 0.38,    Test Acc : 70.0    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 74.12    Test Loss : 0.66\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.23,    Test Acc : 75.42    Test Loss : 0.69\n",
      "Epoch 70 - Train Acc : 97.5    Train Loss : 0.15,    Test Acc : 75.83    Test Loss : 0.78\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 78.04    Test Loss : 0.98\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.92    Test Loss : 1.3\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.67    Test Loss : 1.68\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.83    Test Loss : 1.91\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.08    Test Loss : 2.02\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.04    Test Loss : 2.12\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.08    Test Loss : 2.18\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.04    Test Loss : 2.24\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.0    Test Loss : 2.29\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.88    Test Loss : 2.33\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.83    Test Loss : 2.36\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.83    Test Loss : 2.4\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.75    Test Loss : 2.43\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 78.75 ***\n",
      "Epoch 10 - Train Acc : 73.33    Train Loss : 0.57,    Test Acc : 67.92    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 84.17    Train Loss : 0.47,    Test Acc : 75.21    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 85.83    Train Loss : 0.38,    Test Acc : 80.54    Test Loss : 0.46\n",
      "Epoch 40 - Train Acc : 89.17    Train Loss : 0.28,    Test Acc : 80.42    Test Loss : 0.46\n",
      "Epoch 50 - Train Acc : 93.33    Train Loss : 0.19,    Test Acc : 80.29    Test Loss : 0.52\n",
      "Epoch 60 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 80.62    Test Loss : 0.63\n",
      "Epoch 70 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 81.0    Test Loss : 0.75\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 82.0    Test Loss : 0.9\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.58    Test Loss : 1.07\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.42    Test Loss : 1.25\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.38    Test Loss : 1.41\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.52\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 1.62\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.08    Test Loss : 1.69\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.96    Test Loss : 1.75\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.0    Test Loss : 1.8\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.04    Test Loss : 1.84\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.0    Test Loss : 1.88\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.92    Test Loss : 1.91\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.88    Test Loss : 1.94\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 82.88 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 26 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "Explaned variance ratio by principal components : [0.56050442 0.16106454 0.07318039 0.04436825 0.02512253 0.01573966\n",
      " 0.01420222 0.01224927 0.00876687] \n",
      " Overall ratio:  0.9151981526673507\n",
      "Explaned variance ratio by principal components : [0.56648751 0.25244451 0.0436146  0.02954773 0.02000295 0.01559967] \n",
      " Overall ratio:  0.9276969694469026\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.56648751 0.25244451 0.0436146  0.02954773 0.02000295 0.01559967] \n",
      " Overall ratio:  0.9276969694469017\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2767 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.5,    Test Acc : 74.92    Test Loss : 0.53\n",
      "Epoch 20 - Train Acc : 86.67    Train Loss : 0.37,    Test Acc : 78.21    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 87.5    Train Loss : 0.34,    Test Acc : 78.33    Test Loss : 0.51\n",
      "Epoch 40 - Train Acc : 86.67    Train Loss : 0.31,    Test Acc : 79.96    Test Loss : 0.46\n",
      "Epoch 50 - Train Acc : 86.67    Train Loss : 0.27,    Test Acc : 80.42    Test Loss : 0.43\n",
      "Epoch 60 - Train Acc : 90.0    Train Loss : 0.23,    Test Acc : 81.75    Test Loss : 0.41\n",
      "Epoch 70 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 82.92    Test Loss : 0.41\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.14,    Test Acc : 83.33    Test Loss : 0.42\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 82.42    Test Loss : 0.45\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 82.96    Test Loss : 0.5\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 81.79    Test Loss : 0.6\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.83    Test Loss : 0.72\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.5    Test Loss : 0.86\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.5    Test Loss : 0.98\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 1.06\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.04    Test Loss : 1.12\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 1.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.88    Test Loss : 1.21\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.92    Test Loss : 1.24\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.88    Test Loss : 1.27\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 80.88 ***\n",
      "Epoch 10 - Train Acc : 68.33    Train Loss : 0.53,    Test Acc : 68.25    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 76.67    Train Loss : 0.45,    Test Acc : 71.04    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.39,    Test Acc : 71.96    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 86.67    Train Loss : 0.33,    Test Acc : 75.46    Test Loss : 0.59\n",
      "Epoch 50 - Train Acc : 90.83    Train Loss : 0.26,    Test Acc : 78.83    Test Loss : 0.56\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.2,    Test Acc : 80.5    Test Loss : 0.59\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.14,    Test Acc : 81.46    Test Loss : 0.65\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 81.88    Test Loss : 0.8\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 81.25    Test Loss : 1.0\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 80.54    Test Loss : 1.3\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 79.88    Test Loss : 1.67\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.04    Test Loss : 2.03\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.17    Test Loss : 2.32\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.38    Test Loss : 2.55\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.46    Test Loss : 2.73\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.33    Test Loss : 2.89\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.33    Test Loss : 3.01\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.29    Test Loss : 3.12\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.29    Test Loss : 3.21\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.33    Test Loss : 3.29\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 80.33 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 27 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.58000955 0.13132278 0.0637214  0.02914774 0.02316072 0.02158316\n",
      " 0.01780128 0.0150561  0.01009865] \n",
      " Overall ratio:  0.8919013886157956\n",
      "Explaned variance ratio by principal components : [0.60467016 0.19630067 0.05386153 0.04188624 0.03585332 0.01667116] \n",
      " Overall ratio:  0.9492430806813116\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.60467016 0.19630067 0.05386153 0.04188624 0.03585332 0.01667116] \n",
      " Overall ratio:  0.9492430806813118\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2860 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 77.75    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 80.83    Train Loss : 0.46,    Test Acc : 80.21    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 87.5    Train Loss : 0.41,    Test Acc : 74.08    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 86.67    Train Loss : 0.36,    Test Acc : 73.75    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.31,    Test Acc : 74.25    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 90.0    Train Loss : 0.27,    Test Acc : 75.38    Test Loss : 0.65\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.23,    Test Acc : 77.25    Test Loss : 0.61\n",
      "Epoch 80 - Train Acc : 91.67    Train Loss : 0.2,    Test Acc : 81.0    Test Loss : 0.52\n",
      "Epoch 90 - Train Acc : 92.5    Train Loss : 0.16,    Test Acc : 83.96    Test Loss : 0.48\n",
      "Epoch 100 - Train Acc : 94.17    Train Loss : 0.13,    Test Acc : 85.08    Test Loss : 0.45\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.1,    Test Acc : 86.25    Test Loss : 0.46\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.08,    Test Acc : 86.75    Test Loss : 0.53\n",
      "Epoch 130 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 87.29    Test Loss : 0.64\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 86.83    Test Loss : 0.79\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 87.0    Test Loss : 0.96\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.88    Test Loss : 1.15\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.71    Test Loss : 1.31\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.38    Test Loss : 1.46\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 1.58\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 1.68\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 86.21 ***\n",
      "Epoch 10 - Train Acc : 70.83    Train Loss : 0.57,    Test Acc : 70.62    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.47,    Test Acc : 72.38    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.39,    Test Acc : 73.58    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 74.0    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 87.5    Train Loss : 0.29,    Test Acc : 75.83    Test Loss : 0.68\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.23,    Test Acc : 76.79    Test Loss : 0.68\n",
      "Epoch 70 - Train Acc : 91.67    Train Loss : 0.19,    Test Acc : 75.71    Test Loss : 0.76\n",
      "Epoch 80 - Train Acc : 92.5    Train Loss : 0.15,    Test Acc : 75.21    Test Loss : 0.94\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 76.08    Test Loss : 1.11\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 77.38    Test Loss : 1.25\n",
      "Epoch 110 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 78.5    Test Loss : 1.31\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 79.08    Test Loss : 1.38\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 79.54    Test Loss : 1.42\n",
      "Epoch 140 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 80.0    Test Loss : 1.48\n",
      "Epoch 150 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 80.75    Test Loss : 1.56\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 81.96    Test Loss : 1.65\n",
      "Epoch 170 - Train Acc : 99.17    Train Loss : 0.01,    Test Acc : 80.58    Test Loss : 1.74\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.08    Test Loss : 1.77\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.29    Test Loss : 1.81\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.33    Test Loss : 1.85\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 81.33 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 28 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.51586344 0.2204086  0.06211284 0.0553274  0.02619596 0.01697069\n",
      " 0.01491086 0.01006063 0.00833603] \n",
      " Overall ratio:  0.9301864386446245\n",
      "Explaned variance ratio by principal components : [0.4623089  0.23444884 0.10405433 0.04639846 0.03494082 0.01930008] \n",
      " Overall ratio:  0.9014514179217953\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaned variance ratio by principal components : [0.4623089  0.23444884 0.10405433 0.04639846 0.03494082 0.01930008] \n",
      " Overall ratio:  0.9014514179217953\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1758 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 77.5    Train Loss : 0.44,    Test Acc : 73.88    Test Loss : 0.55\n",
      "Epoch 20 - Train Acc : 83.33    Train Loss : 0.37,    Test Acc : 75.29    Test Loss : 0.55\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.33,    Test Acc : 75.29    Test Loss : 0.52\n",
      "Epoch 40 - Train Acc : 90.0    Train Loss : 0.28,    Test Acc : 78.04    Test Loss : 0.51\n",
      "Epoch 50 - Train Acc : 92.5    Train Loss : 0.24,    Test Acc : 80.29    Test Loss : 0.53\n",
      "Epoch 60 - Train Acc : 93.33    Train Loss : 0.2,    Test Acc : 81.29    Test Loss : 0.57\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.15,    Test Acc : 80.79    Test Loss : 0.61\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 79.83    Test Loss : 0.7\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 79.75    Test Loss : 0.87\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 79.63    Test Loss : 1.11\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 79.96    Test Loss : 1.35\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.25    Test Loss : 1.53\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.54    Test Loss : 1.66\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.58    Test Loss : 1.75\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.67    Test Loss : 1.81\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.62    Test Loss : 1.87\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.67    Test Loss : 1.91\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.67    Test Loss : 1.95\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 1.99\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.75    Test Loss : 2.02\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 80.75 ***\n",
      "Epoch 10 - Train Acc : 65.0    Train Loss : 0.62,    Test Acc : 64.83    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 70.83    Train Loss : 0.57,    Test Acc : 68.92    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 72.5    Train Loss : 0.5,    Test Acc : 71.54    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 81.67    Train Loss : 0.38,    Test Acc : 74.54    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 89.17    Train Loss : 0.25,    Test Acc : 75.58    Test Loss : 0.58\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.16,    Test Acc : 77.92    Test Loss : 0.77\n",
      "Epoch 70 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 78.88    Test Loss : 1.0\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 78.25    Test Loss : 1.24\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 77.62    Test Loss : 1.53\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 75.83    Test Loss : 1.78\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 74.92    Test Loss : 1.99\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 74.96    Test Loss : 2.2\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 75.83    Test Loss : 2.41\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 76.12    Test Loss : 2.62\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 75.96    Test Loss : 2.85\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 75.75    Test Loss : 3.06\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.71    Test Loss : 3.26\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.54    Test Loss : 3.45\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.46    Test Loss : 3.63\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 75.38    Test Loss : 3.79\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 75.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 29 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "Explaned variance ratio by principal components : [0.47039687 0.12674051 0.09903279 0.06471201 0.04196225 0.01985035\n",
      " 0.01652087 0.01484021 0.01090527] \n",
      " Overall ratio:  0.864961144923582\n",
      "Explaned variance ratio by principal components : [0.46412404 0.18277874 0.09547397 0.06043198 0.04659027 0.0318616 ] \n",
      " Overall ratio:  0.8812605945724284\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.46412404 0.18277874 0.09547397 0.06043198 0.04659027 0.0318616 ] \n",
      " Overall ratio:  0.8812605945724283\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1737 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 77.5    Train Loss : 0.49,    Test Acc : 75.79    Test Loss : 0.5\n",
      "Epoch 20 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 79.83    Test Loss : 0.42\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 79.58    Test Loss : 0.43\n",
      "Epoch 40 - Train Acc : 82.5    Train Loss : 0.32,    Test Acc : 79.33    Test Loss : 0.43\n",
      "Epoch 50 - Train Acc : 83.33    Train Loss : 0.31,    Test Acc : 80.58    Test Loss : 0.41\n",
      "Epoch 60 - Train Acc : 84.17    Train Loss : 0.29,    Test Acc : 82.17    Test Loss : 0.39\n",
      "Epoch 70 - Train Acc : 85.83    Train Loss : 0.27,    Test Acc : 83.12    Test Loss : 0.39\n",
      "Epoch 80 - Train Acc : 85.83    Train Loss : 0.24,    Test Acc : 83.42    Test Loss : 0.38\n",
      "Epoch 90 - Train Acc : 86.67    Train Loss : 0.21,    Test Acc : 83.71    Test Loss : 0.38\n",
      "Epoch 100 - Train Acc : 92.5    Train Loss : 0.17,    Test Acc : 84.79    Test Loss : 0.4\n",
      "Epoch 110 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 84.58    Test Loss : 0.46\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.08,    Test Acc : 84.33    Test Loss : 0.56\n",
      "Epoch 130 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 84.5    Test Loss : 0.66\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 84.38    Test Loss : 0.74\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.67    Test Loss : 0.83\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.83    Test Loss : 0.92\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 0.99\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 1.04\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.09\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.12\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 85.21 ***\n",
      "Epoch 10 - Train Acc : 79.17    Train Loss : 0.55,    Test Acc : 75.0    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 82.5    Train Loss : 0.43,    Test Acc : 77.75    Test Loss : 0.5\n",
      "Epoch 30 - Train Acc : 82.5    Train Loss : 0.36,    Test Acc : 78.0    Test Loss : 0.51\n",
      "Epoch 40 - Train Acc : 85.83    Train Loss : 0.29,    Test Acc : 79.38    Test Loss : 0.5\n",
      "Epoch 50 - Train Acc : 89.17    Train Loss : 0.23,    Test Acc : 82.79    Test Loss : 0.44\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.18,    Test Acc : 87.42    Test Loss : 0.36\n",
      "Epoch 70 - Train Acc : 95.0    Train Loss : 0.14,    Test Acc : 88.33    Test Loss : 0.34\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 89.25    Test Loss : 0.38\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 90.71    Test Loss : 0.42\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 91.38    Test Loss : 0.5\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 91.54    Test Loss : 0.6\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 91.5    Test Loss : 0.71\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 90.96    Test Loss : 0.83\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 90.54    Test Loss : 0.94\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.02\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 1.09\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.0    Test Loss : 1.14\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.88    Test Loss : 1.19\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.71    Test Loss : 1.23\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.27\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 89.58 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 30 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.53860918 0.16210924 0.09211102 0.04900104 0.03490006 0.02038517\n",
      " 0.0107367  0.00976345 0.00721595] \n",
      " Overall ratio:  0.9248318079246926\n",
      "Explaned variance ratio by principal components : [0.5011948  0.18725101 0.13573676 0.06151374 0.03823836 0.02731841] \n",
      " Overall ratio:  0.9512530820197244\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.5011948  0.18725101 0.13573676 0.06151374 0.03823836 0.02731841] \n",
      " Overall ratio:  0.9512530820197239\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1759 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 73.33    Train Loss : 0.58,    Test Acc : 64.29    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.49,    Test Acc : 65.54    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 80.0    Train Loss : 0.47,    Test Acc : 67.63    Test Loss : 0.63\n",
      "Epoch 40 - Train Acc : 80.83    Train Loss : 0.43,    Test Acc : 69.33    Test Loss : 0.57\n",
      "Epoch 50 - Train Acc : 83.33    Train Loss : 0.37,    Test Acc : 70.58    Test Loss : 0.55\n",
      "Epoch 60 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 73.5    Test Loss : 0.56\n",
      "Epoch 70 - Train Acc : 90.0    Train Loss : 0.23,    Test Acc : 76.5    Test Loss : 0.61\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 80.13    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 95.0    Train Loss : 0.11,    Test Acc : 81.75    Test Loss : 0.83\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.07,    Test Acc : 81.88    Test Loss : 1.06\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 82.04    Test Loss : 1.29\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.79    Test Loss : 1.52\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.54    Test Loss : 1.76\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.21    Test Loss : 1.96\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.0    Test Loss : 2.12\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.79    Test Loss : 2.24\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.83    Test Loss : 2.34\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.0    Test Loss : 2.42\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.96    Test Loss : 2.49\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.04    Test Loss : 2.55\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 82.04 ***\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.57,    Test Acc : 66.83    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 73.33    Train Loss : 0.51,    Test Acc : 69.29    Test Loss : 0.56\n",
      "Epoch 30 - Train Acc : 76.67    Train Loss : 0.48,    Test Acc : 72.04    Test Loss : 0.54\n",
      "Epoch 40 - Train Acc : 78.33    Train Loss : 0.42,    Test Acc : 74.83    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.35,    Test Acc : 77.75    Test Loss : 0.45\n",
      "Epoch 60 - Train Acc : 87.5    Train Loss : 0.28,    Test Acc : 79.08    Test Loss : 0.47\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.23,    Test Acc : 80.83    Test Loss : 0.52\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.18,    Test Acc : 81.58    Test Loss : 0.58\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.14,    Test Acc : 82.29    Test Loss : 0.67\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.1,    Test Acc : 82.12    Test Loss : 0.77\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 82.38    Test Loss : 0.88\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 82.71    Test Loss : 1.0\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 83.5    Test Loss : 1.1\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.67    Test Loss : 1.21\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.83    Test Loss : 1.31\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.83    Test Loss : 1.39\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.88    Test Loss : 1.45\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.0    Test Loss : 1.51\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.0    Test Loss : 1.55\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.08    Test Loss : 1.6\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 84.08 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 31 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "Explaned variance ratio by principal components : [0.3954156  0.17461501 0.1050674  0.04231871 0.03093074 0.02988044\n",
      " 0.01595323 0.0152407  0.01360145] \n",
      " Overall ratio:  0.8230232901974354\n",
      "Explaned variance ratio by principal components : [0.51965352 0.17437604 0.08535715 0.0393794  0.0328574  0.02538941] \n",
      " Overall ratio:  0.8770129201257585\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.51965352 0.17437604 0.08535715 0.0393794  0.0328574  0.02538941] \n",
      " Overall ratio:  0.8770129201257624\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1751 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 73.33    Train Loss : 0.56,    Test Acc : 66.92    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 78.33    Train Loss : 0.48,    Test Acc : 72.92    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.42,    Test Acc : 74.04    Test Loss : 0.57\n",
      "Epoch 40 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 76.12    Test Loss : 0.53\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.27,    Test Acc : 80.5    Test Loss : 0.49\n",
      "Epoch 60 - Train Acc : 89.17    Train Loss : 0.18,    Test Acc : 83.71    Test Loss : 0.49\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 82.67    Test Loss : 0.59\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 83.29    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 84.25    Test Loss : 0.7\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 84.5    Test Loss : 0.8\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.67    Test Loss : 0.89\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.83    Test Loss : 0.96\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.02\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.54    Test Loss : 1.07\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 1.11\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.92    Test Loss : 1.14\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 1.17\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 1.2\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 1.22\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 1.24\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 86.13 ***\n",
      "Epoch 10 - Train Acc : 80.83    Train Loss : 0.48,    Test Acc : 70.46    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 80.0    Train Loss : 0.4,    Test Acc : 71.96    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 72.75    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.3,    Test Acc : 74.71    Test Loss : 0.51\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.23,    Test Acc : 77.21    Test Loss : 0.54\n",
      "Epoch 60 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 79.33    Test Loss : 0.59\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.11,    Test Acc : 79.75    Test Loss : 0.69\n",
      "Epoch 80 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 79.79    Test Loss : 0.81\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.05,    Test Acc : 81.25    Test Loss : 0.88\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 82.46    Test Loss : 0.95\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 81.88    Test Loss : 1.09\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 81.79    Test Loss : 1.22\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.75    Test Loss : 1.33\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.83    Test Loss : 1.44\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.04    Test Loss : 1.54\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 1.64\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 1.72\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 1.79\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 1.86\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.08    Test Loss : 1.91\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 82.08 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 32 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (756,),    high arousal : (1764,)\n",
      "Explaned variance ratio by principal components : [0.4395234  0.20457745 0.10251503 0.03879003 0.03528077 0.02465768\n",
      " 0.01909694 0.01638334 0.01427687] \n",
      " Overall ratio:  0.8951015054987324\n",
      "Explaned variance ratio by principal components : [0.40379541 0.19594926 0.09724724 0.06942047 0.04882956 0.03339357] \n",
      " Overall ratio:  0.8486355048441744\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Explaned variance ratio by principal components : [0.40379541 0.19594926 0.09724724 0.06942047 0.04882956 0.03339357] \n",
      " Overall ratio:  0.8486355048441733\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1745 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.56,    Test Acc : 68.83    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 80.0    Train Loss : 0.45,    Test Acc : 74.5    Test Loss : 0.51\n",
      "Epoch 30 - Train Acc : 85.83    Train Loss : 0.37,    Test Acc : 77.29    Test Loss : 0.51\n",
      "Epoch 40 - Train Acc : 89.17    Train Loss : 0.28,    Test Acc : 79.46    Test Loss : 0.45\n",
      "Epoch 50 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 83.5    Test Loss : 0.4\n",
      "Epoch 60 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 85.54    Test Loss : 0.44\n",
      "Epoch 70 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 86.46    Test Loss : 0.49\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.05,    Test Acc : 86.79    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 86.79    Test Loss : 0.72\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 86.38    Test Loss : 0.85\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.83    Test Loss : 1.0\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.67    Test Loss : 1.15\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.26\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.35\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 1.43\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.46    Test Loss : 1.49\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.5    Test Loss : 1.54\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 1.59\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 1.63\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.5    Test Loss : 1.67\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 86.5 ***\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.59,    Test Acc : 75.17    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 80.83    Train Loss : 0.53,    Test Acc : 73.58    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 79.17    Train Loss : 0.48,    Test Acc : 76.08    Test Loss : 0.57\n",
      "Epoch 40 - Train Acc : 84.17    Train Loss : 0.43,    Test Acc : 78.12    Test Loss : 0.53\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 78.67    Test Loss : 0.48\n",
      "Epoch 60 - Train Acc : 93.33    Train Loss : 0.21,    Test Acc : 81.83    Test Loss : 0.44\n",
      "Epoch 70 - Train Acc : 98.33    Train Loss : 0.1,    Test Acc : 84.04    Test Loss : 0.53\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 84.75    Test Loss : 0.71\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.21    Test Loss : 0.93\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.21    Test Loss : 1.1\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 1.22\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 1.3\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.35\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.39\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.43\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 1.45\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 1.48\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 1.5\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 1.52\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.54\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN is saved successfully\n",
      "*** Best ACC : 85.33 ***\n",
      "\n",
      "**************** Valence *********************\n",
      "** Best ACC : [79.67, 87.88, 86.79, 81.92, 84.75, 71.58, 86.21, 79.08, 86.17, 84.38, 82.92, 88.17, 81.83, 81.17, 90.12, 82.83, 78.54, 88.96, 90.92, 85.63, 82.62, 83.46, 90.42, 84.0, 78.75, 80.88, 86.21, 80.75, 85.21, 82.04, 86.13, 86.5] **\n",
      " ** Avearge acc : 83.9528125,    std : 4.0385124383668485 **\n",
      "\n",
      "**************** Arousal *********************\n",
      "** Best ACC : [79.46, 80.0, 81.17, 80.25, 78.38, 75.04, 82.29, 73.54, 87.04, 78.21, 87.21, 88.96, 84.33, 81.29, 86.67, 82.0, 81.17, 77.17, 88.5, 86.71, 89.92, 76.75, 87.17, 85.71, 82.88, 80.33, 81.33, 75.38, 89.58, 84.08, 82.08, 85.33] **\n",
      " ** Avearge acc : 82.4978125,    std : 4.410627601582766 **\n",
      "\n",
      "directory already exists\n",
      "vlc_DE_PSD_PCA_SNF_GCN_protocol_60_best_acc_list_231016 is saved successfully\n",
      "directory already exists\n",
      "ars_DE_PSD_PCA_SNF_GCN_protocol_60_best_acc_list_231016 is saved successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vlc_best_epoch = []\n",
    "vlc_orig_acc = []\n",
    "vlc_best_acc = []\n",
    "ars_best_epoch = []\n",
    "ars_orig_acc = []\n",
    "ars_best_acc = []\n",
    "\n",
    "compare_args.gcn_hid_channels = 15\n",
    "compare_args.gcn_out_channels = 30\n",
    "for i in range(32):\n",
    "\n",
    "    print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "    sub_idx = 'sub'+str(i+1)\n",
    "    date = '231016'\n",
    "\n",
    "    sub_de = subject_de[i]\n",
    "    sub_psd = subject_psd[i]\n",
    "    sub_label = subject_label[i]\n",
    "    valence_label, arousal_label = deap_label(sub_label)\n",
    "\n",
    "    de, psd, vlc_identifier, ars_identifier = other_preprocessing(sub_de,sub_psd, (valence_label,arousal_label), n_labels_by_class, args.out_channels, args.seed, isdeap=True)\n",
    "\n",
    "    de_pca,_ = dimensionality_reduction(de, compare_args.pca_components1, 'de_LDS', sub_idx, date)\n",
    "    psd_pca,_ = dimensionality_reduction(psd, compare_args.pca_components2, 'psd_LDS', sub_idx, date)\n",
    "    \n",
    "    print(\"\\nDistance matrix construction start...\")\n",
    "    de_dm = distance_matrix(de_pca)\n",
    "    print(\"\\nDistance matrix construction Done...\")\n",
    "\n",
    "    de_neighbors = kneighbors(de_dm, args.n_samples, args.de_k)\n",
    "\n",
    "    de_ssm, de_nssm = ssm_construction(de_dm,de_neighbors)\n",
    "\n",
    "    psd_pca,_ = dimensionality_reduction(psd, compare_args.pca_components2, 'psd_LDS', sub_idx, date)\n",
    "    \n",
    "    print(\"\\nDistance matrix construction start...\")\n",
    "    psd_dm = distance_matrix(psd_pca)\n",
    "    print(\"\\nDistance matrix construction Done...\")\n",
    "\n",
    "    psd_neighbors = kneighbors(psd_dm, args.n_samples, args.psd_k)\n",
    "\n",
    "    psd_ssm, psd_nssm = ssm_construction(psd_dm,psd_neighbors)\n",
    "    \n",
    "#     save_np(args.tensor_save_path+sub_idx, 'identifier', identifier)\n",
    "#     save_np(args.tensor_save_path+sub_idx, 'label', label)\n",
    "\n",
    "    fsm = ssm_fusion(de_ssm,psd_ssm, de_nssm, psd_nssm, args.k1, args.t1)\n",
    "    adj = fsm\n",
    "\n",
    "\n",
    "    feature = input_feature(de_pca, psd_pca)\n",
    " \n",
    "    feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "    adj = torch.from_numpy(fsm).to(torch.float32).to(device)\n",
    "    adj = normalize_adj(adj,im)\n",
    "    \n",
    "    ars_label = torch.from_numpy(arousal_label).to(torch.long).to(device)\n",
    "    vlc_label = torch.from_numpy(valence_label).to(torch.long).to(device)\n",
    "\n",
    "    vlc_identifier = torch.from_numpy(vlc_identifier).bool()\n",
    "    vlc_train_identifier = vlc_identifier.to(device)\n",
    "    isunlabeled = ~vlc_identifier\n",
    "    vlc_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "    ars_identifier = torch.from_numpy(ars_identifier).bool()\n",
    "    ars_train_identifier = ars_identifier.to(device)\n",
    "    isunlabeled = ~ars_identifier\n",
    "    ars_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "\n",
    "    model = compare_model(compare_args,compare_args.pca_components1+compare_args.pca_components2,adj).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = train(feature, vlc_label, vlc_train_identifier, vlc_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'vlc_DE_PSD_PCA_SNF_GCN', sample)\n",
    "    \n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    vlc_best_acc.append(best_acc)\n",
    "    vlc_orig_acc.append(best_acc)\n",
    "    \n",
    "    model = compare_model(compare_args,compare_args.pca_components1+compare_args.pca_components2,adj).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = train(feature, ars_label, ars_train_identifier, ars_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'ars_DE_PSD_PCA_SNF_GCN', sample)\n",
    "    \n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    ars_best_acc.append(best_acc)\n",
    "    ars_orig_acc.append(best_acc)\n",
    "\n",
    "\n",
    "print(\"\\n**************** Valence *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(vlc_best_acc, np.mean(vlc_best_acc), np.std(vlc_best_acc)))\n",
    "\n",
    "print(\"**************** Arousal *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(ars_best_acc, np.mean(ars_best_acc), np.std(ars_best_acc)))\n",
    "\n",
    "vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "ars_best_acc_list = np.array(ars_best_acc)\n",
    "\n",
    "save_np(args.tensor_save_path+'ablation2/vlc/', 'vlc_DE_PSD_PCA_SNF_GCN_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, vlc_best_acc_list)\n",
    "save_np(args.tensor_save_path+'ablation2/ars/', 'ars_DE_PSD_PCA_SNF_GCN_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, ars_best_acc_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f00b2f",
   "metadata": {},
   "source": [
    "##  Ablation 4 - DE + GE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vlc_best_epoch = []\n",
    "vlc_orig_acc = []\n",
    "vlc_best_acc = []\n",
    "ars_best_epoch = []\n",
    "ars_orig_acc = []\n",
    "ars_best_acc = []\n",
    "for i in range(32):\n",
    "\n",
    "    print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "    sub_idx = 'sub'+str(i+1)\n",
    "    date = '231016'\n",
    "\n",
    "    sub_de = subject_de[i]\n",
    "    sub_psd = subject_psd[i]\n",
    "    sub_label = subject_label[i]\n",
    "    valence_label, arousal_label = deap_label(sub_label)\n",
    "\n",
    "    de, psd, vlc_identifier, ars_identifier = other_preprocessing(sub_de,sub_psd, (valence_label,arousal_label), n_labels_by_class, args.out_channels, args.seed, isdeap=True)\n",
    "\n",
    "    de = normalization(de, axis = 0, ntype='standardization')\n",
    "    \n",
    "    print(\"\\nDistance matrix construction start...\")\n",
    "    de_dm = distance_matrix(de)\n",
    "    print(\"\\nDistance matrix construction Done...\")\n",
    "\n",
    "    de_neighbors = kneighbors(de_dm, args.n_samples, args.de_k)\n",
    "\n",
    "    de_ssm, de_nssm = ssm_construction(de_dm,de_neighbors)\n",
    "    \n",
    "    \n",
    "    adj = de_ssm\n",
    "\n",
    "    feature = de\n",
    "    \n",
    "    feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "    adj = torch.from_numpy(adj).to(torch.float32).to(device)\n",
    "    \n",
    "    adj = normalize_adj(adj,im)\n",
    "    \n",
    "    \n",
    "    ars_label = torch.from_numpy(arousal_label).to(torch.long).to(device)\n",
    "    vlc_label = torch.from_numpy(valence_label).to(torch.long).to(device)\n",
    "\n",
    "    vlc_identifier = torch.from_numpy(vlc_identifier).bool()\n",
    "    vlc_train_identifier = vlc_identifier.to(device)\n",
    "    isunlabeled = ~vlc_identifier\n",
    "    vlc_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "    ars_identifier = torch.from_numpy(ars_identifier).bool()\n",
    "    ars_train_identifier = ars_identifier.to(device)\n",
    "    isunlabeled = ~ars_identifier\n",
    "    ars_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "\n",
    "    encoder = Encoder(args.feature_dimension//2, args.gcn_hid_channels//2, args.gcn_out_channels//2, activation, args.seed, base_model = gcn).to(device)\n",
    "    model = GRACE(encoder, args.feature_dimension//2, args.gcn_out_channels//2, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = encoder_train(feature,adj, vlc_label, vlc_train_identifier, vlc_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'vlc_DE_GE', sample)\n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    vlc_best_acc.append(best_acc)\n",
    "    vlc_orig_acc.append(best_acc)\n",
    "    \n",
    "    encoder = Encoder(args.feature_dimension//2, args.gcn_hid_channels//2, args.gcn_out_channels//2, activation, args.seed, base_model = gcn).to(device)\n",
    "    model = GRACE(encoder, args.feature_dimension//2, args.gcn_out_channels//2, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = encoder_train(feature,adj, ars_label, ars_train_identifier, ars_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'ars_DE_GE', sample)\n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    ars_best_acc.append(best_acc)\n",
    "    ars_orig_acc.append(best_acc)\n",
    "\n",
    "\n",
    "print(\"\\n**************** Valence *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(vlc_best_acc, np.mean(vlc_best_acc), np.std(vlc_best_acc)))\n",
    "\n",
    "print(\"**************** Arousal *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(ars_best_acc, np.mean(ars_best_acc), np.std(ars_best_acc)))\n",
    "\n",
    "vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "ars_best_acc_list = np.array(ars_best_acc)\n",
    "\n",
    "save_np(args.tensor_save_path+'ablation2/vlc/', 'vlc_DE_GE_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, vlc_best_acc_list)\n",
    "save_np(args.tensor_save_path+'ablation2/ars/', 'ars_DE_GE_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, ars_best_acc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ea0e1971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 75.5    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.0    Test Loss : 1.01\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.88    Test Loss : 1.36\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.62    Test Loss : 1.7\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.38    Test Loss : 1.85\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.88\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.21    Test Loss : 1.89\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 1.9\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.25    Test Loss : 1.9\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.21    Test Loss : 1.9\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.21    Test Loss : 1.9\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.25    Test Loss : 1.9\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.25    Test Loss : 1.89\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.25    Test Loss : 1.89\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.29    Test Loss : 1.89\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.29    Test Loss : 1.89\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.38    Test Loss : 1.89\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.38    Test Loss : 1.89\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.33    Test Loss : 1.89\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.38    Test Loss : 1.89\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 83.38 ***\n",
      "Epoch 10 - Train Acc : 90.83    Train Loss : 0.23,    Test Acc : 80.0    Test Loss : 0.48\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.38    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 0.99\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 1.18\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 1.27\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.29\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.29\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.28\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.28\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.46    Test Loss : 1.28\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 1.27\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.27\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.54    Test Loss : 1.27\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.26\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.26\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.54    Test Loss : 1.26\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 1.26\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.26\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.26\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.26\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 87.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 2 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 73.33    Train Loss : 0.49,    Test Acc : 67.71    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 78.62    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.96    Test Loss : 0.93\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 1.38\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.62    Test Loss : 1.56\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 1.7\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 1.79\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 1.82\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.54    Test Loss : 1.82\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.54    Test Loss : 1.82\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.5    Test Loss : 1.82\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.54    Test Loss : 1.82\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.62    Test Loss : 1.82\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.62    Test Loss : 1.82\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.71    Test Loss : 1.82\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.71    Test Loss : 1.82\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 1.83\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 1.83\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 1.83\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 1.83\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 83.79 ***\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.36,    Test Acc : 74.29    Test Loss : 0.52\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 85.17    Test Loss : 0.56\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 0.83\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.19\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 1.37\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.46\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.49\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 1.49\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.17    Test Loss : 1.48\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.21    Test Loss : 1.48\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 1.48\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 1.47\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 1.47\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.47\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 1.47\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.47\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.47\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.47\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.47\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 1.47\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 89.0 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 3 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (2016,),    high arousal : (504,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 91.67    Train Loss : 0.26,    Test Acc : 74.42    Test Loss : 0.55\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 0.9\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.7\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 2.03\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 2.14\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 2.19\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 2.22\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 2.23\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 2.24\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 2.24\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 2.25\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 2.25\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 2.26\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 2.26\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 2.26\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 2.26\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 2.26\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 2.26\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 2.27\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 2.27\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 88.21 ***\n",
      "Epoch 10 - Train Acc : 83.33    Train Loss : 0.37,    Test Acc : 79.46    Test Loss : 0.43\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 91.67    Test Loss : 0.2\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.29    Test Loss : 0.33\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.13    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.04    Test Loss : 0.63\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.17    Test Loss : 0.63\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.21    Test Loss : 0.63\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.17    Test Loss : 0.63\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.21    Test Loss : 0.63\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.21    Test Loss : 0.64\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 0.64\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 0.64\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.29    Test Loss : 0.64\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.29    Test Loss : 0.64\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 0.64\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 0.64\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.29    Test Loss : 0.64\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.29    Test Loss : 0.64\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.29    Test Loss : 0.64\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.29    Test Loss : 0.64\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 92.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 4 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1512,),    high valence : (1008,)\n",
      "low arousal : (1512,),    high arousal : (1008,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 79.17    Train Loss : 0.51,    Test Acc : 70.0    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 80.0    Train Loss : 0.37,    Test Acc : 72.58    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 91.67    Train Loss : 0.22,    Test Acc : 78.5    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 93.33    Train Loss : 0.13,    Test Acc : 82.08    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 86.04    Test Loss : 0.71\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.0\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.22\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 1.36\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.44\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.47\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.79    Test Loss : 1.51\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.53\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.79    Test Loss : 1.55\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.56\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.58\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.58\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.59\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.6\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.61\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.62\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 87.88 ***\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.5,    Test Acc : 69.08    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 90.0    Train Loss : 0.29,    Test Acc : 79.83    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 95.83    Train Loss : 0.12,    Test Acc : 77.67    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 80.0    Test Loss : 0.73\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 80.96    Test Loss : 1.05\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.0    Test Loss : 1.2\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 1.46\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.62    Test Loss : 1.56\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.62    Test Loss : 1.65\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 1.7\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.5    Test Loss : 1.72\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.58    Test Loss : 1.73\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 1.74\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 1.75\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.58    Test Loss : 1.76\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.5    Test Loss : 1.77\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.78\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 1.79\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 1.8\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 1.8\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 82.33 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 5 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1323,),    high arousal : (1197,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 85.0    Train Loss : 0.38,    Test Acc : 74.08    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.12,    Test Acc : 80.21    Test Loss : 0.55\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.33    Test Loss : 0.68\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 0.92\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 1.15\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.46    Test Loss : 1.23\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.21\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.18\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 1.16\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 1.15\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.14\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.13\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.13\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.13\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.12\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.12\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 1.12\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 1.12\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.12\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.12\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 85.04 ***\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.45,    Test Acc : 78.42    Test Loss : 0.48\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 89.33    Test Loss : 0.28\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 0.74\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 0.75\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 0.75\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 0.74\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.5    Test Loss : 0.74\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.5    Test Loss : 0.74\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.74\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.73\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.73\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.73\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.73\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.73\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.73\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.73\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.73\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.73\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 90.58 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 6 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 89.17    Train Loss : 0.34,    Test Acc : 69.29    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.05,    Test Acc : 76.46    Test Loss : 1.14\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.92    Test Loss : 2.47\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.79    Test Loss : 3.23\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.88    Test Loss : 3.56\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.08    Test Loss : 3.66\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.12    Test Loss : 3.68\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.12    Test Loss : 3.68\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.21    Test Loss : 3.68\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.17    Test Loss : 3.67\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.17    Test Loss : 3.67\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.21    Test Loss : 3.67\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.21    Test Loss : 3.66\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.25    Test Loss : 3.66\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.29    Test Loss : 3.66\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.29    Test Loss : 3.66\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.33    Test Loss : 3.66\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.33    Test Loss : 3.66\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.38    Test Loss : 3.66\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.38    Test Loss : 3.66\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 79.38 ***\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.38,    Test Acc : 69.67    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.05,    Test Acc : 79.29    Test Loss : 0.72\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.46    Test Loss : 1.4\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.96    Test Loss : 1.73\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.29    Test Loss : 1.88\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.25    Test Loss : 1.96\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.25    Test Loss : 2.0\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.42    Test Loss : 2.01\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.42    Test Loss : 2.02\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.46    Test Loss : 2.03\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.42    Test Loss : 2.03\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.29    Test Loss : 2.04\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.29    Test Loss : 2.04\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.25    Test Loss : 2.05\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.17    Test Loss : 2.05\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.13    Test Loss : 2.05\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.17    Test Loss : 2.06\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.17    Test Loss : 2.06\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.21    Test Loss : 2.07\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.21    Test Loss : 2.07\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 80.21 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 7 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (756,),    high valence : (1764,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 92.5    Train Loss : 0.22,    Test Acc : 79.08    Test Loss : 0.46\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 0.9\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 1.65\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 2.03\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 2.17\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 2.23\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 2.25\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 2.25\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 2.25\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 2.26\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 2.25\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 2.25\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 2.25\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 2.25\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 2.25\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 2.25\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 2.25\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 2.25\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 2.25\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 2.25\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 86.38 ***\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.41,    Test Acc : 75.79    Test Loss : 0.45\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 83.62    Test Loss : 0.45\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 0.77\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.17    Test Loss : 0.99\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 1.08\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.15\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 1.18\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.2\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.21\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.21\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.21\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.22\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 1.22\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.22\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.22\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.22\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.22\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.22\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.22\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.22\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 88.67 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 8 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.39,    Test Acc : 76.0    Test Loss : 0.53\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 84.62    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 0.81\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.06\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.16\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.22\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.24\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.24\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.24\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.24\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.24\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.24\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.24\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.24\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.24\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.25\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.25\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.25\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.25\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.25\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 87.96 ***\n",
      "Epoch 10 - Train Acc : 86.67    Train Loss : 0.33,    Test Acc : 76.04    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 94.17    Train Loss : 0.11,    Test Acc : 83.21    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.01,    Test Acc : 87.12    Test Loss : 0.69\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.13\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.16\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.2\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 1.24\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.27\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.29\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 1.3\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.04    Test Loss : 1.31\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.32\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 1.32\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 1.33\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 1.33\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 1.33\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 1.33\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.34\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 1.34\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.34\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 86.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 9 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.37,    Test Acc : 73.0    Test Loss : 0.5\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.05,    Test Acc : 90.42    Test Loss : 0.32\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.83    Test Loss : 0.81\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.83    Test Loss : 0.96\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.67    Test Loss : 1.02\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.71    Test Loss : 1.03\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.71    Test Loss : 1.02\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.79    Test Loss : 1.01\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.83    Test Loss : 1.01\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.83    Test Loss : 1.0\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.88    Test Loss : 1.0\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.96    Test Loss : 1.0\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.0    Test Loss : 1.0\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.0    Test Loss : 0.99\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.0    Test Loss : 0.99\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.04    Test Loss : 0.99\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.12    Test Loss : 0.99\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.12    Test Loss : 0.99\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.12    Test Loss : 0.99\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 91.12 ***\n",
      "Epoch 10 - Train Acc : 89.17    Train Loss : 0.35,    Test Acc : 71.88    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 80.08    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.71    Test Loss : 1.13\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 1.5\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.76\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.85\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.29    Test Loss : 1.88\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.33    Test Loss : 1.89\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.33    Test Loss : 1.88\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 1.88\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.5    Test Loss : 1.88\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.54    Test Loss : 1.88\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 1.88\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 1.88\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.54    Test Loss : 1.88\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 1.88\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.62    Test Loss : 1.88\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.62    Test Loss : 1.88\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 1.88\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 1.88\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 83.58 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 10 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1134,),    high arousal : (1386,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 75.83    Train Loss : 0.46,    Test Acc : 67.67    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.15,    Test Acc : 81.08    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.54    Test Loss : 0.75\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 0.86\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 1.12\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.15\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.15\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.17\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.18\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.19\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 1.19\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.19\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.2\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.2\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.2\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.2\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.2\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.21\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 1.21\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 1.21\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 88.83 ***\n",
      "Epoch 10 - Train Acc : 81.67    Train Loss : 0.37,    Test Acc : 82.29    Test Loss : 0.41\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 84.42    Test Loss : 0.39\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.96    Test Loss : 0.45\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.96    Test Loss : 0.74\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 1.11\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.83    Test Loss : 1.24\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.92    Test Loss : 1.28\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.3\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.3\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.3\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.3\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.29\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.29\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.28\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.21    Test Loss : 1.28\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.21    Test Loss : 1.28\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.21    Test Loss : 1.27\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.21    Test Loss : 1.27\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.25    Test Loss : 1.27\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.25    Test Loss : 1.26\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 90.25 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 11 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1575,),    high arousal : (945,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 85.0    Train Loss : 0.4,    Test Acc : 72.88    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 90.83    Train Loss : 0.28,    Test Acc : 74.54    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 94.17    Train Loss : 0.16,    Test Acc : 81.46    Test Loss : 0.38\n",
      "Epoch 40 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 84.75    Test Loss : 0.37\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 87.12    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.62    Test Loss : 0.82\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.42    Test Loss : 0.9\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.04\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.12\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.1\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.12\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.13\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.14\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.15\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.16\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.16\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.17\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.18\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.19\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.19\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 87.88 ***\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.54,    Test Acc : 68.96    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 80.0    Train Loss : 0.41,    Test Acc : 69.83    Test Loss : 0.75\n",
      "Epoch 30 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 74.21    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 89.17    Train Loss : 0.22,    Test Acc : 76.42    Test Loss : 0.58\n",
      "Epoch 50 - Train Acc : 92.5    Train Loss : 0.15,    Test Acc : 77.33    Test Loss : 0.63\n",
      "Epoch 60 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 80.13    Test Loss : 0.91\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 81.83    Test Loss : 0.85\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 81.29    Test Loss : 1.14\n",
      "Epoch 90 - Train Acc : 95.83    Train Loss : 0.07,    Test Acc : 82.54    Test Loss : 0.8\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 82.92    Test Loss : 1.2\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 1.07\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.88    Test Loss : 1.23\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.75    Test Loss : 1.08\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.88    Test Loss : 1.18\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.0    Test Loss : 1.2\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.71    Test Loss : 1.21\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.88    Test Loss : 1.21\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.92    Test Loss : 1.21\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.04    Test Loss : 1.22\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.96    Test Loss : 1.23\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 83.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 12 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 90.83    Train Loss : 0.28,    Test Acc : 81.62    Test Loss : 0.39\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.75    Test Loss : 0.3\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.43\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.88    Test Loss : 0.56\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.79    Test Loss : 0.62\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.71    Test Loss : 0.65\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.58    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.62    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.54    Test Loss : 0.66\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.54    Test Loss : 0.66\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.58    Test Loss : 0.67\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.62    Test Loss : 0.67\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.62    Test Loss : 0.67\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.58    Test Loss : 0.67\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.58    Test Loss : 0.67\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.62    Test Loss : 0.67\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.67\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.67\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.67\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.67\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 93.67 ***\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.41,    Test Acc : 75.5    Test Loss : 0.5\n",
      "Epoch 20 - Train Acc : 93.33    Train Loss : 0.15,    Test Acc : 85.33    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 87.42    Test Loss : 0.69\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.46    Test Loss : 0.75\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.25    Test Loss : 0.85\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.67    Test Loss : 0.93\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.71    Test Loss : 0.96\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.67    Test Loss : 0.98\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.58    Test Loss : 0.99\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.46    Test Loss : 0.99\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.5    Test Loss : 1.0\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.54    Test Loss : 1.0\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.54    Test Loss : 1.0\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.54    Test Loss : 1.0\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.5    Test Loss : 1.0\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.5    Test Loss : 1.01\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 1.01\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.42    Test Loss : 1.01\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.42    Test Loss : 1.01\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 1.02\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 91.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 13 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1386,),    high valence : (1134,)\n",
      "low arousal : (378,),    high arousal : (2142,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 90.0    Train Loss : 0.29,    Test Acc : 77.58    Test Loss : 0.4\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 88.71    Test Loss : 0.38\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 0.44\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.83    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.5    Test Loss : 0.46\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.96    Test Loss : 0.46\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.92    Test Loss : 0.46\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.88    Test Loss : 0.46\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.88    Test Loss : 0.46\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.83    Test Loss : 0.46\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.83    Test Loss : 0.46\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.47\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.47\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.71    Test Loss : 0.47\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.47\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.47\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.71    Test Loss : 0.47\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.71    Test Loss : 0.47\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.47\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.71    Test Loss : 0.48\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 93.71 ***\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 74.58    Test Loss : 0.48\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 79.08    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 1.0\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.47\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 1.73\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.87\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.93\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.95\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.96\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.96\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.96\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 1.96\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.96\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.96\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.96\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 1.96\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 1.96\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.42    Test Loss : 1.97\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 1.97\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 1.97\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 85.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 14 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 74.92    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 83.67    Test Loss : 0.76\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 1.42\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.97\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 2.09\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 2.22\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 2.29\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.88    Test Loss : 2.32\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.88    Test Loss : 2.33\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 2.33\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 2.33\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 2.33\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 2.33\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 2.33\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 2.34\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 2.34\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 2.34\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 2.34\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 2.34\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 2.34\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 85.17 ***\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.35,    Test Acc : 76.67    Test Loss : 0.51\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 83.04    Test Loss : 0.72\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.54    Test Loss : 1.15\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.35\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.79    Test Loss : 1.5\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.58\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.62\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.63\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.64\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.65\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.66\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.66\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.66\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.67\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.67\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.67\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.67\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.67\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.68\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.68\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 87.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 15 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1197,),    high arousal : (1323,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.38,    Test Acc : 80.71    Test Loss : 0.42\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 90.75    Test Loss : 0.32\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.38    Test Loss : 0.41\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.43\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.67    Test Loss : 0.47\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.71    Test Loss : 0.51\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.71    Test Loss : 0.53\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.63    Test Loss : 0.53\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.83    Test Loss : 0.53\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.83    Test Loss : 0.53\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.83    Test Loss : 0.53\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.0    Test Loss : 0.53\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.0    Test Loss : 0.53\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.0    Test Loss : 0.54\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.08    Test Loss : 0.54\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.08    Test Loss : 0.54\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.12    Test Loss : 0.54\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.12    Test Loss : 0.54\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.12    Test Loss : 0.54\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.12    Test Loss : 0.54\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 93.12 ***\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.35,    Test Acc : 76.42    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 87.17    Test Loss : 0.35\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.67    Test Loss : 1.0\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.62    Test Loss : 1.19\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.27\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.46    Test Loss : 1.31\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.46    Test Loss : 1.32\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.46    Test Loss : 1.33\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 1.33\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.33\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.33\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.33\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.33\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.34\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.34\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.34\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.62    Test Loss : 1.34\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.62    Test Loss : 1.34\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.62    Test Loss : 1.34\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 89.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 16 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1575,),    high valence : (945,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.32,    Test Acc : 75.21    Test Loss : 0.48\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 87.54    Test Loss : 0.43\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.87\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.25\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 1.39\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.45\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.38    Test Loss : 1.48\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.42    Test Loss : 1.49\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.42    Test Loss : 1.5\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.38    Test Loss : 1.5\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.51\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.51\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.38    Test Loss : 1.51\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.38    Test Loss : 1.51\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.38    Test Loss : 1.51\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.38    Test Loss : 1.51\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.51\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.51\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.51\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.52\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 89.33 ***\n",
      "Epoch 10 - Train Acc : 86.67    Train Loss : 0.36,    Test Acc : 78.25    Test Loss : 0.53\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 84.08    Test Loss : 0.55\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 84.75    Test Loss : 0.73\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.5    Test Loss : 1.18\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.48\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 1.55\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.56\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.46    Test Loss : 1.55\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.46    Test Loss : 1.55\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.54    Test Loss : 1.54\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.54\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.54\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.54\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.54\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.54\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.54\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.54\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.54\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.54\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 1.54\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 87.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 17 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 80.83    Train Loss : 0.39,    Test Acc : 73.0    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.14,    Test Acc : 79.5    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.29    Test Loss : 0.88\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.04    Test Loss : 1.51\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 1.93\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.42    Test Loss : 2.12\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.25    Test Loss : 2.19\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.08    Test Loss : 2.21\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.0    Test Loss : 2.21\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.96    Test Loss : 2.21\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.88    Test Loss : 2.21\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 2.21\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.75    Test Loss : 2.2\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.83    Test Loss : 2.2\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.75    Test Loss : 2.2\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 2.2\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.62    Test Loss : 2.2\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 2.19\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 2.19\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.62    Test Loss : 2.19\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 83.62 ***\n",
      "Epoch 10 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 67.88    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 80.96    Test Loss : 0.48\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.67    Test Loss : 0.49\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 0.66\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 0.78\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 0.84\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.86\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.87\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.86\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 0.86\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.86\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.86\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.86\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.86\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.86\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 0.86\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 0.85\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 0.85\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 0.85\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.86\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 88.5 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 18 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.37,    Test Acc : 74.58    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 86.75    Test Loss : 0.74\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.34\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.77\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.95\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 2.01\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.79    Test Loss : 2.05\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 2.07\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 2.08\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 2.08\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 2.09\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 2.09\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 2.09\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 2.09\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 2.09\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 2.09\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 2.09\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 2.1\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 2.1\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 2.1\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 88.0 ***\n",
      "Epoch 10 - Train Acc : 86.67    Train Loss : 0.35,    Test Acc : 79.83    Test Loss : 0.44\n",
      "Epoch 20 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 87.79    Test Loss : 0.31\n",
      "Epoch 30 - Train Acc : 98.33    Train Loss : 0.08,    Test Acc : 90.38    Test Loss : 0.32\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 92.54    Test Loss : 0.26\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.92    Test Loss : 0.26\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.54    Test Loss : 0.35\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.92    Test Loss : 0.4\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.04    Test Loss : 0.42\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.04    Test Loss : 0.42\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.04    Test Loss : 0.43\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.04    Test Loss : 0.44\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.08    Test Loss : 0.44\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.04    Test Loss : 0.44\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.04    Test Loss : 0.44\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.04    Test Loss : 0.44\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.08    Test Loss : 0.44\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.08    Test Loss : 0.45\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.04    Test Loss : 0.45\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.08    Test Loss : 0.45\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.08    Test Loss : 0.45\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 94.08 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 19 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.38,    Test Acc : 74.0    Test Loss : 0.5\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 88.21    Test Loss : 0.27\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.21    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 0.51\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.08    Test Loss : 0.58\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.04    Test Loss : 0.69\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.79    Test Loss : 0.65\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.88    Test Loss : 0.64\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.04    Test Loss : 0.65\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.0    Test Loss : 0.65\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.92    Test Loss : 0.65\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.92    Test Loss : 0.66\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.92    Test Loss : 0.66\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.88    Test Loss : 0.66\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.88    Test Loss : 0.66\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.88    Test Loss : 0.67\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.75    Test Loss : 0.67\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.71    Test Loss : 0.67\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.71    Test Loss : 0.67\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.71    Test Loss : 0.67\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 91.71 ***\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.51,    Test Acc : 71.33    Test Loss : 0.54\n",
      "Epoch 20 - Train Acc : 92.5    Train Loss : 0.17,    Test Acc : 83.54    Test Loss : 0.41\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.71    Test Loss : 0.53\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.46    Test Loss : 0.8\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.88    Test Loss : 0.81\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 0.82\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 0.83\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 0.84\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 0.85\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.92    Test Loss : 0.85\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.92    Test Loss : 0.85\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.92    Test Loss : 0.85\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.92    Test Loss : 0.85\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 0.86\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.0    Test Loss : 0.86\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.0    Test Loss : 0.86\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 0.86\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.92    Test Loss : 0.86\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 0.86\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 89.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 20 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (567,),    high arousal : (1953,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 90.83    Train Loss : 0.26,    Test Acc : 82.0    Test Loss : 0.4\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.25    Test Loss : 0.48\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.54    Test Loss : 0.95\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.09\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.16\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.19\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.2\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.2\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.21\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.21\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.21\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 1.21\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 1.21\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 1.22\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.22\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.22\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.22\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.22\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.23\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.23\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 88.67 ***\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.31,    Test Acc : 79.04    Test Loss : 0.41\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 89.21    Test Loss : 0.32\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.25    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.08    Test Loss : 0.71\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.77\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.46    Test Loss : 0.8\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 0.81\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.25    Test Loss : 0.82\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.21    Test Loss : 0.82\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.21    Test Loss : 0.82\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.29    Test Loss : 0.82\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.82\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 0.82\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 0.82\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.82\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.82\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 0.82\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.42    Test Loss : 0.82\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 0.82\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.82\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 91.33 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 21 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (504,),    high arousal : (2016,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 81.67    Train Loss : 0.41,    Test Acc : 66.17    Test Loss : 0.54\n",
      "Epoch 20 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 80.13    Test Loss : 0.42\n",
      "Epoch 30 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 82.83    Test Loss : 0.5\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.01,    Test Acc : 86.75    Test Loss : 0.43\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 0.51\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.79    Test Loss : 0.42\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 0.52\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.67    Test Loss : 0.44\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.46    Test Loss : 0.42\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.88    Test Loss : 0.44\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.46    Test Loss : 0.46\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 0.47\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.25    Test Loss : 0.47\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.25    Test Loss : 0.47\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 0.47\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 0.48\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 0.48\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 0.48\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 0.49\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 0.49\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 90.08 ***\n",
      "Epoch 10 - Train Acc : 80.0    Train Loss : 0.45,    Test Acc : 71.54    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 83.88    Test Loss : 0.41\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 0.72\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 1.08\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 1.27\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 1.32\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.39\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.41\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.41\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.42    Test Loss : 1.4\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.46    Test Loss : 1.4\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.46    Test Loss : 1.39\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.5    Test Loss : 1.39\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.58    Test Loss : 1.39\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.63    Test Loss : 1.39\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.5    Test Loss : 1.39\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.42    Test Loss : 1.39\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.5    Test Loss : 1.39\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.54    Test Loss : 1.39\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.58    Test Loss : 1.39\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 85.58 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 22 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 66.67    Train Loss : 0.55,    Test Acc : 65.42    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 84.17    Train Loss : 0.35,    Test Acc : 66.58    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 91.67    Train Loss : 0.22,    Test Acc : 72.79    Test Loss : 0.9\n",
      "Epoch 40 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 76.21    Test Loss : 1.02\n",
      "Epoch 50 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 78.12    Test Loss : 1.3\n",
      "Epoch 60 - Train Acc : 93.33    Train Loss : 0.26,    Test Acc : 75.08    Test Loss : 2.01\n",
      "Epoch 70 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 75.54    Test Loss : 1.88\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 78.04    Test Loss : 1.43\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 79.67    Test Loss : 1.6\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.06,    Test Acc : 77.25    Test Loss : 1.8\n",
      "Epoch 110 - Train Acc : 93.33    Train Loss : 0.21,    Test Acc : 73.67    Test Loss : 2.41\n",
      "Epoch 120 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 77.96    Test Loss : 1.81\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 77.25    Test Loss : 1.95\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 78.71    Test Loss : 1.98\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.29    Test Loss : 2.29\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 78.88    Test Loss : 2.46\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.67    Test Loss : 2.63\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.62    Test Loss : 2.77\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.62    Test Loss : 2.89\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.58    Test Loss : 3.0\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 78.58 ***\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.47,    Test Acc : 68.96    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 84.17    Train Loss : 0.37,    Test Acc : 72.46    Test Loss : 0.69\n",
      "Epoch 30 - Train Acc : 88.33    Train Loss : 0.23,    Test Acc : 76.08    Test Loss : 0.87\n",
      "Epoch 40 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 80.25    Test Loss : 1.12\n",
      "Epoch 50 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 81.67    Test Loss : 1.55\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.08    Test Loss : 1.97\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 2.24\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.58    Test Loss : 2.43\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.62    Test Loss : 2.55\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 2.64\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 2.67\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.58    Test Loss : 2.67\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 2.67\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.58    Test Loss : 2.69\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 2.7\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.5    Test Loss : 2.71\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.5    Test Loss : 2.72\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 2.73\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 2.74\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 2.75\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 82.46 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 23 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1701,),    high arousal : (819,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 92.5    Train Loss : 0.15,    Test Acc : 82.5    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 0.98\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 1.2\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 1.28\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.38    Test Loss : 1.39\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.29    Test Loss : 1.46\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.17    Test Loss : 1.48\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.21    Test Loss : 1.48\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.25    Test Loss : 1.48\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.21    Test Loss : 1.48\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.29    Test Loss : 1.48\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.25    Test Loss : 1.48\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.48\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.25    Test Loss : 1.48\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.21    Test Loss : 1.48\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.17    Test Loss : 1.48\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 1.48\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 1.48\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 1.48\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 1.48\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 89.08 ***\n",
      "Epoch 10 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 87.17    Test Loss : 0.33\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.0    Test Loss : 0.39\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.69\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.0    Test Loss : 0.88\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.21    Test Loss : 0.93\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.17    Test Loss : 0.94\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.17    Test Loss : 0.95\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.17    Test Loss : 0.95\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.21    Test Loss : 0.95\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.17    Test Loss : 0.94\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.25    Test Loss : 0.94\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.29    Test Loss : 0.94\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.29    Test Loss : 0.94\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.29    Test Loss : 0.94\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.29    Test Loss : 0.94\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.25    Test Loss : 0.94\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.25    Test Loss : 0.94\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.25    Test Loss : 0.94\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.25    Test Loss : 0.94\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.29    Test Loss : 0.93\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 91.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 24 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 77.38    Test Loss : 0.47\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 84.42    Test Loss : 0.53\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.75    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 0.74\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 0.77\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.86\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 0.92\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 0.95\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 0.95\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 0.95\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 0.95\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 0.95\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 0.96\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.96\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 0.96\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 0.96\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 0.97\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 0.97\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 0.97\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 0.98\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 88.21 ***\n",
      "Epoch 10 - Train Acc : 88.33    Train Loss : 0.36,    Test Acc : 78.08    Test Loss : 0.54\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 82.75    Test Loss : 0.46\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 0.7\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.63    Test Loss : 1.09\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.29\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 1.36\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.37\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.42    Test Loss : 1.37\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.58    Test Loss : 1.36\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.35\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.34\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.33\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.32\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.32\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.31\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 1.31\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 1.3\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.3\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.29\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 1.29\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 86.33 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 25 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (630,),    high arousal : (1890,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 79.17    Train Loss : 0.42,    Test Acc : 68.92    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 93.33    Train Loss : 0.15,    Test Acc : 80.25    Test Loss : 0.48\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 85.92    Test Loss : 0.57\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.67    Test Loss : 0.82\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.79    Test Loss : 1.06\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 1.02\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 0.99\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 0.99\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 0.99\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 0.99\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 0.98\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 0.98\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 0.98\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 0.98\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 0.98\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 0.98\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.46    Test Loss : 0.98\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.46    Test Loss : 0.98\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.46    Test Loss : 0.98\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 86.46 ***\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.49,    Test Acc : 65.75    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 74.42    Test Loss : 0.7\n",
      "Epoch 30 - Train Acc : 98.33    Train Loss : 0.12,    Test Acc : 80.08    Test Loss : 0.87\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 80.58    Test Loss : 1.15\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.21    Test Loss : 1.58\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.7\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.58    Test Loss : 1.9\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 1.98\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 2.05\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 2.09\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 2.09\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 2.1\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 2.11\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 2.12\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 2.12\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 2.13\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.79    Test Loss : 2.14\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 2.14\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 2.15\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 2.15\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 82.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 26 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 89.17    Train Loss : 0.32,    Test Acc : 76.54    Test Loss : 0.52\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 82.67    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.71    Test Loss : 1.04\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.33    Test Loss : 1.43\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.79    Test Loss : 1.52\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 1.58\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.62\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 1.63\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.64\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 1.65\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 1.65\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.65\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.65\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 1.66\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.66\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.92    Test Loss : 1.66\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.66\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.67\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 1.67\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 1.67\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 85.0 ***\n",
      "Epoch 10 - Train Acc : 87.5    Train Loss : 0.33,    Test Acc : 78.12    Test Loss : 0.46\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 83.83    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 81.88    Test Loss : 0.57\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.0    Test Loss : 0.99\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.62    Test Loss : 1.25\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.5    Test Loss : 1.4\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.25    Test Loss : 1.5\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.38    Test Loss : 1.54\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 1.54\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 1.55\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 1.56\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 1.57\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 1.57\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 1.58\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 1.58\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.62    Test Loss : 1.59\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.62    Test Loss : 1.59\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 1.6\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 1.6\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.62    Test Loss : 1.61\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 81.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 27 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 89.17    Train Loss : 0.27,    Test Acc : 77.58    Test Loss : 0.54\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 85.75    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 86.83    Test Loss : 0.77\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.54    Test Loss : 0.89\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.62    Test Loss : 0.99\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.21    Test Loss : 1.12\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.17\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.18\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.18\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.17\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 1.17\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 1.17\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 1.17\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 1.17\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.17    Test Loss : 1.17\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.17    Test Loss : 1.17\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.17    Test Loss : 1.17\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.21    Test Loss : 1.17\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.21    Test Loss : 1.17\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.21    Test Loss : 1.17\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 89.21 ***\n",
      "Epoch 10 - Train Acc : 86.67    Train Loss : 0.34,    Test Acc : 73.71    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 77.04    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 81.88    Test Loss : 0.82\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.29    Test Loss : 1.08\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 1.36\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.96    Test Loss : 1.54\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.96    Test Loss : 1.63\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.0    Test Loss : 1.66\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.04    Test Loss : 1.67\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 1.67\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 1.67\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 1.68\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 1.68\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.38    Test Loss : 1.68\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.42    Test Loss : 1.69\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.42    Test Loss : 1.69\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.42    Test Loss : 1.69\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.38    Test Loss : 1.7\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.38    Test Loss : 1.7\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.38    Test Loss : 1.7\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 82.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 28 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 85.0    Train Loss : 0.4,    Test Acc : 76.58    Test Loss : 0.51\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 78.67    Test Loss : 0.89\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.42    Test Loss : 1.47\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.29    Test Loss : 1.87\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.83    Test Loss : 2.11\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.21    Test Loss : 2.19\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.33    Test Loss : 2.21\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.42    Test Loss : 2.2\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.46    Test Loss : 2.2\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 2.2\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 2.2\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 2.2\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 2.2\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 2.21\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 2.21\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 2.21\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 2.21\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 2.21\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 2.21\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 2.21\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 81.58 ***\n",
      "Epoch 10 - Train Acc : 88.33    Train Loss : 0.4,    Test Acc : 74.08    Test Loss : 0.53\n",
      "Epoch 20 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 80.29    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.83    Test Loss : 0.71\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.25    Test Loss : 1.1\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.38    Test Loss : 1.34\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.5    Test Loss : 1.47\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.42    Test Loss : 1.5\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.5    Test Loss : 1.52\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.54    Test Loss : 1.54\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.54    Test Loss : 1.55\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 1.55\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 1.55\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 1.55\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 1.55\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.54    Test Loss : 1.55\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.5    Test Loss : 1.56\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.5    Test Loss : 1.56\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.5    Test Loss : 1.56\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.42    Test Loss : 1.56\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.38    Test Loss : 1.56\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 83.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 29 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 87.5    Train Loss : 0.32,    Test Acc : 83.92    Test Loss : 0.46\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 89.0    Test Loss : 0.37\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 0.72\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.38    Test Loss : 0.97\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 1.11\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.67    Test Loss : 1.15\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.67    Test Loss : 1.16\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.71    Test Loss : 1.17\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.71    Test Loss : 1.17\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.67    Test Loss : 1.17\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.71    Test Loss : 1.18\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.18\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.18\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.18\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.18\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.18\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.18\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.18\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.18\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 1.18\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 89.79 ***\n",
      "Epoch 10 - Train Acc : 87.5    Train Loss : 0.37,    Test Acc : 84.12    Test Loss : 0.39\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 85.5    Test Loss : 0.37\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 0.66\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 1.04\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 1.2\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 1.27\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 1.3\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 1.32\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 1.32\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.88    Test Loss : 1.33\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.83    Test Loss : 1.33\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.83    Test Loss : 1.33\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 1.33\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.88    Test Loss : 1.33\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 1.34\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 1.34\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 1.34\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 1.34\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 1.34\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 1.34\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 86.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 30 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 88.33    Train Loss : 0.32,    Test Acc : 77.25    Test Loss : 0.51\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 83.79    Test Loss : 0.8\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 1.39\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.64\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 1.78\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.84\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.87\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 1.88\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 1.88\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.88\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 1.88\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 1.89\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.89\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.89\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.89\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.89\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.89\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 1.89\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 1.89\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.89\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 84.71 ***\n",
      "Epoch 10 - Train Acc : 83.33    Train Loss : 0.36,    Test Acc : 66.96    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 80.58    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.67    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 0.79\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.42    Test Loss : 0.78\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 0.9\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.83    Test Loss : 0.96\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 0.96\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 0.96\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 0.96\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 0.96\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 0.96\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 0.97\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 0.97\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 0.98\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 0.98\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 0.98\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 0.99\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 0.99\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 0.99\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 87.17 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 31 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 90.0    Train Loss : 0.29,    Test Acc : 76.83    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 85.96    Test Loss : 0.47\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.42    Test Loss : 0.85\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.13\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 1.27\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.33\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.36\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.79    Test Loss : 1.36\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.79    Test Loss : 1.37\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.37\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.37\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.37\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.37\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.37\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.37\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.37\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.37\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.37\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.37\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.37\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 87.83 ***\n",
      "Epoch 10 - Train Acc : 94.17    Train Loss : 0.22,    Test Acc : 82.5    Test Loss : 0.41\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 0.91\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.56\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 1.97\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 2.15\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 2.23\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 2.26\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 2.27\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 2.28\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 2.28\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 2.28\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 2.28\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 2.28\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 2.28\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 2.28\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 2.28\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 2.28\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 2.29\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 2.29\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 2.29\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 86.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 32 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (756,),    high arousal : (1764,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 85.0    Train Loss : 0.38,    Test Acc : 72.92    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 95.0    Train Loss : 0.11,    Test Acc : 83.75    Test Loss : 0.41\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 88.71    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.79    Test Loss : 1.05\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 1.38\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.04    Test Loss : 1.48\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 1.5\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.5    Test Loss : 1.52\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.54    Test Loss : 1.52\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.54    Test Loss : 1.52\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.58    Test Loss : 1.52\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.58    Test Loss : 1.52\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.58    Test Loss : 1.52\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.52\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.52\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.52\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 1.52\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 1.52\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.52\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.52\n",
      "directory already exists\n",
      "vlc_DE_GE is saved successfully\n",
      "*** Best ACC : 86.71 ***\n",
      "Epoch 10 - Train Acc : 89.17    Train Loss : 0.32,    Test Acc : 82.25    Test Loss : 0.42\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 91.04    Test Loss : 0.37\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.62    Test Loss : 0.71\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.38    Test Loss : 1.05\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 1.17\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 1.23\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 1.24\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 1.25\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 1.25\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.25\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 1.25\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.25\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.25\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.25\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.25\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.25\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.25\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.25\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.25\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 1.25\n",
      "directory already exists\n",
      "ars_DE_GE is saved successfully\n",
      "*** Best ACC : 88.71 ***\n",
      "\n",
      "**************** Valence *********************\n",
      "** Best ACC : [83.38, 83.79, 88.21, 87.88, 85.04, 79.38, 86.38, 87.96, 91.12, 88.83, 87.88, 93.67, 93.71, 85.17, 93.12, 89.33, 83.62, 88.0, 91.71, 88.67, 90.08, 78.58, 89.08, 88.21, 86.46, 85.0, 89.21, 81.58, 89.79, 84.71, 87.83, 86.71] **\n",
      " ** Avearge acc : 87.3153125,    std : 3.6161287867474727 **\n",
      "\n",
      "**************** Arousal *********************\n",
      "** Best ACC : [87.75, 89.0, 92.29, 82.33, 90.58, 80.21, 88.67, 86.29, 83.58, 90.25, 83.96, 91.38, 85.38, 87.75, 89.62, 87.62, 88.5, 94.08, 89.96, 91.33, 85.58, 82.46, 91.29, 86.33, 82.75, 81.62, 82.38, 83.38, 86.96, 87.17, 86.29, 88.71] **\n",
      " ** Avearge acc : 87.0453125,    std : 3.463678485706166 **\n",
      "\n",
      "directory already exists\n",
      "vlc_DE_GE_protocol_60_best_acc_list_231016 is saved successfully\n",
      "directory already exists\n",
      "ars_DE_GE_protocol_60_best_acc_list_231016 is saved successfully\n"
     ]
    }
   ],
   "source": [
    "vlc_best_epoch = []\n",
    "vlc_orig_acc = []\n",
    "vlc_best_acc = []\n",
    "ars_best_epoch = []\n",
    "ars_orig_acc = []\n",
    "ars_best_acc = []\n",
    "\n",
    "for i in range(32):\n",
    "    print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "    sub_idx = 'sub'+str(i+1)\n",
    "    date = '231016'\n",
    "\n",
    "    sub_de = subject_de[i]\n",
    "    sub_psd = subject_psd[i]\n",
    "    sub_label = subject_label[i]\n",
    "    valence_label, arousal_label = deap_label(sub_label)\n",
    "\n",
    "    de, psd, vlc_identifier, ars_identifier = other_preprocessing(sub_de,sub_psd, (valence_label,arousal_label), n_labels_by_class, args.out_channels, args.seed, isdeap=True)\n",
    "\n",
    "    de = normalization(de, axis = 0, ntype='standardization')\n",
    "    \n",
    "    print(\"\\nDistance matrix construction start...\")\n",
    "    de_dm = distance_matrix(de)\n",
    "    print(\"\\nDistance matrix construction Done...\")\n",
    "\n",
    "    de_neighbors = kneighbors(de_dm, args.n_samples, args.de_k)\n",
    "\n",
    "    de_ssm, de_nssm = ssm_construction(de_dm,de_neighbors)\n",
    "    \n",
    "    adj = de_ssm\n",
    "    \n",
    "    feature = de\n",
    "    \n",
    "    feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "    adj = torch.from_numpy(adj).to(torch.float32).to(device)\n",
    "    \n",
    "    adj = normalize_adj(adj,im)\n",
    "    \n",
    "    ars_label = torch.from_numpy(arousal_label).to(torch.long).to(device)\n",
    "    vlc_label = torch.from_numpy(valence_label).to(torch.long).to(device)\n",
    "\n",
    "    vlc_identifier = torch.from_numpy(vlc_identifier).bool()\n",
    "    vlc_train_identifier = vlc_identifier.to(device)\n",
    "    isunlabeled = ~vlc_identifier\n",
    "    vlc_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "    ars_identifier = torch.from_numpy(ars_identifier).bool()\n",
    "    ars_train_identifier = ars_identifier.to(device)\n",
    "    isunlabeled = ~ars_identifier\n",
    "    ars_test_identifier = isunlabeled.to(device)\n",
    "    \n",
    "    encoder = Encoder(args.feature_dimension//2, args.gcn_hid_channels//2, args.gcn_out_channels//2, activation, args.seed, base_model = gcn).to(device)\n",
    "    model = GRACE(encoder, args.feature_dimension//2, args.gcn_out_channels//2, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = encoder_train(feature,adj, ars_label, ars_train_identifier, ars_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "\n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'vlc_DE_GE', sample)\n",
    "    \n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    vlc_best_acc.append(best_acc)\n",
    "    vlc_orig_acc.append(best_acc)\n",
    "    \n",
    "    encoder = Encoder(args.feature_dimension//2, args.gcn_hid_channels//2, args.gcn_out_channels//2, activation, args.seed, base_model = gcn).to(device)\n",
    "    model = GRACE(encoder, args.feature_dimension//2, args.gcn_out_channels//2, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = encoder_train(feature,adj, vlc_label, vlc_train_identifier, vlc_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "\n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'ars_DE_GE', sample)\n",
    "    \n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    ars_best_acc.append(best_acc)\n",
    "    ars_orig_acc.append(best_acc)\n",
    "\n",
    "\n",
    "print(\"\\n**************** Valence *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(vlc_best_acc, np.mean(vlc_best_acc), np.std(vlc_best_acc)))\n",
    "\n",
    "print(\"**************** Arousal *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(ars_best_acc, np.mean(ars_best_acc), np.std(ars_best_acc)))\n",
    "\n",
    "vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "ars_best_acc_list = np.array(ars_best_acc)\n",
    "\n",
    "save_np(args.tensor_save_path+'ablation2/vlc/', 'vlc_DE_GE_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, vlc_best_acc_list)\n",
    "save_np(args.tensor_save_path+'ablation2/ars/', 'ars_DE_GE_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, ars_best_acc_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c5e47",
   "metadata": {},
   "source": [
    "##  Ablation 5 - PSD + GE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5986e8f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 91.67    Train Loss : 0.25,    Test Acc : 80.88    Test Loss : 0.45\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 85.58    Test Loss : 0.57\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.04\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.46\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.5    Test Loss : 1.71\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.5    Test Loss : 1.81\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 1.85\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.79    Test Loss : 1.87\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 1.88\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 1.89\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.79    Test Loss : 1.89\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.79    Test Loss : 1.9\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.88    Test Loss : 1.9\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.88    Test Loss : 1.9\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.92    Test Loss : 1.9\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.92    Test Loss : 1.9\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.88    Test Loss : 1.91\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.91\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.91\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.91\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 82.83 ***\n",
      "Epoch 10 - Train Acc : 90.83    Train Loss : 0.22,    Test Acc : 78.38    Test Loss : 0.52\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.67    Test Loss : 0.8\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.33\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.71    Test Loss : 1.66\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.38    Test Loss : 1.77\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.83\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.86\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.87\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.87\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.87\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.79    Test Loss : 1.87\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.79    Test Loss : 1.88\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.88\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.88\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.88\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.88\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.88\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.88\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.88\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 1.88\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 84.83 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 2 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 77.5    Train Loss : 0.5,    Test Acc : 68.12    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 73.63    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 82.79    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 94.17    Train Loss : 0.11,    Test Acc : 86.46    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 95.83    Train Loss : 0.08,    Test Acc : 83.54    Test Loss : 0.7\n",
      "Epoch 60 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 89.17    Test Loss : 0.75\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.58    Test Loss : 0.86\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 0.99\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.17\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 1.22\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 1.25\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 1.28\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.38    Test Loss : 1.3\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 1.32\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 1.33\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 1.34\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 1.35\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 1.36\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 1.37\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 1.38\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 88.12 ***\n",
      "Epoch 10 - Train Acc : 72.5    Train Loss : 0.54,    Test Acc : 60.17    Test Loss : 0.71\n",
      "Epoch 20 - Train Acc : 85.0    Train Loss : 0.33,    Test Acc : 69.25    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 90.0    Train Loss : 0.21,    Test Acc : 76.33    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 79.92    Test Loss : 0.59\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 81.71    Test Loss : 0.75\n",
      "Epoch 60 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 81.88    Test Loss : 0.79\n",
      "Epoch 70 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 82.17    Test Loss : 0.95\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 81.5    Test Loss : 0.92\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 82.88    Test Loss : 0.9\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.29    Test Loss : 0.95\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 1.0\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 1.07\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.11\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 1.14\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.16\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.18\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.21\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.79    Test Loss : 1.22\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 1.24\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.25\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 84.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 3 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (2016,),    high arousal : (504,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.43,    Test Acc : 74.58    Test Loss : 0.5\n",
      "Epoch 20 - Train Acc : 94.17    Train Loss : 0.12,    Test Acc : 85.71    Test Loss : 0.46\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 90.04    Test Loss : 0.61\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.29    Test Loss : 0.93\n",
      "Epoch 50 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 85.38    Test Loss : 1.17\n",
      "Epoch 60 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 89.12    Test Loss : 0.83\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.67    Test Loss : 0.71\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.04    Test Loss : 0.72\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.13    Test Loss : 0.74\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.79    Test Loss : 0.81\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.79    Test Loss : 0.83\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.71    Test Loss : 0.86\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.75    Test Loss : 0.88\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.67    Test Loss : 0.89\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.91\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.54    Test Loss : 0.92\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.54    Test Loss : 0.93\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.54    Test Loss : 0.94\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.54    Test Loss : 0.94\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.54    Test Loss : 0.95\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 91.54 ***\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.35,    Test Acc : 71.21    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 82.17    Test Loss : 0.94\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.25    Test Loss : 1.86\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.46    Test Loss : 2.12\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 2.4\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 2.57\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 2.64\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 2.67\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 2.68\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 2.68\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 2.68\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 2.67\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 2.67\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 2.67\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 2.67\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 2.67\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 2.67\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 2.67\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 2.68\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 2.68\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 85.79 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 4 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1512,),    high valence : (1008,)\n",
      "low arousal : (1512,),    high arousal : (1008,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 69.17    Train Loss : 0.56,    Test Acc : 61.38    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 77.5    Train Loss : 0.42,    Test Acc : 67.5    Test Loss : 0.54\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.33,    Test Acc : 73.46    Test Loss : 0.51\n",
      "Epoch 40 - Train Acc : 84.17    Train Loss : 0.31,    Test Acc : 74.04    Test Loss : 0.48\n",
      "Epoch 50 - Train Acc : 85.83    Train Loss : 0.27,    Test Acc : 79.58    Test Loss : 0.48\n",
      "Epoch 60 - Train Acc : 86.67    Train Loss : 0.25,    Test Acc : 78.88    Test Loss : 0.49\n",
      "Epoch 70 - Train Acc : 86.67    Train Loss : 0.25,    Test Acc : 78.83    Test Loss : 0.54\n",
      "Epoch 80 - Train Acc : 87.5    Train Loss : 0.23,    Test Acc : 82.79    Test Loss : 0.51\n",
      "Epoch 90 - Train Acc : 90.0    Train Loss : 0.22,    Test Acc : 82.29    Test Loss : 0.56\n",
      "Epoch 100 - Train Acc : 85.83    Train Loss : 0.23,    Test Acc : 76.46    Test Loss : 0.55\n",
      "Epoch 110 - Train Acc : 90.83    Train Loss : 0.21,    Test Acc : 82.71    Test Loss : 0.56\n",
      "Epoch 120 - Train Acc : 90.0    Train Loss : 0.21,    Test Acc : 82.0    Test Loss : 0.68\n",
      "Epoch 130 - Train Acc : 75.83    Train Loss : 0.57,    Test Acc : 63.79    Test Loss : 1.51\n",
      "Epoch 140 - Train Acc : 83.33    Train Loss : 0.28,    Test Acc : 77.58    Test Loss : 0.54\n",
      "Epoch 150 - Train Acc : 85.0    Train Loss : 0.25,    Test Acc : 72.83    Test Loss : 0.81\n",
      "Epoch 160 - Train Acc : 87.5    Train Loss : 0.23,    Test Acc : 78.88    Test Loss : 0.6\n",
      "Epoch 170 - Train Acc : 88.33    Train Loss : 0.21,    Test Acc : 80.54    Test Loss : 0.54\n",
      "Epoch 180 - Train Acc : 86.67    Train Loss : 0.2,    Test Acc : 81.04    Test Loss : 0.57\n",
      "Epoch 190 - Train Acc : 87.5    Train Loss : 0.19,    Test Acc : 81.5    Test Loss : 0.62\n",
      "Epoch 200 - Train Acc : 90.0    Train Loss : 0.2,    Test Acc : 79.38    Test Loss : 0.66\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 79.38 ***\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.53,    Test Acc : 64.08    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 75.83    Train Loss : 0.49,    Test Acc : 66.67    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 80.83    Train Loss : 0.46,    Test Acc : 66.71    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 68.21    Test Loss : 0.57\n",
      "Epoch 50 - Train Acc : 84.17    Train Loss : 0.4,    Test Acc : 64.79    Test Loss : 0.69\n",
      "Epoch 60 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 68.46    Test Loss : 0.7\n",
      "Epoch 70 - Train Acc : 86.67    Train Loss : 0.3,    Test Acc : 69.04    Test Loss : 0.79\n",
      "Epoch 80 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 72.29    Test Loss : 0.82\n",
      "Epoch 90 - Train Acc : 84.17    Train Loss : 0.34,    Test Acc : 73.29    Test Loss : 0.94\n",
      "Epoch 100 - Train Acc : 85.83    Train Loss : 0.32,    Test Acc : 74.42    Test Loss : 0.75\n",
      "Epoch 110 - Train Acc : 90.0    Train Loss : 0.27,    Test Acc : 71.58    Test Loss : 0.79\n",
      "Epoch 120 - Train Acc : 91.67    Train Loss : 0.24,    Test Acc : 71.88    Test Loss : 0.92\n",
      "Epoch 130 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 73.96    Test Loss : 1.04\n",
      "Epoch 140 - Train Acc : 94.17    Train Loss : 0.18,    Test Acc : 75.33    Test Loss : 1.16\n",
      "Epoch 150 - Train Acc : 90.83    Train Loss : 0.16,    Test Acc : 76.67    Test Loss : 1.37\n",
      "Epoch 160 - Train Acc : 89.17    Train Loss : 0.31,    Test Acc : 73.17    Test Loss : 1.53\n",
      "Epoch 170 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 72.21    Test Loss : 1.56\n",
      "Epoch 180 - Train Acc : 90.83    Train Loss : 0.21,    Test Acc : 75.0    Test Loss : 1.28\n",
      "Epoch 190 - Train Acc : 93.33    Train Loss : 0.18,    Test Acc : 74.75    Test Loss : 1.26\n",
      "Epoch 200 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 75.92    Test Loss : 1.41\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 75.92 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 5 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1323,),    high arousal : (1197,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.38,    Test Acc : 76.38    Test Loss : 0.47\n",
      "Epoch 20 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 81.08    Test Loss : 0.4\n",
      "Epoch 30 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 81.04    Test Loss : 0.52\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 81.08    Test Loss : 0.85\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.67    Test Loss : 1.11\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 1.3\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.92    Test Loss : 1.62\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 1.73\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.42    Test Loss : 1.83\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.42    Test Loss : 1.91\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.25    Test Loss : 1.95\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.99\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.08    Test Loss : 2.02\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.04    Test Loss : 2.05\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.08    Test Loss : 2.07\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 2.1\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 2.12\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 2.14\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 2.16\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 2.18\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 83.17 ***\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.48,    Test Acc : 72.12    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 76.58    Test Loss : 0.68\n",
      "Epoch 30 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 77.79    Test Loss : 0.87\n",
      "Epoch 40 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 81.46    Test Loss : 0.93\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.38    Test Loss : 1.38\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.62    Test Loss : 1.62\n",
      "Epoch 70 - Train Acc : 97.5    Train Loss : 0.04,    Test Acc : 81.42    Test Loss : 1.61\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.08,    Test Acc : 80.75    Test Loss : 0.93\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 79.5    Test Loss : 0.83\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 80.88    Test Loss : 0.88\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.21    Test Loss : 1.06\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.04    Test Loss : 1.21\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.0    Test Loss : 1.31\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.0    Test Loss : 1.4\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.83    Test Loss : 1.49\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.75    Test Loss : 1.54\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.67    Test Loss : 1.59\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.62    Test Loss : 1.63\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.58    Test Loss : 1.67\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.54    Test Loss : 1.71\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 80.54 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 6 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 77.5    Train Loss : 0.39,    Test Acc : 71.46    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 79.42    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 79.38    Test Loss : 1.12\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.42    Test Loss : 1.67\n",
      "Epoch 50 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 76.38    Test Loss : 2.31\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 76.33    Test Loss : 2.47\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.25    Test Loss : 2.15\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.79    Test Loss : 2.33\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.0    Test Loss : 2.16\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.25    Test Loss : 2.12\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.29    Test Loss : 2.1\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.33    Test Loss : 2.09\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.25    Test Loss : 2.08\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.17    Test Loss : 2.09\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.13    Test Loss : 2.09\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.04    Test Loss : 2.08\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.0    Test Loss : 2.08\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.04    Test Loss : 2.08\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.0    Test Loss : 2.08\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.0    Test Loss : 2.08\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 80.0 ***\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.45,    Test Acc : 70.33    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.09,    Test Acc : 81.54    Test Loss : 0.53\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.71    Test Loss : 1.34\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.96    Test Loss : 2.04\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.42    Test Loss : 2.32\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 2.44\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 2.55\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 2.58\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 2.57\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.71    Test Loss : 2.56\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.67    Test Loss : 2.56\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 2.57\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 2.56\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.67    Test Loss : 2.56\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.67    Test Loss : 2.56\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.62    Test Loss : 2.57\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.67    Test Loss : 2.57\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.58    Test Loss : 2.57\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.62    Test Loss : 2.57\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.54    Test Loss : 2.57\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 81.54 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 7 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (756,),    high valence : (1764,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.4,    Test Acc : 72.67    Test Loss : 0.49\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 84.0    Test Loss : 0.41\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 0.61\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 0.76\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 0.92\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 0.99\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 1.0\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 0.98\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 0.98\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 0.98\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 0.98\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 0.98\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 0.98\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 0.98\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 0.98\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 0.98\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 0.98\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 0.98\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 0.98\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 0.98\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 88.75 ***\n",
      "Epoch 10 - Train Acc : 86.67    Train Loss : 0.3,    Test Acc : 74.62    Test Loss : 0.51\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.29    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.13\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.54\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.71\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.42    Test Loss : 1.77\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.78\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.78\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.77\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.77\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.76\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.76\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.75\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.75\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.75\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.75\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.74\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.74\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.74\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.74\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 87.71 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 8 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 83.33    Train Loss : 0.36,    Test Acc : 74.92    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 94.17    Train Loss : 0.21,    Test Acc : 75.33    Test Loss : 0.68\n",
      "Epoch 30 - Train Acc : 94.17    Train Loss : 0.11,    Test Acc : 78.46    Test Loss : 0.99\n",
      "Epoch 40 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 81.17    Test Loss : 1.15\n",
      "Epoch 50 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 78.83    Test Loss : 1.24\n",
      "Epoch 60 - Train Acc : 96.67    Train Loss : 0.06,    Test Acc : 79.5    Test Loss : 1.31\n",
      "Epoch 70 - Train Acc : 97.5    Train Loss : 0.04,    Test Acc : 80.54    Test Loss : 1.35\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 80.75    Test Loss : 1.34\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 80.92    Test Loss : 1.45\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 81.08    Test Loss : 1.56\n",
      "Epoch 110 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 80.54    Test Loss : 1.69\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 81.0    Test Loss : 1.77\n",
      "Epoch 130 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 80.5    Test Loss : 1.81\n",
      "Epoch 140 - Train Acc : 97.5    Train Loss : 0.04,    Test Acc : 80.0    Test Loss : 1.71\n",
      "Epoch 150 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 79.42    Test Loss : 1.52\n",
      "Epoch 160 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 80.17    Test Loss : 1.43\n",
      "Epoch 170 - Train Acc : 98.33    Train Loss : 0.02,    Test Acc : 80.04    Test Loss : 1.64\n",
      "Epoch 180 - Train Acc : 98.33    Train Loss : 0.02,    Test Acc : 80.08    Test Loss : 1.81\n",
      "Epoch 190 - Train Acc : 99.17    Train Loss : 0.01,    Test Acc : 81.12    Test Loss : 1.91\n",
      "Epoch 200 - Train Acc : 99.17    Train Loss : 0.01,    Test Acc : 80.92    Test Loss : 1.98\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 80.92 ***\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.45,    Test Acc : 70.62    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 86.67    Train Loss : 0.25,    Test Acc : 74.67    Test Loss : 0.63\n",
      "Epoch 30 - Train Acc : 90.83    Train Loss : 0.2,    Test Acc : 78.17    Test Loss : 0.71\n",
      "Epoch 40 - Train Acc : 92.5    Train Loss : 0.15,    Test Acc : 78.83    Test Loss : 0.79\n",
      "Epoch 50 - Train Acc : 94.17    Train Loss : 0.13,    Test Acc : 78.5    Test Loss : 0.92\n",
      "Epoch 60 - Train Acc : 93.33    Train Loss : 0.13,    Test Acc : 79.0    Test Loss : 1.0\n",
      "Epoch 70 - Train Acc : 94.17    Train Loss : 0.11,    Test Acc : 79.21    Test Loss : 1.06\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 71.96    Test Loss : 1.19\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 76.21    Test Loss : 1.2\n",
      "Epoch 100 - Train Acc : 95.83    Train Loss : 0.09,    Test Acc : 78.96    Test Loss : 1.27\n",
      "Epoch 110 - Train Acc : 95.83    Train Loss : 0.08,    Test Acc : 72.38    Test Loss : 1.41\n",
      "Epoch 120 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 78.75    Test Loss : 1.41\n",
      "Epoch 130 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 78.5    Test Loss : 1.49\n",
      "Epoch 140 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 73.29    Test Loss : 1.64\n",
      "Epoch 150 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 76.5    Test Loss : 1.69\n",
      "Epoch 160 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 78.38    Test Loss : 1.7\n",
      "Epoch 170 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 79.12    Test Loss : 1.81\n",
      "Epoch 180 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 73.12    Test Loss : 2.29\n",
      "Epoch 190 - Train Acc : 89.17    Train Loss : 0.41,    Test Acc : 77.67    Test Loss : 1.47\n",
      "Epoch 200 - Train Acc : 92.5    Train Loss : 0.15,    Test Acc : 77.96    Test Loss : 0.84\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 77.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 9 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.4,    Test Acc : 75.75    Test Loss : 0.52\n",
      "Epoch 20 - Train Acc : 95.0    Train Loss : 0.19,    Test Acc : 82.75    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 85.21    Test Loss : 0.65\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.58    Test Loss : 1.06\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.54    Test Loss : 1.19\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 1.27\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 1.35\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.39\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.4\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 1.4\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.4\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.92    Test Loss : 1.4\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 1.4\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.4\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.4\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.4\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.4\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.4\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.4\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.41\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 86.08 ***\n",
      "Epoch 10 - Train Acc : 80.0    Train Loss : 0.37,    Test Acc : 71.0    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 79.83    Test Loss : 0.87\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 81.96    Test Loss : 1.2\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.33    Test Loss : 1.46\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 1.54\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 1.68\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.42    Test Loss : 1.74\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.79\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 1.82\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.83\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.83\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 1.84\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 1.84\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 1.85\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 1.86\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 1.86\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 1.87\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 1.87\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 1.88\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 1.88\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 85.25 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 10 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1134,),    high arousal : (1386,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 80.0    Train Loss : 0.45,    Test Acc : 72.46    Test Loss : 0.55\n",
      "Epoch 20 - Train Acc : 85.83    Train Loss : 0.29,    Test Acc : 76.83    Test Loss : 0.73\n",
      "Epoch 30 - Train Acc : 89.17    Train Loss : 0.24,    Test Acc : 77.96    Test Loss : 0.92\n",
      "Epoch 40 - Train Acc : 90.0    Train Loss : 0.2,    Test Acc : 78.88    Test Loss : 0.98\n",
      "Epoch 50 - Train Acc : 90.83    Train Loss : 0.16,    Test Acc : 80.5    Test Loss : 1.13\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.19,    Test Acc : 78.21    Test Loss : 1.21\n",
      "Epoch 70 - Train Acc : 91.67    Train Loss : 0.14,    Test Acc : 79.54    Test Loss : 1.22\n",
      "Epoch 80 - Train Acc : 95.0    Train Loss : 0.11,    Test Acc : 78.71    Test Loss : 1.4\n",
      "Epoch 90 - Train Acc : 94.17    Train Loss : 0.14,    Test Acc : 76.88    Test Loss : 1.59\n",
      "Epoch 100 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 78.96    Test Loss : 1.52\n",
      "Epoch 110 - Train Acc : 95.0    Train Loss : 0.11,    Test Acc : 78.21    Test Loss : 1.58\n",
      "Epoch 120 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 79.46    Test Loss : 1.7\n",
      "Epoch 130 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 80.13    Test Loss : 1.86\n",
      "Epoch 140 - Train Acc : 95.83    Train Loss : 0.09,    Test Acc : 80.88    Test Loss : 1.99\n",
      "Epoch 150 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 79.63    Test Loss : 2.08\n",
      "Epoch 160 - Train Acc : 95.83    Train Loss : 0.08,    Test Acc : 79.0    Test Loss : 2.21\n",
      "Epoch 170 - Train Acc : 95.83    Train Loss : 0.09,    Test Acc : 80.88    Test Loss : 2.33\n",
      "Epoch 180 - Train Acc : 94.17    Train Loss : 0.13,    Test Acc : 75.71    Test Loss : 2.38\n",
      "Epoch 190 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 80.21    Test Loss : 2.29\n",
      "Epoch 200 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 80.67    Test Loss : 2.35\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 80.67 ***\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.59,    Test Acc : 57.0    Test Loss : 0.77\n",
      "Epoch 20 - Train Acc : 79.17    Train Loss : 0.45,    Test Acc : 68.58    Test Loss : 1.01\n",
      "Epoch 30 - Train Acc : 88.33    Train Loss : 0.34,    Test Acc : 68.17    Test Loss : 1.17\n",
      "Epoch 40 - Train Acc : 84.17    Train Loss : 0.31,    Test Acc : 69.33    Test Loss : 1.48\n",
      "Epoch 50 - Train Acc : 95.0    Train Loss : 0.17,    Test Acc : 72.67    Test Loss : 1.61\n",
      "Epoch 60 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 73.38    Test Loss : 1.81\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.14,    Test Acc : 72.71    Test Loss : 1.96\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 73.12    Test Loss : 2.23\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 73.96    Test Loss : 2.49\n",
      "Epoch 100 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 72.83    Test Loss : 2.74\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 74.75    Test Loss : 2.9\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 74.33    Test Loss : 3.21\n",
      "Epoch 130 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 75.42    Test Loss : 3.33\n",
      "Epoch 140 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 75.21    Test Loss : 3.54\n",
      "Epoch 150 - Train Acc : 84.17    Train Loss : 0.74,    Test Acc : 69.29    Test Loss : 3.32\n",
      "Epoch 160 - Train Acc : 89.17    Train Loss : 0.23,    Test Acc : 65.92    Test Loss : 1.58\n",
      "Epoch 170 - Train Acc : 93.33    Train Loss : 0.24,    Test Acc : 69.62    Test Loss : 1.17\n",
      "Epoch 180 - Train Acc : 92.5    Train Loss : 0.19,    Test Acc : 69.5    Test Loss : 1.18\n",
      "Epoch 190 - Train Acc : 95.83    Train Loss : 0.14,    Test Acc : 71.46    Test Loss : 1.36\n",
      "Epoch 200 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 71.12    Test Loss : 1.66\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 71.12 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 11 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1575,),    high arousal : (945,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.54,    Test Acc : 66.71    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 82.5    Train Loss : 0.41,    Test Acc : 70.83    Test Loss : 0.74\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.32,    Test Acc : 76.29    Test Loss : 0.78\n",
      "Epoch 40 - Train Acc : 90.83    Train Loss : 0.26,    Test Acc : 72.92    Test Loss : 1.27\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.2,    Test Acc : 78.12    Test Loss : 1.35\n",
      "Epoch 60 - Train Acc : 86.67    Train Loss : 0.27,    Test Acc : 75.12    Test Loss : 1.27\n",
      "Epoch 70 - Train Acc : 89.17    Train Loss : 0.19,    Test Acc : 79.42    Test Loss : 1.23\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 79.29    Test Loss : 1.21\n",
      "Epoch 90 - Train Acc : 91.67    Train Loss : 0.15,    Test Acc : 81.92    Test Loss : 1.28\n",
      "Epoch 100 - Train Acc : 90.0    Train Loss : 0.17,    Test Acc : 78.62    Test Loss : 1.37\n",
      "Epoch 110 - Train Acc : 93.33    Train Loss : 0.14,    Test Acc : 78.96    Test Loss : 1.38\n",
      "Epoch 120 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 81.25    Test Loss : 1.32\n",
      "Epoch 130 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 81.12    Test Loss : 1.38\n",
      "Epoch 140 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 81.79    Test Loss : 1.49\n",
      "Epoch 150 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 81.17    Test Loss : 1.72\n",
      "Epoch 160 - Train Acc : 97.5    Train Loss : 0.05,    Test Acc : 79.08    Test Loss : 1.98\n",
      "Epoch 170 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 80.25    Test Loss : 2.17\n",
      "Epoch 180 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 78.42    Test Loss : 2.34\n",
      "Epoch 190 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 78.71    Test Loss : 2.27\n",
      "Epoch 200 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 79.71    Test Loss : 2.43\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 79.71 ***\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 71.5    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 89.17    Train Loss : 0.31,    Test Acc : 72.17    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 85.83    Train Loss : 0.27,    Test Acc : 75.21    Test Loss : 0.59\n",
      "Epoch 40 - Train Acc : 92.5    Train Loss : 0.22,    Test Acc : 76.25    Test Loss : 0.65\n",
      "Epoch 50 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 76.04    Test Loss : 0.86\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.15,    Test Acc : 78.96    Test Loss : 0.89\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.11,    Test Acc : 80.08    Test Loss : 1.11\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.14,    Test Acc : 75.25    Test Loss : 1.6\n",
      "Epoch 90 - Train Acc : 79.17    Train Loss : 0.44,    Test Acc : 63.08    Test Loss : 1.93\n",
      "Epoch 100 - Train Acc : 88.33    Train Loss : 0.25,    Test Acc : 74.88    Test Loss : 0.93\n",
      "Epoch 110 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 74.46    Test Loss : 0.79\n",
      "Epoch 120 - Train Acc : 93.33    Train Loss : 0.15,    Test Acc : 77.12    Test Loss : 0.77\n",
      "Epoch 130 - Train Acc : 94.17    Train Loss : 0.14,    Test Acc : 77.92    Test Loss : 0.81\n",
      "Epoch 140 - Train Acc : 93.33    Train Loss : 0.12,    Test Acc : 77.96    Test Loss : 0.9\n",
      "Epoch 150 - Train Acc : 93.33    Train Loss : 0.11,    Test Acc : 77.96    Test Loss : 0.98\n",
      "Epoch 160 - Train Acc : 93.33    Train Loss : 0.1,    Test Acc : 78.46    Test Loss : 1.05\n",
      "Epoch 170 - Train Acc : 94.17    Train Loss : 0.1,    Test Acc : 79.46    Test Loss : 1.12\n",
      "Epoch 180 - Train Acc : 95.0    Train Loss : 0.09,    Test Acc : 79.96    Test Loss : 1.2\n",
      "Epoch 190 - Train Acc : 95.0    Train Loss : 0.08,    Test Acc : 80.25    Test Loss : 1.27\n",
      "Epoch 200 - Train Acc : 95.83    Train Loss : 0.08,    Test Acc : 80.46    Test Loss : 1.33\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 80.46 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 12 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 80.83    Train Loss : 0.45,    Test Acc : 75.67    Test Loss : 0.48\n",
      "Epoch 20 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 81.96    Test Loss : 0.43\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 0.76\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.37\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.65\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.77\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 1.81\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.83\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.83\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.84\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.84\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.84\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.84\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.84\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.84\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.84\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.84\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.84\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.84\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.84\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 87.25 ***\n",
      "Epoch 10 - Train Acc : 93.33    Train Loss : 0.22,    Test Acc : 79.92    Test Loss : 0.46\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 88.58    Test Loss : 0.39\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.33    Test Loss : 1.18\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.71    Test Loss : 1.59\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.67    Test Loss : 1.64\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 1.63\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.58    Test Loss : 1.62\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.75    Test Loss : 1.61\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.6\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.04    Test Loss : 1.6\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.04    Test Loss : 1.6\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.04    Test Loss : 1.6\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.6\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.6\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 1.6\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.21    Test Loss : 1.6\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.29    Test Loss : 1.6\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.29    Test Loss : 1.6\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.33    Test Loss : 1.6\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.33    Test Loss : 1.6\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 83.33 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 13 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1386,),    high valence : (1134,)\n",
      "low arousal : (378,),    high arousal : (2142,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 88.33    Train Loss : 0.31,    Test Acc : 77.12    Test Loss : 0.55\n",
      "Epoch 20 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 83.42    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 85.29    Test Loss : 0.79\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.58    Test Loss : 1.08\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.92    Test Loss : 1.33\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 1.52\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.5    Test Loss : 1.58\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.5    Test Loss : 1.6\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.61\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 1.61\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 1.61\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 1.61\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 1.61\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 1.61\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.61\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.61\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.61\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.61\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 1.61\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 1.61\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 87.04 ***\n",
      "Epoch 10 - Train Acc : 88.33    Train Loss : 0.35,    Test Acc : 79.17    Test Loss : 0.39\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 87.25    Test Loss : 0.28\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.71    Test Loss : 0.32\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.21    Test Loss : 0.66\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.5    Test Loss : 0.65\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.58    Test Loss : 0.59\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.08    Test Loss : 0.58\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.04    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.67    Test Loss : 0.6\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.54    Test Loss : 0.62\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.42    Test Loss : 0.63\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.25    Test Loss : 0.64\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.08    Test Loss : 0.65\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.08    Test Loss : 0.66\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.04    Test Loss : 0.67\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.0    Test Loss : 0.67\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.96    Test Loss : 0.67\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.92    Test Loss : 0.68\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.92    Test Loss : 0.68\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.92    Test Loss : 0.68\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 90.92 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 14 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.47,    Test Acc : 69.92    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 77.38    Test Loss : 0.72\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.33    Test Loss : 1.12\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.88    Test Loss : 1.7\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.95\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 2.05\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 2.1\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 2.12\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 2.12\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 2.13\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.58    Test Loss : 2.13\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 2.13\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 2.13\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 2.13\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 2.13\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 2.13\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 2.13\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.62    Test Loss : 2.14\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 2.14\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.71    Test Loss : 2.14\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 84.71 ***\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.4,    Test Acc : 70.17    Test Loss : 0.55\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 84.96    Test Loss : 0.41\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 88.0    Test Loss : 0.53\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.96    Test Loss : 0.74\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 0.89\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 0.84\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 0.87\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 0.89\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.88\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.88\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.38    Test Loss : 0.9\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 0.9\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.91\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.91\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.92\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.38    Test Loss : 0.92\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.38    Test Loss : 0.93\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 0.93\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 0.93\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.33    Test Loss : 0.94\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 88.33 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 15 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1197,),    high arousal : (1323,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 74.62    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 77.79    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 88.33    Train Loss : 0.18,    Test Acc : 83.42    Test Loss : 0.47\n",
      "Epoch 40 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 82.0    Test Loss : 0.82\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.04,    Test Acc : 85.75    Test Loss : 0.97\n",
      "Epoch 60 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 85.96    Test Loss : 1.22\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.29    Test Loss : 1.48\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.75    Test Loss : 1.73\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.92\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 2.07\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.18\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 2.27\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 2.34\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.4\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.45\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 2.49\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 2.53\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 2.56\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 2.59\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 2.63\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 87.21 ***\n",
      "Epoch 10 - Train Acc : 72.5    Train Loss : 0.49,    Test Acc : 69.17    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 89.17    Train Loss : 0.27,    Test Acc : 78.08    Test Loss : 0.55\n",
      "Epoch 30 - Train Acc : 90.0    Train Loss : 0.16,    Test Acc : 83.42    Test Loss : 0.85\n",
      "Epoch 40 - Train Acc : 94.17    Train Loss : 0.14,    Test Acc : 86.38    Test Loss : 0.89\n",
      "Epoch 50 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 87.54    Test Loss : 1.01\n",
      "Epoch 60 - Train Acc : 95.83    Train Loss : 0.07,    Test Acc : 88.29    Test Loss : 1.32\n",
      "Epoch 70 - Train Acc : 92.5    Train Loss : 0.19,    Test Acc : 86.75    Test Loss : 1.38\n",
      "Epoch 80 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 88.08    Test Loss : 1.07\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 87.58    Test Loss : 1.1\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 90.0    Test Loss : 1.26\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.58    Test Loss : 1.42\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.58    Test Loss : 1.58\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.25    Test Loss : 1.7\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.79\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.46    Test Loss : 1.86\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.93\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.98\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 2.02\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 2.06\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 2.09\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 89.5 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 16 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1575,),    high valence : (945,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 72.62    Test Loss : 0.54\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 81.17    Test Loss : 0.69\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 0.88\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 1.18\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 1.34\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.39\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.41\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.42\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.43\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.43\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.43\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.43\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.43\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.43\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.43\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 1.43\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 1.43\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 1.44\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 1.44\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.21    Test Loss : 1.44\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 88.21 ***\n",
      "Epoch 10 - Train Acc : 85.0    Train Loss : 0.34,    Test Acc : 75.96    Test Loss : 0.51\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 83.5    Test Loss : 0.51\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 0.8\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.58    Test Loss : 1.3\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.61\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.77\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.79    Test Loss : 1.82\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 1.82\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.81\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 1.81\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.81\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.81\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.81\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.81\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.81\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.81\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.81\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.8\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.8\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.8\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 85.12 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 17 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 80.0    Train Loss : 0.44,    Test Acc : 70.58    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 74.04    Test Loss : 0.74\n",
      "Epoch 30 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 75.83    Test Loss : 0.94\n",
      "Epoch 40 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 77.38    Test Loss : 1.13\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.83    Test Loss : 1.36\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.04    Test Loss : 1.53\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.62    Test Loss : 1.77\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.92    Test Loss : 1.95\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.88    Test Loss : 2.09\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 2.16\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 2.22\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 2.26\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 2.29\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 2.32\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.71    Test Loss : 2.34\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 2.36\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 2.38\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.62    Test Loss : 2.4\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 2.42\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.67    Test Loss : 2.44\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 82.67 ***\n",
      "Epoch 10 - Train Acc : 81.67    Train Loss : 0.42,    Test Acc : 71.25    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 89.17    Train Loss : 0.27,    Test Acc : 75.58    Test Loss : 0.54\n",
      "Epoch 30 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 77.17    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.88    Test Loss : 1.06\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.08    Test Loss : 1.63\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.88    Test Loss : 1.91\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.29    Test Loss : 2.04\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.38    Test Loss : 2.08\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.42    Test Loss : 2.11\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.5    Test Loss : 2.12\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.62    Test Loss : 2.12\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.75    Test Loss : 2.12\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.79    Test Loss : 2.13\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.79    Test Loss : 2.13\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.71    Test Loss : 2.13\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.71    Test Loss : 2.14\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.75    Test Loss : 2.14\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.75    Test Loss : 2.15\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.75    Test Loss : 2.15\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.75    Test Loss : 2.15\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 81.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 18 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 83.33    Train Loss : 0.35,    Test Acc : 76.33    Test Loss : 0.47\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.16,    Test Acc : 84.25    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 85.83    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 88.12    Test Loss : 0.67\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 90.25    Test Loss : 0.73\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 90.62    Test Loss : 0.73\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.4,    Test Acc : 79.25    Test Loss : 1.29\n",
      "Epoch 80 - Train Acc : 93.33    Train Loss : 0.13,    Test Acc : 84.79    Test Loss : 0.47\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 89.42    Test Loss : 0.57\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 89.92    Test Loss : 0.66\n",
      "Epoch 110 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 90.67    Test Loss : 0.69\n",
      "Epoch 120 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 91.33    Test Loss : 0.74\n",
      "Epoch 130 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 91.33    Test Loss : 0.79\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 91.5    Test Loss : 0.86\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.42    Test Loss : 0.93\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.29    Test Loss : 0.98\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 1.02\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.46    Test Loss : 1.05\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.5    Test Loss : 1.08\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.54    Test Loss : 1.1\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 91.54 ***\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.43,    Test Acc : 72.79    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 78.83    Test Loss : 0.73\n",
      "Epoch 30 - Train Acc : 95.0    Train Loss : 0.12,    Test Acc : 80.92    Test Loss : 0.98\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 85.38    Test Loss : 1.41\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.92    Test Loss : 1.87\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 2.31\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 2.63\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.33    Test Loss : 2.82\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 2.93\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.46    Test Loss : 2.95\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.21    Test Loss : 2.99\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.33    Test Loss : 3.01\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 3.04\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 3.06\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 3.08\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 3.1\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 3.12\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 3.14\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.25    Test Loss : 3.16\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 3.18\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 84.17 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 19 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 80.0    Train Loss : 0.51,    Test Acc : 71.88    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 87.5    Train Loss : 0.28,    Test Acc : 78.75    Test Loss : 0.42\n",
      "Epoch 30 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 83.5    Test Loss : 0.48\n",
      "Epoch 40 - Train Acc : 97.5    Train Loss : 0.11,    Test Acc : 83.92    Test Loss : 0.9\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.5    Test Loss : 0.64\n",
      "Epoch 60 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 87.0    Test Loss : 0.71\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.96    Test Loss : 0.71\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 0.73\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 0.75\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 0.79\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 0.83\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 0.84\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 0.86\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.88\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.89\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.91\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.92\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.93\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.94\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.95\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 88.54 ***\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.45,    Test Acc : 73.0    Test Loss : 0.48\n",
      "Epoch 20 - Train Acc : 95.0    Train Loss : 0.2,    Test Acc : 84.88    Test Loss : 0.36\n",
      "Epoch 30 - Train Acc : 96.67    Train Loss : 0.13,    Test Acc : 85.58    Test Loss : 0.56\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 89.88    Test Loss : 0.51\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 0.66\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 0.68\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 0.74\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 0.78\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.88    Test Loss : 0.81\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 0.83\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.0    Test Loss : 0.84\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.92    Test Loss : 0.86\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.88    Test Loss : 0.87\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.88    Test Loss : 0.88\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 0.88\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 0.89\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 0.9\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 0.9\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 0.91\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.71    Test Loss : 0.92\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 89.71 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 20 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (567,),    high arousal : (1953,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 80.83    Train Loss : 0.38,    Test Acc : 75.75    Test Loss : 0.48\n",
      "Epoch 20 - Train Acc : 93.33    Train Loss : 0.15,    Test Acc : 82.42    Test Loss : 0.44\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 86.21    Test Loss : 0.54\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.25    Test Loss : 0.71\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 0.84\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.25    Test Loss : 0.95\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 1.01\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.01\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.02\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.03\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.03\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.46    Test Loss : 1.03\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.42    Test Loss : 1.03\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 1.04\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.04\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.04\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.05\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.05\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.05\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.06\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 89.58 ***\n",
      "Epoch 10 - Train Acc : 92.5    Train Loss : 0.25,    Test Acc : 77.62    Test Loss : 0.54\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.29    Test Loss : 0.71\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.42    Test Loss : 1.1\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.83    Test Loss : 1.38\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 1.79\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 1.89\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.9\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 1.88\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.88\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.87\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 1.87\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.42    Test Loss : 1.87\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.87\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.5    Test Loss : 1.87\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 1.87\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 1.87\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.5    Test Loss : 1.87\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.87\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.87\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.46    Test Loss : 1.87\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 82.46 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 21 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (504,),    high arousal : (2016,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.5,    Test Acc : 68.96    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 88.33    Train Loss : 0.27,    Test Acc : 71.17    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 96.67    Train Loss : 0.15,    Test Acc : 77.08    Test Loss : 0.84\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 82.46    Test Loss : 0.97\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 83.25    Test Loss : 1.3\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.08    Test Loss : 1.56\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.58    Test Loss : 1.78\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 1.9\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.29    Test Loss : 1.98\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 2.02\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.33    Test Loss : 2.05\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.17    Test Loss : 2.08\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.08    Test Loss : 2.11\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.13\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.08    Test Loss : 2.15\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.04    Test Loss : 2.17\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.08    Test Loss : 2.18\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.04    Test Loss : 2.2\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.04    Test Loss : 2.22\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.08    Test Loss : 2.23\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 82.08 ***\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.46,    Test Acc : 68.0    Test Loss : 0.54\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.12,    Test Acc : 86.0    Test Loss : 0.34\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 88.62    Test Loss : 0.36\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.46    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 0.67\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 0.69\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 0.71\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 0.77\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 0.8\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.54    Test Loss : 0.8\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 0.79\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 0.78\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 0.78\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 0.79\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 0.79\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 0.8\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 0.8\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.62    Test Loss : 0.8\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 0.8\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 0.8\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 87.58 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 22 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 80.0    Train Loss : 0.5,    Test Acc : 70.92    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 80.83    Train Loss : 0.41,    Test Acc : 69.21    Test Loss : 0.75\n",
      "Epoch 30 - Train Acc : 83.33    Train Loss : 0.34,    Test Acc : 70.33    Test Loss : 1.05\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.32,    Test Acc : 70.58    Test Loss : 1.33\n",
      "Epoch 50 - Train Acc : 89.17    Train Loss : 0.24,    Test Acc : 73.38    Test Loss : 1.25\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.22,    Test Acc : 74.5    Test Loss : 1.39\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.2,    Test Acc : 75.08    Test Loss : 1.47\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.16,    Test Acc : 75.33    Test Loss : 1.55\n",
      "Epoch 90 - Train Acc : 94.17    Train Loss : 0.13,    Test Acc : 75.29    Test Loss : 1.76\n",
      "Epoch 100 - Train Acc : 94.17    Train Loss : 0.11,    Test Acc : 75.21    Test Loss : 1.95\n",
      "Epoch 110 - Train Acc : 95.0    Train Loss : 0.12,    Test Acc : 75.5    Test Loss : 2.09\n",
      "Epoch 120 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 75.21    Test Loss : 2.19\n",
      "Epoch 130 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 75.58    Test Loss : 2.35\n",
      "Epoch 140 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 75.62    Test Loss : 2.64\n",
      "Epoch 150 - Train Acc : 96.67    Train Loss : 0.06,    Test Acc : 75.71    Test Loss : 2.9\n",
      "Epoch 160 - Train Acc : 93.33    Train Loss : 0.14,    Test Acc : 73.33    Test Loss : 3.2\n",
      "Epoch 170 - Train Acc : 86.67    Train Loss : 0.48,    Test Acc : 71.54    Test Loss : 2.68\n",
      "Epoch 180 - Train Acc : 88.33    Train Loss : 0.24,    Test Acc : 71.83    Test Loss : 1.8\n",
      "Epoch 190 - Train Acc : 94.17    Train Loss : 0.15,    Test Acc : 75.5    Test Loss : 1.37\n",
      "Epoch 200 - Train Acc : 95.0    Train Loss : 0.13,    Test Acc : 75.25    Test Loss : 1.43\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 75.25 ***\n",
      "Epoch 10 - Train Acc : 75.0    Train Loss : 0.53,    Test Acc : 69.38    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 82.5    Train Loss : 0.41,    Test Acc : 68.5    Test Loss : 0.64\n",
      "Epoch 30 - Train Acc : 85.83    Train Loss : 0.32,    Test Acc : 66.96    Test Loss : 0.83\n",
      "Epoch 40 - Train Acc : 87.5    Train Loss : 0.25,    Test Acc : 70.46    Test Loss : 0.83\n",
      "Epoch 50 - Train Acc : 91.67    Train Loss : 0.18,    Test Acc : 73.25    Test Loss : 1.04\n",
      "Epoch 60 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 71.17    Test Loss : 1.38\n",
      "Epoch 70 - Train Acc : 92.5    Train Loss : 0.14,    Test Acc : 72.17    Test Loss : 1.29\n",
      "Epoch 80 - Train Acc : 95.0    Train Loss : 0.12,    Test Acc : 74.88    Test Loss : 1.33\n",
      "Epoch 90 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 76.08    Test Loss : 1.49\n",
      "Epoch 100 - Train Acc : 95.83    Train Loss : 0.09,    Test Acc : 75.46    Test Loss : 1.74\n",
      "Epoch 110 - Train Acc : 94.17    Train Loss : 0.16,    Test Acc : 73.67    Test Loss : 2.03\n",
      "Epoch 120 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 74.71    Test Loss : 2.03\n",
      "Epoch 130 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 75.79    Test Loss : 2.19\n",
      "Epoch 140 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 75.71    Test Loss : 2.33\n",
      "Epoch 150 - Train Acc : 96.67    Train Loss : 0.06,    Test Acc : 75.46    Test Loss : 2.53\n",
      "Epoch 160 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 75.33    Test Loss : 2.73\n",
      "Epoch 170 - Train Acc : 97.5    Train Loss : 0.05,    Test Acc : 75.38    Test Loss : 2.84\n",
      "Epoch 180 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 75.0    Test Loss : 2.99\n",
      "Epoch 190 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 74.79    Test Loss : 3.12\n",
      "Epoch 200 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 74.92    Test Loss : 3.26\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 74.92 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 23 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1701,),    high arousal : (819,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 78.29    Test Loss : 0.49\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 90.92    Test Loss : 0.34\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.5    Test Loss : 0.54\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.46    Test Loss : 0.73\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.5    Test Loss : 0.82\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.17    Test Loss : 0.83\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.79    Test Loss : 0.83\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.67    Test Loss : 0.84\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.67    Test Loss : 0.84\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.84\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.84\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.84\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.84\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.84\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.84\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.84\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.84\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.5    Test Loss : 0.84\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.5    Test Loss : 0.84\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.5    Test Loss : 0.84\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 90.5 ***\n",
      "Epoch 10 - Train Acc : 89.17    Train Loss : 0.21,    Test Acc : 81.42    Test Loss : 0.44\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.17    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.62    Test Loss : 0.89\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.5    Test Loss : 1.01\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 1.15\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.83    Test Loss : 1.2\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 1.2\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 1.18\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.0    Test Loss : 1.17\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 1.17\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 1.17\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.17\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.17\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.17\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.17\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.17\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.17\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.17\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 1.17\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.17\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 90.17 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 24 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.49,    Test Acc : 70.88    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 89.17    Train Loss : 0.25,    Test Acc : 82.12    Test Loss : 0.45\n",
      "Epoch 30 - Train Acc : 91.67    Train Loss : 0.16,    Test Acc : 81.62    Test Loss : 0.49\n",
      "Epoch 40 - Train Acc : 95.0    Train Loss : 0.1,    Test Acc : 83.67    Test Loss : 0.49\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 83.46    Test Loss : 0.56\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.92    Test Loss : 0.7\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 0.92\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 1.06\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.14\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.54    Test Loss : 1.2\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.63    Test Loss : 1.23\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.23\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.25\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 1.26\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.27\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.28\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.28\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.29\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.3\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.31\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 85.79 ***\n",
      "Epoch 10 - Train Acc : 80.0    Train Loss : 0.39,    Test Acc : 75.38    Test Loss : 0.45\n",
      "Epoch 20 - Train Acc : 90.0    Train Loss : 0.2,    Test Acc : 83.38    Test Loss : 0.37\n",
      "Epoch 30 - Train Acc : 94.17    Train Loss : 0.12,    Test Acc : 85.96    Test Loss : 0.48\n",
      "Epoch 40 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 85.38    Test Loss : 0.61\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 83.46    Test Loss : 0.93\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.22\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.38    Test Loss : 1.4\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.21    Test Loss : 1.54\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.0    Test Loss : 1.66\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.08    Test Loss : 1.69\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.04    Test Loss : 1.71\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.0    Test Loss : 1.75\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.08    Test Loss : 1.76\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.78\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.08    Test Loss : 1.79\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.8\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.81\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.83\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.84\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.21    Test Loss : 1.85\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 83.21 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 25 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (630,),    high arousal : (1890,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.48,    Test Acc : 69.25    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 89.17    Train Loss : 0.32,    Test Acc : 73.33    Test Loss : 0.67\n",
      "Epoch 30 - Train Acc : 94.17    Train Loss : 0.17,    Test Acc : 77.71    Test Loss : 0.91\n",
      "Epoch 40 - Train Acc : 94.17    Train Loss : 0.11,    Test Acc : 80.5    Test Loss : 1.13\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 82.75    Test Loss : 1.41\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 83.75    Test Loss : 1.67\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.12    Test Loss : 1.85\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.38    Test Loss : 1.99\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.04    Test Loss : 2.06\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.0    Test Loss : 2.14\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 2.17\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 2.21\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 2.23\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 2.25\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 2.26\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 2.28\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 2.3\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 2.31\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 2.33\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 2.34\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 84.12 ***\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.41,    Test Acc : 69.96    Test Loss : 0.54\n",
      "Epoch 20 - Train Acc : 90.0    Train Loss : 0.24,    Test Acc : 81.88    Test Loss : 0.44\n",
      "Epoch 30 - Train Acc : 95.83    Train Loss : 0.13,    Test Acc : 85.0    Test Loss : 0.4\n",
      "Epoch 40 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 87.33    Test Loss : 0.43\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 87.54    Test Loss : 0.47\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.63,    Test Acc : 74.62    Test Loss : 1.75\n",
      "Epoch 70 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 87.38    Test Loss : 0.43\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 87.96    Test Loss : 0.4\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 89.58    Test Loss : 0.35\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.25    Test Loss : 0.46\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 0.51\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 0.55\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 0.57\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 0.59\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 0.62\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 0.62\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 0.64\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 0.65\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 0.66\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 0.67\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 89.0 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 26 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 81.67    Train Loss : 0.38,    Test Acc : 76.38    Test Loss : 0.51\n",
      "Epoch 20 - Train Acc : 90.0    Train Loss : 0.22,    Test Acc : 82.88    Test Loss : 0.48\n",
      "Epoch 30 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 84.38    Test Loss : 0.53\n",
      "Epoch 40 - Train Acc : 95.0    Train Loss : 0.12,    Test Acc : 85.08    Test Loss : 0.52\n",
      "Epoch 50 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 83.92    Test Loss : 0.6\n",
      "Epoch 60 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 86.0    Test Loss : 0.57\n",
      "Epoch 70 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 85.29    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 85.96    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 86.25    Test Loss : 0.74\n",
      "Epoch 100 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 85.46    Test Loss : 0.55\n",
      "Epoch 110 - Train Acc : 92.5    Train Loss : 0.22,    Test Acc : 77.29    Test Loss : 0.55\n",
      "Epoch 120 - Train Acc : 96.67    Train Loss : 0.1,    Test Acc : 86.0    Test Loss : 0.42\n",
      "Epoch 130 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 86.38    Test Loss : 0.56\n",
      "Epoch 140 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 87.0    Test Loss : 0.54\n",
      "Epoch 150 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 87.29    Test Loss : 0.52\n",
      "Epoch 160 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 87.17    Test Loss : 0.6\n",
      "Epoch 170 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 87.0    Test Loss : 0.69\n",
      "Epoch 180 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 87.04    Test Loss : 0.72\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.04    Test Loss : 0.78\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 0.88\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 87.0 ***\n",
      "Epoch 10 - Train Acc : 72.5    Train Loss : 0.47,    Test Acc : 70.79    Test Loss : 0.54\n",
      "Epoch 20 - Train Acc : 86.67    Train Loss : 0.26,    Test Acc : 78.54    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 90.83    Train Loss : 0.17,    Test Acc : 81.79    Test Loss : 0.52\n",
      "Epoch 40 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 83.21    Test Loss : 0.71\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 85.58    Test Loss : 0.83\n",
      "Epoch 60 - Train Acc : 95.0    Train Loss : 0.11,    Test Acc : 82.46    Test Loss : 1.29\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 85.54    Test Loss : 1.02\n",
      "Epoch 80 - Train Acc : 95.83    Train Loss : 0.06,    Test Acc : 84.83    Test Loss : 0.92\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 85.25    Test Loss : 1.03\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.33    Test Loss : 1.2\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 1.33\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.5    Test Loss : 1.5\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.46    Test Loss : 1.61\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 1.69\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.75\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.81\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.17    Test Loss : 1.86\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.9\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.93\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.97\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 85.04 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 27 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.39,    Test Acc : 84.58    Test Loss : 0.49\n",
      "Epoch 20 - Train Acc : 86.67    Train Loss : 0.34,    Test Acc : 85.54    Test Loss : 0.45\n",
      "Epoch 30 - Train Acc : 86.67    Train Loss : 0.31,    Test Acc : 85.29    Test Loss : 0.41\n",
      "Epoch 40 - Train Acc : 90.83    Train Loss : 0.28,    Test Acc : 83.96    Test Loss : 0.46\n",
      "Epoch 50 - Train Acc : 89.17    Train Loss : 0.24,    Test Acc : 84.88    Test Loss : 0.39\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.21,    Test Acc : 84.88    Test Loss : 0.43\n",
      "Epoch 70 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 70.92    Test Loss : 0.5\n",
      "Epoch 80 - Train Acc : 89.17    Train Loss : 0.25,    Test Acc : 85.12    Test Loss : 0.36\n",
      "Epoch 90 - Train Acc : 89.17    Train Loss : 0.21,    Test Acc : 85.5    Test Loss : 0.37\n",
      "Epoch 100 - Train Acc : 93.33    Train Loss : 0.19,    Test Acc : 78.83    Test Loss : 0.5\n",
      "Epoch 110 - Train Acc : 89.17    Train Loss : 0.22,    Test Acc : 84.71    Test Loss : 0.46\n",
      "Epoch 120 - Train Acc : 89.17    Train Loss : 0.28,    Test Acc : 85.92    Test Loss : 0.35\n",
      "Epoch 130 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 86.0    Test Loss : 0.37\n",
      "Epoch 140 - Train Acc : 90.0    Train Loss : 0.22,    Test Acc : 86.38    Test Loss : 0.38\n",
      "Epoch 150 - Train Acc : 94.17    Train Loss : 0.18,    Test Acc : 86.96    Test Loss : 0.42\n",
      "Epoch 160 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 83.96    Test Loss : 0.47\n",
      "Epoch 170 - Train Acc : 95.0    Train Loss : 0.16,    Test Acc : 79.0    Test Loss : 0.58\n",
      "Epoch 180 - Train Acc : 96.67    Train Loss : 0.14,    Test Acc : 81.38    Test Loss : 0.54\n",
      "Epoch 190 - Train Acc : 96.67    Train Loss : 0.15,    Test Acc : 81.08    Test Loss : 0.54\n",
      "Epoch 200 - Train Acc : 95.83    Train Loss : 0.14,    Test Acc : 85.04    Test Loss : 0.43\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 85.04 ***\n",
      "Epoch 10 - Train Acc : 67.5    Train Loss : 0.52,    Test Acc : 58.04    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 82.5    Train Loss : 0.4,    Test Acc : 72.33    Test Loss : 0.53\n",
      "Epoch 30 - Train Acc : 86.67    Train Loss : 0.33,    Test Acc : 81.29    Test Loss : 0.48\n",
      "Epoch 40 - Train Acc : 90.83    Train Loss : 0.3,    Test Acc : 81.04    Test Loss : 0.54\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.32,    Test Acc : 80.71    Test Loss : 0.57\n",
      "Epoch 60 - Train Acc : 90.0    Train Loss : 0.29,    Test Acc : 80.96    Test Loss : 0.57\n",
      "Epoch 70 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 75.71    Test Loss : 0.65\n",
      "Epoch 80 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 77.5    Test Loss : 0.66\n",
      "Epoch 90 - Train Acc : 86.67    Train Loss : 0.28,    Test Acc : 81.79    Test Loss : 0.62\n",
      "Epoch 100 - Train Acc : 87.5    Train Loss : 0.27,    Test Acc : 81.92    Test Loss : 0.59\n",
      "Epoch 110 - Train Acc : 91.67    Train Loss : 0.22,    Test Acc : 82.0    Test Loss : 0.64\n",
      "Epoch 120 - Train Acc : 85.83    Train Loss : 0.25,    Test Acc : 74.71    Test Loss : 0.77\n",
      "Epoch 130 - Train Acc : 90.0    Train Loss : 0.22,    Test Acc : 79.0    Test Loss : 0.71\n",
      "Epoch 140 - Train Acc : 90.0    Train Loss : 0.21,    Test Acc : 79.75    Test Loss : 0.73\n",
      "Epoch 150 - Train Acc : 92.5    Train Loss : 0.2,    Test Acc : 81.08    Test Loss : 0.74\n",
      "Epoch 160 - Train Acc : 85.0    Train Loss : 0.26,    Test Acc : 72.25    Test Loss : 0.77\n",
      "Epoch 170 - Train Acc : 92.5    Train Loss : 0.19,    Test Acc : 82.92    Test Loss : 0.62\n",
      "Epoch 180 - Train Acc : 92.5    Train Loss : 0.19,    Test Acc : 80.67    Test Loss : 0.71\n",
      "Epoch 190 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 83.79    Test Loss : 0.75\n",
      "Epoch 200 - Train Acc : 90.0    Train Loss : 0.22,    Test Acc : 81.96    Test Loss : 0.82\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 81.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 28 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.42,    Test Acc : 71.42    Test Loss : 0.53\n",
      "Epoch 20 - Train Acc : 91.67    Train Loss : 0.19,    Test Acc : 81.67    Test Loss : 0.46\n",
      "Epoch 30 - Train Acc : 95.0    Train Loss : 0.1,    Test Acc : 81.29    Test Loss : 0.76\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 82.38    Test Loss : 0.96\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.46    Test Loss : 1.25\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.54    Test Loss : 1.51\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.92    Test Loss : 1.62\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.04    Test Loss : 1.68\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.08    Test Loss : 1.72\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.74\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.08    Test Loss : 1.77\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.12    Test Loss : 1.78\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 1.8\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 1.82\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 1.83\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.21    Test Loss : 1.84\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.21    Test Loss : 1.85\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.21    Test Loss : 1.86\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 1.87\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.17    Test Loss : 1.88\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 83.17 ***\n",
      "Epoch 10 - Train Acc : 86.67    Train Loss : 0.42,    Test Acc : 74.54    Test Loss : 0.51\n",
      "Epoch 20 - Train Acc : 91.67    Train Loss : 0.19,    Test Acc : 77.17    Test Loss : 0.72\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 80.67    Test Loss : 0.81\n",
      "Epoch 40 - Train Acc : 98.33    Train Loss : 0.02,    Test Acc : 80.38    Test Loss : 0.94\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 79.88    Test Loss : 1.08\n",
      "Epoch 60 - Train Acc : 99.17    Train Loss : 0.01,    Test Acc : 78.58    Test Loss : 1.29\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 78.29    Test Loss : 1.51\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.67    Test Loss : 1.74\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.54    Test Loss : 1.91\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.46    Test Loss : 2.02\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.29    Test Loss : 2.11\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.25    Test Loss : 2.17\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.38    Test Loss : 2.22\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.33    Test Loss : 2.26\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.42    Test Loss : 2.29\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.42    Test Loss : 2.32\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.38    Test Loss : 2.35\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.42    Test Loss : 2.37\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.38    Test Loss : 2.4\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 77.38    Test Loss : 2.42\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 77.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 29 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 83.33    Train Loss : 0.38,    Test Acc : 80.58    Test Loss : 0.44\n",
      "Epoch 20 - Train Acc : 91.67    Train Loss : 0.19,    Test Acc : 84.79    Test Loss : 0.37\n",
      "Epoch 30 - Train Acc : 94.17    Train Loss : 0.11,    Test Acc : 87.92    Test Loss : 0.35\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 89.62    Test Loss : 0.36\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 89.25    Test Loss : 0.45\n",
      "Epoch 60 - Train Acc : 97.5    Train Loss : 0.04,    Test Acc : 85.29    Test Loss : 0.76\n",
      "Epoch 70 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 90.33    Test Loss : 0.63\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.62    Test Loss : 0.47\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.38    Test Loss : 0.49\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 0.47\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.17    Test Loss : 0.53\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 0.6\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 0.61\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 0.63\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 0.65\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 0.65\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 0.67\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 0.68\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 0.69\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 0.7\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 88.88 ***\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.29,    Test Acc : 80.46    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 94.17    Train Loss : 0.16,    Test Acc : 82.79    Test Loss : 0.78\n",
      "Epoch 30 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 86.25    Test Loss : 0.79\n",
      "Epoch 40 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 86.33    Test Loss : 0.88\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 87.46    Test Loss : 0.91\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.23\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.45\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.61\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.7\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.76\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.79\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.81\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.83\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.85\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.87\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.88\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.9\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.91\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.93\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.94\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 88.08 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 30 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.51,    Test Acc : 69.71    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 80.83    Train Loss : 0.39,    Test Acc : 69.54    Test Loss : 0.66\n",
      "Epoch 30 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 71.96    Test Loss : 0.69\n",
      "Epoch 40 - Train Acc : 86.67    Train Loss : 0.26,    Test Acc : 77.12    Test Loss : 0.67\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.23,    Test Acc : 78.0    Test Loss : 0.68\n",
      "Epoch 60 - Train Acc : 88.33    Train Loss : 0.26,    Test Acc : 78.71    Test Loss : 0.8\n",
      "Epoch 70 - Train Acc : 91.67    Train Loss : 0.18,    Test Acc : 75.25    Test Loss : 0.84\n",
      "Epoch 80 - Train Acc : 94.17    Train Loss : 0.14,    Test Acc : 79.33    Test Loss : 0.91\n",
      "Epoch 90 - Train Acc : 91.67    Train Loss : 0.19,    Test Acc : 74.92    Test Loss : 1.07\n",
      "Epoch 100 - Train Acc : 93.33    Train Loss : 0.12,    Test Acc : 79.79    Test Loss : 1.05\n",
      "Epoch 110 - Train Acc : 94.17    Train Loss : 0.11,    Test Acc : 79.83    Test Loss : 1.2\n",
      "Epoch 120 - Train Acc : 92.5    Train Loss : 0.18,    Test Acc : 75.88    Test Loss : 1.43\n",
      "Epoch 130 - Train Acc : 95.0    Train Loss : 0.1,    Test Acc : 78.17    Test Loss : 1.34\n",
      "Epoch 140 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 80.92    Test Loss : 1.4\n",
      "Epoch 150 - Train Acc : 95.0    Train Loss : 0.1,    Test Acc : 80.71    Test Loss : 1.58\n",
      "Epoch 160 - Train Acc : 94.17    Train Loss : 0.11,    Test Acc : 76.71    Test Loss : 1.81\n",
      "Epoch 170 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 80.79    Test Loss : 1.67\n",
      "Epoch 180 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 80.42    Test Loss : 1.72\n",
      "Epoch 190 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 79.0    Test Loss : 1.97\n",
      "Epoch 200 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 81.17    Test Loss : 2.15\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 81.17 ***\n",
      "Epoch 10 - Train Acc : 70.0    Train Loss : 0.55,    Test Acc : 67.21    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 79.17    Train Loss : 0.43,    Test Acc : 72.04    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 84.17    Train Loss : 0.33,    Test Acc : 77.38    Test Loss : 0.62\n",
      "Epoch 40 - Train Acc : 90.0    Train Loss : 0.3,    Test Acc : 77.92    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 90.0    Train Loss : 0.28,    Test Acc : 79.12    Test Loss : 0.74\n",
      "Epoch 60 - Train Acc : 85.83    Train Loss : 0.27,    Test Acc : 78.67    Test Loss : 0.73\n",
      "Epoch 70 - Train Acc : 86.67    Train Loss : 0.25,    Test Acc : 78.25    Test Loss : 0.76\n",
      "Epoch 80 - Train Acc : 88.33    Train Loss : 0.23,    Test Acc : 79.12    Test Loss : 0.81\n",
      "Epoch 90 - Train Acc : 89.17    Train Loss : 0.2,    Test Acc : 80.25    Test Loss : 0.87\n",
      "Epoch 100 - Train Acc : 91.67    Train Loss : 0.17,    Test Acc : 79.42    Test Loss : 0.97\n",
      "Epoch 110 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 79.12    Test Loss : 1.09\n",
      "Epoch 120 - Train Acc : 93.33    Train Loss : 0.16,    Test Acc : 79.58    Test Loss : 1.24\n",
      "Epoch 130 - Train Acc : 96.67    Train Loss : 0.11,    Test Acc : 80.46    Test Loss : 1.35\n",
      "Epoch 140 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 80.62    Test Loss : 1.47\n",
      "Epoch 150 - Train Acc : 97.5    Train Loss : 0.05,    Test Acc : 79.92    Test Loss : 1.65\n",
      "Epoch 160 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 80.0    Test Loss : 1.78\n",
      "Epoch 170 - Train Acc : 97.5    Train Loss : 0.06,    Test Acc : 79.67    Test Loss : 1.89\n",
      "Epoch 180 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 79.58    Test Loss : 1.95\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 80.17    Test Loss : 2.04\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 81.62    Test Loss : 2.1\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 81.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 31 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 88.33    Train Loss : 0.34,    Test Acc : 85.08    Test Loss : 0.41\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.29    Test Loss : 0.42\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 0.79\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.46    Test Loss : 1.1\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.23\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 1.27\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.28\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.28\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.28\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.27\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.26\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.38    Test Loss : 1.26\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.25\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.25\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.24\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.24\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.24\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.23\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.23\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.22\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 87.88 ***\n",
      "Epoch 10 - Train Acc : 87.5    Train Loss : 0.34,    Test Acc : 74.04    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 84.21    Test Loss : 0.44\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 0.78\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.13\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 1.25\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 1.32\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.35\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.36\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.35\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.35\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.35\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.35\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.35\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.35\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.35\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.34\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.34\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.34\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.34\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.34\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 88.92 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 32 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (756,),    high arousal : (1764,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.42,    Test Acc : 75.79    Test Loss : 0.49\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 86.17    Test Loss : 0.37\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.29    Test Loss : 0.5\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.92    Test Loss : 0.72\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.08    Test Loss : 0.78\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.0    Test Loss : 0.83\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.83    Test Loss : 0.86\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.75    Test Loss : 0.87\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.75    Test Loss : 0.88\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.75    Test Loss : 0.88\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.75    Test Loss : 0.88\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.75    Test Loss : 0.88\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.71    Test Loss : 0.88\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.88\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.88\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.88\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.88\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.89\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.89\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.89\n",
      "directory already exists\n",
      "vlc_PSD_GE is saved successfully\n",
      "*** Best ACC : 90.62 ***\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.43,    Test Acc : 71.25    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.12,    Test Acc : 83.21    Test Loss : 0.47\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 86.04    Test Loss : 0.55\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.42    Test Loss : 1.11\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.35\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.58    Test Loss : 1.47\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 1.58\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.59\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.61\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 1.63\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.64\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.64\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.64\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 1.65\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.65\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 1.65\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.65\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.65\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.65\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.65\n",
      "directory already exists\n",
      "ars_PSD_GE is saved successfully\n",
      "*** Best ACC : 85.83 ***\n",
      "\n",
      "**************** Valence *********************\n",
      "** Best ACC : [82.83, 88.12, 91.54, 79.38, 83.17, 80.0, 88.75, 80.92, 86.08, 80.67, 79.71, 87.25, 87.04, 84.71, 87.21, 88.21, 82.67, 91.54, 88.54, 89.58, 82.08, 75.25, 90.5, 85.79, 84.12, 87.0, 85.04, 83.17, 88.88, 81.17, 87.88, 90.62] **\n",
      " ** Avearge acc : 85.294375,    std : 3.9975710887206253 **\n",
      "\n",
      "**************** Arousal *********************\n",
      "** Best ACC : [84.83, 84.75, 85.79, 75.92, 80.54, 81.54, 87.71, 77.96, 85.25, 71.12, 80.46, 83.33, 90.92, 88.33, 89.5, 85.12, 81.75, 84.17, 89.71, 82.46, 87.58, 74.92, 90.17, 83.21, 89.0, 85.04, 81.96, 77.38, 88.08, 81.62, 88.92, 85.83] **\n",
      " ** Avearge acc : 83.9021875,    std : 4.724399257031919 **\n",
      "\n",
      "directory already exists\n",
      "vlc_PSD_GE_protocol_60_best_acc_list_231016 is saved successfully\n",
      "directory already exists\n",
      "ars_PSD_GE_protocol_60_best_acc_list_231016 is saved successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vlc_best_epoch = []\n",
    "vlc_orig_acc = []\n",
    "vlc_best_acc = []\n",
    "ars_best_epoch = []\n",
    "ars_orig_acc = []\n",
    "ars_best_acc = []\n",
    "for i in range(32):\n",
    "\n",
    "    print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "    sub_idx = 'sub'+str(i+1)\n",
    "    date = '231016'\n",
    "\n",
    "    sub_de = subject_de[i]\n",
    "    sub_psd = subject_psd[i]\n",
    "    sub_label = subject_label[i]\n",
    "    valence_label, arousal_label = deap_label(sub_label)\n",
    "\n",
    "    de, psd, vlc_identifier, ars_identifier = other_preprocessing(sub_de,sub_psd, (valence_label,arousal_label), n_labels_by_class, args.out_channels, args.seed, isdeap=True)\n",
    "\n",
    "    psd = normalization(psd, axis = 0, ntype='standardization')\n",
    "    \n",
    "    print(\"\\nDistance matrix construction start...\")\n",
    "    psd_dm = distance_matrix(psd)\n",
    "    print(\"\\nDistance matrix construction Done...\")\n",
    "\n",
    "    psd_neighbors = kneighbors(psd_dm, args.n_samples, args.psd_k)\n",
    "\n",
    "    psd_ssm, psd_nssm = ssm_construction(psd_dm,psd_neighbors)\n",
    "    \n",
    "    adj = psd_ssm\n",
    "    \n",
    "    feature = psd\n",
    "    \n",
    "    feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "    adj = torch.from_numpy(adj).to(torch.float32).to(device)\n",
    "    \n",
    "    adj = normalize_adj(adj,im)\n",
    "    \n",
    "    ars_label = torch.from_numpy(arousal_label).to(torch.long).to(device)\n",
    "    vlc_label = torch.from_numpy(valence_label).to(torch.long).to(device)\n",
    "\n",
    "    vlc_identifier = torch.from_numpy(vlc_identifier).bool()\n",
    "    vlc_train_identifier = vlc_identifier.to(device)\n",
    "    isunlabeled = ~vlc_identifier\n",
    "    vlc_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "    ars_identifier = torch.from_numpy(ars_identifier).bool()\n",
    "    ars_train_identifier = ars_identifier.to(device)\n",
    "    isunlabeled = ~ars_identifier\n",
    "    ars_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "\n",
    "    encoder = Encoder(args.feature_dimension//2, args.gcn_hid_channels//2, args.gcn_out_channels//2, activation, args.seed, base_model = gcn).to(device)\n",
    "    model = GRACE(encoder, args.feature_dimension//2, args.gcn_out_channels//2, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = encoder_train(feature,adj, vlc_label, vlc_train_identifier, vlc_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'vlc_PSD_GE', sample)\n",
    "    \n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    vlc_best_acc.append(best_acc)\n",
    "    vlc_orig_acc.append(best_acc)\n",
    "    \n",
    "    encoder = Encoder(128, 64, 32, activation, args.seed, base_model = gcn).to(device)\n",
    "    model = GRACE(encoder, 128, 32, 16, args.out_channels, args.ptau).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = encoder_train(feature,adj, ars_label, ars_train_identifier, ars_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'ars_PSD_GE', sample)\n",
    "    \n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    ars_best_acc.append(best_acc)\n",
    "    ars_orig_acc.append(best_acc)\n",
    "\n",
    "\n",
    "print(\"\\n**************** Valence *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(vlc_best_acc, np.mean(vlc_best_acc), np.std(vlc_best_acc)))\n",
    "\n",
    "print(\"**************** Arousal *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(ars_best_acc, np.mean(ars_best_acc), np.std(ars_best_acc)))\n",
    "\n",
    "vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "ars_best_acc_list = np.array(ars_best_acc)\n",
    "\n",
    "save_np(args.tensor_save_path+'ablation2/vlc/', 'vlc_PSD_GE_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, vlc_best_acc_list)\n",
    "save_np(args.tensor_save_path+'ablation2/ars/', 'ars_PSD_GE_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, ars_best_acc_list)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679ab22",
   "metadata": {},
   "source": [
    "##  Ablation 6 - DE+PSD+GE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27c5e065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2967 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 92.5    Train Loss : 0.17,    Test Acc : 81.54    Test Loss : 0.56\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 85.67    Test Loss : 0.56\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 0.81\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 1.05\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 1.11\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.14\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.79    Test Loss : 1.15\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.16\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.16\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.17\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.17\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.17\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.17\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.17\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.17\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.17\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 1.18\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.18\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 1.18\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 1.18\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.17 ***\n",
      "Epoch 10 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 82.33    Test Loss : 0.53\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.04    Test Loss : 0.86\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.27\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.55\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.66\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.69\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.38    Test Loss : 1.7\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.7\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.7\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.7\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.7\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.7\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.7\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.79    Test Loss : 1.7\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.71\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.71\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.71\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.71\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.71\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.71\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 87.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 2 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2880 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 77.5    Train Loss : 0.43,    Test Acc : 69.58    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 80.83    Test Loss : 0.54\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 86.5    Test Loss : 0.74\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.17    Test Loss : 1.01\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.25\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.36\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.46    Test Loss : 1.41\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 1.41\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.41\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 1.41\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.41\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.42\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.42\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.42\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.42\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.42\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.42\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.43\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.43\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 1.43\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.17 ***\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 68.29    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 91.67    Train Loss : 0.19,    Test Acc : 79.79    Test Loss : 0.59\n",
      "Epoch 30 - Train Acc : 97.5    Train Loss : 0.05,    Test Acc : 80.62    Test Loss : 1.05\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.29    Test Loss : 1.47\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.38    Test Loss : 1.65\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 1.79\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 1.75\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.75\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.78\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 1.8\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 1.79\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.79\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.79\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.8\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.8\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.81\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 1.82\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 1.82\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 1.82\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 85.25 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 3 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (2016,),    high arousal : (504,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2899 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 93.33    Train Loss : 0.18,    Test Acc : 86.17    Test Loss : 0.32\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.01,    Test Acc : 90.46    Test Loss : 0.47\n",
      "Epoch 30 - Train Acc : 96.67    Train Loss : 0.24,    Test Acc : 92.46    Test Loss : 0.75\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.83    Test Loss : 0.69\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.04    Test Loss : 0.37\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.38    Test Loss : 0.36\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.5    Test Loss : 0.37\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.38    Test Loss : 0.39\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.33    Test Loss : 0.39\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.38    Test Loss : 0.4\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.33    Test Loss : 0.41\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.33    Test Loss : 0.41\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.42    Test Loss : 0.41\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.42    Test Loss : 0.42\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.42    Test Loss : 0.42\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.42    Test Loss : 0.42\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.38    Test Loss : 0.43\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.38    Test Loss : 0.43\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.38    Test Loss : 0.43\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.42    Test Loss : 0.43\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 93.42 ***\n",
      "Epoch 10 - Train Acc : 95.0    Train Loss : 0.12,    Test Acc : 82.62    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.83    Test Loss : 1.01\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.83    Test Loss : 1.26\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.56\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.42    Test Loss : 1.72\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 1.79\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 1.8\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 1.8\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 1.8\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.79\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.79\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.78\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.78\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.78\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.77\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.77\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.77\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.76\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.76\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.76\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 87.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 4 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1512,),    high valence : (1008,)\n",
      "low arousal : (1512,),    high arousal : (1008,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2922 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 80.83    Train Loss : 0.43,    Test Acc : 73.0    Test Loss : 0.5\n",
      "Epoch 20 - Train Acc : 89.17    Train Loss : 0.25,    Test Acc : 82.58    Test Loss : 0.46\n",
      "Epoch 30 - Train Acc : 91.67    Train Loss : 0.17,    Test Acc : 81.17    Test Loss : 0.44\n",
      "Epoch 40 - Train Acc : 90.0    Train Loss : 0.2,    Test Acc : 79.54    Test Loss : 0.51\n",
      "Epoch 50 - Train Acc : 88.33    Train Loss : 0.23,    Test Acc : 73.67    Test Loss : 1.29\n",
      "Epoch 60 - Train Acc : 92.5    Train Loss : 0.13,    Test Acc : 81.58    Test Loss : 0.88\n",
      "Epoch 70 - Train Acc : 95.0    Train Loss : 0.09,    Test Acc : 82.33    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 84.0    Test Loss : 0.7\n",
      "Epoch 90 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 85.04    Test Loss : 0.79\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 84.67    Test Loss : 0.82\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 0.93\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 0.95\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.38    Test Loss : 0.94\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.62    Test Loss : 0.95\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 0.99\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.02\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.03\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.04\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.04\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.05\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 86.25 ***\n",
      "Epoch 10 - Train Acc : 76.67    Train Loss : 0.48,    Test Acc : 65.46    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 86.67    Train Loss : 0.3,    Test Acc : 77.29    Test Loss : 0.61\n",
      "Epoch 30 - Train Acc : 89.17    Train Loss : 0.25,    Test Acc : 80.04    Test Loss : 0.6\n",
      "Epoch 40 - Train Acc : 94.17    Train Loss : 0.15,    Test Acc : 82.58    Test Loss : 0.64\n",
      "Epoch 50 - Train Acc : 95.0    Train Loss : 0.22,    Test Acc : 80.21    Test Loss : 1.08\n",
      "Epoch 60 - Train Acc : 91.67    Train Loss : 0.2,    Test Acc : 79.25    Test Loss : 0.96\n",
      "Epoch 70 - Train Acc : 93.33    Train Loss : 0.11,    Test Acc : 80.13    Test Loss : 0.73\n",
      "Epoch 80 - Train Acc : 97.5    Train Loss : 0.05,    Test Acc : 83.04    Test Loss : 0.89\n",
      "Epoch 90 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 82.83    Test Loss : 1.11\n",
      "Epoch 100 - Train Acc : 99.17    Train Loss : 0.05,    Test Acc : 84.04    Test Loss : 1.01\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.03,    Test Acc : 84.42    Test Loss : 0.95\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.25    Test Loss : 1.25\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 1.61\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.21    Test Loss : 1.77\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.38    Test Loss : 1.84\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.33    Test Loss : 1.89\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.33    Test Loss : 1.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.33    Test Loss : 1.92\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.29    Test Loss : 1.94\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.25    Test Loss : 1.96\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 83.25 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 5 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1323,),    high arousal : (1197,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2944 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 94.17    Train Loss : 0.23,    Test Acc : 84.04    Test Loss : 0.38\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 90.54    Test Loss : 0.43\n",
      "Epoch 30 - Train Acc : 95.0    Train Loss : 0.1,    Test Acc : 89.42    Test Loss : 0.68\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 91.54    Test Loss : 0.41\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 0.3\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.25    Test Loss : 0.29\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.58    Test Loss : 0.31\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.62    Test Loss : 0.32\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.32\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.96    Test Loss : 0.31\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.0    Test Loss : 0.32\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.92    Test Loss : 0.32\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.96    Test Loss : 0.32\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.0    Test Loss : 0.32\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.96    Test Loss : 0.33\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.0    Test Loss : 0.33\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.0    Test Loss : 0.33\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.0    Test Loss : 0.33\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.0    Test Loss : 0.33\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.0    Test Loss : 0.33\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 94.0 ***\n",
      "Epoch 10 - Train Acc : 80.83    Train Loss : 0.33,    Test Acc : 70.79    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 81.21    Test Loss : 0.72\n",
      "Epoch 30 - Train Acc : 96.67    Train Loss : 0.15,    Test Acc : 80.33    Test Loss : 1.03\n",
      "Epoch 40 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 78.21    Test Loss : 1.39\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 83.62    Test Loss : 1.08\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 1.18\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.92    Test Loss : 1.37\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.25    Test Loss : 1.42\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 1.44\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.71    Test Loss : 1.47\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 1.49\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 1.5\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 1.51\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.75    Test Loss : 1.53\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 1.54\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.75    Test Loss : 1.55\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.71    Test Loss : 1.56\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 1.57\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 1.58\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 1.58\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 83.67 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 6 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2918 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 86.67    Train Loss : 0.31,    Test Acc : 64.79    Test Loss : 0.62\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 83.38    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.83    Test Loss : 1.38\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 1.74\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.93\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.38    Test Loss : 2.03\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 2.07\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.17    Test Loss : 2.08\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.08    Test Loss : 2.09\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.09\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.09\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.1\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.17    Test Loss : 2.1\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.1\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.1\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.1\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.17    Test Loss : 2.1\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.17    Test Loss : 2.1\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 2.1\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.04    Test Loss : 2.1\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 82.04 ***\n",
      "Epoch 10 - Train Acc : 95.0    Train Loss : 0.15,    Test Acc : 78.0    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.08    Test Loss : 1.14\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.38    Test Loss : 2.28\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.04    Test Loss : 2.96\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.12    Test Loss : 3.19\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.25\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 3.27\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 3.28\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.29\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.29\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.3\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.17    Test Loss : 3.3\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.3\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.29\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.29\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.29\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.25    Test Loss : 3.29\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.29\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.21    Test Loss : 3.28\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 82.21 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 7 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (756,),    high valence : (1764,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.4555 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 95.0    Train Loss : 0.18,    Test Acc : 82.12    Test Loss : 0.52\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 0.73\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.21\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.46\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.56\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.61\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.63\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.64\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.64\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.65\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.65\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.65\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.65\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.65\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.65\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.65\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.65\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.65\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.66\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.66\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.04 ***\n",
      "Epoch 10 - Train Acc : 92.5    Train Loss : 0.17,    Test Acc : 80.96    Test Loss : 0.53\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 0.75\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 1.19\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 1.3\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 1.34\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 1.36\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.36\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.37\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.37\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.37\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 87.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 8 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3917 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 90.83    Train Loss : 0.24,    Test Acc : 81.0    Test Loss : 0.68\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 82.17    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.42    Test Loss : 1.06\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 1.68\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 2.09\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 2.11\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 2.17\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 2.21\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 2.22\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.25    Test Loss : 2.22\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 2.22\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 2.21\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 2.21\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 2.2\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 2.2\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 2.2\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 2.19\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 2.19\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.38    Test Loss : 2.19\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 2.19\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 85.33 ***\n",
      "Epoch 10 - Train Acc : 85.0    Train Loss : 0.31,    Test Acc : 76.62    Test Loss : 0.58\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.11,    Test Acc : 81.79    Test Loss : 0.5\n",
      "Epoch 30 - Train Acc : 96.67    Train Loss : 0.06,    Test Acc : 83.38    Test Loss : 0.69\n",
      "Epoch 40 - Train Acc : 90.0    Train Loss : 0.27,    Test Acc : 77.08    Test Loss : 1.26\n",
      "Epoch 50 - Train Acc : 95.83    Train Loss : 0.07,    Test Acc : 86.46    Test Loss : 0.63\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 90.0    Test Loss : 0.57\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 0.69\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 0.74\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.77\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.29    Test Loss : 0.83\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 0.83\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.5    Test Loss : 0.83\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 0.83\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 0.85\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 0.85\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 0.85\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 0.85\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 0.86\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 0.86\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 90.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 9 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2795 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 91.67    Train Loss : 0.25,    Test Acc : 82.0    Test Loss : 0.46\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.54    Test Loss : 0.72\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.44\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.54    Test Loss : 2.0\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.92    Test Loss : 2.26\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.0    Test Loss : 2.34\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.29    Test Loss : 2.36\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.5    Test Loss : 2.37\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.58    Test Loss : 2.37\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.58    Test Loss : 2.37\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.58    Test Loss : 2.37\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 2.37\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 2.36\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 2.36\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 2.36\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 2.36\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 2.36\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 2.36\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 2.36\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 2.36\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 85.75 ***\n",
      "Epoch 10 - Train Acc : 94.17    Train Loss : 0.13,    Test Acc : 86.5    Test Loss : 0.41\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 1.03\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 1.49\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.74\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 1.88\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.95\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.97\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.97\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.98\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.97\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.97\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.97\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.97\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.97\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.97\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.96\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.96\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 1.96\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 1.96\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 1.96\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 89.5 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 10 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1134,),    high arousal : (1386,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2813 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 81.67    Train Loss : 0.34,    Test Acc : 80.88    Test Loss : 0.4\n",
      "Epoch 20 - Train Acc : 94.17    Train Loss : 0.14,    Test Acc : 86.21    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 96.67    Train Loss : 0.09,    Test Acc : 82.21    Test Loss : 0.86\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 84.38    Test Loss : 0.9\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.11\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.19\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.54    Test Loss : 1.22\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.32\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.38    Test Loss : 1.33\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.42    Test Loss : 1.34\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.36\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.37\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.37\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.38\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.38\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.39\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.39\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.4\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.41\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.41\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 87.21 ***\n",
      "Epoch 10 - Train Acc : 85.0    Train Loss : 0.38,    Test Acc : 74.04    Test Loss : 0.73\n",
      "Epoch 20 - Train Acc : 91.67    Train Loss : 0.2,    Test Acc : 76.83    Test Loss : 0.94\n",
      "Epoch 30 - Train Acc : 95.83    Train Loss : 0.09,    Test Acc : 77.83    Test Loss : 1.12\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 79.75    Test Loss : 1.59\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 81.54    Test Loss : 2.09\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.33    Test Loss : 2.41\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.62    Test Loss : 2.7\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 2.81\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.96    Test Loss : 2.77\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.0    Test Loss : 2.8\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.96    Test Loss : 2.85\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.71    Test Loss : 2.87\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 2.87\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.75    Test Loss : 2.87\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 2.87\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.67    Test Loss : 2.87\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.58    Test Loss : 2.88\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.5    Test Loss : 2.89\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 2.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.46    Test Loss : 2.89\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 83.46 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 11 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1008,),    high valence : (1512,)\n",
      "low arousal : (1575,),    high arousal : (945,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.4486 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 74.17    Train Loss : 0.53,    Test Acc : 65.17    Test Loss : 0.66\n",
      "Epoch 20 - Train Acc : 83.33    Train Loss : 0.34,    Test Acc : 71.67    Test Loss : 0.73\n",
      "Epoch 30 - Train Acc : 89.17    Train Loss : 0.18,    Test Acc : 77.92    Test Loss : 0.71\n",
      "Epoch 40 - Train Acc : 97.5    Train Loss : 0.11,    Test Acc : 81.92    Test Loss : 0.8\n",
      "Epoch 50 - Train Acc : 96.67    Train Loss : 0.06,    Test Acc : 83.17    Test Loss : 0.95\n",
      "Epoch 60 - Train Acc : 97.5    Train Loss : 0.03,    Test Acc : 81.21    Test Loss : 1.24\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 82.25    Test Loss : 1.45\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.96    Test Loss : 1.73\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.67    Test Loss : 2.03\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.08    Test Loss : 2.17\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 2.28\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.92    Test Loss : 2.32\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 2.35\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 2.35\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.88    Test Loss : 2.36\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 2.39\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 2.4\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 2.41\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 2.43\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.79    Test Loss : 2.44\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 80.79 ***\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.3,    Test Acc : 76.12    Test Loss : 0.64\n",
      "Epoch 20 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 75.46    Test Loss : 0.58\n",
      "Epoch 30 - Train Acc : 95.0    Train Loss : 0.12,    Test Acc : 79.75    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 84.62    Test Loss : 0.7\n",
      "Epoch 50 - Train Acc : 90.83    Train Loss : 0.28,    Test Acc : 72.46    Test Loss : 2.21\n",
      "Epoch 60 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 84.12    Test Loss : 0.94\n",
      "Epoch 70 - Train Acc : 99.17    Train Loss : 0.06,    Test Acc : 89.92    Test Loss : 0.28\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 86.96    Test Loss : 0.59\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.92    Test Loss : 0.49\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 0.56\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 0.65\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.25    Test Loss : 0.67\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.69\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.71\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.73\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 0.74\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.75\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.76\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 0.77\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.78\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.42 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 12 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.4484 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 93.33    Train Loss : 0.22,    Test Acc : 81.33    Test Loss : 0.45\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.29    Test Loss : 0.74\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 1.21\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.45\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.55\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.6\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.62    Test Loss : 1.62\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.62\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.63\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.63\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.63\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.63\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.63\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.63\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.63\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.63\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.63\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.63\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.63\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.63\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 89.54 ***\n",
      "Epoch 10 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 90.33    Test Loss : 0.32\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.88    Test Loss : 0.24\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.67    Test Loss : 0.45\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.83    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.12    Test Loss : 0.73\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.96    Test Loss : 0.77\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.96    Test Loss : 0.78\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.0    Test Loss : 0.79\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 93.0 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 13 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1386,),    high valence : (1134,)\n",
      "low arousal : (378,),    high arousal : (2142,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3548 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 91.67    Train Loss : 0.16,    Test Acc : 80.92    Test Loss : 0.53\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.71    Test Loss : 1.01\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.77\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.46    Test Loss : 2.24\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.45\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.54\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.57\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.59\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.59\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.6\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.6\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 2.6\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 2.6\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 2.6\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 2.6\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 2.61\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.04    Test Loss : 2.61\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 2.61\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 2.61\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.96    Test Loss : 2.61\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 86.96 ***\n",
      "Epoch 10 - Train Acc : 92.5    Train Loss : 0.16,    Test Acc : 85.92    Test Loss : 0.32\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 0.36\n",
      "Epoch 30 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 92.25    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 89.33    Test Loss : 0.47\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.54    Test Loss : 0.36\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.21    Test Loss : 0.38\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.63    Test Loss : 0.4\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.38    Test Loss : 0.44\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.0    Test Loss : 0.46\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.79    Test Loss : 0.47\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.83    Test Loss : 0.48\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.08    Test Loss : 0.48\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.08    Test Loss : 0.48\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.13    Test Loss : 0.49\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.08    Test Loss : 0.49\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.0    Test Loss : 0.5\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.0    Test Loss : 0.5\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.88    Test Loss : 0.5\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.83    Test Loss : 0.51\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.83    Test Loss : 0.51\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 91.83 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 14 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1961 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.32,    Test Acc : 73.88    Test Loss : 0.67\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 82.79    Test Loss : 1.02\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 2.06\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.44\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 2.55\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 2.6\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.79    Test Loss : 2.62\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 2.63\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.88    Test Loss : 2.64\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.88    Test Loss : 2.64\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 2.64\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 2.64\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.96    Test Loss : 2.65\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 2.65\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 2.65\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 2.65\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.04    Test Loss : 2.65\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 2.65\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.08    Test Loss : 2.65\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 2.65\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 85.12 ***\n",
      "Epoch 10 - Train Acc : 88.33    Train Loss : 0.24,    Test Acc : 78.62    Test Loss : 0.49\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 87.58    Test Loss : 0.52\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 1.06\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.41\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.54    Test Loss : 1.53\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.58\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 1.61\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 1.62\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 1.63\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.83    Test Loss : 1.63\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.92    Test Loss : 1.63\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 1.63\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.63\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.17    Test Loss : 1.62\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.62\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.62\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.29    Test Loss : 1.62\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.46    Test Loss : 1.62\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.62\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 1.62\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 87.58 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 15 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (1197,),    high arousal : (1323,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1959 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 90.83    Train Loss : 0.27,    Test Acc : 80.33    Test Loss : 0.49\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 84.88    Test Loss : 0.71\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.5    Test Loss : 0.92\n",
      "Epoch 40 - Train Acc : 97.5    Train Loss : 0.05,    Test Acc : 89.79    Test Loss : 0.81\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.83    Test Loss : 0.89\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.67    Test Loss : 1.03\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.14\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.67    Test Loss : 1.18\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.54    Test Loss : 1.2\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.21\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 1.22\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.25    Test Loss : 1.23\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.25    Test Loss : 1.24\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.25    Test Loss : 1.25\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.26\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.26\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.27\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.27\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.28\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.29\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 90.17 ***\n",
      "Epoch 10 - Train Acc : 87.5    Train Loss : 0.23,    Test Acc : 81.71    Test Loss : 0.48\n",
      "Epoch 20 - Train Acc : 95.0    Train Loss : 0.14,    Test Acc : 87.12    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 89.96    Test Loss : 0.57\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.83    Test Loss : 0.68\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.74\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.5    Test Loss : 0.77\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.75    Test Loss : 0.78\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.88    Test Loss : 0.79\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.79\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.88    Test Loss : 0.79\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.96    Test Loss : 0.8\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.8\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.8\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.8\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.96    Test Loss : 0.8\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.92    Test Loss : 0.8\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.96    Test Loss : 0.81\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.96    Test Loss : 0.81\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.96    Test Loss : 0.81\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.0    Test Loss : 0.81\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 93.0 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 16 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1575,),    high valence : (945,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1987 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 92.5    Train Loss : 0.27,    Test Acc : 81.17    Test Loss : 0.59\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.42    Test Loss : 0.75\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.63    Test Loss : 1.61\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 2.1\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 2.32\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 2.41\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.04    Test Loss : 2.45\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 2.46\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 2.46\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 2.46\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 2.46\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 2.46\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 2.46\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 2.46\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 2.46\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 2.46\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 2.46\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 2.46\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 2.46\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 2.46\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 86.13 ***\n",
      "Epoch 10 - Train Acc : 94.17    Train Loss : 0.18,    Test Acc : 83.67    Test Loss : 0.39\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 0.72\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 1.43\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.86\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.98\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 2.03\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 2.05\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 2.05\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 2.05\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 2.05\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 2.05\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 2.05\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 2.05\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 2.05\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 2.05\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 2.04\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 2.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 2.04\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 2.04\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 2.04\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 17 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1134,),    high valence : (1386,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1984 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.33,    Test Acc : 71.04    Test Loss : 0.65\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.06,    Test Acc : 84.21    Test Loss : 0.73\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.12\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.28\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 1.32\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 1.38\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 1.41\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 1.42\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 1.42\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 1.43\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 1.44\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.54    Test Loss : 1.44\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 1.45\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 1.46\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 1.46\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 1.47\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 1.47\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 1.48\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 1.48\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 1.49\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.58 ***\n",
      "Epoch 10 - Train Acc : 88.33    Train Loss : 0.28,    Test Acc : 78.67    Test Loss : 0.44\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.05,    Test Acc : 82.62    Test Loss : 0.5\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.17\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.97\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.29    Test Loss : 2.48\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.08    Test Loss : 2.69\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.33    Test Loss : 2.73\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.38    Test Loss : 2.74\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.75\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.75\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.75\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.75\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.75\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.75\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.75\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.75\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.75\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.5    Test Loss : 2.75\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.54    Test Loss : 2.75\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.54    Test Loss : 2.75\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 84.54 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 18 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1948 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 89.17    Train Loss : 0.23,    Test Acc : 83.08    Test Loss : 0.42\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.08,    Test Acc : 89.58    Test Loss : 0.5\n",
      "Epoch 30 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 90.17    Test Loss : 0.7\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.83    Test Loss : 0.91\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.5    Test Loss : 1.05\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 1.1\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.83    Test Loss : 1.11\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.08    Test Loss : 1.13\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 1.14\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 1.14\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.29    Test Loss : 1.14\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.38    Test Loss : 1.14\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.38    Test Loss : 1.14\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.14\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.14\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.14\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.5    Test Loss : 1.15\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.46    Test Loss : 1.15\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.46    Test Loss : 1.15\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.5    Test Loss : 1.15\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 92.5 ***\n",
      "Epoch 10 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 77.21    Test Loss : 0.78\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.08,    Test Acc : 83.92    Test Loss : 1.24\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.0    Test Loss : 1.6\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 1.93\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 2.3\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 2.44\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 2.5\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 2.52\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 2.54\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 2.54\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 2.54\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 2.54\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 2.55\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 2.55\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.71    Test Loss : 2.55\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 2.56\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 2.56\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 2.57\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 2.57\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 2.58\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.62 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 19 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.1952 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.36,    Test Acc : 79.21    Test Loss : 0.43\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 87.67    Test Loss : 0.32\n",
      "Epoch 30 - Train Acc : 98.33    Train Loss : 0.08,    Test Acc : 86.04    Test Loss : 0.72\n",
      "Epoch 40 - Train Acc : 96.67    Train Loss : 0.07,    Test Acc : 87.42    Test Loss : 0.71\n",
      "Epoch 50 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 92.04    Test Loss : 0.3\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.46    Test Loss : 0.3\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.75    Test Loss : 0.3\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.71    Test Loss : 0.33\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.67    Test Loss : 0.36\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.83    Test Loss : 0.36\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.88    Test Loss : 0.36\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.17    Test Loss : 0.36\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.13    Test Loss : 0.37\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.13    Test Loss : 0.37\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.08    Test Loss : 0.37\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.13    Test Loss : 0.37\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.13    Test Loss : 0.37\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.21    Test Loss : 0.38\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 0.38\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 0.38\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 92.25 ***\n",
      "Epoch 10 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 79.12    Test Loss : 0.41\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 92.0    Test Loss : 0.22\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.46    Test Loss : 0.4\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.83    Test Loss : 0.2\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.79    Test Loss : 0.28\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.92    Test Loss : 0.31\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.0    Test Loss : 0.33\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.92    Test Loss : 0.34\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.83    Test Loss : 0.34\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.83    Test Loss : 0.35\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.83    Test Loss : 0.35\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.83    Test Loss : 0.35\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.35\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.35\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.35\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.35\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.79    Test Loss : 0.35\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.79    Test Loss : 0.35\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.83    Test Loss : 0.35\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.35\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 93.75 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 20 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (567,),    high arousal : (1953,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2710 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 93.33    Train Loss : 0.17,    Test Acc : 85.21    Test Loss : 0.32\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.01,    Test Acc : 92.0    Test Loss : 0.45\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 94.04    Test Loss : 0.5\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.92    Test Loss : 0.72\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.92    Test Loss : 0.76\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.75    Test Loss : 0.77\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.71    Test Loss : 0.77\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.58    Test Loss : 0.77\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.77\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.77\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.62    Test Loss : 0.77\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.62    Test Loss : 0.77\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.62    Test Loss : 0.77\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.77\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.77\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.77\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.77\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.77\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.77\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 93.67    Test Loss : 0.77\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 93.67 ***\n",
      "Epoch 10 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 86.29    Test Loss : 0.37\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 1.1\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.01,    Test Acc : 90.83    Test Loss : 1.02\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.88    Test Loss : 0.75\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.88    Test Loss : 0.56\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.29    Test Loss : 0.78\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.66\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.96    Test Loss : 0.64\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.0    Test Loss : 0.63\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.17    Test Loss : 0.62\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.21    Test Loss : 0.62\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.21    Test Loss : 0.62\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.17    Test Loss : 0.61\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.17    Test Loss : 0.61\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.17    Test Loss : 0.61\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.17    Test Loss : 0.61\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.17    Test Loss : 0.61\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.21    Test Loss : 0.6\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 0.6\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.25    Test Loss : 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 92.25 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 21 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (504,),    high arousal : (2016,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2689 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 82.5    Train Loss : 0.39,    Test Acc : 70.33    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.12,    Test Acc : 83.0    Test Loss : 0.49\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.12    Test Loss : 0.71\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 1.06\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.16\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 1.3\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.34\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.63    Test Loss : 1.31\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.5    Test Loss : 1.29\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 1.27\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 1.27\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.26\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.04    Test Loss : 1.26\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.25\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.04    Test Loss : 1.25\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.25\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 1.25\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 1.25\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 1.25\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.17    Test Loss : 1.24\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 86.17 ***\n",
      "Epoch 10 - Train Acc : 92.5    Train Loss : 0.2,    Test Acc : 87.62    Test Loss : 0.29\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 91.5    Test Loss : 0.24\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.83    Test Loss : 0.48\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.71    Test Loss : 0.61\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.46    Test Loss : 0.67\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.0    Test Loss : 0.65\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.21    Test Loss : 0.65\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 0.65\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.65\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.33    Test Loss : 0.65\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.17    Test Loss : 0.66\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.17    Test Loss : 0.66\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.12    Test Loss : 0.66\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.12    Test Loss : 0.66\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.12    Test Loss : 0.66\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.12    Test Loss : 0.66\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.21    Test Loss : 0.66\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.21    Test Loss : 0.66\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.17    Test Loss : 0.66\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.17    Test Loss : 0.66\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 91.17 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 22 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (945,),    high arousal : (1575,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2714 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 79.17    Train Loss : 0.45,    Test Acc : 71.88    Test Loss : 0.6\n",
      "Epoch 20 - Train Acc : 85.0    Train Loss : 0.32,    Test Acc : 73.83    Test Loss : 0.7\n",
      "Epoch 30 - Train Acc : 91.67    Train Loss : 0.21,    Test Acc : 77.83    Test Loss : 0.9\n",
      "Epoch 40 - Train Acc : 94.17    Train Loss : 0.14,    Test Acc : 79.08    Test Loss : 0.86\n",
      "Epoch 50 - Train Acc : 95.83    Train Loss : 0.12,    Test Acc : 78.83    Test Loss : 1.1\n",
      "Epoch 60 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 82.25    Test Loss : 1.09\n",
      "Epoch 70 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 83.54    Test Loss : 1.12\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 84.12    Test Loss : 1.29\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.58    Test Loss : 1.54\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.88    Test Loss : 1.57\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.79    Test Loss : 1.59\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.67    Test Loss : 1.66\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.88    Test Loss : 1.65\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.88    Test Loss : 1.67\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.83    Test Loss : 1.68\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.79    Test Loss : 1.69\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.75    Test Loss : 1.7\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.79    Test Loss : 1.71\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.88    Test Loss : 1.72\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.88    Test Loss : 1.72\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 84.88 ***\n",
      "Epoch 10 - Train Acc : 78.33    Train Loss : 0.44,    Test Acc : 67.63    Test Loss : 0.61\n",
      "Epoch 20 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 73.38    Test Loss : 0.6\n",
      "Epoch 30 - Train Acc : 94.17    Train Loss : 0.12,    Test Acc : 79.79    Test Loss : 0.8\n",
      "Epoch 40 - Train Acc : 93.33    Train Loss : 0.18,    Test Acc : 73.29    Test Loss : 1.02\n",
      "Epoch 50 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 78.12    Test Loss : 0.79\n",
      "Epoch 60 - Train Acc : 98.33    Train Loss : 0.06,    Test Acc : 78.75    Test Loss : 0.91\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 79.79    Test Loss : 1.14\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 80.29    Test Loss : 1.32\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 79.96    Test Loss : 1.6\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.96    Test Loss : 1.71\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.17    Test Loss : 1.78\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.12    Test Loss : 1.84\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.25    Test Loss : 1.9\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.04    Test Loss : 1.94\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.04    Test Loss : 1.98\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 81.04    Test Loss : 2.01\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.88    Test Loss : 2.04\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.83    Test Loss : 2.06\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.88    Test Loss : 2.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 80.83    Test Loss : 2.11\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 80.83 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 23 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1701,),    high arousal : (819,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2715 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 97.5    Train Loss : 0.12,    Test Acc : 86.71    Test Loss : 0.45\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 91.83    Test Loss : 0.3\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.29    Test Loss : 0.49\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.29    Test Loss : 0.63\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.88    Test Loss : 0.72\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.67    Test Loss : 0.76\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.67    Test Loss : 0.77\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.78\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.78\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.78\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.78\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.77\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.77\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.77\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.77\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.77\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.77\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.77\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.63    Test Loss : 0.77\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.71    Test Loss : 0.77\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 91.71 ***\n",
      "Epoch 10 - Train Acc : 98.33    Train Loss : 0.07,    Test Acc : 87.54    Test Loss : 0.32\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.21    Test Loss : 0.85\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.71    Test Loss : 0.92\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.67    Test Loss : 0.96\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.63    Test Loss : 0.98\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.58    Test Loss : 0.99\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.46    Test Loss : 1.0\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.0\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.38    Test Loss : 1.01\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.38    Test Loss : 1.01\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.38    Test Loss : 1.01\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.01\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.01\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.01\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.01\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.01\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.01\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.01\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.42    Test Loss : 1.01\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 92.42 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 24 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (441,),    high arousal : (2079,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2697 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.34,    Test Acc : 77.88    Test Loss : 0.52\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.14,    Test Acc : 86.21    Test Loss : 0.36\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 87.96    Test Loss : 0.42\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 0.55\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.0    Test Loss : 0.79\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 0.74\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.72\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.67    Test Loss : 0.72\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.62    Test Loss : 0.73\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.58    Test Loss : 0.74\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.74\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 0.75\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 0.75\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.46    Test Loss : 0.76\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.76\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.5    Test Loss : 0.76\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.76\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.77\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.77\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.38    Test Loss : 0.77\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.38 ***\n",
      "Epoch 10 - Train Acc : 91.67    Train Loss : 0.2,    Test Acc : 76.75    Test Loss : 0.48\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.05,    Test Acc : 86.96    Test Loss : 0.45\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.58    Test Loss : 0.81\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.75    Test Loss : 1.08\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.54    Test Loss : 1.25\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 1.28\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.67    Test Loss : 1.31\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.28\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.28\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.28\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.28\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.28\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.28\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.27\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.27\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.27\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.27\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.04    Test Loss : 1.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.12    Test Loss : 1.27\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.27\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.08 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 25 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1197,),    high valence : (1323,)\n",
      "low arousal : (630,),    high arousal : (1890,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2707 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 86.67    Train Loss : 0.36,    Test Acc : 73.04    Test Loss : 0.63\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.12,    Test Acc : 80.17    Test Loss : 0.79\n",
      "Epoch 30 - Train Acc : 97.5    Train Loss : 0.1,    Test Acc : 82.0    Test Loss : 1.15\n",
      "Epoch 40 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 84.12    Test Loss : 1.22\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 85.25    Test Loss : 1.52\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.56\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.13    Test Loss : 1.72\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 1.82\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 1.87\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.85\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.92    Test Loss : 1.85\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.87\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.92    Test Loss : 1.88\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.92    Test Loss : 1.89\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 1.9\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.9\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.79    Test Loss : 1.91\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.75    Test Loss : 1.92\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.92\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.71    Test Loss : 1.93\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 85.71 ***\n",
      "Epoch 10 - Train Acc : 85.83    Train Loss : 0.29,    Test Acc : 78.5    Test Loss : 0.45\n",
      "Epoch 20 - Train Acc : 95.0    Train Loss : 0.12,    Test Acc : 85.25    Test Loss : 0.3\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 88.12    Test Loss : 0.42\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 0.53\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.0    Test Loss : 0.39\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.67    Test Loss : 0.58\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.92    Test Loss : 0.58\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.62    Test Loss : 0.54\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.75    Test Loss : 0.52\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.79    Test Loss : 0.53\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.71    Test Loss : 0.53\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.71    Test Loss : 0.54\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.58    Test Loss : 0.55\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.5    Test Loss : 0.56\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 0.56\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 0.57\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 0.57\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 0.58\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 0.58\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.29    Test Loss : 0.58\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 90.29 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 26 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1449,),    high arousal : (1071,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2713 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 89.17    Train Loss : 0.26,    Test Acc : 81.12    Test Loss : 0.45\n",
      "Epoch 20 - Train Acc : 96.67    Train Loss : 0.08,    Test Acc : 86.21    Test Loss : 0.44\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.62    Test Loss : 0.8\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.21    Test Loss : 1.19\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.5    Test Loss : 1.41\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.54    Test Loss : 1.62\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.33    Test Loss : 1.71\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.74\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.74\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.54    Test Loss : 1.74\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.54    Test Loss : 1.73\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.67    Test Loss : 1.72\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.72\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.71\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.71\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.71    Test Loss : 1.71\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 1.71\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 1.71\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.83    Test Loss : 1.71\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.83    Test Loss : 1.71\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 86.83 ***\n",
      "Epoch 10 - Train Acc : 90.83    Train Loss : 0.26,    Test Acc : 79.79    Test Loss : 0.45\n",
      "Epoch 20 - Train Acc : 98.33    Train Loss : 0.04,    Test Acc : 86.13    Test Loss : 0.56\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.42    Test Loss : 0.87\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.29    Test Loss : 1.16\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.75    Test Loss : 1.31\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.37\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.17    Test Loss : 1.4\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 1.41\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.41\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.41\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.41\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 1.41\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 1.41\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.41\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.41\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.42\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.42\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.42\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.92    Test Loss : 1.42\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.92 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 27 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (630,),    high valence : (1890,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2684 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 93.33    Train Loss : 0.25,    Test Acc : 78.5    Test Loss : 0.55\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 84.5    Test Loss : 0.48\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.29    Test Loss : 0.65\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.21    Test Loss : 0.99\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.25    Test Loss : 1.2\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 1.29\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.96    Test Loss : 1.32\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.71    Test Loss : 1.34\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 1.34\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.83    Test Loss : 1.34\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.34\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 1.34\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 1.34\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.34\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.34\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.34\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.79    Test Loss : 1.34\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.34\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.34\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.75    Test Loss : 1.34\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 89.75 ***\n",
      "Epoch 10 - Train Acc : 87.5    Train Loss : 0.31,    Test Acc : 76.75    Test Loss : 0.51\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 84.67    Test Loss : 0.54\n",
      "Epoch 30 - Train Acc : 98.33    Train Loss : 0.03,    Test Acc : 87.62    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.79    Test Loss : 1.13\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.14\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 0.91\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.83    Test Loss : 0.95\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.42    Test Loss : 1.05\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.11\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 1.13\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 1.14\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.83    Test Loss : 1.15\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.15\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.15\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.79    Test Loss : 1.15\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.15\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.15\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.15\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.88    Test Loss : 1.16\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.16\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 88.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 28 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (945,),    high valence : (1575,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2725 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 90.0    Train Loss : 0.27,    Test Acc : 76.67    Test Loss : 0.57\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.09,    Test Acc : 85.67    Test Loss : 0.43\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 86.71    Test Loss : 0.67\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.58    Test Loss : 1.09\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.25\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.34\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.39\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.04    Test Loss : 1.4\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.0    Test Loss : 1.39\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.38\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 1.38\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.21    Test Loss : 1.38\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.38\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.38\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.25    Test Loss : 1.38\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.39\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.39\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.39\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.39\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.29    Test Loss : 1.39\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 86.29 ***\n",
      "Epoch 10 - Train Acc : 85.0    Train Loss : 0.35,    Test Acc : 77.04    Test Loss : 0.51\n",
      "Epoch 20 - Train Acc : 97.5    Train Loss : 0.07,    Test Acc : 81.08    Test Loss : 0.65\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 82.83    Test Loss : 1.03\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.0    Test Loss : 1.45\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.29    Test Loss : 1.74\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.96    Test Loss : 1.79\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.08    Test Loss : 1.83\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 1.85\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.79    Test Loss : 1.86\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.92    Test Loss : 1.86\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.04    Test Loss : 1.86\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.12    Test Loss : 1.86\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.17    Test Loss : 1.86\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.08    Test Loss : 1.86\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 84.0    Test Loss : 1.86\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.96    Test Loss : 1.86\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.96    Test Loss : 1.86\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.96    Test Loss : 1.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.92    Test Loss : 1.86\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 83.92    Test Loss : 1.86\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 83.92 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 29 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1071,),    high valence : (1449,)\n",
      "low arousal : (819,),    high arousal : (1701,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2692 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 92.5    Train Loss : 0.23,    Test Acc : 84.08    Test Loss : 0.36\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.67    Test Loss : 0.62\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.2\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.08    Test Loss : 1.48\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.59\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.33    Test Loss : 1.63\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.65\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.66\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.66\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.58    Test Loss : 1.67\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 89.58 ***\n",
      "Epoch 10 - Train Acc : 94.17    Train Loss : 0.15,    Test Acc : 86.54    Test Loss : 0.44\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.02,    Test Acc : 88.29    Test Loss : 0.73\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.29    Test Loss : 1.03\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.21\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.36\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 1.43\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.25    Test Loss : 1.46\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 1.47\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.48\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.47\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.47\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.21    Test Loss : 1.47\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.21    Test Loss : 1.47\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.46\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.46\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.46\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.46\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.46\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.46\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.46\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 90.12 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 30 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (819,),    high valence : (1701,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2676 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 84.17    Train Loss : 0.36,    Test Acc : 74.92    Test Loss : 0.5\n",
      "Epoch 20 - Train Acc : 89.17    Train Loss : 0.21,    Test Acc : 81.0    Test Loss : 0.5\n",
      "Epoch 30 - Train Acc : 94.17    Train Loss : 0.09,    Test Acc : 83.12    Test Loss : 0.58\n",
      "Epoch 40 - Train Acc : 99.17    Train Loss : 0.02,    Test Acc : 84.92    Test Loss : 0.91\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.33    Test Loss : 1.18\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.21    Test Loss : 1.4\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.04    Test Loss : 1.48\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.67    Test Loss : 1.54\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.08    Test Loss : 1.57\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.59\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.6\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.92    Test Loss : 1.62\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 1.63\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.83    Test Loss : 1.63\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 1.64\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.96    Test Loss : 1.65\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.92    Test Loss : 1.65\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 1.66\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.88    Test Loss : 1.67\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 85.92    Test Loss : 1.67\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 85.92 ***\n",
      "Epoch 10 - Train Acc : 87.5    Train Loss : 0.33,    Test Acc : 78.38    Test Loss : 0.47\n",
      "Epoch 20 - Train Acc : 95.83    Train Loss : 0.1,    Test Acc : 86.54    Test Loss : 0.46\n",
      "Epoch 30 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 86.96    Test Loss : 0.64\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 87.67    Test Loss : 0.89\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.1\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.0    Test Loss : 1.24\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.25\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.08    Test Loss : 1.31\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.33\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.34\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.35\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.88    Test Loss : 1.35\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.36\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.92    Test Loss : 1.37\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.37\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.38\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.38\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.39\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.96    Test Loss : 1.4\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 87.96 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 31 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (882,),    high valence : (1638,)\n",
      "low arousal : (1260,),    high arousal : (1260,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2719 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 99.17    Train Loss : 0.04,    Test Acc : 90.08    Test Loss : 0.29\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.17    Test Loss : 1.1\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.54    Test Loss : 1.47\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.12    Test Loss : 1.75\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 1.88\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 88.96    Test Loss : 1.94\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 1.96\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.0    Test Loss : 1.97\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.97\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.97\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.97\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.97\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.98\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.98\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.98\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.98\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.98\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.98\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.98\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 89.04    Test Loss : 1.98\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 89.04 ***\n",
      "Epoch 10 - Train Acc : 95.83    Train Loss : 0.14,    Test Acc : 84.25    Test Loss : 0.41\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.71    Test Loss : 0.86\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.42    Test Loss : 1.41\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.75    Test Loss : 1.7\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 86.79    Test Loss : 1.82\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.08    Test Loss : 1.87\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.88\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.88\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.12    Test Loss : 1.88\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.87\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.25    Test Loss : 1.87\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.87\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.86\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.86\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.86\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.33    Test Loss : 1.86\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.38    Test Loss : 1.86\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.38    Test Loss : 1.85\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.38    Test Loss : 1.85\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 87.38    Test Loss : 1.85\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 87.38 ***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 32 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1260,),    high valence : (1260,)\n",
      "low arousal : (756,),    high arousal : (1764,)\n",
      "\n",
      "Distance matrix construction start...\n",
      "\n",
      "Distance matrix construction Done...\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2781 sec\n",
      "Done\n",
      "**********************************************\n",
      "Epoch 10 - Train Acc : 95.83    Train Loss : 0.15,    Test Acc : 85.33    Test Loss : 0.36\n",
      "Epoch 20 - Train Acc : 100.0    Train Loss : 0.01,    Test Acc : 88.46    Test Loss : 0.81\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.42    Test Loss : 0.86\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.83    Test Loss : 1.1\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.21\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.29    Test Loss : 1.26\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.04    Test Loss : 1.28\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 1.28\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.08    Test Loss : 1.28\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.28\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.28\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.28\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.28\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.28\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.28\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.28\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.28\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.27\n",
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.17    Test Loss : 1.27\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.27\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 90.12 ***\n",
      "Epoch 10 - Train Acc : 95.83    Train Loss : 0.14,    Test Acc : 82.08    Test Loss : 0.44\n",
      "Epoch 20 - Train Acc : 99.17    Train Loss : 0.03,    Test Acc : 88.58    Test Loss : 0.51\n",
      "Epoch 30 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 92.04    Test Loss : 0.78\n",
      "Epoch 40 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 91.38    Test Loss : 1.03\n",
      "Epoch 50 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.2\n",
      "Epoch 60 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.12    Test Loss : 1.27\n",
      "Epoch 70 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.25    Test Loss : 1.28\n",
      "Epoch 80 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.29    Test Loss : 1.28\n",
      "Epoch 90 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 1.28\n",
      "Epoch 100 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 1.28\n",
      "Epoch 110 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.33    Test Loss : 1.27\n",
      "Epoch 120 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 1.27\n",
      "Epoch 130 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 1.27\n",
      "Epoch 140 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.27\n",
      "Epoch 150 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.27\n",
      "Epoch 160 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.27\n",
      "Epoch 170 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.27\n",
      "Epoch 180 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.38    Test Loss : 1.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.27\n",
      "Epoch 200 - Train Acc : 100.0    Train Loss : 0.0,    Test Acc : 90.42    Test Loss : 1.27\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE is saved successfully\n",
      "*** Best ACC : 90.42 ***\n",
      "\n",
      "**************** Valence *********************\n",
      "** Best ACC : [88.17, 88.17, 93.42, 86.25, 94.0, 82.04, 88.04, 85.33, 85.75, 87.21, 80.79, 89.54, 86.96, 85.12, 90.17, 86.13, 88.58, 92.5, 92.25, 93.67, 86.17, 84.88, 91.71, 88.38, 85.71, 86.83, 89.75, 86.29, 89.58, 85.92, 89.04, 90.12] **\n",
      " ** Avearge acc : 88.07718750000001,    std : 3.1193461197571115 **\n",
      "\n",
      "**************** Arousal *********************\n",
      "** Best ACC : [87.96, 85.25, 87.75, 83.25, 83.67, 82.21, 87.29, 90.38, 89.5, 83.46, 88.42, 93.0, 91.83, 87.58, 93.0, 88.96, 84.54, 88.62, 93.75, 92.25, 91.17, 80.83, 92.42, 88.08, 90.29, 88.92, 88.96, 83.92, 90.12, 87.96, 87.38, 90.42] **\n",
      " ** Avearge acc : 88.22312500000001,    std : 3.3294110191406237 **\n",
      "\n",
      "directory already exists\n",
      "vlc_DE_PSD_SNF_GE_protocol_60_best_acc_list_231016 is saved successfully\n",
      "directory already exists\n",
      "ars_DE_PSD_SNF_GE_protocol_60_best_acc_list_231016 is saved successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vlc_best_epoch = []\n",
    "vlc_orig_acc = []\n",
    "vlc_best_acc = []\n",
    "ars_best_epoch = []\n",
    "ars_orig_acc = []\n",
    "ars_best_acc = []\n",
    "for i in range(32):\n",
    "\n",
    "    print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "    sub_idx = 'sub'+str(i+1)\n",
    "    date = '231016'\n",
    "\n",
    "    sub_de = subject_de[i]\n",
    "    sub_psd = subject_psd[i]\n",
    "    sub_label = subject_label[i]\n",
    "    valence_label, arousal_label = deap_label(sub_label)\n",
    "\n",
    "    de, psd, vlc_identifier, ars_identifier = other_preprocessing(sub_de,sub_psd, (valence_label,arousal_label), n_labels_by_class, args.out_channels, args.seed, isdeap=True)\n",
    "\n",
    "    de = normalization(de, axis = 0, ntype='standardization')\n",
    "    psd = normalization(psd, axis=0, ntype='standardization')\n",
    "    \n",
    "    print(\"\\nDistance matrix construction start...\")\n",
    "    de_dm = distance_matrix(de)\n",
    "    psd_dm = distance_matrix(psd)\n",
    "    print(\"\\nDistance matrix construction Done...\")\n",
    "\n",
    "    de_neighbors = kneighbors(de_dm, args.n_samples, args.de_k)\n",
    "    psd_neighbors = kneighbors(psd_dm, args.n_samples, args.psd_k)\n",
    "\n",
    "    de_ssm, de_nssm = ssm_construction(de_dm,de_neighbors)\n",
    "    psd_ssm, psd_nssm = ssm_construction(psd_dm,psd_neighbors)\n",
    "    \n",
    "    fsm = ssm_fusion(de_ssm,psd_ssm, de_nssm, psd_nssm, args.k1, args.t1)\n",
    "    \n",
    "    adj = fsm\n",
    "\n",
    "    feature = input_feature(de,psd)\n",
    "    \n",
    "    feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "    adj = torch.from_numpy(adj).to(torch.float32).to(device)\n",
    "    \n",
    "    adj = normalize_adj(adj,im)\n",
    "    \n",
    "    \n",
    "    ars_label = torch.from_numpy(arousal_label).to(torch.long).to(device)\n",
    "    vlc_label = torch.from_numpy(valence_label).to(torch.long).to(device)\n",
    "\n",
    "    vlc_identifier = torch.from_numpy(vlc_identifier).bool()\n",
    "    vlc_train_identifier = vlc_identifier.to(device)\n",
    "    isunlabeled = ~vlc_identifier\n",
    "    vlc_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "    ars_identifier = torch.from_numpy(ars_identifier).bool()\n",
    "    ars_train_identifier = ars_identifier.to(device)\n",
    "    isunlabeled = ~ars_identifier\n",
    "    ars_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "\n",
    "    encoder = Encoder(args.feature_dimension, args.gcn_hid_channels, args.gcn_out_channels, activation, args.seed, base_model = gcn).to(device)\n",
    "    model = GRACE(encoder, args.feature_dimension, args.gcn_out_channels, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = encoder_train(feature,adj, vlc_label, vlc_train_identifier, vlc_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'vlc_DE_PSD_SNF_GE', sample)\n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    vlc_best_acc.append(best_acc)\n",
    "    vlc_orig_acc.append(best_acc)\n",
    "    \n",
    "    encoder = Encoder(args.feature_dimension, args.gcn_hid_channels, args.gcn_out_channels, activation, args.seed, base_model = gcn).to(device)\n",
    "    model = GRACE(encoder, args.feature_dimension, args.gcn_out_channels, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = compare_args.learning_rate)\n",
    "    best_acc, graph = encoder_train(feature,adj, ars_label, ars_train_identifier, ars_test_identifier, model, optimizer, compare_args.epochs)\n",
    "\n",
    "    sample = graph.cpu().detach().numpy().copy()\n",
    "\n",
    "#     drmodel = TSNE(n_components = 2, perplexity=50, n_iter_without_progress = 4000)\n",
    "#     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "#     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "#     save_scatter(dr_result, label, best_acc,sub_idx, date, args.figure_save_path, visualization_type, train_identifier)\n",
    "    \n",
    "    save_np(args.tensor_save_path+'/ablation3/'+sub_idx,'ars_DE_PSD_SNF_GE', sample)\n",
    "    \n",
    "    print(\"*** Best ACC : {} ***\".format(best_acc))\n",
    "    ars_best_acc.append(best_acc)\n",
    "    ars_orig_acc.append(best_acc)\n",
    "\n",
    "\n",
    "print(\"\\n**************** Valence *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(vlc_best_acc, np.mean(vlc_best_acc), np.std(vlc_best_acc)))\n",
    "\n",
    "print(\"**************** Arousal *********************\")\n",
    "print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(ars_best_acc, np.mean(ars_best_acc), np.std(ars_best_acc)))\n",
    "\n",
    "vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "ars_best_acc_list = np.array(ars_best_acc)\n",
    "\n",
    "save_np(args.tensor_save_path+'ablation2/vlc/', 'vlc_DE_PSD_SNF_GE_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, vlc_best_acc_list)\n",
    "save_np(args.tensor_save_path+'ablation2/ars/', 'ars_DE_PSD_SNF_GE_protocol_'+str(n_labels_by_class)+'_best_acc_list_'+date, ars_best_acc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806539ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df52a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4127e999",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8844e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 2\n",
      "Count of using GPUs: 3\n",
      "+++++++++++++++++++++++++++ Pe: 0.1, Pf:0.1 +++++++++++++++++++++++++++++++++++\n",
      "========================================== DEAP Protocol 120 ==========================================\n",
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "************* The number of samples by class ***********\n",
      "Threshold : 5.0\n",
      "low valence : (1323,),    high valence : (1197,)\n",
      "low arousal : (1008,),    high arousal : (1512,)\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230513 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230513 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230513 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230513 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3366 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230513 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230513 is saved successfully\n",
      "Epoch 100 - Train Acc : 92.29    Train Loss : 0.28,    Test Acc : 89.3,    Test Loss :0.35,    Total Acc : 90.79\n",
      "Epoch 200 - Train Acc : 95.21    Train Loss : 0.19,    Test Acc : 90.96,    Test Loss :0.29,    Total Acc : 93.09\n",
      "Epoch 300 - Train Acc : 98.13    Train Loss : 0.14,    Test Acc : 93.73,    Test Loss :0.24,    Total Acc : 95.93\n",
      "Epoch 400 - Train Acc : 98.33    Train Loss : 0.13,    Test Acc : 93.86,    Test Loss :0.29,    Total Acc : 96.1\n",
      "Epoch 500 - Train Acc : 95.83    Train Loss : 0.19,    Test Acc : 90.75,    Test Loss :0.38,    Total Acc : 93.29\n",
      "Epoch 600 - Train Acc : 98.12    Train Loss : 0.14,    Test Acc : 95.79,    Test Loss :0.31,    Total Acc : 96.96\n",
      "Epoch 700 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 95.92,    Test Loss :0.25,    Total Acc : 97.75\n",
      "Epoch 800 - Train Acc : 99.79    Train Loss : 0.08,    Test Acc : 95.88,    Test Loss :0.28,    Total Acc : 97.83\n",
      "Epoch 900 - Train Acc : 99.79    Train Loss : 0.08,    Test Acc : 96.45,    Test Loss :0.21,    Total Acc : 98.12\n",
      "Epoch 1000 - Train Acc : 99.79    Train Loss : 0.08,    Test Acc : 97.24,    Test Loss :0.2,    Total Acc : 98.51\n",
      "Epoch 1100 - Train Acc : 99.79    Train Loss : 0.08,    Test Acc : 96.84,    Test Loss :0.27,    Total Acc : 98.32\n",
      "Epoch 1200 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 96.71,    Test Loss :0.23,    Total Acc : 98.36\n",
      "Epoch 1300 - Train Acc : 98.33    Train Loss : 0.13,    Test Acc : 92.46,    Test Loss :0.51,    Total Acc : 95.39\n",
      "Epoch 1400 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 97.15,    Test Loss :0.17,    Total Acc : 98.57\n",
      "Epoch 1500 - Train Acc : 99.79    Train Loss : 0.09,    Test Acc : 95.18,    Test Loss :0.35,    Total Acc : 97.48\n",
      "Epoch 1600 - Train Acc : 99.79    Train Loss : 0.08,    Test Acc : 97.28,    Test Loss :0.31,    Total Acc : 98.54\n",
      "Epoch 1700 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 96.23,    Test Loss :0.41,    Total Acc : 98.11\n",
      "Epoch 1800 - Train Acc : 99.79    Train Loss : 0.08,    Test Acc : 97.59,    Test Loss :0.21,    Total Acc : 98.69\n",
      "Epoch 1900 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 96.36,    Test Loss :0.27,    Total Acc : 98.18\n",
      "Epoch 2000 - Train Acc : 99.79    Train Loss : 0.08,    Test Acc : 96.89,    Test Loss :0.2,    Total Acc : 98.34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [58], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m model \u001b[38;5;241m=\u001b[39m GRACE(encoder, args\u001b[38;5;241m.\u001b[39mfeature_dimension, args\u001b[38;5;241m.\u001b[39mgcn_out_channels, args\u001b[38;5;241m.\u001b[39mproj_hid_channels, args\u001b[38;5;241m.\u001b[39mout_channels, args\u001b[38;5;241m.\u001b[39mptau)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    110\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[0;32m--> 112\u001b[0m best_acc, best_epoch, best_z, best_result \u001b[38;5;241m=\u001b[39m \u001b[43muniform_GCA_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvlc_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mvlc_train_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvlc_test_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43msub_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misdeap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Best ACC : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ***\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mround\u001b[39m(best_acc\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m    116\u001b[0m vlc_best_acc\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mround\u001b[39m(best_acc\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn [57], line 15\u001b[0m, in \u001b[0;36muniform_GCA_train\u001b[0;34m(model, otimizer, feature, orig_adj, label, train_identifier, test_identifier, args, device, date, sub_idx, isdeap)\u001b[0m\n\u001b[1;32m     13\u001b[0m         x1 \u001b[38;5;241m=\u001b[39m uniform_drop_features(feature, orig_adj, p \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mpf1, threshold \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mtpf1)\n\u001b[1;32m     14\u001b[0m         x2 \u001b[38;5;241m=\u001b[39m uniform_drop_features(feature, orig_adj, p \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mpf2, threshold \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mtpf2)\n\u001b[0;32m---> 15\u001b[0m         e1 \u001b[38;5;241m=\u001b[39m \u001b[43muniform_drop_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpe1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtpe1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         e2 \u001b[38;5;241m=\u001b[39m uniform_drop_edges(orig_adj, p \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mpe2, threshold \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mtpe2)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#         x1 = drop_features(feature, adj, p = 0.1, threshold = args.tpf1)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#         x2 = drop_features(feature, adj, p = 0.2, threshold = args.tpf2)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#         e1 = drop_edges(adj, p = 0.1, threshold = args.tpe1)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#         e2 = drop_edges(adj, p = 0.2, threshold = args.tpe2)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [57], line 116\u001b[0m, in \u001b[0;36muniform_drop_edges\u001b[0;34m(edge_weights, p, threshold)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muniform_drop_edges\u001b[39m(edge_weights, p: \u001b[38;5;28mfloat\u001b[39m, threshold: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m):\n\u001b[0;32m--> 116\u001b[0m     drop_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbernoulli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    118\u001b[0m     edge_weights_view \u001b[38;5;241m=\u001b[39m edge_weights\u001b[38;5;241m.\u001b[39mwhere(drop_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, torch\u001b[38;5;241m.\u001b[39mzeros_like(edge_weights))\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m edge_weights_view\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x1600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cp.cuda.Device(2).use()\n",
    "\n",
    "args = get_deap_args()\n",
    "\n",
    "device = get_device(args.bus_id, args.cuda_id[2])\n",
    "setting_os_path(args.os_path)\n",
    "# fix_random_variables(args.seed)\n",
    "\n",
    "\n",
    "subject_de, subject_psd, subject_label, _ = load_subject_data(args.tensor_save_path, isdeap=True)\n",
    "\n",
    "visualization_type = 1\n",
    "\n",
    "for p in range(1):\n",
    "    if p == 0:\n",
    "        n_labels_by_class = args.n_labels_by_class3\n",
    "    elif p == 1:\n",
    "        n_labels_by_class = args.n_labels_by_class2\n",
    "    else:\n",
    "        n_labels_by_class = args.n_labels_by_class1\n",
    "    \n",
    "    \n",
    "    Best_EF_vlc_acc = [[0 for _ in range(9)] for _ in range(9)]\n",
    "    Best_EF_vlc_std = [[0 for _ in range(9)] for _ in range(9)]\n",
    "\n",
    "    Best_EF_ars_acc = [[0 for _ in range(9)] for _ in range(9)]\n",
    "    Best_EF_ars_std = [[0 for _ in range(9)] for _ in range(9)]\n",
    "    \n",
    "    for e in range(1,10):\n",
    "        for f in range(1,10):\n",
    "            print(\"+++++++++++++++++++++++++++ Pe: {}, Pf:{} +++++++++++++++++++++++++++++++++++\".format(e/10,f/10))\n",
    "\n",
    "            args.pe1 = e/10\n",
    "            args.pe2 = e/10\n",
    "            args.pf1 = f/10\n",
    "            args.pf2 = f/10\n",
    "           \n",
    "            vlc_best_epoch = []\n",
    "            vlc_orig_acc = []\n",
    "            vlc_best_acc = []\n",
    "            ars_best_epoch = []\n",
    "            ars_orig_acc = []\n",
    "            ars_best_acc = []\n",
    "            print(\"========================================== DEAP Protocol {} ==========================================\".format(int(n_labels_by_class)))\n",
    "\n",
    "            for i in range(32):\n",
    "                print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "                sub_idx = 'sub'+str(i+1)\n",
    "                date = '230501'\n",
    "\n",
    "                sub_de = subject_de[i]\n",
    "                sub_psd = subject_psd[i]\n",
    "                sub_label = subject_label[i]\n",
    "                valence_label, arousal_label = deap_label(sub_label)\n",
    "\n",
    "                de, psd, vlc_identifier, ars_identifier = other_preprocessing(sub_de,sub_psd, (valence_label,arousal_label), n_labels_by_class, args.out_channels, args.seed, isdeap=True)\n",
    "\n",
    "                de = normalization(de, axis = 0, ntype='standardization')\n",
    "                psd = normalization(psd, axis = 0, ntype='standardization')\n",
    "\n",
    "                de_ssm, de_nssm = ssm_construction(de, args.n_samples,args.de_k)\n",
    "                psd_ssm, psd_nssm = ssm_construction(psd, args.n_samples,args.psd_k)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'de_ssm_'+date, de_ssm)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'psd_ssm_'+date, psd_ssm)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'de_nssm_'+date, de_nssm)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'psd_nssm_'+date, psd_nssm)\n",
    "                save_heatmap(de_ssm, \"DE SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/DE_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "                save_heatmap(psd_ssm, \"PSD SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/PSD_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "                save_heatmap(de_nssm, \"DE NSSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/DE_NSSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "                save_heatmap(psd_nssm, \"PSD NSSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/PSD_NSSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "\n",
    "                fsm = ssm_fusion(de_ssm,psd_ssm, de_nssm, psd_nssm, args.k1, args.t1)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'fused_ssm_'+date, fsm)\n",
    "                save_heatmap(fsm, \"Fused SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/fused_ssm/Fused_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "                adj = normalize_adj(fsm)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'adjacency_matrix_'+date, adj)\n",
    "                save_heatmap(adj, \"Normalized Adjacecy Matrix\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/adjacency_matrix/Adjacecny_Matrix_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "                feature = input_feature(de, psd)\n",
    "\n",
    "                save_heatmap(feature, \"Feature matrix\", \"Feature dimensions\", \"Sample index\", args.figure_save_path+'heatmap/'+sub_idx+'/feature/feature_matrix_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight') \n",
    "\n",
    "                feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "                adj = torch.from_numpy(adj).to(torch.float32).to(device)\n",
    "                ars_label = torch.from_numpy(arousal_label).to(torch.long).to(device)\n",
    "                vlc_label = torch.from_numpy(valence_label).to(torch.long).to(device)\n",
    "\n",
    "                vlc_identifier = torch.from_numpy(vlc_identifier).bool()\n",
    "                vlc_train_identifier = vlc_identifier.to(device)\n",
    "                isunlabeled = ~vlc_identifier\n",
    "                vlc_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "                ars_identifier = torch.from_numpy(ars_identifier).bool()\n",
    "                ars_train_identifier = ars_identifier.to(device)\n",
    "                isunlabeled = ~ars_identifier\n",
    "                ars_test_identifier = isunlabeled.to(device)\n",
    "\n",
    "                activation = get_activation('celu')\n",
    "                gcn = GraphConvolution\n",
    "\n",
    "                encoder = Encoder(args.feature_dimension, args.gcn_hid_channels, args.gcn_out_channels, activation, args.seed, base_model = gcn).to(device)\n",
    "                model = GRACE(encoder, args.feature_dimension, args.gcn_out_channels, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr = args.learning_rate)\n",
    "\n",
    "                model, best_acc, best_epoch, best_model, best_z, result = GCA_train2(model, optimizer, feature, adj, vlc_label,\n",
    "                                                                            vlc_train_identifier, vlc_test_identifier,\n",
    "                                                                            args,device,date,sub_idx, isdeap=True)\n",
    "                print(\"*** Best ACC : {} ***\".format(round(best_acc.item(), 2)))\n",
    "                vlc_best_acc.append(round(best_acc.item(), 2))\n",
    "                vlc_orig_acc.append(best_acc.item())\n",
    "                vlc_best_epoch.append(best_epoch)\n",
    "\n",
    "                experiment_type = 'subject_dependent'\n",
    "                model_save_name = sub_idx+'_model_valence'\n",
    "                model_path = args.model_save_path+experiment_type+'/'+date+'/'+model_save_name\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "\n",
    "\n",
    "                encoder = Encoder(args.feature_dimension, args.gcn_hid_channels, args.gcn_out_channels, activation, args.seed, base_model = gcn).to(device)\n",
    "                model = GRACE(encoder, args.feature_dimension, args.gcn_out_channels, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr = args.learning_rate)\n",
    "\n",
    "                model, best_acc, best_epoch, best_model, best_z, result = GCA_train2(model, optimizer, feature, adj, ars_label,\n",
    "                                                                                    ars_train_identifier, ars_test_identifier,\n",
    "                                                                                    args,date,sub_idx, isdeap=True)\n",
    "\n",
    "                print(\"*** Best ACC : {} ***\".format(round(best_acc.item(), 2)))\n",
    "                ars_best_acc.append(round(best_acc.item(), 2))\n",
    "                ars_orig_acc.append(best_acc.item())\n",
    "                ars_best_epoch.append(best_epoch)\n",
    "\n",
    "                experiment_type = 'subject_dependent'\n",
    "                model_save_name = sub_idx+'_model_arousal'\n",
    "                model_path = args.model_save_path+experiment_type+'/'+date+'/'+model_save_name\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "\n",
    "            print(\"\\n**************** Valence *********************\")\n",
    "            print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(vlc_best_acc, np.mean(vlc_best_acc), np.std(vlc_best_acc)))\n",
    "            print(\"\\n Best Epochs : {}\".format(vlc_best_epoch))\n",
    "            print(\"**************** Arousal *********************\")\n",
    "            print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(ars_best_acc, np.mean(ars_best_acc), np.std(ars_best_acc)))\n",
    "            print(\"\\n Best Epochs : {}\".format(ars_best_epoch))\n",
    "\n",
    "\n",
    "            vlc_best_acc_list = np.array(vlc_best_acc)\n",
    "            save_np(args.tensor_save_path+sub_idx, 'protocol '+str(n_labels_by_class)+'_vlc_best_acc_list_'+date, vlc_best_acc_list)\n",
    "            ars_best_acc_list = np.array(ars_best_acc)\n",
    "            save_np(args.tensor_save_path+sub_idx, 'protocol '+str(n_labels_by_class)+'_ars_best_acc_list_'+date, ars_best_acc_list)\n",
    "\n",
    "            Best_EF_vlc_acc[e-1][f-1] = round(np.mean(vlc_orig_acc),2)\n",
    "            Best_EF_vlc_std[e-1][f-1] = round(np.std(vlc_orig_acc),2)\n",
    "\n",
    "            Best_EF_ars_acc[e-1][f-1] = round(np.mean(ars_orig_acc),2)\n",
    "            Best_EF_ars_std[e-1][f-1] = round(np.std(ars_orig_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "884e7de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[97.48, 97.63, 97.52, 97.45, 97.37, 96.92, 96.29, 95.25, 93.67],\n",
       " [97.45, 97.6, 97.57, 97.43, 97.26, 96.87, 96.21, 95.09, 93.54],\n",
       " [97.5, 97.67, 97.42, 97.45, 97.17, 96.94, 96.24, 95.0, 93.43],\n",
       " [97.53, 97.55, 97.47, 97.35, 97.15, 96.94, 96.1, 94.97, 93.36],\n",
       " [97.57, 97.5, 97.46, 97.32, 97.09, 96.79, 95.93, 94.76, 93.22],\n",
       " [97.54, 97.48, 97.38, 97.25, 97.08, 96.61, 95.96, 94.48, 92.72],\n",
       " [97.39, 97.4, 97.25, 97.17, 96.83, 96.48, 95.7, 94.32, 92.27],\n",
       " [97.3, 97.18, 97.12, 96.93, 96.58, 96.17, 95.24, 93.77, 91.54],\n",
       " [96.61, 96.38, 96.31, 95.89, 95.54, 95.02, 94.11, 92.34, 89.96]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_EF_vlc_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f420adcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.45, 1.74, 1.74, 1.9, 2.04, 2.37, 2.76, 3.21, 3.49],\n",
       " [1.44, 1.6, 1.73, 1.81, 2.05, 2.4, 2.84, 3.12, 3.48],\n",
       " [1.57, 1.6, 1.88, 1.89, 2.05, 2.28, 2.75, 3.25, 3.4],\n",
       " [1.5, 1.68, 1.85, 1.88, 1.95, 2.23, 2.84, 3.16, 3.32],\n",
       " [1.56, 1.55, 1.74, 1.79, 2.0, 2.34, 2.89, 3.27, 3.35],\n",
       " [1.49, 1.58, 1.67, 1.91, 2.03, 2.39, 2.88, 3.39, 3.51],\n",
       " [1.55, 1.7, 1.78, 1.91, 2.04, 2.42, 2.89, 3.37, 3.55],\n",
       " [1.56, 1.69, 1.72, 1.89, 2.24, 2.53, 2.99, 3.43, 3.72],\n",
       " [1.8, 1.83, 1.91, 2.03, 2.37, 2.65, 3.11, 3.49, 3.58]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_EF_vlc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49953ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[97.68, 97.72, 97.64, 97.44, 97.26, 96.92, 96.44, 95.49, 93.86],\n",
       " [97.84, 97.71, 97.68, 97.55, 97.23, 97.03, 96.38, 95.56, 93.82],\n",
       " [97.76, 97.59, 97.57, 97.42, 97.26, 96.93, 96.35, 95.29, 93.56],\n",
       " [97.72, 97.62, 97.59, 97.34, 97.18, 96.98, 96.28, 95.2, 93.35],\n",
       " [97.83, 97.6, 97.54, 97.44, 97.14, 96.76, 96.21, 94.93, 93.24],\n",
       " [97.62, 97.62, 97.43, 97.29, 97.0, 96.63, 95.95, 94.86, 92.92],\n",
       " [97.65, 97.61, 97.45, 97.11, 96.93, 96.48, 95.81, 94.5, 92.5],\n",
       " [97.42, 97.43, 97.15, 96.96, 96.69, 96.19, 95.48, 93.95, 91.92],\n",
       " [96.63, 96.56, 96.39, 96.09, 95.76, 95.24, 94.28, 92.66, 90.29]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_EF_ars_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15b04991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.67, 1.71, 2.01, 2.05, 2.3, 2.3, 2.6, 2.88, 3.28],\n",
       " [1.62, 1.74, 1.99, 1.99, 2.18, 2.46, 2.6, 2.85, 3.44],\n",
       " [1.58, 1.88, 1.9, 2.15, 2.09, 2.38, 2.53, 2.85, 3.32],\n",
       " [1.71, 1.87, 2.08, 2.13, 2.18, 2.19, 2.45, 2.9, 3.34],\n",
       " [1.59, 1.88, 1.98, 2.09, 2.16, 2.3, 2.45, 3.07, 3.34],\n",
       " [1.69, 1.79, 2.06, 2.12, 2.21, 2.27, 2.7, 3.07, 3.56],\n",
       " [1.77, 1.71, 2.02, 2.1, 2.36, 2.48, 2.74, 3.09, 3.46],\n",
       " [1.77, 1.92, 2.02, 2.22, 2.27, 2.44, 2.75, 3.23, 3.48],\n",
       " [1.93, 2.1, 2.23, 2.3, 2.44, 2.55, 2.84, 3.2, 3.86]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_EF_ars_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b6d0a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neuroai/anaconda3/envs/py39_dh/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/neuroai/anaconda3/envs/py39_dh/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "visualization_type = 1\n",
    "sample = best_z.cpu().detach().numpy().copy()\n",
    "drmodel = TSNE(n_components = 2, perplexity = 50., n_iter_without_progress = 4000)\n",
    "tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "dr_result = drmodel.fit_transform(tsne_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ba3988d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_scatter(dr_result, label, best_acc.item(),sub_idx, date, args.figure_save_path, visualization_type, identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9465e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scatter(result, label, best_acc,sub_idx, date, save_path, dr_type, iden):\n",
    "\n",
    "    negw = np.where(label.cpu()==0)[0]\n",
    "    neuw = np.where(label.cpu()==1)[0]\n",
    "    posw = np.where(label.cpu()==2)[0]\n",
    "    if dr_type == 0:\n",
    "        dr_name = 'PCA'\n",
    "    elif dr_type == 1:\n",
    "        dr_name = 'TSNE'\n",
    "    else:\n",
    "        dr_name = ''\n",
    "    neg = result[negw]\n",
    "    neu = result[neuw]\n",
    "    pos = result[posw]\n",
    "\n",
    "    gts = np.where(iden.cpu().numpy() ==True)[0]\n",
    "\n",
    "    neggtw,neugtw,posgtw = [], [], []\n",
    "    \n",
    "    for i in gts:\n",
    "        if i in negw:\n",
    "            neggtw.append(i)\n",
    "        elif i in neuw:\n",
    "            neugtw.append(i)\n",
    "        elif i in posw:\n",
    "            posgtw.append(i)\n",
    "\n",
    "    neggt = result[neggtw,:]\n",
    "    neugt = result[neugtw,:]\n",
    "    posgt = result[posgtw,:]\n",
    "    \n",
    "    plt.clf()\n",
    "    c1 = plt.scatter(neg[:,0], neg[:,1], marker = \"o\", color='#FF6600',s=1.)\n",
    "    gt1 = plt.scatter(neggt[:,0], neggt[:,1], marker = \"x\", color='red',s=2.)\n",
    "    c2 = plt.scatter(neu[:,0], neu[:,1], marker = \"o\",color ='#CCFF66', s=1.)\n",
    "    gt2 = plt.scatter(neugt[:,0], neugt[:,1], marker = \"x\", color='green',s=2.)\n",
    "    c3 = plt.scatter(pos[:,0], pos[:,1], marker = \"o\",color ='#33CCFF', s=1.)\n",
    "    gt3 = plt.scatter(posgt[:,0], posgt[:,1], marker = \"x\", color='blue',s=2.)\n",
    "    \n",
    "    plt.title('Classfication result of '+sub_idx + ' - Acc : '+ str(best_acc) +'%')\n",
    "    plt.xlabel(\"Reduced axis - 1\")\n",
    "    plt.ylabel(\"Reduced axis - 2\")\n",
    "    plt.legend(handles = (c1,c2,c3, gt1,gt2,gt3),labels=(\"negative\",\"neutral\", \"positive\", \"negative-gt\", \"neutral-gt\", \"positive-gt\"))\n",
    "    plt.savefig(save_path+'test_result/'+sub_idx+'/'+dr_name+'_classification_result_scatter_'+date+'.png', dpi=300, facecolor = \"#eeeeee\", bbox_inches = 'tight')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43ab7668",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAHHCAYAAAC/R1LgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAADZWklEQVR4nOydd3hUVfrHv5Nk0ptIKJGWZCZKE+xiAQsr+rM3xBAmk4kFF0RXV9Etgrsqu7a1oyghdOyua1nFslZUFAURhIQq0hI1E5hAZkjO74+TM7fMvTN3JtPzfp7nPjNzbju3zD3vfauJMcZAEARBEATRDUiJdQcIgiAIgiCiBQk+BEEQBEF0G0jwIQiCIAii20CCD0EQBEEQ3QYSfAiCIAiC6DaQ4EMQBEEQRLeBBB+CIAiCILoNJPgQBEEQBNFtIMGHIAiCIIhuAwk+RNQYNGgQ7HZ7TPuwcOFCHHXUUTCbzSgsLAQAnHHGGTjjjDOi3pe6ujqYTCZs3bo16vuON6J5b6xcuRKnnHIKcnJyYDKZ8N1330V8n1u3boXJZMKDDz4Y8X0RBOEfEnyILrNp0yZcf/31KC0tRWZmJvLz83Hqqafi0UcfxYEDB2LdPS8//vgj7HY7ysrK8Oyzz2LOnDlR2e99992H1157LSr7ShbWrVuHmTNnhl0o9Hg8uPLKK/Hrr7/iX//6FxYuXIiBAweGdR9d5eOPP8ZFF12E/v37IzMzE3369MG5556Lzz77LKL7vf3222EymXDVVVdFdD/h4N1330VNTQ2GDRuG1NRUDBo0SHfZjo4O3H///SgpKUFmZiaOPvpoLF26VHPZ9evX49xzz0Vubi569OiBSZMmobGx0XC/Xn/9dRx77LHIzMzEgAEDMGPGDBw6dEixzLp163D66acjLy8Pxx9/PFasWOGznYcffhhDhw71WZcIE4wgusAbb7zBsrKyWGFhIZs2bRqbM2cOe+KJJ9iECROY2Wxm1157rXfZgQMHsqqqqpj1dfbs2QwAq6+vV7S3tbWxtra2iO03JydH87gPHTrEDhw4wDo6OiK270RBfW+8+OKLDAD78MMPw7qf9evXMwDs2WefDet2A7FlyxYGgD3wwAMBl3322WfZxRdfzO655x723HPPsQceeICNGDGCpaSksLfffjsi/evo6GD9+vVjgwYNYllZWaylpSUi+wkXVVVVLDMzk51yyimsX79+bODAgbrL3nHHHQwAu/baa9mcOXPY+eefzwCwpUuXKpb76aefWM+ePVlZWRl79NFH2b333ssOO+wwNmLECEPPh7feeouZTCZ25plnsjlz5rAbb7yRpaSksMmTJ3uXOXToEDvyyCPZqFGj2OzZs9l5553HioqKmNPp9C6zZ88eVlBQwN55553gTwxhCBJ8iJDZvHkzy83NZUcddRTbuXOnz/z6+nr2yCOPeH/HWvC5++67GQDW2NgY1f3qCT7xRHt7Oztw4EDM9h8tweejjz5iANiLL74Y1u0GIhjBRwuXy8V69+7Nxo0bF+aecT744AMGgH3wwQfMbDazurq6iOwnXPz888/M7XYzxhg7//zzdQWfHTt2MLPZzKZMmeJt6+joYKeffjrr168fO3TokLf9hhtuYFlZWWzbtm3etuXLlzMA7JlnngnYpyFDhrARI0Ywj8fjbfvzn//MTCYTW79+PWNMErzFPlwuF8vKymL//e9/vevU1NSwCy+80MBZIEKFBB8iZCZPnswAsM8++8zQ8urB7ZdffmG33norGzZsGMvJyWF5eXns3HPPZd99953Puo899hgbMmSIV7t03HHHscWLF3vnt7S0sJtuuokNHDiQpaens6KiIjZ27Fj2zTffePcNQDHNmDGDMcbYmDFj2JgxYxT7O3DgAJsxYwazWq0sIyOD9enTh1166aWsoaHBu8wDDzzARo0axXr06MEyMzPZscce6zOgqvcJwHsO5s2bxwCwLVu2KNZ58skn2ZAhQ1h6ejrr27cv+/3vf89+++03xTJjxoxhQ4cOZT/88AM744wzWFZWFisuLmb//Oc/DVwJ3q8pU6awRYsWsSFDhrC0tDT26quvMsb4YFFdXc169erF0tPT2ZAhQ9jcuXODviZVVVWaA9KMGTOYWtksvzfEeVFPgYSg999/n5122mksOzubFRQUsIsuuoitW7dO0R/1NtXXXY7b7WYzZ85kFouFZWRksB49erBTTz2Vvfvuu95ltO4drWOXCz4PP/wwGzBgAMvMzGSjR49m33//vd/jEgwbNoyddNJJhpYNlpqaGjZkyBDGGGPnnXce+93vfqe53I4dO5jD4WB9+/Zl6enpbNCgQWzy5MkKjchvv/3Gbr75Zu9/8YgjjmCTJk0K+MLR2NjI1q9fz1wuV1B99yf4PPnkkwwA++GHHxTtS5YsYQDYJ5984m3r1asXu/LKK322UV5ezs4++2y/ffjhhx8YAPbkk08q2n/++WcGgP39739njDG2atUqBkChUevRowd75ZVXGGOMffPNNywzM9NHK02El7SI2dCIpOc///kPSktLccopp4S0/ubNm/Haa6/hyiuvRElJCfbs2YNnnnkGY8aMwbp161BcXAwAePbZZzFt2jRcccUVuOmmm3Dw4EGsWbMGX375JSoqKgAAkydPxksvvYSpU6diyJAh+OWXX/Dpp59i/fr1OPbYY/HII49gwYIFePXVVzF79mzk5ubi6KOP1uxXe3s7LrjgArz//vuYMGECbrrpJuzbtw/Lly/H2rVrUVZWBgB49NFHcdFFF2HixIlwu91YtmwZrrzySrzxxhs4//zzAXBn6muuuQYnnngirrvuOgDwrq/FzJkzcffdd2Ps2LG44YYbsGHDBsyePRsrV67EZ599BrPZ7F32t99+w7nnnovLLrsM48ePx0svvYTp06dj+PDhOO+88wKe/w8++AAvvPACpk6dip49e2LQoEHYs2cPTj75ZJhMJkydOhVFRUV4++23UVNTg5aWFtx8882Gr0mojB49GtOmTcNjjz2GP/3pTxg8eDAAeD+1eO+993DeeeehtLQUM2fOxIEDB/D444/j1FNPxapVqzBo0CBcf/31OOKII3Dfffdh2rRpOOGEE9C7d2/dbc6cOROzZs3yXr+WlhZ8/fXXWLVqFX73u9+FdGwLFizAvn37MGXKFBw8eBCPPvoozjrrLHz//fc+fWlpaYHb7UZTUxMWLFiAtWvX4k9/+lNI+/VHW1sbXn75Zdx6660AgKuvvhrV1dXYvXs3+vTp411u586dOPHEE9Hc3IzrrrsORx11FH7++We89NJLaG1tRXp6Ovbv34/TTz8d69evh8PhwLHHHoumpia8/vrr2LFjB3r27KnbjyeeeAJ33303Pvzww7AFG3z77bfIycnxuXdOPPFE7/zTTjsNP//8M/bu3Yvjjz/eZxsnnngi3nrrrYD7AeCzfnFxMfr16+edX15ejoKCAsycORPTpk3DCy+8gJaWFhx77LEAgGnTpmHq1KmwWCyhHTBhjFhLXkRi4nQ6GQB28cUXG15HrfE5ePAga29vVyyzZcsWlpGRwf72t7952y6++GI2dOhQv9suKChQqLO1EJoG9Zun+q29traWAWAPP/ywzzbk/jitra2KeW63mw0bNoydddZZinY9U5da47N3716Wnp7OzjnnHMV5eeKJJxgAVltbq+gzALZgwQJvW1tbG+vTpw+7/PLL9U9CJwBYSkqKz5twTU0N69u3L2tqalK0T5gwgRUUFHiP2cg1CVXjw1jwpq6RI0eyXr16sV9++cXbtnr1apaSksJsNpu37cMPPzRs6hoxYgQ7//zz/S4TrMYnKyuL7dixw9v+5ZdfMgDsD3/4g882xo0b59VMpaens+uvvz4i5siXXnpJ4fvW0tLCMjMz2b/+9S/FcjabjaWkpLCVK1f6bEP8L+666y4GwKvB0FpGD3FfBGve9KfxOf/881lpaalPu8vlYgDYHXfcwRhjbOXKlT7/J8Ftt93GALCDBw/q9uGBBx5gANj27dt95p1wwgns5JNP9v5esmQJy8rKYgBYamoqe/DBBxljjC1evJj17t1b4e9DRAaK6iJCoqWlBQCQl5cX8jYyMjKQksJvwfb2dvzyyy/Izc3FkUceiVWrVnmXKywsxI4dO7By5UrdbRUWFuLLL7/Ezp07Q+6P4OWXX0bPnj1x4403+swzmUze71lZWd7vv/32G5xOJ04//XRF34Phvffeg9vtxs033+w9LwBw7bXXIj8/H2+++aZi+dzcXFRWVnp/p6en48QTT8TmzZsN7W/MmDEYMmSI9zdjDC+//DIuvPBCMMbQ1NTkncaNGwen0+k9NiPXJFrs2rUL3333Hex2O3r06OFtP/roo/G73/0u4Nu6HoWFhfjhhx9QX18frq7ikksuwRFHHOH9feKJJ+Kkk07S7OM//vEPvPvuu5g7dy5OPvlkuN3uiET5LF68GMcff7xXy5CXl4fzzz8fixcv9i7T0dGB1157DRdeeKGmVkT8L15++WWMGDECl156qe4yesycOROMsbCmljhw4AAyMjJ82jMzM73z5Z9GltXbj7/15eteffXV+Pnnn7FixQr8/PPPuPXWW9Ha2orp06fj3nvvRW5uLu6++26Ulpbi6KOPxquvvmr0cAmDkOBDhER+fj4AYN++fSFvo6OjA//6179gtVqRkZGBnj17oqioCGvWrIHT6fQuN336dOTm5uLEE0+E1WrFlClTfEJ777//fqxduxb9+/fHiSeeiJkzZxoWANRs2rQJRx55JNLS/FuC33jjDZx88snIzMxEjx49UFRUhNmzZyv6Hgzbtm0DABx55JGK9vT0dJSWlnrnC/r16+czmBx22GH47bffDO2vpKRE8buxsRHNzc2YM2cOioqKFFN1dTUAYO/evQCMXZNooXfeAG4ea2pqgsvlCnq7f/vb39Dc3Izy8nIMHz4ct912G9asWdOlvlqtVp+28vJyzbD9kSNH4ne/+x0cDgeWL1+Or776KmCuo/3792P37t3eKVAodnNzM9566y2MGTMGDQ0N3unUU0/F119/jY0bNwLg90ZLSwuGDRvmd3ubNm0KuEw0ycrKQltbm0/7wYMHvfPln0aW1duPv/XV6x522GE4+eSTvebNWbNmoVevXqiurkZtbS2efvppPPfcc7j55ptx1VVXoaGhIeCxEsYhwYcIifz8fBQXF2Pt2rUhb+O+++7DLbfcgtGjR2PRokV45513sHz5cgwdOhQdHR3e5QYPHowNGzZg2bJlOO200/Dyyy/jtNNOw4wZM7zLjB8/Hps3b8bjjz+O4uJiPPDAAxg6dCjefvvtLh2nHp988gkuuugiZGZm4qmnnsJbb72F5cuXo6KiAoyxiOxTTWpqqma70f2rH8binFdWVmL58uWa06mnngrA2DXRe8Nvb2831L9YM3r0aGzatAm1tbUYNmwYnnvuORx77LF47rnnvMtE6xjT09Nx0UUX4ZVXXvGreXjwwQfRt29f73TCCSf43e6LL76ItrY2PPTQQ7Bard7plltuAQCF1icR6du3L3bv3u3zn9i1axcAeP0I+/btq2hXL9ujRw9NbY58P/7WF/vRYuvWrXjooYfw6KOPIiUlBUuXLsX111+Ps846Cw6HA6NGjcKyZcsCHCkRDOTcTITMBRdcgDlz5mDFihUYNWpU0Ou/9NJLOPPMMzF37lxFe3Nzs48TZE5ODq666ipcddVVcLvduOyyy3Dvvffizjvv9Kqi+/bti9///vf4/e9/j7179+LYY4/Fvffea8jRV05ZWRm+/PJLeDwehTOxnJdffhmZmZl45513FA/EefPm+SwbSMUvEIn0NmzYgNLSUm+72+3Gli1bMHbs2GAOI2iKioqQl5eH9vZ2Q/sKdE0OO+wwNDc3+6yn1lxpYfScAcrzpubHH39Ez549kZOTY3h7cnr06IHq6mpUV1dj//79GD16NGbOnIlrrrkGAH9z19Is6h2jltls48aNfhPwCQ4cOADGGPbt26erfbDZbDjttNO8v/1pKQAu2AwbNkwhsAqeeeYZLFmyBHfffTeKioqQn58f8EWnrKysSy9D4WbkyJF47rnnsH79eoVZ98svv/TOB4AjjjgCRUVF+Prrr3228dVXX3mX87cfAPj666+9jtMAdwjfsWOHN7BBiz/+8Y+46KKLvNdt586dCkGpuLgYP//8s9/9E8FBGh8iZG6//Xbk5OTgmmuuwZ49e3zmb9q0CY8++qju+qmpqT5vYi+++KLPn/yXX35R/E5PT8eQIUPAGIPH40F7e7uPealXr14oLi7WVD0H4vLLL0dTUxOeeOIJn3miv6mpqTCZTIo3+61bt2pmaM7JydEUANSMHTsW6enpeOyxxxTnZe7cuXA6nd5IsUiRmpqKyy+/HC+//LLm4CU3mwS6JgAfBJ1Op8I8tGvXLkM+C0JQMXLe+vbti5EjR2L+/PmK5deuXYt3330X//d//xdwG1qojzE3NxcWi0VxT5WVleHHH39UnJvVq1frmv1ee+01xf391Vdf4csvv1QI58KcKKe5uRkvv/wy+vfvj169eun2ubS0FGPHjvVOQkOnxU8//YSPP/4Y48ePxxVXXOEzVVdXo6GhAV9++SVSUlJwySWX4D//+Y+mcCDu18svvxyrV6/WvMaBNJFNTU348ccf0dra6ne5YLj44othNpvx1FNPKfrx9NNP44gjjlBEpF5++eV444038NNPP3nb3n//fWzcuBFXXnmlt83j8eDHH39UaHeGDh2Ko446CnPmzFE8E2bPng2TyYQrrrhCs38ffvgh3nrrLdx///3ett69e+PHH3/0/l6/fr0iuo7oOqTxIUKmrKwMS5YswVVXXYXBgwfDZrNh2LBhcLvd+Pzzz/Hiiy/69Um44IIL8Le//Q3V1dU45ZRT8P3332Px4sUKbQcAnHPOOejTpw9OPfVU9O7dG+vXr8cTTzyB888/H3l5eWhubka/fv1wxRVXYMSIEcjNzcV7772HlStX4qGHHgr6uGw2GxYsWIBbbrkFX331FU4//XS4XC689957+P3vf4+LL74Y559/Ph5++GGce+65qKiowN69e/Hkk0/CYrH4+IEcd9xxeO+99/Dwww+juLgYJSUlOOmkk3z2W1RUhDvvvBN33303zj33XFx00UXYsGEDnnrqKZxwwgkKR+ZI8Y9//AMffvghTjrpJFx77bUYMmQIfv31V6xatQrvvfcefv31VwCBrwkATJgwAdOnT8ell16KadOmobW1FbNnz0Z5eXlAB/CRI0ciNTUV//znP+F0OpGRkYGzzjpLd9B/4IEHcN5552HUqFGoqanxhrOL0OFQGDJkCM444wwcd9xx6NGjB77++mtvygSBw+HAww8/jHHjxqGmpgZ79+7F008/jaFDh3oDAORYLBacdtppuOGGG9DW1oZHHnkEhx9+OG6//XbvMueddx769euHk046Cb169cL27dsxb9487Ny5E88//3xIx6LFkiVLwBjDRRddpDn///7v/5CWlobFixfjpJNOwn333Yd3330XY8aMwXXXXYfBgwdj165dePHFF/Hpp5+isLAQt912G1566SVceeWVcDgcOO644/Drr7/i9ddfx9NPP40RI0bo9ieYcPY1a9bg9ddfBwA0NDTA6XTinnvuAQCMGDECF154IQDuB3fzzTfjgQcegMfjwQknnIDXXnsNn3zyCRYvXqwwF//pT3/Ciy++iDPPPBM33XQT9u/fjwceeADDhw/3+rgBwM8//4zBgwejqqoKdXV13vYHHngAF110Ec455xxMmDABa9euxRNPPIFrrrlGMxVDe3s7br75Ztx2220YMGCAt/2KK67A7bffjqKiImzbts37XCTCSPQDyYhkY+PGjezaa69lgwYNYunp6SwvL4+deuqp7PHHH1eEgGqFs996662sb9++LCsri5166qlsxYoVPiHCzzzzDBs9ejQ7/PDDWUZGBisrK2O33XabN+yzra2N3XbbbWzEiBEsLy+P5eTksBEjRrCnnnpK0U+j4eyM8VD1P//5z6ykpISZzWbWp08fdsUVV7BNmzZ5l5k7d643weFRRx3F5s2bpxmq/eOPP7LRo0d7Q1gDJTB84okn2FFHHcXMZjPr3bs3u+GGG3QTGKrRCyFXg84Ehlrs2bOHTZkyhfXv39977GeffTabM2eOd5lA10Tw7rvvsmHDhrH09HR25JFHskWLFhkKZ2eMl24oLS1lqamphsKc33vvPXbqqaeyrKwslp+fzy688EJFAkPGggtnv+eee9iJJ57ICgsLWVZWFjvqqKPYvffe680YLFi0aBErLS1l6enpbOTIkeydd97xm8DwoYceYv3792cZGRns9NNPZ6tXr1Zs74knnmCnnXYa69mzJ0tLS2NFRUXswgsvZB9//HHAPgfD8OHD2YABA/wuc8YZZ7BevXp5sxFv27aN2Ww2VlRUxDIyMlhpaSmbMmWKIoHhL7/8wqZOncqOOOIIlp6ezvr168eqqqp8UiSoCSacXS/Jpfz/JWhvb2f33XefN6Hi0KFD2aJFizS3u3btWnbOOeew7OxsVlhYyCZOnMh2796tWEZcS60UFa+++iobOXIky8jIYP369WN/+ctffO4XwZNPPsn69evnk7DR4/GwW265hfXs2ZMNHDiQzZ8/P+D5IILDxFiUPDEJgiAIgiBiDPn4EARBEATRbSDBhyAIgiCIbgMJPgRBEARBdBtI8CEIgiAIottAgg9BEARBEN0GEnwIgiAIgug2UAJDFR0dHdi5cyfy8vKCSptPEARBEETsYJ0lXYqLi5GSoq/XIcFHxc6dO9G/f/9Yd4MgCIIgiBD46aef0K9fP935JPioEOn2f/rpJ+Tn58e4NwRBEARBGKGlpQX9+/f3juN6kOCjQpi38vPzSfAhCIIgiAQjkJsKOTcTBEEQBNFtIMGHIAiCIIhuAwk+BEEQBEF0G0jwIQiCIAii20CCD0EQBEEQ3YaEEXza29vx17/+FSUlJcjKykJZWRn+/ve/gzHmXYYxhrvuugt9+/ZFVlYWxo4di/r6+hj2miAIgiCIeCJhBJ9//vOfmD17Np544gmsX78e//znP3H//ffj8ccf9y5z//3347HHHsPTTz+NL7/8Ejk5ORg3bhwOHjwYw54TBEEQBBEvmJhcZRLHXHDBBejduzfmzp3rbbv88suRlZWFRYsWgTGG4uJi3HrrrfjjH/8IAHA6nejduzfq6uowYcIEQ/tpaWlBQUEBnE4n5fEhCIIgiATB6PidMBqfU045Be+//z42btwIAFi9ejU+/fRTnHfeeQCALVu2YPfu3Rg7dqx3nYKCApx00klYsWKF7nbb2trQ0tKimAiCIAiCSE4SJnPzHXfcgZaWFhx11FFITU1Fe3s77r33XkycOBEAsHv3bgBA7969Fev17t3bO0+LWbNm4e67745cxwmCIAiCiBsSRuPzwgsvYPHixViyZAlWrVqF+fPn48EHH8T8+fO7tN0777wTTqfTO/30009h6jFBEARBEPFGwmh8brvtNtxxxx1eX53hw4dj27ZtmDVrFqqqqtCnTx8AwJ49e9C3b1/venv27MHIkSN1t5uRkYGMjIyI9p0gCIIgiPggYTQ+ra2tSElRdjc1NRUdHR0AgJKSEvTp0wfvv/++d35LSwu+/PJLjBo1Kqp9JQgi8ng8se4BQRCJSMIIPhdeeCHuvfdevPnmm9i6dSteffVVPPzww7j00ksB8GqsN998M+655x68/vrr+P7772Gz2VBcXIxLLrkktp0nCCKsVFcD6elATQ3Q2uorBHk8wPbtsekbQRDxTcKEs+/btw9//etf8eqrr2Lv3r0oLi7G1Vdfjbvuugvp6ekAeALDGTNmYM6cOWhubsZpp52Gp556CuXl5Yb3Q+HsBBHfVFcDdXW+7Q4HMHcuF4Zqa6V2lwvIzo5a9wiCiBFGx++EEXyiBQk+BBG/eDxc06OHywXk5Pi2WyzAunWA2RyefjidXJjyePg2w7VdgiBCJ+ny+BAEQZjNgM2mP//GGwGr1be9oUEyjQmzmMdj3E/I4+EmNYALVoWFfHs5OfyzqorPdzq5ia2pSVqeIIj4gjQ+KkjjQxDxTSCtjxGsVkCU8bPbgSeflDQ4Ho/0HQCuu07btGYEoWkS/SbtEEFEDtL4EATR7bDbjS0nr11cV8c1N3l5khanoIB/T08PXegBJE2TXDt09dWhb48giK5Dgg9BEAmF2cwdmQGgslI5b84caV6w7N8vfY9k5ZplywCTKXLbJwjCPyT4EASRcMydC7jdwMKFkqDjcCjNSJWVfBktn59QKCvjn1lZUpvDwffhcvGpuRnYtg0oKQm8vV27tEPxCYKILOTjo4J8fAgi8RD+M2r/H70or0CYTIB4MsojwsR+WlsD++sI52axjMcj9cVk4tsVJjcRik8QROiQjw9BECGTaFoIIVzIzWBqDZAcl0tazmLxnc8Y0NjIl6uvV24f4M7PgZyUs7Ol5cxm/p0xYOdOblaT+xnV1irPudPJI8NEhBjAP53OxLs2BBFvkOBDEN0Uj0caSMVg6nQqsyKLQVcLf/P87TPSA7cwg82dqxSEhIDjcHAhRCwnoq7k5OUBPXtGJvFh3758u3ITnBDSPB7uWF1YCBQVAQMH8k+TiX+KMPqamvD3iyC6CyT4EEQ3w+PheWfS06WBND2dD7yFhVIUU20tH2y1QsfT0/XnqfclqKmR9hXugVtoQwRybYwQcOrrJYFIvpyWILZvX+QFtI0blc7ZQuA04lhdW0t5gggiVEjwIYhuhBB4FizwnXfokPY6Ho9Su9PUpEwCqKf5UdfTkpeRUJt2uoIQwgoLubZEC7WpSmueHH9msnBRXQ0sWsS/19YGHzafkwNMmhT2bhFE0kOCD0F0EywWbYHHCNOnS9979lQKEj17+i4vr6dVW8sHabkvTbgEC7kQBnBtiVzzYwS1X5BaKxQJPB59Qcdu59FhFRX8d0UF9w1qaPBddtEigGIwCCI4KKpLBUV1EcmEiEKqqtIWeuTRS4Fwu5XCSlOTttBjJLNysFFM8qgttcCUni4JP/n5wQs+6n1EA6eTa6gEZWXApk1c6Jk3T79PBQXaprDmZn1tF0F0FyiqiyC6OcKnprpaX9NjVOix2XyFAi2hB1BqUPTQ81HRMn+J47Batf2D3G4egdXcHLrQA0S3lERBgaSpycvj2hy3Wyn0aPXJ6eTHKXIKAXw7JPQQhHFI46OCND5EMhBsPaucHB66nZurzGAM8EFWy8xipA89evhuT47NBjz3HBeCbrmFC0QOB/D009p5eQRq7VOi4nSGLrSI5Ick9BAEhzQ+BNGNkDsbA8DkycGt//PPXMBRCymlpaEJPQJ/Qg/ANVEiukw4P9fWSpoqLez22Ao94Yz26orQkp1NQg9BhAIJPgSRwHg8kimovFwSGOQRVIEQYeybNvnO+/TTrvWtK9TV8crocrOZ2gcmWLpaIkKc66qq0LdBEERsIcGHIBIUES4uhByRCVgeLWS1ahfEzMuTvusJAiYTT7YXKuHQytTVKcPsU2RPrGDz2FitUoX0UPIIeTzSuV6wgG+PsigTROJBgg9BxCGBBlR5uLg/6uu1HZj37ePaE0ByshWfdjsvq9DRYbCzOhhxcjaC3DG7tpYX9ywr40JMebn+evJzWFWlNNmFkkfIbFaG5Dc0UBZlgkhESPAhiDhDmFP0BlR/OWAGDjS2D4eDm4zcbu5g63LxTxFZ1BVNjxyRNVlULg8HxcXA5s38e329tuZHfg5bW32j2tRRakZKaXg82v5O4UzGSBBE5CHBhyDiCLk5RT6gygdWf5qUbduk73ITV1oa/8zP54LI008rc8SImlShmqf8DfyiQGdBgdRveZ0qgEeTCaxWSRtlBLWQpj6HWtXZxfkAjJfSUJ93oSGLRpbnYCAhjCD8Q4IPQcQRZrNy0J88WVsDJDQp/kxJchOX8JNpaeHrGK2ZJTQhWgKYaJeXpgiE6PcPPyjbf/1V0gz98INSo2Wz+d+mVrZmI3mERP/1SmloCRCffCJ9v+SS6GR5DoZA2kKCIAAwQoHT6WQAmNPpjHVXiG5GYyNjNhtjXGTRntxuaXm3m7GyMv/LA4zZ7YG36XJJ22SMseZmxhwO5XJiXxMmMFZZGbh/gRDbdzj8z3O7Ax+j2IY4VoeDH4O/dSwW322XlvJzIY7Pbpf65HJpbyPWuN18Uh9vc7N0XQmiO2B0/CbBRwUJPkS0aWxkLC1Nf4C2Wn0FBC1hRm8bLpevECOf8vOVn2ZzYEFDb2psDO7Y/QlKYp7bLQmEFov+vtVCo9stnTu9yajgKNDaXjiEC73zEEiQ9Hdd40k4I4hoYHT8JlMXQcQQs5lXFterjA5wB16XSzKp6EV0jR/PTS9yE5gI4ZabaNSI2k/iM1QfEb2CpYHW8TdPmG4WLOARVV9/rVxGlG5QF2AtLeXrq01qarRyF6mpq5Py/2zcyMtjaBHseROmNnlpEfk21GYruQlO9MdIvqaGBh7VJtYRZsHW1uBTAhBEUhAlQSxhII0PES0qKoxpUeSankBmH/nbvZZpRmvKy1NqfPxpn7S0IW538JoeIxgxcWkdh5hyc301IoFMiXrnVHyvrOT9Em1WK++r2I84H3JtlRb+NDV2u6/ZSpje5H3pimbOZFJqvVyu4MyU8YzLxdj69bHuBRELyNQVIiT4ENGgsdF3MLriCu2BWW5qYUw5yGoNoHLTi5ivNtHk5iq3rfbxKS31XV4Mjjt38oE50gNlMIJPTk5wwpq6TQg0WtdFb7LZpHOnNV+ccyEMifMXyPdIT5CLxiR8qhIV9X1OdC+Mjt9UpFQFFSklIk1BgWRWEuTkAL/9xk0RWuHX6qKc8lB0jwcYMoSbNKxWbo6RI5aVm0qys5Xb0KK1lS/XlUKaXaWmJrjyG3pYLPz8OBzA44/rn+PDD+fJHeXrHX88sGyZ9nbtdmOJJBMNeaHYRKG11fe6FhdzU7FI10AkN1SklCDiEKfTV+gpKwOuuor7c4wY4buOVlFO+W+zWfIDUgs98mXNZimnjnobWojlYlkIU4S/i8nl4p+VlcbWdzgkoQfgvk45Ob55hBwOPnDKhR6Ar6cn9ADxKfQEel9rbg68jCgUm0hh8dnZvtd1587AGb6J7gdpfFSQxoeIJFVVSifc5mb+wE5P116+shJYtIgPzPGULyYeEE7eeXm+AgvAz63ZrK3dAbgQBfgKhv4czeMJoZW57jp+HqxWqV6bPxobuRO608k1XO3t/pd3uYxpCOOFpiYeMKBGHAeRvJDGhyDijOpqpdBjt3NtiroGlJxFi/gnlUXwRZTcaGmRkhyKZ53Vys9tdrb2uXU4gBtv5ELR0KFc8LRagxd6HA7eh+ZmSQuldy1tNmWGaj30tFlyAc5u54Kw2czPg8tlTOiRR94VFPDjHTRIf3mLhe/XYpE0QPF+H+oJZzfeGN1+EHFMFPyNEgpybiYigZajrnAi1UsGqLc8oY3brZ8UUTiNC+fdQI7TeXnSdZFHuYlIKqtV+3rIE0DKt9fczNuN5FNyOIzl51HvX530UT1pRd4FGzkndxCPZ/Qcw+k/lNwkZVTXjh072MSJE1mPHj1YZmYmGzZsGFu5cqV3fkdHB/vrX//K+vTpwzIzM9nZZ5/NNm7cGNQ+SPAhIoU6WV5jY+AEevIBm/CPehBXD3J6gkKwkxBiAiEijETIu5aQsW2bdqSXXGBZv9644BHKwC7Og83G1w+U6Vt+b8Yz6shEivRKfpJO8Pn111/ZwIEDmd1uZ19++SXbvHkze+edd1hDQ4N3mX/84x+soKCAvfbaa2z16tXsoosuYiUlJezAgQOG90OCDxEJ1IOJkVw5IicPvaUax18ZDC3kWiKhcQmnpkOkCWhs9BUq1H00UsIjUtoWIWSJ/hrNdyT6Eq/3qN5xJFPeIkIi6QSf6dOns9NOO013fkdHB+vTpw974IEHvG3Nzc0sIyODLV261PB+SPAhwo36TT8lJfHfpuOZUAY0sY7LpT9Yhipw6CUaFJogo32XJ0YMN3KBLNj8QWLdigou4MWbUOHPnEea1OQi6UpWvP766zj++ONx5ZVXolevXjjmmGPw7LPPeudv2bIFu3fvxtixY71tBQUFOOmkk7BixQrd7ba1taGlpUUxEUQ4ECUJKiqU7R0dyt8DB3LnWHnY9vz5Uetm0hFK5JFYJzubn3vhsMwYj4Jyu7kTcbA0Nek7A9fX+5aMCFTCIxJRVeoSKFoRcnJcLu5cDSjzGC1ZwqOpcnK4I/TEieHvayiYzfz6aVFbS2U7uiMJI/hs3rwZs2fPhtVqxTvvvIMbbrgB06ZNw/zOEWL37t0AgN69eyvW6927t3eeFrNmzUJBQYF36t+/f+QOgug2iDpL6enASy8p56kHr23bgBNOkAa2RAgZTnbMZil/Uc+eoV8Tf+tarbEPr/Z4fHMR+cvi4XDwPouIuiefBCZM0F52yRIgNTVsXe0SZrMU+SentJQLapMmRb9PROxImDw+6enpOP744/H5559726ZNm4aVK1dixYoV+Pzzz3Hqqadi586d6Nu3r3eZ8ePHw2Qy4fnnn9fcbltbG9ra2ry/W1pa0L9/f8rjQ4SMx6Ofl8cflGckeWlqkgQpp5Nf53i41rt28ezGgoYGnlDT4wEmT5ayZpeVAevXK4W48nJjIfSpqfGTG2nQIP6ioUVubmBtFxHfJF0en759+2LIkCGKtsGDB2P79u0AgD59+gAA9uzZo1hmz5493nlaZGRkID8/XzERRFfweKTq6Gpyc6U3T3mW2Xh4+ycih9D8iDw68XKt+/YFTCbp93338U+zWcqa7XJxgUgu9LS2+go9epqf9nYu+MUDW7fqz9u/P37Mc0RkSRjB59RTT8WGDRsUbRs3bsTAgQMBACUlJejTpw/ef/997/yWlhZ8+eWXGDVqVFT7SnRfysu56lxt3hLs38+TGFosvLyEGFi0Sk0QRDSQKbx9EmXKS5zI0TLfPf00v58bG5XtqalS0sR4wJ+NY8kS7vNEJDcJI/j84Q9/wBdffIH77rsPDQ0NWLJkCebMmYMpU6YAAEwmE26++Wbcc889eP311/H999/DZrOhuLgYl1xySWw7T3QL5G/BgXzkGxp4+Qq9gYUgooXZLGkoHQ5j/kxaPjNyjZbQZpaWxo+ZS44oV6JFXV38Z6cmukbC+PgAwBtvvIE777wT9fX1KCkpwS233IJrr73WO58xhhkzZmDOnDlobm7GaaedhqeeegrlQVSoo1pdRFcQfg/5+ZLwY7cDc+YA11yjLFkB+FZdJ4hYEUotLquVC/FWq6/WsrU1voV6fz5K9L9MTIyO3wkl+EQDEnyIriIe+OKtUf4A9XgkAYgKjxLxjFFBKN4FHH+0tgK9evlqgMTLioCEoMQg6ZybCSJREIOAVmi62SzliSGhh4hXRDqGqirfeSI/lRDs5UJ+opGdzf3u5AVgAW7uEukoRHFWInkgwYcgYgC9QRLxiscjhbEvWMD9dATy/FTp6dwRWLQlsnCwfz9PJKqH2umbSGzI1KWCTF0EQXR3qqq0/dEC5adKZN+YQPm3KM9W/EOmLoIgCCIk5s8HSkqUbVdeKZWq0OO666TviVYKwmz2f3w33hi1rhARhgQfgiAIwofNm5W///1v7vtis3HNjpaQUFfHBR6RzyqIgNq4YN48oLJSe15tLc+6TSQ+JPgQBEEQmjAGXHyxsm3BAh6ZqEdOjhQmrlWINd5ZuJCXttCisJAnHyUSG/LxUUE+PgRBEBKtrb5RT8GQqL4x8lIeanJyuEM0EV+Qjw9BEATRZbKzQ9dyWCyJKfQAXNsl6o+lpSnnuVz+BSMiviHBhyCIkPF4uEZg1y5g+3YK+U1W6ut9S1QYYfXq8Pclmixdyv2ZPB4gK8t3Pgk/iQkJPgQRIlqD/KZN/LO1VUrylmg+DkZobeWVrNPTudq/uJjnQUn0fC6EPiLxZkMD/xQFdvUsCoMGJa62R44Iz29tBXJzfed3xQxIxAYSfAgiBNRJ25xO/vZnsfDPnBwpyVtODm9PRG2I6LMQ4pxOKWJnyRLtdSjZW/JiNgNlZVJW8uxsfk80NyvNPyYTsGVLTLsaEfbt8xV0WluBSZPonk8kSPAhiCCRZ7atreVvvIWF/tfZtCn+tSHyB7fHw5PYpafzApRCiCss1C/sKDBa4ZtIHgoKuBDU0QHs3Mk/k5WrrvJtW7SI/z9IAEoMKKpLBUV1EYG4+mpg2TL+PSfHt8BhIOIpu60oRFldLeVoSUnh341iMgE//8y31bdv/BxbvKFVtJZILAJldxbY7TwnEBFdKKqLIMKMMGcJoQfgQk9ennI5h4O3ayV4iydtiDDXWa2SoLNgQWChJzeXH19jo/R237cvMGBA/BxbvCGvcVVdHeveEKFiNvP/cCDq6ug6xzOk8VFBGh9Ci4ICoKXFt91qBTZu5EKR0+mr8ZBXsdaq1h4rjL65qikr486thHG0zjVpBBIbpzOweRvgvk8FBZHuDSEgjQ9BhAmnU1voaW7mQg/AH25aGg/hAJqdHT9CTyjYbFzLQ0JP8JjNvqHgdXU8BQCRmBQUKKvW60GZnuMTEnwIIgQcjvh4k9u+PbT1/Kns5bWKRF2m+fOTIzQ5VmgV/Swu5onxyBk2Mdm0STuUXf1ysGmTMSGJiB5pgRchiO6NWlMTL+prefK0UAzWBw9qtz/zjBS1lshaqnhj82Yu6LS3S23t7dwMVlnJa0QRicX+/dzHT16+Ytw43+W2bOHL7dsXvb4R+pDGhyACkJ3NfXkA/hkPQk+/fsrfepoftTZB/M7L087DU1YmmeVI6AkP8mtw6JB2tt9Fi7jTOGl/Eo99+5TavE2bgIoK3+X27+dJP4nYQ4IPQfhBDEQbN3IfF+HTE0vMZh4+LqdvX98s0eokiyIvj8WiXWDRYiEfnnAjroGI8PF49LVzLlf853oitNmwQfl7yRJt354lSyjaKx4gwYcgdFAPWkDsy080NXGtgZyKCmWW6PJy3ySLJSU8VB2QymoIKiv5oBsoMSERHPJrIMKb5b5VlZXA+PG+69XWxv4+I4JDy4G9oYGbxdXU1dH1jTUUzq6CwtkJwDcEWW6ft1hiKyQYKYzocgEjR/rvZ2UlH2TJpBU5RGJIgUheKRJHAtx8qqVpcziAuXOj0k0iTKivpd0OfPaZ9v+Qrm/4oXB2ggiR1lbgqKOUbXKnxIYGbjaKBUbU5ELFrif0pKXxAXjhQhJ6Is28ecpElpMn80/5ea+v54JqWZlyXaH5Ie1A4qCuRl9Xp/8/pJp2sYMEH4KQYbVyc9Hmzf6XW7Ag+g8tjydwVmWbDTjlFP2K0aWlSm0DEXnmzJG+6w122dlcoHa5JFOYuBdzcvj31lYaKOMdeSAEwK+l2gQmZ/DgyPeJ8IUEH4LopKrKv3OvPBdHLEpPaOXeEeUyrFauxfn0U8mXR052Nh9U1f49ROzQE4DmzvX1uWpo4AIQlbyIf0QghNvNr+Vjj+knMdy0iTR6sYAEH4IAH4S0BAY5mzcrH2ixYO5cvn8xtbTwPv3wA3dq1tJUlZXxZSgBYXzg8Sgj7sTAJ9foZGdr13oDqA5UIiBSQhQU8OzNe/fy/2BWlu+yJPhEHxJ8CALGiw/GQ34b0QcRvn7ttXwQ3bpVuRyVmYgP5PeWMF/JI+5ycvgyco2Ox8NNZHpmkro63/QFRHwhL3XT0sKvlVaZklGjotsvggQfgvAyd652+KlgwoTYCz2C8nLJ/0MrEaHdTmUmAuF0Rs9nRst8JUeeoqCuTkpPkJKiL/wMGSKlL5BDfkDxgfq/V1QETJvmu1xDAwmw0YYEH4KQUVCgb49//PHo9kULj4cP2HoDaGoqN4FR5W//CBNENBIGiqza2dmS5sfh4NcpUAHLujrJBCtftqxM0uTV10sDZ3U1P6aqKn6fELHDbPY1Vy5Y4Bu9J7KlE9GDBB+CUFFfr/2WXVSkzMAb7TdrMagVFmrPr6jgmoN40UrFK3ITBBDZsGKTCRg4UMq9JHy05s7l10nvXtNCRH0J86W8jEp2tjJn0IIF/D6Jh/Iq3Zl585RFfwHgiy+Uvzdtomzd0SZhBZ9//OMfMJlMuPnmm71tBw8exJQpU3D44YcjNzcXl19+Ofbs2RO7ThIJy/z5fIBSJwusq+MDjTBFROuBpU6EJ8dk4n1dvDg6fUl01IKhzRYZYVFdP038Vu/rueeMbU9EEgrtgIge+uEH/VQHLS18YCXtT+xYuFDS1uXn8xcoNZTTJ7okpOCzcuVKPPPMMzj66KMV7X/4wx/wn//8By+++CI++ugj7Ny5E5dddlmMekkkOmYz0Nbm2y53Fo7GAytQ/p79+5WDaTL6C3g8vFyHONfis7VVGtSNDu7yXCsWCxdyI8GAAf5/B8vHH/sK2zfeyNsmT9Z3zrdYuPaHEtHHjvp67j8o1zTKGTSINLXRJOEEn/3792PixIl49tlncdhhh3nbnU4n5s6di4cffhhnnXUWjjvuOMybNw+ff/45vlDrFgkijOiFHYcLrYgzoYkSZg6BcHpWO7wmMiL0u6iIf5aX88/8fH6shYX8fIjBXU/wkwuoQlsS6dIjjAHbtukXJgW0fUG0EAK3ELZbW5XRYQ8/zDV/etvat49XByftT2woKNC/Nlu3ksYnmiSc4DNlyhScf/75GDt2rKL9m2++gcfjUbQfddRRGDBgAFasWBHtbhJJgtnsa6NXs2SJNBCFO8RYPAzVhUkZAxobldXiW1ulgVzu8JrIyAt9CsQxysuICPbt48KQPNkkoF1wNlpv2EY0PfLszoGw2biGJydH0uKkpXHBb+hQHgkmUJtqlywh359Yoi5hIqisJI1PNEkowWfZsmVYtWoVZs2a5TNv9+7dSE9PR6HK87N3797YvXu37jbb2trQ0tKimAhCzsKFUoZkLRwOPuCIPCxC4yIED+EIHewbnRis8/O1kyvedpv0vbXV98GZDA9SLW1XoEgoANiyhQ/6QhiVV0mvqlImEIwH5Mdpt/vPKTV7tnQ84nElBOP6eqWgyBh3eldXgW9p4aZDIvpoCbnygshEFGAJwvbt21mvXr3Y6tWrvW1jxoxhN910E2OMscWLF7P09HSf9U444QR2++236253xowZDIDP5HQ6w34MRGJTUcEYH0qUU3OzdjvAWH6+8rfD4btdt1u7TW+b8sntZsxi4d+tVr599X7cbu19JBJuN2ONjdJx2O38OG02fv6tVv1zVFoqLa93DuMB+XXSu/4Wi/9j9Tfl5Pi2ad2PROQR/9N4vA8TGafTaWj8ThjB59VXX2UAWGpqqncCwEwmE0tNTWXvvfceA8B+++03xXoDBgxgDz/8sO52Dx48yJxOp3f66aefSPAhdKms9H1gWa2+Ao6/yeWSBjktQYUx5YPRbJYGPSHkiHVsNv1tu93KAT/ZBjn1QOFyMZabqz/oawmu+fmx6bsa+X3gcinbyspCE3SMTs3Nyr6I/RORo7HR9zrY7bHuVeJjVPAxMcZYjJRNQbFv3z5s27ZN0VZdXY2jjjoK06dPR//+/VFUVISlS5fi8ssvBwBs2LABRx11FFasWIGTTz7Z0H5aWlpQUFAAp9OJfAqDIFR4PMbU0qKkhJqyMv1CoW63tJ56H83Nkl+G3KylXq6sDBgzxtcvRr2PZMbp5D4wy5YZW17UMZNfr2ieI63r3a+fVHfN4+HmU4G/eyhY8vO52ctq5f5i5eXcXCZ+E5FD7X8FdI//ZyQxOn4njI9PXl4ehg0bpphycnJw+OGHY9iwYSgoKEBNTQ1uueUWfPjhh/jmm29QXV2NUaNGGRZ6CCIQRiJwmpv5A8zl8l1Wb8CSV3tX+7U4HEpnVFEA0Wz29d3YtElf6OkuFBQAS5cai5SyWPj5FD4/0c7PBGj7Me3YIYWpy8Pv8/PDI/QInzXhI1Rfz31+ks05Pl4xEnlIRI6E0fhoccYZZ2DkyJF45JFHAPAEhrfeeiuWLl2KtrY2jBs3Dk899RT69OljeJuk8SGMUFWlX829pARYu1b6LX9b10KuzZEjHoKB3gC13hy1cDhiV1U+2hjVzAE8SkrrWkb77dvj4dFoO3Zo98Pp1M/aHQirFWhv51okPY2R282d9EnjE3laW32fC/IyJERoGB2/E1rwiQQk+BBGufxy4JVXurYNiyU8uWS+/x5Q5fMEAOzcCfTsyb8bHcQ9nuRQt9fUcO2XntkxEDZb5JIb+kMuyKqFVXFMXcFm4yHvIgt5fT3fz+OPc+1SU5N0zxCRYft2XspETXd6OYkESWfqIoh44+WXQ1tPmC1stvAl0OtUevpQXMyreBsRZDwe7Xw3iYqoi+V2c62akTD41FTp+4IFsTE9MAasWSPV9JIjjsmfGa+5War/pXXMCxZwocduB04/nbe99JKUjqGoiN+jP/7Y9WMhtNH7P1LpiuhAgg9BdAHGuHraX6HJCROUv+vruf9PuLQJWkn+5DQ0BB70hcAjz3eTDMKPGGAKCqTzXlGhv3x7u5SwUu53FW2GD9fft9nME+EJPzK5oCP8webP54JNQwMvh6BFXZ1vPiAx6DY0AIMHGzejEsFxxx3a7VZrcmhb4x0SfAiiiwwYoO/vAwCZmb5tN94Yvv3LnWMdDknLIRd2Nm1SJlRUf2oJTnV1yff2mZ3Ni7mqMzsLysok36COjvg+frOZ30eFhdL99/HHUtJGUd9t61bt9R0O6b6RZ4BWQ5qf8OLx6D8v6uvj+55LFkjwIYguohY8GJO0PHa7doHRcKu0hQlk7lwp4qu+XnKgzM/ng351NR/YRYX5mhrtqCIgudPob9oE5OZqt8u1XvGU3VmNlsDa0MCv+ZAhvstPmCBpicS9Iu4bp5O3ezy+2sujjorcMXRH/P3vk/k/F0+Qc7MKcm4mQkXtFCx+6zmkivwxkcJqVUaJ6EUviX7II9Vyc3nV92R3tpw4kdevCkS85lfx5+wsv955efqVwbXweLgQSEJP+NGLOMzN1a4/RxiHorpChAQfIhKIt7whQ7gwEulwYa1wWX9YLPqhtG43/9SK9hK/5fMSLSrMX2oCQWlp+JIGhhuPB7jmGuUxiPtLFM2loqTxw6RJwKJFvu3xKlwnEhTVRRBxhNz85HJFPkeKPOkdoPTn0MJf/pChQ6Xiq/Ikf8IMJByjq6r4Qz3RosKEI7A/Nm/mxxePmM38GIRvl/z+MptJ6IknPB5tocdmI6EnmpDGRwVpfIhkQbzti0zPou2667T9jgAu3Lhc4dm/3c6jjxIFLc2JmmR9K080LV0ik5/va9KKtNm7u0AaH4LoxggtTGEhL3sgCDS4uVzKXDaAFPETLIkWFSY0J/7C3UXEVDKhzt2UbMcXT5SWavvxkNAZXUjjo4I0PkSiIt7atZwn/RVADTdpacChQ6E5RgsNlVENRKQ0FeKtPC9Pe6CKVVbncKO+H4SvV7I7tceCvDweMKBFsmoSow1pfAiiGyHC1PV8a667jn/qFVm1WJQh+eoiqep11MVR5TCmnXU4EOXl3NRWUCAdi1z7IM871Noa+Ji7QksLTwzY0qKt8VqwQOlDlahkZCh/C1+v2loqUhpOnE59oSeWiTK7LYxQ4HQ6GQDmdDpj3RWCMITdzhgXN/hktzPmcCjbAMbcbj7pzWNM+hTf5b/FfhwO7f3KpyuuCO4YXC79bTkcUp+tVu1l7Hapvy5X186nHLdbv18AY42N4dtXtNm50/+xAYzZbOE9n92V3Fzfc1tRofx/EV3H6PhNpi4VZOoiEgm9sHWXS9lusQCjR2vnfAkmx4tWriKPB7j2Wt98OEa2K9foiFD/cDhYhzNdQHW1vjM4wM/tihWJWdjTaEkKqtYeOlddBbzwgm87mbfCD5m6CCLJqanhQkKKxr9YbaZoaNBPdLdvn3GzhlYeH1EGQl0PbN8+4Oqr9Z1lhVOtmISZxeXyrVAuTG9GzUv19eEz1cyb59/huaGBF/ZMxEGMMWP5nsJ5PrsT2dnaQg8gmZ+J6EOCD0HEOUJwEBFFTU3KcgUdHcrl8/O59kHup6Pl1yOEC6s1PKG0IkdRXp7UtmyZ5IcjHzgDFVZlDNi507e0wsaNyrIL4lOdoyhcxyRYvDjw9g4d4oJeorF/P/dn0hKgBXl5iSnYxZKUFODAAf35iRb1mEyQ4EMQcYzQihQUSAkEi4p8nVIBHirb3MwdKQEuLAiBJyXFVzgQRu7TTw+tb1oP7exsbt5SV6Svq+P9F1ohj8d/QkWzGejbVznYiu9CyySSQprNkmCkTuAXToyY35Yti99Eh/4oKOCV6dXXTbBvn7JuGQ3Y/rn6aun/RcQfJPgQRJwi14qofWW0Hqo//qjM0iuv0F1bCzz9tPbgbSSCRz3QCYFMXsBTHnWllwRw0yYuqOTkAP/7H9DYKE2iOGZFhVQmQ2vfwq9IZIkW5jThfxSpRHBGB/sFCxIrc7WcpUv9Z7GureWCXXo6911paopa1xIGj4cLwIGw20mLFjOi4mqdQFBUFxFPiGim/PzAEThaESJifRGJ5XbzaBK96Cl1JJd8G3Y7j2JSR2DJI8VE1JXNFri/gY5Fvl2bTT8iTT5ZrZG7FoEivNSTiIZKxMgdI+daTGZzrHsbX+hFKKojuxLxvoh3jI7fJPioIMGHiDYul/+HoBhAm5v1H6ZCsNFCbLuyUhJgjIQxi3UDCRp6y1gsoQs+XVk3kuHXRs6d+vwA/Nwn4kDndjM2aFDg44y3sP6Ghujuz+Xi6QH0hEW7nS8nXgj8/V+J0CHBJ0RI8CGiiTwvjdbDUJ47R0/A0BvohdbE7WYsL8/3QWxE+DDy1t/crC2oiJw6Yp7FIglfkZoiqfFRX5NQJiFQJhr+jiktLda94zQ3+/5HIo3LxVhZmf65Efml5CSiAJwokOATIiT4ENFCSyUu1/6oB9hAyQfl+BNYhPahKwO4mNQClZ4QJxfOurJfh0PaZ06O9KYd7sSFgXC7+UDrcvFPo2YhgGtQEhF/mp/Kytj1y+3m94JWv7qi+dG6n+T/NX9aSfGiQkQXEnxChAQfIprovS2qNSNCVc6Yto+NHH/mqbQ04/43Fouvb5FWBlr5JHxxAiHXRrnd0vFOmOArGJWU+JoDm5vDc/7DiZZmzd+UiPi7d4QgGk0CCZxGEYKz0BqVlkr/ASHkimO32fTPg8lEAk8soczNIUKZm4loU1YGbN7sfxmXS4pWUmdrls8T1NT4z5MTiMpK4JlnjCW3EwSTAVoLeVZoEaUFRC5KKxIEUwR2/Xp+7RMtssfj4cn39LJZl5by6L1o9EPvXA8aBGzZYmwb/o7FKGVlwCef8BQMROygzM0EkQDU1AQWegAugIjQ8exsKYOxXqK+hx8Orh92u5RXx24HFi7k21VnY/bHvn1dy++iztmTnZ1YQg/A+y3PT+Qv0/TgwVJKAKdTyr8U75jNPJu12w3k5vrO37wZSE2N/PGozzXA712Xy5jQI1IydFXosdl49m4SehIH0vioII0PES2C0Q4IRH4bs5lrfrKzpRw8QkgoL+dZlI1it/OBTPRJrYGoqpLy8jgcPB+QxwNMmaIcNByO4CuyJytCADSb+Xe73beWmRb5+cD33wMDBkS0e2Fl0iRg0SLtebm5XAiJZB0zj0f6LxjVnoXy35NjtQI//MC/J5rGLpkxOn6T4KOCBB8immiZpNLSePkDLcQ8hwN4/HHg6KMls4LVCnz3nXHzVH4+T0Bn5MEtH8i12rXmEUry87lWDJAEIn8k0pPZ4wGysnj2Zy3S0oBdu+KrkKvFErxJzmYDZs9OPE1kd4FMXQSRAPzzn75tV1zBMxlrIQSi2lou4Mgf3ELLIzeDiSy8cpOL3S6VtjAqrIjSEHrtJPQEpqWFn3dRWkN813s+b98env1Go7yE2czvTb1irocO8VIrKSlc2I51wdNghB5h7rXbgfnzSehJBkjjo4I0PkQ08adyT03Vf4PWwmKRhB+h+hf7kGsYSEiJP4Q/TGGh1BaOJ7PQKFZUAA8+yDUukb7+Hg/3XwokWFitwOefS2VWItkv+f9BbroNhDADa5mA1RhZhogsEdH4HDhwAJ9++inWrVvnM+/gwYNYYPRuIggCgLaDpiAYocdmU/r1yN9K5cU96cEcnxQU8IkxYNu28Ag98lpvS5YAxcVcyK6u5oLWrl1cqxTuCCyzmTv7Njf7X66+nmuB0tN96751FaeTCzutrdznLSeHf/qrI1daKhW5FYgK6oH+N1q164j4xbDGZ+PGjTjnnHOwfft2mEwmnHbaaVi2bBn6drqy79mzB8XFxWgP5mkdh5DGh4gFHg9/WPfqZWzQy8/nAxdAAg2hjdOp1CAForEx/D44QuNUWanvAC3H7Q7tXpZrM/PygP37tZdzuYAbb5QEwspKHsEo1wjJ+23EYV+ttQ31GIiuE3aNz/Tp0zFs2DDs3bsXGzZsQF5eHk499VRsD5chmiC6MWYzH3Q6OoCdOyXfHOFf4HBIb6PCP0eEe9NDltCioEDff0gLoX0JJ3Pn8vt24UIu0K9fr+8HFGy1co+H+wtNmiRpjfwJPSL1g+iT6Bfg67cjlvEn9LS2StqgK67gbQ4H/R8TAqMZEXv16sXWrFnj/d3R0cEmT57MBgwYwDZt2sR2797NUlJSgk20aJj77ruPHX/88Sw3N5cVFRWxiy++mP3444+KZQ4cOMB+//vfsx49erCcnBx22WWXsd27dwe1H8rcnCi4GGPNjLGGzk935xTl1LERRGSApUywRFdobuZFRHfuNFYuJBoFR8U9XVHhm5ncCMGUCLFaw59R2l+5CiJ2GB2/DWt8Dhw4gLS0NO9vk8mE2bNn48ILL8SYMWOwcePGCIhlEh999BGmTJmCL774AsuXL4fH48E555wDl8wg+4c//AH/+c9/8OKLL+Kjjz7Czp07cdlll0W0X0S08QCwAMgBUNj5vRBAeueUA6A8Rn0LL3LfHIIIlYICrk3s21dKPNjczDWL27ZJ2gpA0jxGGnFPL17M+yPySBlB7rvkj5wcriHduDE8kVjbt0sapoYG/eV+/LHr+yIii2EfnxNPPBE33ngjJk2a5DNv6tSpWLx4MVpaWqLm49PY2IhevXrho48+wujRo+F0OlFUVIQlS5bgis5/8o8//ojBgwdjxYoVOPnkkw1tl3x84pkqAEYd6F0AKO6UIIwgfMziKc+OPwKVZMnJ0Td5hYLJZHxZipOOHWH38bn00kuxdOlSzXlPPPEErr76ahiUocKCszP+s0ePHgCAb775Bh6PB2PHjvUuc9RRR2HAgAFYsWKF7nba2trQ0tKimIh4xALjQo8VJPQQhHGipekJF8IHp7GRa68qK3l7ZSX/HU6h56qrjC23fj0JPYlCQubx6ejowEUXXYTm5mZ8+umnAIAlS5aguroabW1timVPPPFEnHnmmfinVqY4ADNnzsTdd9/t004an3ihFcD1AAKFhOQC+BXcFEZCD0F0N7TCzkUQgJgXrNlYL8+W3Q7MmcO3t2sX1emKF5I6c/OUKVOwdu1aLFu2rMvbuvPOO+F0Or3TTz/9FIYeEhJdSdFqBffZ0RN6xO1bCmAfADNI6CGI7olcqGlt5RFthYVccMnJkXIYBbtNeZ6tigrJJ0nsj4SexCMt8CLxxdSpU/HGG2/g448/Rr9+/bztffr0gdvtRnNzMwplySv27NmDPn366G4vIyMDGRkZkexyN0TkyD8SwBZwASZY5/dJAPx4EKIZQAG4YJXduU+P7Le5cyIIojvhr0ivKKobjDP13Lm8MC9AgQbJQsJofBhjmDp1Kl599VV88MEHKCkpUcw/7rjjYDab8f7773vbNmzYgO3bt2PUqFHR7m43pgZShNWWzrZ6cIFECESBigdVwb9pywYu3IhtVkOK6Crq/Ezv7AtBEN2F1lZ9oUcgsjEHAyUJTS4SRuMzZcoULFmyBP/+97+Rl5eH3bt3AwAKCgqQlZWFgoIC1NTU4JZbbkGPHj2Qn5+PG2+8EaNGjTIc0UUEwgP/WhQPAK1QixJIfjpWcEHIAUCdHcwD4Br4d2IuA79tjWRaqwXwdIA+EwSR6Hg8xoUZSjJIJIzGZ/bs2XA6nTjjjDPQt29f7/T88897l/nXv/6FCy64AJdffjlGjx6NPn364JVXXolhrxONps5PYTJydn53gpueAmlRzOACjdZ2hQZHvI7VQqn5EVqbQELPJmgLV1o4QEIPQSQ3ok5WTg6f5D6tubnSd5H9PFAJCiL56VJUV35+Pr777juUlpaGs08xpfvk8dkFyVxU0DkdAmACEOiWcMO/QFEGYLOBPojtVAOo87NcKYDvwU1YetgBPAny8SGI7oNe1JWc5mYq7dJdiEpUVwJGwhPwgF/2YvCMx8XgAsWhzvmBrmkluEChp1duhTGhBwAmd26nzs8yNnAtTzYkbZJVNq8ZXICa17lMT0iCD0EQyYzZLNWz06KsjGeuJqGHkJMwpi4iHAjH41AF1iwACyGZpdRmLw+AG4LYnjBZCYHGIvvtAhdo5suWn9vZtlE2rwAk5HQXgvRIJZKe6mr98hEWi//SEkT3pUuCT2VlZZKbg5IJPcdjNQ5wocIFrk2xd7abABwAv2XqOtuEn44HklBlNLsywAUdMySBpr7zcy70tTZm1SeR/Mjvrypws6fwPwOUEYNEd6G1VQpP12Lduqh1hUgwuiT4zJ49Gz0TKc95t0bueKwWGmwAGsGFHREFld051XUuw1SfAJAHbq5Kh3GHYzkNkAYsEmgILYTAI+6vBQCOhlSYtgDK9AVdSZhJJAo1NdyRWdTNzsvjBUlFskGK3CL8kZAlKyJJ8js3i5B0p6ytP3jmY4EINffAWNi4HnZwc5T6FrOACz1aIe3BsqvzswCUtTnZCPX+CyVhJpEo6Dk0u1zK8hRE9yOpS1YQXUE8EU4Af2suhFLoASQTllxL5ADXCllly1ll8+U3mfDReRJAB4BtnVNe5/y9kExaXUE4aQsH7fIubo+IL/TSI8jReriJhJlGITNZIhEoXw8JPUQgSPDplrRCyqejhR2SgCT8b+aCR0xtBBdqXJ3fn+6cf4Vs/Y/BBZEccE3MwM5JCFgt6LpJYhd8NUnBDnhE/CI0kh/7WcbVuZxwhBdCuRXGtX/ClDYphD4S0aa8nJu41AwcSAIPYRwSfLol/l6Z7OCh4XLUTxTh/yMGjeug9PGRh1K0aOwjH1wg6gp9wR2u5QQz4BHxSz64JjIN+vXa7JCutXCEF0K5UTOX3OF/EbS1R4HWJ6KFv3IUZ57JzV81VKWGMEDQgs+qVavw/fffe3//+9//xiWXXII//elPcLvdYe0cESkKoHzI2yC9NRut3icfNOoghaIHohFK/6Ku0AFgZ+cUzIBHxC+TIGkG23WWsUH/Pg1G8FULLvvA780mjXlqhNB/eRD7I7pCdjZ3YlZjs0nRXbW1wdfhIrofQQs+119/PTZu5APM5s2bMWHCBGRnZ+PFF1/E7bffHvYOEkYQIeXB4ISU/G8+pArnRjGDD0ACIwkzHODmsnDSt3MiTU/i44H/4rQAv+fmB1jGyH7Ep/wFIB+8yG0R/JdnkQv9r8BX80hEgtZWYJ/KHdFmAxbIMmikpZHJiwhM0ILPxo0bMXLkSADAiy++iNGjR2PJkiWoq6vDyy+/HO7+EQGpglQNPVg9r0j+5wE3EwXjIFwO4zl7LOiaMzO9wnUP1MK0Gju0hR7h19UEYDu0NTbit9DUmMHNaXJT7I+q9dT15ARa/5Ef9bsdEbR82XZptCUHVVW+vj12OzB/PlBZKbUdOgQ4w6VQJpKWoAUfxhg6OjoAAO+99x7+7//+DwDQv39/NDU1+VuVCDtWKIUPvQe1P0QWZqGxMeIgHMg5Ws06hJafxwP9LNFEciGSFGoJ0zbom2Et4AK7CVxTMxC+Ghsh7FRD0tQcUm4GDnDNoVnVpr5vWwFs1ejHAI22cCAKBssphfIlRV6GJvncNq1WpVYH4JqeeZ23w8KFgKlT6WYy8RIVBOGPoP8lxx9/PO655x4sXLgQH330Ec4//3wAwJYtW9C7d++wd5DQoxW+5iVRR8soesVBb9RZXghVw4PYR6gV0oXAU9f5Wwh1TVBm7SUSH3WSQkEOuO/Wc9C+hyzgddz0qAX/n8h90fR4uvPTDe6HpqehHKHRpnaq99enYBDnJQdSxJoJwJbO7/WQNL7yBKMlYdp/7Glt1S47sWCB5MvT2gqIbHSM8d8E4Y+gBZ9HHnkEq1atwtSpU/HnP/8Zls4KcS+99BJOOeWUsHeQ0EMd05kDXkfLKP6Kg2ppjuQlAwIVIc2D5D8UinmrSqNvFeDHWAQpay9pgRIfuWAiJwXAVVBmZZb7slXBmIChJaioqYBSsOoJX0HLAy5wy0fhgfB1qjeBC2Rd9ftRl5hp6NyfGi0N2VYkS1oHPX8dm02aJ6+8bjbz3wThj7Blbj548CBSU1NhTnDPssTI3LwLXK0tx43AmhWPahl/b8xie07wt1l5qtQ8+CY9FFQiOAFMjZYWygT9wqpGjpuIT/Q0jhWd7XpZm+066wVCZAzXwl8W8RpIQkg+uF+QBb7m3k1QRjdeDuClEPopqIJ/PzobeMh/LXz/ky4kg8N/dbWyHldpKZCSwrVAViuwcSPX8Mj9f0QGZ6L7EfXMzZmZmQkv9CQOd6h+26Ac/NXFG9VFHsUyaqFHOJYK81QBuHZF/RSRP2DtsnXc6JrQo6eF0hN6QjWjEbFHS6sHAGWd7ZP9rFsHLhwFgx1SEVw3fDNC6/nHOaHUvLSAazO1fNzUEYsvQ/q/BYvwd/KXJmI2uLDmAnCOat72EPcbP3g8vkVIv/9eMn3V13OhRz3s0DBEBMKQxqdHjx7YuHEjevbsicMOOwwmk74a99dffw1rB6NN/Gt81PWLxJtnK6SomGWQ/CO0sAA4Gb6hw24ozQmFAfoir+nVladNK6Rw+iMh+TCoyQcX1kQRVXrCJSZ6mp5I0QzthJlN4KZTwSAo771y+Ao4gcLpC+CbtDPYEHz1f9wFYJiqb6Xg/wW5NkpOI8KfOiL65OZyDY5g/Xrgoou40CM0PgBPXFhby4uTzu1qJRwiYTE6fhsSfObPn48JEyYgIyMDdXV1fgWfqqpQ33Dig/gXfADpYSceqFoP6GApBXAGpIeoP3OWA1IV964i+u5vf3YAj6Dr2Z4J/4gIokie52ALj1rB7w87uGC+RGMZoRVp6Fz+BwBDO9fTK1gq/kPq+y4N0nlQ+9GVwVi+KieAaVCaqewwnhxU3j8HeASalsnLDm0BUhxDYqM2YQE8aqujg89Tm7OoOCkRVsGnO5EYgg8gaVm0HtDhohJcKyQEHUG4ni5OBNYq2RHcgEGEhtqPJZLJUPS0FHJs4KYcM3hJlDo/ywltitAcQue3IJDwVQFgMZQvFJWdfTZ676u1SUDw/mhCePHXVzt8z00zkuUlwWzmuXnkZGVR5BahTcR8fOrURtdODh06hDvvvDPYzRFBIX+LC1b4sIK/CRolD9xfR0RmmWVTOKiBf6HHX+6WZCIenuDqCKIWhE/wUWsenABmGFhvAaSIrjqN+ZWQso4L1EKOnoervOq7A1KouGAJeL9Pl7UtQnCRhD3h+3gN9lqL/1ulznwHgE812m8Jcj/xSWurr9ADAAcOAGVlvqUpSBgijBK04DNt2jRceeWV+O2337xtGzZswEknnYSlS5eGtXOEHOGcrH7wZkN6cGsJNnZIIbcecNs/Azdt6VEJyU8hErpj9UArJxXSgJaMemv507ocfHAvheSIHount1wQAMJTRBZQ3rOt4MJ0IbTDso1ih+RE35X7Yy4kof4Hnf1o3aPBJAkNl7/jv1S/RZ6e/0Hb9BZKItP4w5/ZavNmZVFSUbW93GjieaJbE7Tg8+2332LHjh0YPnw4li9fjieffBLHHnssjjrqKKxevToSfSQUgoLWQ01UpfZAKjYqpnlQvvkKh8dNACbo7C8YH4xQ8PdQPoDkFHgAKSljFZTZr7dA0m7Ik9VFEyEINCOwtseIgKa+Z3MA7A+xbyJiUNzP4bo/5NtRl8pYAiliUd0Xo/uXFwPuijCpXk84Oavzadk7P5Mj2tGhDrzToLYW2L5dqtouIr0Iwh8h+fh0dHTg5ptvxpNPPonU1FTMnz8fV199dST6F3Xi08cnH5IDpr98I13dtpxI5scxQ1kyQORXCfexxQMiSu5aKB1z/eUmArjW7V5ErhRCqMhzy+g5Dnvg3y8nGCKdj0Ycjx3avjLqfYfyn3Ci6xq0QAEMIrpTK8JSq03P/yk+8Hi4RicU3G5ycu6uRDSPz5tvvolly5Zh1KhRKCwsxNy5c7Fz586QO0v4oxRKweThMG//co02OyIn9EyEUuiZACm/SrwLPcG+SgoNTw58o5ECvW8sAjcJxVPl70FQRhdp1XUT5q26ELZfCi5s2Dt/OxDZwVle664Ovr40Zo0pFLoq9HgQOGqzAdoCjtpE3gqpvlly2oXUvj8EoSZowef666/HlVdeienTp+OTTz7BmjVrkJ6ejuHDh+OFF16IRB+7MVVQ5u7IQ3ijNbQSBtoQOYdiD3wFACHsxPsrmvDHMWqGCiZXTWrnp16yunhIRpcCYJuqzQIp/xLg33dLjhVc0JWfyzJw82sB+P0XaUFYq9ad2kfOSLmLaKBVtV78FveMlnlLbW60gt/DInGpkYLEscFslkxdFn85HDUgUxcREBYkQ4cOZd99951P+xNPPMFycnKC3Vzc4XQ6GQDmdDpj3BM3YwyqaWeY99Gs2n5FmLevxqbanyXC+wsXLqbsd6Vqnls2MeZ7Xv1NEwwsE2t2Mt8+iXPg6Pzt6Pxt0lhWfr1dqm27NNqigdb/S2uKRd9E/8Sn+N9YmPJcuwN8MiZdn3g7PmO4Ow/FbmcMYMxq5Z96k9kc2/6GhMslHWg4cLv5NrshRsfvoDU+33zzDUaM8H0TmjJlCr755pswiGIEZ5dGW18/y4ei35WHveaB5y6JFNVQmkkq0fWki7FiEfjxCC1QumwSZT6MsszPvIEIbBKLJK3g/il/UbXbwaOq1BqFbOj31wZ+vbVCzmPha6KOZNPjhkh3RANhnirv/BT/mwZwnye1ltSssU4V+PWR599Sk4N49vMBJF+defO4787GjfzT5eKT0ApVVgKNjXxewuDxAAMH8nA0eYhaV6ip4duiEDe/UAJDFfHl3Cz37/B3meRZXo2aB9RJ3CLpzKzeV7Ap/OOBULNjVyA0n5dYn6My+EYNAXzglfu7iHtvEHhVcH/EY0FZj2wq1Fkmmv32l5BU3BNyX55ASQ4DOdHH4zUJjoTL2LxrF3DHHcACjWzcoXpmC8cmtUd4N6vYGlHn5pdeegnjx4/HySefjGOPPVYxEeGEgftV+HtwBQp194c8iVsknxzqN+vZEdxXpBApA+ydv/WSQcrbLeACz5OqZbQKbOZ1fgr/l1gIPSJMPR/aQo8DwI3Qzie1NaI9ixyi7lsBpPw4saIK+kJPCfg9ITQ71ZCc54f62aa/Z4e6uHFikjBCT1MTLy1fXKwt9NhsoR2M0PJMngwMGuS7T8KHoAWfxx57DNXV1ejduze+/fZbnHjiiTj88MOxefNmnHfeeZHoYzcnEuHM4uEJRNaJtBU8iktdDDVRnlQCIUxmQ4pI00gp69N+Gvh5vhGSI68V3KQod+61gCeMFIkmY3F+xD2RA9/0Bvng/X0aSiG7Fb7OzON1tp8IuWU2+JkXyQFkF3wj5tRshvJ810HSIoaiicxD4mldExSnE0hLA4qKuCuSFhYLMD+E6+Hx8GRGAP/culU5f/r04LfZDQha8HnqqacwZ84cPP7440hPT8ftt9+O5cuXY9q0aXA6I1nfh9BGnX4/0OCi1hBFChEyq1VUMpHiTeXhwHnwFeLkWCFdCzukgakWPDuwEGwAfp2EFkkMXLFQSQs/Hq17IQ9SQkNh3pJHF90IZZI/C4DnobwfReLBeE9VoEcl+H1cBH784b53TQCK4RsxJ8cNfv8FW5NPfq3UoVH7kFj/wwQlPx8oLATa233nWSzAmjXcHFUfivAKZfibw8GdneQsW0bx/RoELfhs374dp5xyCgAgKysL+/bxt8NJkybFTcmKJ598EoMGDUJmZiZOOukkfPXVV7HuUoSRp9/3hwfAYNlvK8L7Fi7+YHmQQmbVWBE/DpWBHghqIVEv83AaJKFGXIt58BVItY47ludCOGcXasyrANdCydMnWKDUStSCC3d2KAU4+f3Ylfw3rYhuuLUZkslRcD+k++QQgqvXFQi9pK9yAUfcQ0ZfUuT9TwG/Di74hu7bEf8auAQnNxfYp5EctqREEnaGD++6D87cudw3aO5c7ayPdjv/JAHIS9CCT58+ffDrr7wGzYABA/DFF18AALZs2YJ48JN+/vnnccstt2DGjBlYtWoVRowYgXHjxmHv3r2x7lqE8fcQ80DSXMgFknrwt/mu/CGaOrcxqXP7k+C/NMHpfuZFE7mvhN7xmxE4b09u5/ryh5e4FkYF0lggL5mhxg4pwk/u96MnzNbB9/7r6qAqcs5EM9FeK3zNfNnw9ecKRy0sD7Qj+krABRXB09AunSFHaNZcAH6RtdcBuAb8GMpU67xkvKtE8DidXLiRk5rK2zZvDr/DsdmsNHvJWbIEsFrDFzmWDAQbJ19TU8NmzpzJGOO5e7KystjYsWNZYWEhczgcAdaOPCeeeCKbMmWK93d7ezsrLi5ms2bNMrR+/OTxCQduxpidGctXEsq1M+tsKy/AvsKYsyJomhljjRp9smssq7VcvB1PV7Ay6RisjB+vPCeRXo6hss756hw+4cDNeI6gWOSb0cpX1Nw5r0LWFq7jFedvAmNsG/P939iYfr6htM6+ad176v+81vmUHxsREfLzpQRDJSWR35/L5T/JkZjCmTMozjA6fgcdzt7R0YGOjg6kpfG3oGXLluHzzz+H1WrF9ddfj/RQC6yEAbfbjezsbLz00ku45JJLvO1VVVVobm7Gv//9b5912tra0NbW5v3d0tKC/v37x0E4uzr9vFY6ej2c4Dl6gvXhCSa0tQnc70FNJXiOFyeA38PXx8eOyGWGDkQe/Guj7ADmdH4/HNo1zGwAPoOk/Yj3+mL+7hsRii4PnQ+UcToP3ARmZPvBordvUYcq0qhDybWOFQi/edgM/n8plLWXQrrHxHUS7V9CKjash7ymmh7NCG8meMIHp5NrY6IRUt7ayvP3+MPh4CaxJMVwOpqoiGFR4ueff2YA2Oeff65ov+2229iJJ56ouc6MGTMYeMynYoqtxkf9Jm1n+m+aLtnUyBjLZ8a0FOrJFmQftd5E83SWE8ejpVWJJG4maQpSWGjnRa5xkL8pqX/HI/7Ou/r6uVhg7WAkM3vr7bssgvvUQmjBSqO8X3V2cLWGy63RFgh1pvRk0VQSmrjd/jU93SCbc8QyNycbd955J5xOp3f66aefYtwjtUNtFZTRQfK6SCJySkxFUL6hqrF3fooIjzzZ72BDKbUi+K7UaDND6fAbaYRPShWk8OxcAB1d2KYd3E9C/qav/h1rxHGLZHxNUIY+V6uWl0cDCn+aOp1tl4FrhZYgfI69op8Av5fU+66AtlNupBGRdnr+TJEiG8qUB1pV4YPVGsxHYP8goltgt3erRIaBSCrBp2fPnkhNTcWePXsU7Xv27EGfPn0018nIyEB+fr5iii3yAckGpbpaCCrCkTjYh/MccAFEVEMXuWNCMSP0hO/A78/pMxxCgth2q+y3fH/yaujy86ZyMvQWBXVAGhjs0C5hYEfsTHNGkQt5onSG2gxZB+W52gXuONsM7etvAbAT/NydDul8hsOxVziWp4M7TReq5ueCO1fH6kEdq/0KoWtjoAWDQBR8VVOJ+BLciS4zebL+vCfVSVS7N3rpZxOS9PR0HHfccXj//fe9Pj4dHR14//33MXXq1Nh2ToHcV0A+mIu3urngGoo61Xr7oJ+aXo98cAFHneNHfO/KQ94NrlmYDqlkRqQepsLPIQ/8PGRDEoDs4OcrkE8DIPlOyH1T5si+q2sbxfPg4ARwDIAtBpaVXxuTvwUh+WkB/DzVyebZ0bVzoq7grhVFpeVb1V2IhNClTr6YC+n6EkmBXkSXIGHSW0eHpNL4AMAtt9yCZ599FvPnz8f69etxww03wOVyobpareqPBU3gmYzF265F9r0QUuiuerAxinBsk4e3OhHZkOqeiHzYtnywFIOiPL9LHfwLPUJTVgHge/g65Kq/y6d4RRRDDST02MCvzeOdv3MDLG+HclCUayDt6Lr2y19xUBN8tXNE1+kLpbDbnQXLJEWeyJAISNIJPldddRUefPBB3HXXXRg5ciS+++47/Pe//0Xv3r1j3DNhfpBHOWmZqurBB2Z75+9AA5XABh6xJE8cJ94eozGAR3IfZgTvqyAe9DZwjZcF/NwLc1Ai57Nwwr8vl5wFkHzA/AkWZdD3wwq3j5ZexfCu+GER/ukAN13GPtcaEQE8HqDDz/+nNZqJQOMfQ+HsxxxzDEymQOpxzqpVq7rcqVgSmerseqHfWljBfSpqAWQBOKCznAXc8dMBPpDEs3YiXGiFO6dBqo9lBy8I2gquiRKaHb2K14lamXoXeJmDcHEFgBfDuD0jyEO0JwCIj6zvBJFw1NT4N3MBoVd9TzCMjt+GfHzkOXEOHjyIp556CkOGDMGoUaMAAF988QV++OEH/P73v+9ar5MW4Qis5xRqB/CIbJnCznYtoacCUqbccOZQSQTmgfvjiOglM7jJR51fRa3pEhEzcifeRCiaqYcwXWi9s9g7P+s05mmtY0L0hR6Aa5GE5idRrwNBxJhAvj0Aj+jqBkJPMASdwPCaa65B37598fe//13RPmPGDPz000+oDXQR4pzIaHwEwslQCC0iJFrclOXwH2GlTqhGBIdQ98a7/45RdgH4C7jmpALAs+DHpXaAtwBYDX6/TYTS3JqoWi+CIADwchQNOmkfysr05yUhRsfvoAWfgoICfP3117BalTWM6uvrcfzxxyd8hfbICj7+0DPHqKGBilCTD8lh1QHtiEAR0iwXiuyIbah+K+KnYC1BJCAej3ZhUjndxMwFGB+/g3ZuzsrKwmeffebT/tlnnyEzMzPYzRFejAwAiWyeISKDE8oonVpwc6Bd1ibum3BHaHUFURk+UBFYgiB00aq4Xlmp/E2OzT4Encfn5ptvxg033IBVq1bhxBNPBAB8+eWXqK2txV//+tewd7D7UOpnXiX4gEZCD6GmAFKuJkAScoQ/FKC8b4RvTSzvJXll+AZIjvpqupsPG0EEQXU1UFcn/bbbgTlzgMGDlctRxmYfgjZ1AcALL7yARx99FOvXrwcADB48GDfddBPGjx8f9g5Gm9iYuvyZueyI/8zBROxxIv7KaOjhga8fkgtKraeI+rLD2P1PZjOiG6EWegDA5QKuvRZYoioMTaYuH0ISfJKZ2Pn4yB2b7eBRXokykBFEsKirh+eA56ECfAUjG4DnoP1f2A5gLPh/x4rwlnsgiDhEqwp7aSmQkuLryJzk1djVRMzHBwCam5vx3HPP4U9/+hN+/fVXADx/z88//xxabwlIdXpEorgCkNBDJC/zoTTvusAjzoTPgl02bwG4IDSpc76z89MEYCCkF4Z6KDN6E0SSUVXlK/QAwObN2tFbT+slC+3eBK3xWbNmDcaOHYuCggJs3boVGzZsQGlpKf7yl79g+/btWLDASL2k+CV2Gh8iPiE/k8jhz8Qr91syCml8YoZwshWOtNnZ3LzS2ko+JuHA4+G+O5uCLEzdjcxcQAQ1Prfccgvsdjvq6+sVUVz/93//h48//ji03hJEVDGiFfBAqiJeI2sjwkc2uGOzFsEKPeGuak4YpqaGh1SnpwOFhXxKT+eaiZwcnkumqYkLQRRhFDxXXsnPZ7BCD6FL0ILPypUrcf311/u0H3HEEdi9e3dYOkUQkUOEUZf7WUYIPCIZZy14uQwhBNHDOzzUQDuaC5AKywZCZKMmrUJM8Jc5WAg5mzcDRUWSIFReDjidXBhqalIuGwytrdrh3MmEyQS89FJw65R2mpAdjm6l7QmGoAWfjIwMtLT4vo1t3LgRRUVG61ERRCyQh1HXQ/IVkeOEJPDIqev8rEVgwYkIjAfa51mwGVyLo8pJgjwAzeC+cDtBhU1jzOTJwa9TX8+1QkVFfDKZJIFIjp5g09rKsxXn5HBNSE0iFxzWweMJTcNjsfD13O5u5dQcLEELPhdddBH+9re/wdN5Q5pMJmzfvh3Tp0/H5ZdfHvYOEkR4ECVC5MV2C8G1OFWdv8s724xoG8iRNjScndN1AZYrAjASwEJwIacRXOBpgeT43zdSnSSMYKROVDDU10saILVgIwSg8nLeLnfkra3l85NF+1NdzY/7nnt85+Xnc6FGVE4QGh2LhYez19cr2/Xo5ibHoAWfhx56CPv370evXr1w4MABjBkzBhaLBXl5ebj33nsj0UeCQNeEDGG6KoN2Yc8F4L4mQhu0T2MZLZLkQRt2PKpJUAAuWBZCu4iqGiFcmsEL/RaEsY9ElzGbedI8NXa7ZG4pKwN27gS2bQOamwNvs6iID+5qwSY9nUc0iYFdjZaQlIjI8/PU1fFz2dAgnT+nk5/3jRu5oON288916yQn8kDHL4RHtYatGxFyHp/PPvsMq1evxv79+3Hsscdi7Nix4e5bTKCornhE5Dgqg75PiB5ayfLCQXcoGKuueq83XyzjATAZviYsB4CHwQWeYKAorYRADNa5ucD+/UBaGnDokO9yVitw+uld0xLl5QH7DLyYOBxSKLfHkxiRZXp1twJFZtXU8HPq6CxHI75rmbrUOYBcrsQ4NwYxPH4zQoHT6WQAmNPpjHVXCMYYYy7GGGRTbgjbcHSum6/alnwqY4xZ/cyXTxUhH03iIM4ZOr8L3J1TJVOeEwvzf87sOm3NnVNeZ1te5/ZdkTw4Itw0NzMGBJ5cLj4ZWdZmY8ztZszh4L/tdv1l09L8b8tqjfUZMob6GO12/8u73frH7HYHXj7Q9hMMo+N30KauadOm4bHHHvNpf+KJJ3DzzTcHuzmCCEA2uKZHsB88Wy/ga2rSU/HOheQfoscmSKauQNQZXC5RUTt410IZ3p8OYJFqnUCauDrZ90YoE3UWgF+b5s5PM5I6Skvtj5LIphlBQYGv3wnAzVYCq5VrF7KzJe2EP557jm9r7lyu9Zg3T389oWESfVBTX58Yfi3z5knmQ7ud//aH2SydE5tNeb6NOJ7X1SXH/RcswUpUxcXF7Ouvv/Zp/+abb9gRRxwR7ObiDtL4xCtqbYGZKbUGQkMhtBPytx2HxvrBTGrthlwDkmxoaW4qGT+foZ4/B/O9Pt0QufYC4N/FG74jSc6LyyV9Co2D0PKocbt9z4n83OjhdjOWl+dfq6TeZqJofARa2hp/WCzGtT5qrVKw+4pjjI7fQfv4ZGZmYu3atbBYlInHGhoaMGzYMBw8eDCMYln0IR+feERd1ykQdnANgwO8EnkgHx/hnxIMbiR+Rmd1Vmqt8yz3ZRKFQ+WkAaiA5CDeAH7+n5RtW3wmQRZsjwfYtYt/79uXO5sWFPA376Ym6bvHo/zUKiqppptl2VUgtGCtrdI5DITTCUydCiySaR/lWhKhyUgUH59Q0ardJdC6p9S+RBaLvtN4ghGxzM0WiwX//e9/fdrffvttlApPfoIIGx4EJ/QAypw7/tTbDvBcMcEKPQ7wAdwZ5HrxhDBbifpYWue5AsBuSPmOntfYzqDO9ezgpkJhwhIFduUP3QQf1EWG4oED+ZSezqOQ0tN5gUjxvbxc+Wm1BhZ67PbICD2JYN4B+LFnZwM9exo/DwUFwMKF+qYhs1nabjKjd75ycrTnqU1bDQ2Jc5+EiaA1PrW1tZg6dSpuu+02nHXWWQCA999/Hw899BAeeeQRXHvttRHpaLQgjU88IjQNFQCWBLGeHcAcAIdDGaLugnJQFtsXGotA2zODa0L2g9eUSjQBSCvSzQGeDLCu87cNwOcILoouGC2YP+1PHGqG9CJuwkUktD1WKx/ULBZg9erkFgCEZi2WOJ1SjbJoI661Gq2oLa17ubGRC50JTkSjup566il2xBFHMJPJxEwmEyspKWHz588PZVNxB/n4xCtuxpiNGfcrqdBptzCl/498+/78WOTRD2Wqec1hO8rw4i8ySu/8VDJfnyZ/UykL3ndHz9/HxRibEML2ooSWL4qYTCalP4nWp15UksXCtx9OX4vKSt/9WK1J5c8RV+TnK/2T1Oc5kuc92MguxnjEnNovKgkwOn6HJPgI9u7dy/bt29eVTcQdJPjEK11xrg0kyMiRD8pu2SQIR3h9NBCh+XpOnV11+AZjLK1zW8E81NXXUYSua6USiMNB2u1mbNs2PrndjDU2SoOL/Lv8UwhMKSn6A9SECdKg2ZW+MeY/7BtgrKI7pGOIEM3NvsKEXii/uJbi+kfCgV30RU8oT0vTXi9JHZwj5tyc7JCpK54RJqky8PBzOVptgbCD+6OoCWRq6UpCxUjjAbALwEBZm6vzU6i8W8HrjRnBBuAx8POhtU6wTt5OAL+HZLLMg36m7CRwIA/FRBaK2Us4T9vtgf2JAJ5ksDuGMXeFggJA1KmUJwhsauL+XVq4XErH466aNOUmPXniwrlz9Z2cBw0CtmxRbkN9TyZJIsOIOTeXlJSgtLRUdyKIyDEXfDBs6Py0dbY7AHwTwvbqoO3YHOjBtBFcmIg3oUc4LMuFHit4zauczu81MCb0iHplaZBqYxnIvaKLp3ObhVD6aekJPcKBPMGJhnChLnNQqS7sqsGhQ1JdLCIwTqck9ABSfTCA+8aYTNrrXX+9lGenK9XSPR7Jub6mhvdHZMAWfdHLj7R1Ky/3IbhOo05erP2jokzQGp9HH31U8dvj8eDbb7/Ff//7X9x222244447wtrBaEMan0RDaGf0tBhpADTS5wPgg2uyVDDWcljeBq7l0Xkb1WQQgO+gLC9hBxcS7eBh6jeCa97k509dvkK0maEdBq/GAmA1uEaoJxJa6BFv5aK6eM+e2iUc9PCXuE4dJq9+ezda0sFs5toHwji5uVwzImhu5lqgQFq9nBzg55/5sgK5QBxI6NBLhZCfz4WxykrgmWd429FH61d1b2zkwpGWVqibaXy65OMj54knnmD2JEh/TT4+iYzaT6RU9Vvu35McNm1+HM2d3+V+O2YWuIyEns+OfFt2jeWE/5N6Wfl8f+urpzKWNNdD+FrInV31ppIS/XlazqZi28JZ2uHw73Ctni6+mPujNDZG/bQkDSJxYn6+sl3tLKw1Cedy9TXz5/sTyF8rN9f49RdTWZnyt0h+mARJNKPu47N582aMHDkSLXJ1YAJCGp9ER56PIhtANXxLTCSB7wgApSZFhNV7Oj9vhbH8R7ngYfkVABar5om3Uq23WXEOu1IEVrw91wBYhoTXwAXjz5OXx9/WxZv/dddJb/VWK08op07GF65wenLr7BoiaaW6rbBQ2ZaSAnR0GNumkUSDakpLgc2b/W83NRVob/dtt1h4+LvNBiyQPScSPIlmxHx89HjppZfQo0ePcG2OIEIkWzZpYYH/pIaJggdK81ELuMBjBvfJMZr0cX/n5xL4+juJXEdqvwG5/00wvj9lqt83ggteyzp/i5pgCYq8bpKa0lJuamhs5CYS8YJoNvOaSkLoKSuTsujW1QFXXy0llxO+O6IelcPBB65g2b498DKEPmqhB9D25TIq9ITq+7NqlbI2l0BUVbDbtYUegAs9Lhcwf77yntXy/0lCgtb4HHPMMTDJHLkYY9i9ezcaGxvx1FNP4boEP3Gk8Ukm/GkjEjHxoBq1xmcX9LVcRrCDR7lpRbVp+fDI0fOxsoJHwIltV0FfKJsAYKnh3sYtwq9HCDc2Gx9g9JZVv9UHepO3WoEfftD28TECaXwiQ3o6vx4mk7Fz7HJJ2aW18Hdt8/O5lgngn2IbYntCEPN3bwi/HvV+jBRHjVMipvG55JJLcPHFF3unyy67DDNmzMDatWsjJvRs3boVNTU1KCkpQVZWFsrKyjBjxgy4Vc55a9aswemnn47MzEz0798f999/f0T6QyQK/u5HoSFJZESUWyO4A7OI3KoLcXt14EJTOrhQJccsm4zSDODUzu8p8F9+xISkEHoAPvA4nVyz43brCz1iWbWWKJD5or5eGtjk6wtNkLyOomirrAS2bSOhJ5K43Vyj19EBTJjA2/SqxeflBc7yLL+2djvfttvN7yun7NlVUCBVvVcLQPJ7q7JSKu9htXIn55rO/7n8nukOFdsj727Udd5++21mt9vZO++8wzZt2sT+/e9/s169erFbb73Vu4zT6WS9e/dmEydOZGvXrmVLly5lWVlZ7JlnnglqX+TcnCzoJTxM6/zM11/VZzvxipsFl4hwvEablUkOyGpHZKPHLvognMtLdPYv769d9n1CSEefVLjd2tmW9ZxktdZXf6rbiOhgNisdh91u7qzuz4Hd3zXq6vWT3wuMafdFPiVwkFJYMzc7nU7DU7S4//77WUlJiff3U089xQ477DDW1tbmbZs+fTo78sgjg9ouCT7JgjrDMhgvecGY8RITYmCuDHvvuk6wmZflAp+WQOJWbTdQhIc8q7V8W/7KXZTK1mUa3wm/UTwpKUlTWiBpaWz0vW42m7awoc66HK2oKn+CT15edPoQIYyO34ZMXYWFhTjssMMMTdHC6XQqnKlXrFiB0aNHI11mqxw3bhw2bNiA3377LWr9IuKFG1S/KwEIk4OGc6IPcufhReA+NNHEI/tUq53Vjs162DsnQMpl1AJughIqcOGoLFTuwnzmL7pKmMPSAagDGhb5WW8zuC9QElVsDzfz5nFzhphcLm7aaGzkjqpJkGslqdEyXS1YwNvl5iTh0Ozx+CYijEUfBfv2dYtK7YYEnw8//BAffPABPvjgA9TW1qJXr164/fbb8eqrr+LVV1/F7bffjt69e6O21sjDuOs0NDTg8ccfx/XXX+9t2717N3r37q1YTvzevXu37rba2trQ0tKimIhER+1LUgZgYQjbkLMP0fMJEoJFOSQBQ+5zI4+kskPKYC2nArySfJ3GvGz4F3BEmLqaVnDnZPk292ssp4cV+tF2hBfhn2E2c0GnoCApKmd3CwoKfBMEDhrEo6VE+LjbLZW7UAsZ0RA6zGbJ10eLKVO025PJ7ydYVdJZZ53FlixZ4tO+ePFiNmbMmKC2NX36dAbA77R+/XrFOjt27GBlZWWspqZG0f673/2OXXfddYq2H374gQFg69at0+3DjBkzNPdLpq5Y01VziPA3KQtx//9lSjNNZojbCRa1n40/nxu9avVCXe3P3OcPuR+O2I66Ir3RycG4aTEJTDQul+QvQX4zkWHnzlj3oOvoFS2V+/bI7x+R7FIkRYzG/eWvorva/4gxyRxnt8f1vR9WU5ecFStW4Pjjj/dpP/744/HVV18Fta1bb70V69ev9zvJ63/t3LkTZ555Jk455RTMmTNHsa0+ffpgz549ijbxu0+fPrp9uPPOO+F0Or3TTz/9FNQxEOFkV+enqDlVA0n7UR3kdjpzoWATQssNM071+0AI2wgWD/QjstS1q6qhHSHVCG7OEjW5LKr5gf7ycjNaHbiJLwf+C8CmqX7bwbVJQqNUgITU9Hg8UtkJEQWTni5NVVV8flMTXyaZ3ohjgckEFBfzxH+JTEEBL2+hh7iPRESViAB0OqV6XPL5wRCOe9BiUUZ8yc1xdXWh9y2eCFaiKi8vZ7fddptP+2233cbKy8uD3ZxhduzYwaxWK5swYQI7dOiQz3zh3OyWSaN33nknOTcnDCbGNQTiU2sKFG3gZoylqtbRiIAJiv92cf1gUTst25mvpkdLk6Ne3p8WJtAbW7ClLtxMGRmWwIjnh5ESBFpTEqT9jwnq8h1ZWbHuUdfJzg58v8i1J1paGC3til6bcIw3eg8GKoch9q+nHWpuDu28RJCwRnXJefPNN1lmZiYbNmwYq6mpYTU1NWz48OEsMzOTvfnmmyF32B87duxgFouFnX322WzHjh1s165d3knQ3NzMevfuzSZNmsTWrl3Lli1bxrKzsymcPSGYwIIbZLXwF+UUv6pZbdRmJX91sbSEFHmbnRkPU3drLBtocqjWT2DEQCDqMYU6xbEpIC7RizKKw4E1aALV0pKHjhup4aUVAaZVry3QPSg3XflLoyD6p96HMM9ZLF0/R2EkYoIPY4xt376d3XnnnezSSy9ll156KfvTn/7Etm/fHlJHjTBv3jxdHyA5q1evZqeddhrLyMhgRxxxBPvHP/4R9L5I8Ik2/rQTwodFDOQO2TpGt6EenOMdLW1OI9MOHQdjLFejTe88agk+6jD2YASeJBrgQ9XwqCebER8qQsHOndrnMlmKqV5xRWBBWUurMn68cjvqZRobtdcLlIdHvY7e+ReT2rdNHbIfR/d8RAWfZIYEn2gTSFMjBlfxXS/PjN3PdtSDfbyTx/SFDSMCSiBTlVrYCXTukljgYcyYyl89lZXxAcHlYqy0lMXj22/CoJX7JtnOZ1qa9jHKNTcVFdpCkUBLyMnJCU0IERocq9X4Pe9w6GtF4yS/VEQFn48//phNnDiRjRo1iu3YsYMxxtiCBQvYJ598Esrm4goSfIKhqwOgP02NXbYMY9oRTGKei/kf7BNJ4xNIe+XPv0d+3vwtp6c9EtMVsu8i4WESCjyMaQ8mDgdjqanKtooK6c1X6yEfJw/+hMRfhFGynFetY9Qy5ckFJC1Tl5aQLu7VYDMuB8rgHOwUB/5tEYvqevnllzFu3DhkZWVh1apVaGtrA8ATCt53331ddrYmEgV55FWo+Kvs/alsH/nQjmC6Bjw3TA6ABp3tlMJ/Mr54wwwp6aAaO3h0lLrKuaASPHeP2I4cEd0losP8RX+8CB6R5QLPXSSis5Iw2aC6HpLIsXLokFRJ3W4HliwBbrxRyq0jhyK6uoa/cxdK1fJ4xGzmOXzkFBb6Rkd5PFJNrrkaz61583xz8IgK7MEWFtU7tzYbT5zpdvvWkfNHtBIwhoNgJaqRI0ey+fPnM8YYy83NZZs2bWKMMbZq1SrWu3fvEGS0+II0PkZQawu6mnNnG2MsR7XNcE5C/ZtIb49qDZfIR2Qkn45485KbsrTKUmhNSeJXESx6zqDqN3W16UH+Bp5vtP4bocBf3ptk0fgwpq/ZCsUZ3u32NXNddlnw21I7LWtpjdzuwLmJxFQZ2/I+EdP4bNiwAaNHj/ZpLygoQHNzc9clMSIByer81Kvs7Q8TgIHg2gU19s7PYMtFqHNoLICkGSoPcluxoAa+Gq5N4FobdT4dLe1PLbhGZy54eQqAX5fJ4NmX9TKsmwF00wzBem+/co2QvMyAyLdSVyct29KirJpNGEPv3FutyVWiw2wGxo/3bQ8lW7PZDOzfz3MfCV55hd+T1UHkPJs7V1kiRUtrZDbz3ER6leblLFqUEBrQoAWfPn36oKHB16zw6aefKpINEsmM+o/aDm5Squv8LQZerTpTci70M88BYB64mcUJLhjJJz1zTx58yyjYIJnC6jX6H0/4q8OllURQtNnhW3/LCqAQyuuS09kO2acNPPGhO7QuJzticJg7VxJ4tMrz5OXxAYLoOjYbsHFjrHsRfp5/Xvk7P9/YPaMnSHR0AJddpmyrqwtO+JGXSPHHxo3cBCZqjuXl8c8rrlAud/jh8Z/kMFhV0n333ceGDBnCvvjiC5aXl8c++eQTtmjRIlZUVMQee+yxkFVU8QKZuoyiF3kkTCtyc4qW05vWemlMaZIJhL9K4MI8JLYlSlh0NaFhNAg2gaDc5OjPGVw+CRNCEjosRwp/TrgxVvEnNHpOtsmcD2nbNuN5ioQ5qrJS/5yonfHVZkKxXrjOqdh2oISfUb6GEYvq6ujoYPfccw/LyclhJpOJmUwmlpmZyf7yl7+E3Nl4ggQfozQz/4Oq1qAs2KYxf0KI/fDn86KV8TgShLO+UCCBRW9SJxLUWsaksWw3JdQHsl7oezQf8G53ctS0EugJlMnk3xMqweTpGTTId1mHQxKcLBapLRKUlRkTviJIxHx8TCYT/vznP+PXX3/F2rVr8cUXX6CxsRF///vfceBANOoZEfFBAbhZSY0NvtE/dlWbWrVbAWBpCH2ohv8aUoJWAE0a/QoFT+e2hC9HCoBihGA11kCv/pYeNihrYgWCAdhpcNkkRpirwqWKF74/0UD0PRlqWgn0zDhx7icSM/RMWVu2+NYIq62VzLLCRSVS0VcNDYDa3SUnh/dV3LdXXx3+/YZCOKSsgwcPsoceeoiiurol45lSq1DR2a6u8K1G5IfJ05kfCLVWSWh+hElLvNVYVct15W1HHQ2VrfrdlbfwQPl51FOg5G56ZsAkNh8YwV+UVrDr+jM9+NtGqGi9/SeD5sft9q3VBcRH5mZ51uJYoVWSwt+9668EhT+NUbgYP97//k2miO067KaugwcPsjvuuIMdd9xxbNSoUezVV19ljDFWW1vL+vbty/r16xdSiYh4gwSfYNEyq9hl8/zRHOI+tcKx1VmexfbDNfgHMh+F8mcOpVyEgwU22eltj0xcjDHtekdGkPsxBJtV2O1mbMKErpsa5INgBAeQqKE3qMfSx0dk5BamITHZbIytX6/0zTHSx3CY7NxupSkp0D2klw07WuUl9DJVi2lCqK4N/gm74HP77bezgoICdvnll7O+ffuytLQ0du2117Lhw4ezpUuXalZMT0RI8AmFCuY7yEbKPq8lgGj9mfUG/6687ai3KfK2hPLWLbZl1KfHzowJbP4yMocqaCYhwWp61INgMANzKEUkA/UnWTQ96vMiND+xygKsdZ21pvx8YwK0KAlhsYRHkBMaKCMEcniONCaT/3MYAcE27IJPSUkJ+/e//80YY+z7779nJpOJVVdXs46Ojq71NM4gwSdUUll0NAyNGvsxWrS0K0KPfNuNrGtCRKCyFFqTUe2ZnomLkuuFhJ5Gwqi5IJxJ6+TbFEnlRAmN5mZJU7FzZ2IIRnqRQOK44qU/Riat/mpFq1VWRlb4kEdvxVqLpqd1Mqq1CoGwCz5ms9lbl4sxxjIzM9maNWtC72GcQoJPqDSz0AbsYNGK4gok+FREoB9dxc6MCz3+HhBuJmW9NqnWEyHWXRHSuiGBBg9/A4g6s7PWYOrvgS8EGVF5W70ff6Yh9RTPpjAjmpVoan2CrVtlVOOjd5ylpeEXQtT90bpXoi0Qa2mdIiiIhV3wSUlJYXv37vX+zs3NZZs3bw69h3EKCT5dQS+3D2NdEzyE/46WA7DeQyeQc3W00XrLM1J+wp/w6M83iPLKhIQYLIQvhFb4unqgEw9vsa7drq89UIf3yv1F9ELlxf78CWJ6UzxqfoIRMqKhoVBXRbdYJJOSMFWJauSXXRa8j49WmLdcAxQO9Jz21VoXo7mDwom/6xtm7ZfR8dvE+xWYlJQUnHfeecjIyAAA/Oc//8FZZ52FnJwcxXKvvPJKeMLNYkRLSwsKCgrgdDqRnx9sqYTujge8NIIeDgQfSl0D/UzGFQAWB+hPPBQ5LAfPGG0FILLRBjpXctzwPY5A62ut001ZtQo49tjAy3k8PORWkJcH7NunXMblUpZRqK7m4cUVFbyQqT/sduDJJ3no+3XXSeUu8vN59l15+Qs1bjdwzTXAgiDSHZhMPLNvvKE+z/4Q57upSSqdEM5+ZGVJRT7luN1SioLWVt4Hjyf0tAVVVfrXLjMT2LwZ6Ns3tG2LPsrHYnHenE5eDFXQ3Bz97OL+rrf6/9RFjI7fhgWfaoMpsOcFWyE2ziDBp6v4E1SA4AZkI8JBvA/wreBlIgQu8ArrTvByEoGwg5fuUKNVt0tOvJ+XKCGvZRToURdoQLbblbWMhNATCC0BKlgsFikPiz/KyoBPPuHfuzKQRpqaGp5PJtBxud18QBd5Z/Lzw1MPzZ8g4nBoV0bvKh4PMHgwsEnnf9tVQbW8HKiv5zW1RLmPXbt4zidBLAQfAJg0idfxUrNzZ1jvU8Pjd1j1TEkAmbrCgZvxTMzC7CLPGBys6jpQqHcihGhrlctoZoFNXHpmukA5f6IUshrvfPONUq3+zTeB15H7ReTnS9/VzsyhmJ38TSkpoa8rIoYSLdOxMMfomfhsNm0H2a6Ya5qbuX+N3v6iYVpzuXzNa2IaNKjr2xYIM518amjo2va70i91XyLggxaxzM0EERgzeCZme+fvakgFMNMBVAWxrcfBsw3rIQqixjMbwTU98qKLBdCvOl8Jfr70tKfZkAqMqrEAmB9CH5OQsjL/v7UQBUldLuCSS3ib0PTINQ1mMy+kGS4CvenrVcYeP55rTByOxKtkLsxGTz7pOy8vD5g/H+jZU2leMlrUU4uCAm722bzZd57dzvcXjQzc2dnA4sX8PpNrJAFg69bQqrXLtw3wbdTX+87v2TP0bXeF7GypuKlgv7qYdPQgwYeIEB74VmsXJrAF4AN0IKzgZqIx0Dfb2P3Miye0BiW9h1AtAh+TEKYcsjYbuC8RAcB3ADE6oJjNwNFHS6aQujo+4BYWSoNuTU1w/jYAH1xdLj7gBSM0uVzcdOF2c1OFnBde4J+LFvE+trZyU4rHEx6TUDS44Qbftn37JPOW2w00NvJjD/WYnE6gpcW3vaSEbz8WLhpmMxd4Bw2S2qzW8AiwWoJGXl5szFyC+nrp5SNcxxkiJPgQEcIMaVB2gA/88of9JgAT/ax/NQBh+68H0AygEUpNhx36WpF4xwpA/uYpHlIOGBfkssGdxUW9LtL0KFA/5MVvj8d/raJJk3z9MISPTksLd7StVfmxqQcZQWkpV+yLwTU7mw948+dzQQjgA5IaMUDINTnCuVdPaNq3j/vDWCzcV6mwkAtD8VzzyuPRFiAnTFBqX3r27NqgPXmyb1tZGdf+RKvOmh5btnDhVgi44WLdOuXvX34J37ZDpaEh/McZCmE3siU45OMTbtyq72p/lFLV8i6mHRbvUi0Tb3l5gkHtoyPOQSIfUxwiQpDlIb5yHx6t/CtGkti5XNrbEQkERSi0EZ8b4VMiD3kW/kT+/E2MZhj2d6zxgla+mXD6K2n5YyWaP1SoqH3Wkpywh7N3FyiqK5LoRXzlAtgHKexbjUWnPZFogmTakp+HZDi2OEQdxgtwU4m6TR62bCRKSx4xIzQpWhoDEQIdDK2tfFtGNRCtrbwPt9zCNVD5+drmHIH8WOMNjwcYOtQ3KilciCiyCROApUvDu+14Jh7C2aOI0fGbTF1ElJD7+KjZD2AXtAWAMp32RMIMoAjcsVt9HtZprkH44csvAy+jJ3Q4HMrvQhDwePwLPSaTr4peLaQIHyKrlZucyssD91Pd52AEk+xsPogJh2ynk/exoYH/ljtzy481HjGb+bmNlBlEnKPuJPQAvj5RieL3FWFI8CGihNrnRx7NkA9t599mSH4+icpEAIc6v2vlJaIHUVCYTMDJJ/tGw6hRP+Bzc5VCgtutzNWi5QMCcIFh507uhKonTHk8XMjIyeH+OiIvTX191yJ0gkEINdnZvC9ms+RPoT7WeCaSDq/xLPhFCnUUV6yiuuIMEnyIKCIccecC6AAPU2+GdjK/CeAh34mMB4C/bL6p0I/sInxQa3oGDDC+7pYt0ne1psbj8XVWBoBt27jA4C/BWlUVdyQWIdLyEF2LJfYh5sFqkYjEprVVKfRnZ0upEGIcSRVPkOBDRBn5Q7gvuHCzS2O5ZFBJa2UBlmsqDmnMJ3RRCzo//aSvUVEP9v4Gf715gQQrq9U3Iik3l3/abNp5VAgiUpSXc61jYaFUYgOIrAkxQSHBh4gD1JodV0x6EV62a7Q5IGm6KKYgaLQ0L8OHay9bUMCdfYHASe+uukr5u18//fIWYjBpbfUttZCaykPK3W4ert5diOdw+e6COmHhgQNcEzlpEv9Nmh4FJPgQcYA8E7EV2v4+icbdqt/CxAdwTRcREm638vfmzfoZmZ3OwEnvPB4pCaB8m2paW3nUV3o6jxCSmxAAruk51KnBS1bTksfDz0NTk2RSEaa+mppY9657o74fBSKxJaGAwtlVUDh7LGlFcgg9aidmKhgaViZO9K2EXlZmrIinFvKCleoCla2tXKukFoZEaLgIKU/iEGEAUji4P+I5XL67oK7SLkjyMHYBhbMTCUgyCD2AbwRbuAeDbm5aePZZ37ZNm0KLoCov50KPxaKMfvJ4pLB0tdBjtyujqJJ9QNFz/pZjs/k6jKs1bWQSizzZ2dxMKy+DAQDHHx+T7sQrJPgQRESQR7CFkxpwbVI3Ni3oaRXUyQkD4XRKfhENDdLAXFPDzTdaGqQJE2JT1ymWmM3K/EdqLBalT5Mwf8lrm5FJLLps2QJUVEi/Gxqil1ohAUg4waetrQ0jR46EyWTCd999p5i3Zs0anH766cjMzET//v1x//33x6aTBAEgMpoe8eadCFXpo4zHw/1PjFBTI9WyAqRQX3/ajbS07pcATyCvWt/YyD+bm/mn3KnWYlFGurW08EKgoq22ljQ/0WLxYqmGHIWyK0g4wef2229HcXGxT3tLSwvOOeccDBw4EN988w0eeOABzJw5E3PmzIlBLwkiEqjD47vpG5zZrF8U9JRTAq8vF25aWvjbsHiJUms3ysr4QN/YSAO22cwHz549JROffDCtqvIt7goAW7dK30VyRSI61Ndz4fSjj2Ldk7gioQSft99+G++++y4efPBBn3mLFy+G2+1GbW0thg4digkTJmDatGl4+OGHY9BTIni66SBuGHV4fA4SP8FjiHg8+o7MRrIly4Ubk4kLUfISE3LtRkMDH+gp461/9Kqsq9m0iUfHdXchMprk5gLFxUBK53BP5z5xBJ89e/bg2muvxcKFC5GtobJbsWIFRo8ejfR06a143Lhx2LBhA3777bdodpUImnLwgTzI2kbdAg+4P89AVfvPMehLnBDI5yQvL/A25s7lpSjkQa1yoUloNwhj9OhhfNm6OvL3iRa7dkn3OGPA1Vfzcz9xYmz7FWMSQvBhjMFut2Py5Mk4Xsc7fffu3ejdu7eiTfzevXu37rbb2trQ0tKimIho0gqpCGk9eBVzgiMcmbV8Trr5oPz00/rzOjqMCT99+yrNLuQHERpOp7JUhxYOB4+Gk0P+PpFHbVZctox/LlnSrU2OMRV87rjjDphMJr/Tjz/+iMcffxz79u3DnXfeGfY+zJo1CwUFBd6pf//+Yd8H4Q958kKAVzEnzY//avaV6PZ5gQJpffbvN1aJ2u2WnHUppX9oqIXFsjIe3g5wYUekCZg3j38X1y3eK8Z3laYmrnGJZUV09bUZP176fuhQtxX0Y5rAsLGxEb/88ovfZUpLSzF+/Hj85z//gUlWkbm9vR2pqamYOHEi5s+fD5vNhpaWFrz22mveZT788EOcddZZ+PXXX3HYYYdpbr+trQ1tbW3e3y0tLejfvz8lMIwq1QDqVG0udHutBmqgLfx0w4SIra2+D+nycimiqKzM17G2sZF8c6KB/DoAXNiZN49rc4Rg09QkRc317MkHXbPZNxN3MuDxABkZSjNqfn5sBCCPh5u2BG43vw6HZHUCS0q0s5UnIEYTGKZFsU8+FBUVoaioKOByjz32GO655x7v7507d2LcuHF4/vnncdJJJwEARo0ahT//+c/weDwwd/7Zli9fjiOPPFJX6AGAjIwMZGRkdPFIiNDxwFfoIbjJLwkHhVAYOBDYvp2booRWRl2baNMmrmUQDrZmMwk90UCeC0lQV8c/hfCTk6Nt0hLpB5LhOrW28nvuuuuk45fT0sLPVbSTXQrNaG2tpGHbvp07Owu2bOEO/qFmPk9AErJkxdatW1FSUoJvv/0WI0eOBAA4nU4ceeSROOecczB9+nSsXbsWDocD//rXv3DdddcZ3jaVrIgm4mE4GID8bd0Cye+nO2KGfuV2O4BulEDPZFL+drkkzY98nig1ITIGJ8NgGu8EKmNht2sLAXLk1zMe8XgkzZXc8V0+7+STtcP45cRK4yOQa98A3/8VEP/XwgDdrmRFQUEB3n33XWzZsgXHHXccbr31Vtx1111BCT1ENBGOu+lQCj0AsDr63Ykbroa+0GNDtxJ6UjQeT+LBvGuXsl1ohEnTEx20Ej26XJIDsxGhJ94RGbxzcqRM1IWF/HdODv9eVORf6JkwIXCh3Gig9qViDOjXT9mmVeMrSUlIjU8kIY1PNFAX8ZRTCl9BqLug5esk6GZasKYmPqio2bmTR2Pt2qVU14t2IjpYrUrTiLy4q9AuCI2Q1crNYTYbv27Ll0vrbdsGDBgQ3b4bQe0bEwx2O3D33b5Rg/GG1jHm5ASO0ItjjI7fJPioIMEnGrSC5+3Rohs67gLwf04E3ezcpKby0HQ5cnV8SorkQJqXx/0oiMhjsSi1HP4qf+tVCxfEc0V3IxXpBRYLsG4d/x6vx6NGT7hL4Eru3c7URSQS2QByNdonoFsN7ACkBIWBhB47ut25ESHRApFhWSS+kycm3bePZ6glIofHo12W4oQT9NfxJwTIq9zHIyKDd2Wl/jIVFVK9MrM5vo9HjdmsfWyJdAwhQhofFaTxiQZWAFoRBM3oPmUYPAAmQz9Xj5xKAAsj2514Q/02mpurVMELTYHZrAzNTeC31bimutq/z46eY6yeVkGEvCcK6uNPS5MiuRIBfxFleXnK/1ZZWcJGeJHGh4hTWqEt9ADdJ2+Pv4zMakrR7YQewLcQqfzBLNo9HqXQI9qI8BJI6LFYlEKPuAYeD5CZ6bt8c3NiCT2AlHxRJLxUR0nFMwUF3BFbTxDYs0f5e9OmwPXuEhwSfIgoc0OsOxBj/GVk1uLHSHUkvvFXiLShgWsRJk/WXo/oOnLhxZ/QU1mpzOMjIqFKS/mn2kerrCxxNXJCw5hIUYNOp+T7tm8fMGmS7zLZ2TyJoXq9JIYEHyKKeADoVXDOQ/fxYbEFXgQA4ED3OScB0DKjaDmeUmRXaMgFRiG8BCoiarMBC2XaSHmI+5Ytvsvn5iasCSVhUQswixZpvxx8+63yd4Ln8wkECT5EFDncz7x94GawZEaYuAL97SrAI7jmRrxHcYv6wXvFFYHXaW6OSFeSEpHo0ePhpqz0dO64LBdeamt5JmI9nntO+dts9tUcCCoquMaBiC5aqQK0TF4FBVJ7fn7iauUMQoIPESWc4MKNP5JZuyE3cdX5Wa4MwGIk97kIwMSJvr47Cxb4VvdWk+RvqWFDCDqFhfxTmLIWLAB69JCWs1h8zVzCv0pdYFRkMdbS9NjtwOLF4es/ERzqemgHD2qbspzO+Ei2GAVI8CGiRKCBPFHNOh5IpTf80QTtEH45Nug7fncTPB5gyZLg17PZEsfZNJYEclSWO5E3NEjCpsPBB9D6eqnaukCYxtTaodJSvmyiOTInG1ph64WF2ssmuaZHQOHsKiicPVIEStC3E0Ci+WfIq6c7ADwM7XB8jbo4XnIB/Nr5nQbugBlz9UohUBh7YAIlE1Qjr3+mJ1Sqr5e4PjYbMH9+V3pLhJvcXJ52QE6SDf8Uzk7EGdngZReSBXV0Vi2AQigFn1YAaX62UQJu/jODhJ5ORDVpQX6+9NvhkMKK1ct0Z6FH7awq/93aKvnxGBV67HalVsefJk1+veTXh4Se+EOrFEU3qs8lhzQ+KkjjE0n0anSZAHRotMc7kwAs0mj/BsCVADb7WbcM3d6spYdaiyB8FNQDsMfDB/buIvSoq4MDPKS/tpYLK3PmKH9/8kngquFybDbusByKyTCR8tp0Z7Q0qgmcsFAN1eoKERJ8Io3cPCRwIXGTF+YjsNO2nDIAa5C4xxsF1NmY9bICdydKS7Udh0MlLU06x1Yr8MMPJLh0FyZN4mHtcpLkP0amLiJOmQtemkJOIj9wW8CPhyHwcZSAa3kS/wETMZqalEJPSUlSPJBDRmhSwiX02GzcH8rj4Zo0lwvYuJGEnu7EwoW+Jq5uZvIiwYeIMjXgvjByEj18sgDcXOcvuqsM/k1fhCZffRXrHsQGj4e/maen+4b2B0tenlRuYf58yTRoNndvobI7o+XvE4xZNMEhwYeIInrlGhL9bVNv8BCOzRSmbpimJv+/uwMiPFxtjhDYbFyI0UsWKKe5mZcsSLTK4UTkUXu5lJXFph8xgAQfIoqYAdhj3Ykw4wRwQNWWB27+8oBnYKYIF8OoM81qZZ5NRkQCQHnmZC0qK3miwSFDApu/GOs+jt9EaDDGHZu7masvCT5ElJkHXnFcTiK/iRaAOzgDQBa4wNMCKaw9kY8tBmRnc2dbgH92B1NMVRXX8IgkgPJQ/bw86U08L0/SAsmjcHJViTFLSiIzkDU1JX3V7m5JN9L0CEjwIaKMB76+LiNi0ZEw4gQXeFqhncCQCIqNGyWn22RDhOCLyWrlGhxBXR2vaO52A42NwKWXSr4X8lpXonSEzcbbhQ+PywVsDoMvmbw6e2srN5MVFXEn2PLyrm+fIGKIv+xqBBEBtByAG8CFhkR+uyeBJ6wkm6antRW48Ub/ZiyBEH7kApEak4kLOsJvR/3ZFWpqeD/LyrQdXuvr+fEk2zUiug2Ux0cF5fGJNHpJDC0A6qPcF4KIEMJfBwCOPjoyETORyL3S1MQ1O/6wWpNTG0ckPJTHh4hT9ELXhdaHIBIQURoCkHx2cnL4FAmhx2IJv9BTUOBf6MnJSV4TJNGtIMGHiDJ6JiErEtvURXRLPB6uAcnJ4cJOfr5/E1VXSOl8XNts3NwUTpxOHvauRV4eD4vfvz+wsKWuG0YQcQgJPkSUmRzrDhBE1/F4gIkTubAjj7DaF0z5EhnySDaBKBbqcnHBo71dvwBoVwUOLYGmslLKA2QkLF4kXKyp6VpfCCLCkOBDRBG9BIYA9+8hUxcRZ2gJFCLB4JIloW1TRGQBknCzcaPy0+3mlc5FdmV5tmUREeZ08k9hWuuKwCGvsi4SJC5caEzg8Xi4pkuE2tfWkuaHiGtI8CHihDKQqYuIGzweScCprla2G4nMEgghRy7sjB7NzUcA8PLL2pFZetFZ5eWS71BhIf8UprWuChxz50oaJSPRYR6PJHSFqukiiBhA4exEnLAm1h0gCD6YOxzKchF1dcDBg8A//wn8+c/Bba+hgQs969ZxAQFQCk779nET0cKFgbfV2urft8dmCymcvb29HR65wNTeHnilP/4ReOMN/n3gQN/5+/cDWVlB94Ug/GE2m5Gamtrl7VA4uwoKZ480VQC0nD/doCzHRMxobQWuvTZ081UgXC4pj4/dzoUpOfKcPP6wWpU+RQKLJWiHZ8YYdu/ejebm5qDWw7Zt/uenpQF9+gBhGKAIQk1hYSH69OkDk8nkM8/o+E0aHyLKzAfwGYDuUwmYiHPKy7sWJSUEGauVb8ds5pojk4mXjhClN+bOBZ5+ms9PSZE0Pw6HcU1NfT03Ly1YwJ2Pn3mGt4cQ2i6Enl69eiE7O1tzIPFh40agZ8/Ayx08yD+HDQu6XwShBWMMra2t2Lt3LwCgb9++IW+LND4qSOMTLcwADsl+N4OyHxNRp7WV+8moEUKLHmlpwKFDUjI/j0cSeMxm7nhcUOA/w7EwL4WSbVnsJ0Ta29uxceNG9OrVC4cffrjRlYBvv/Vt79GDm7u05h19tGTiI4gw8Msvv2Dv3r0oLy/3MXtRAkMijnFCKfQA5NhMxAR5UVTBhAn6Qo/NxkO8D3Xev/X1SiFEZGwWwo4/TYw/J+ZAdLE0hfDpyQ6kKerokL6npgIZGfx7RgYwYgRw+OHAr78CP/2krQkioYcIM+Ke9XTBkT+hBJ8333wTJ510ErKysnDYYYfhkksuUczfvn07zj//fGRnZ6NXr1647bbbcOiQeoAlYo/Ww/a6qPeCIABIRVEbG7mvzdKlkjBksXBBx+WSIp4KCqTQb7mZSkRciUrrCZDPRte81dHBi52uWgVs3Sq1Dx8OHHMMMGQIF4R++YW3NzUBAwYAxx7Lp6OPBo4/PuL9J7ofhkyyAUgYH5+XX34Z1157Le677z6cddZZOHToENauXeud397ejvPPPx99+vTB559/jl27dsFms8FsNuO+++6LYc8JX7Qk9ToAc0AOzkRMyM5Wamc2bvRvppL76wDaEVe1tcplEoGODu68LAQaQBJqRObodeuAtjau9enZk8/v2VOaD5Cmh4hrEkLjc+jQIdx000144IEHMHnyZJSXl2PIkCEYP368d5l3330X69atw6JFizBy5Eicd955+Pvf/44nn3wSbrc7hr0nfMkGUKpqqwAJPURcEcgMJBdotExmwTgtxwNbt3INj1zoAbgPjxBq2tu50APwz/79uYZn0KBo9jRi/O9//4PJZAoY6TZo0CA88sgjUelTvHHGGWfg5ptvjnU3ukRCCD6rVq3Czz//jJSUFBxzzDHo27cvzjvvPIXGZ8WKFRg+fDh69+7tbRs3bhxaWlrwww8/6G67ra0NLS0tiomIBl+qfj8ak14QRNgQJjOReXnu3Fj3yDhtbVxzo0Wp7CVF7eeTmqrU9EQBu90Ok8kEk8mE9PR0WCwW/O1vfwuLW8Mpp5yCXbt2oaAzY3VdXR0KCwt9llu5ciWuu47M84lKQgg+mzdvBgDMnDkTf/nLX/DGG2/gsMMOwxlnnIFff/0VAA/NlAs9ALy/d+/erbvtWbNmoaCgwDv1798/QkdBKFGbuyjFPREGPB5udpL/jibZ2V1zWo4mHR1cQPv6a+D777WX0fLTEX4+w4dHtn9+OPfcc7Fr1y7U19fj1ltvxcyZM/HAAw90ebvp6em6OWLkFBUVBXYMJ+KWmAo+d9xxh1dy15t+/PFHdHRGFvz5z3/G5ZdfjuOOOw7z5s2DyWTCiy++2KU+3HnnnXA6nd7pp59+CsehEQFRDwx/jEkviCSiupr7luTkcEfjcNSwSjZE1Nlxx/FIrI0btZdLSfHvnBzj5IQZGRno06cPBg4ciBtuuAFjx47F66+/DgD47bffYLPZcNhhhyE7OxvnnXce6mX+V9u2bcOFF16Iww47DDk5ORg6dCjeeustAEpT1//+9z9UV1fD6XR6x6OZM2cCUJq6KioqcNVVVyn65/F40LNnTyzoLCfS0dGBWbNmoaSkBFlZWRgxYgReeuklv8f41FNPwWq1IjMzE71798YVV1zhnfff//4Xp512GgoLC3H44YfjggsuwKZNUm60rVu3wmQy4YUXXsDpp5+OrKwsnHDCCdi4cSNWrlyJ448/Hrm5uTjvvPPQ2NjoXc9ut+OSSy7B3XffjaKiIuTn52Py5Ml+3UXa2trwxz/+EUcccQRycnJw0kkn4X//+5+h8x0rYurcfOutt8Jut/tdprS0FLt27QIADBkyxNuekZGB0tJSbN++HQDQp08ffPXVV4p19+zZ452nR0ZGBjKE6paIImrBZwm4g3MCvCkT8YdI6ieor5ecjRPRyTjceDzA5MlS0kStMhMA9+cZMIDnKUogsrKy8Eunb5Ldbkd9fT1ef/115OfnY/r06fi///s/rFu3DmazGVOmTIHb7cbHH3+MnJwcrFu3Drm5uT7bPOWUU/DII4/grrvuwoYNGwBAc7mJEyfiyiuvxP79+73z33nnHbS2tuLSSy8FwC0LixYtwtNPPw2r1YqPP/4YlZWVKCoqwpgxY3y2+fXXX2PatGlYuHAhTjnlFPz666/45JNPvPNdLhduueUWHH300di/fz/uuusuXHrppfjuu++QIjM9zpgxA4888ggGDBgAh8OBiooK5OXl4dFHH0V2djbGjx+Pu+66C7Nnz/au8/777yMzMxP/+9//sHXrVlRXV+Pwww/Hvffeq3nup06dinXr1mHZsmUoLi7Gq6++inPPPRfff/89rFar4fMdVVgC4HQ6WUZGBnvuuee8bW63m/Xq1Ys988wzjDHG3nrrLZaSksL27NnjXeaZZ55h+fn57ODBg0HtCwBzOp3hOwBCh1zGGGTTtth2h0gs3G7+abczxjPvaE82W2z7GStcLn6OHA6fc3Jg4EC27u232YGVKxkTU3t7l3YnLkekqaqqYhdffDFjjLGOjg62fPlylpGRwf74xz+yjRs3MgDss88+8y7f1NTEsrKy2AsvvMAYY2z48OFs5syZmtv+8MMPGQD222+/McYYmzdvHisoKPBZbuDAgexf//oXY4wxj8fDevbsyRYsWOCdf/XVV7OrrrqKMcbYwYMHWXZ2Nvv8888V26ipqWFXX321Zj9efvlllp+fz1paWgKeD8YYa2xsZADY999/zxhjbMuWLQyAYsxcunQpA8Def/99b9usWbPYkUce6f1dVVXFevTowVwul7dt9uzZLDc3l7V33h9jxoxhN910E2OMsW3btrHU1FT2888/K/pz9tlnszvvvJMx5v98h8KBAwfYunXr2IEDB3zmGR2/E8LHR6jbZsyYgXfffRcbNmzADTfcAAC48sorAQDnnHMOhgwZgkmTJmH16tV455138Je//AVTpkwhjU7colazd+M3ciI4ROX0q69W1r2y2biDsTwPz/z5MelizGhq4g7JIqeQv2ryJhNPRHj88V1yUhaXI1pWxTfeeAO5ubnIzMzEeeedh6uuugozZ87E+vXrkZaWhpNOOsm77OGHH44jjzwS69evBwBMmzYN99xzD0499VTMmDEDa9Z0rUByWloaxo8fj8WLFwPg2ph///vfmDhxIgCgoaEBra2t+N3vfofc3FzvtGDBAoV5Ss7vfvc7DBw4EKWlpZg0aRIWL16MVpnvWn19Pa6++mqUlpYiPz8fgzqj6oQFRHD00Ud7vwuf1+Ey36zevXt7S0AIRowYofBfGjVqFPbv36/pBvL999+jvb0d5eXlimP76KOPvMcW7vMdDhJGn/nAAw8gLS0NkyZNwoEDB3DSSSfhgw8+wGGHHQYASE1NxRtvvIEbbrgBo0aNQk5ODqqqqvC3v/0txj0n9FE7B5KzIGEAj0cazJctU8577jlu0gqUhycZaW3lyRX1optELTG7HXjsMWD7dqCsLAxZoKXLES2r4plnnonZs2cjPT0dxcXFSAvCNHfNNddg3LhxePPNN/Huu+9i1qxZeOihh3DjjTeG3J+JEydizJgx2Lt3L5YvX46srCyce+65AID9+/cD4Al4jzjiCMV6ei/leXl5WLVqFf73v//h3XffxV133YWZM2di5cqVKCwsxIUXXoiBAwfi2WefRXFxMTo6OjBs2DAfXxyz7EIIh211W4c8O3eQ7N+/H6mpqfjmm298ykcIc1YkzndXSQiND8Av1oMPPog9e/agpaUFy5cvx9ChQxXLDBw4EG+99RZaW1vR2NiIBx98MKg/BBFt1BE3/WLSCyLBMJuBigrteSKKS142Qt6ebIgotrIyruHREnomTODRWxs38s9586RCqWHAbNZOZB1JcnJyYLFYMGDAAMUzfvDgwTh06BC+/FJKl/HLL79gw4YNCh/R/v37Y/LkyXjllVdw66234tlnn9XcT3p6Otrb2wP255RTTkH//v3x/PPPY/Hixbjyyiu9AsaQIUOQkZGB7du3w2KxKCZ/UcRpaWkYO3Ys7r//fqxZswZbt27FBx984D2ev/zlLzj77LMxePBg/PbbbwH7aJTVq1fjwIED3t9ffPEFcnNzNft6zDHHoL29HXv37vU5NrlvrdHzHS0SRvAhkhH1E3I/eB0vggiA3LwlR0R0ye0uwg5TXc1/J4sQJI9i60z5ocnSpZI0EiGpZO7c+EhdZLVacfHFF+Paa6/Fp59+itWrV6OyshJHHHEELr74YgDAzTffjHfeeQdbtmzBqlWr8OGHH2Lw4MGa2xs0aBD279+P999/H01NTQpzk5qKigo8/fTTWL58udfMBXDtzR//+Ef84Q9/wPz587Fp0yasWrUKjz/+OObrmGHfeOMNPPbYY/juu++wbds2LFiwAB0dHTjyyCNx2GGH4fDDD8ecOXPQ0NCADz74ALfccksXzpoSt9uNmpoarFu3Dm+99RZmzJiBqVOnKpymBeXl5Zg4cSJsNhteeeUVbNmyBV999RVmzZqFN998E0Bw5ztakOBDxBAtISdJBiUissjVDGrk0VytrZIdpq6Om3v0nFESRSDyeHgUm57wB3Atz86d/ivMh5l4CZqbN28ejjvuOFxwwQUYNWoUGGN46623vBqY9vZ2TJkyBYMHD8a5556L8vJyPPXUU5rbOuWUUzB58mRcddVVKCoqwv3336+734kTJ2LdunU44ogjcOqppyrm/f3vf8df//pXzJo1y7vfN998EyUlJZrbKiwsxCuvvIKzzjoLgwcPxtNPP42lS5di6NChSElJwbJly/DNN99g2LBh+MMf/hCWHEaCs88+G1arFaNHj8ZVV12Fiy66yBvGr8W8efNgs9lw66234sgjj8Qll1yClStXYsCAAQCCO9/RwsRYFP8ZCYDRsvZEONgFoFjV5gL5+hCG8Xi4M29BAdd8qHG7geuu0xYS3G5ptK6p4QKSw6GvtpBXYY8mHg/3xxkwALjmGmXYvpy8PK75KSgI2M+DBw9iy5YtKCkpQWZmZgQ6TSQidrsdzc3NeO2112LdFV383btGx2/S+BAxpC8AeYZUK0joIYLCbAb69uX+PEIDJCK6hMPJvHncoVdrHuDrnaul+ZGHLUVTMyT2a7HwTy2hJy2NV5BvaeHFQuNF9UIQcQoJPkSM6QCwE1zTo5NFliCMIBxNhBPv009L8+bN42HuGzcCjY3A449zM5hwDhbO0lreuWrBKFpx2/L9amG382PxeLiWhyAIQ5DgQ8QBfUGaHiIsmM1SlmLh0Ozx8M+cHD6/qIh/F3luCguBJUv4+h98wAWh7dsBp1Mq8aDOMK+nGQr3sWj5MVksUnRWz56R7QPRrairq4trM1e4IB8fFeTjQxAJgpbPjfDViQTjxwMvvCD9lvsIRRK5j486TD9EyMeHSFTIx4cgiO7JpEm+JqdApqGuIhd6AK5VigZms5RosDslZCSICEGCD0EQiUV+PrBoEf8uNzkFK4iUlXGtjU5IcUCiYe4iCCLskOBDEETiMGkSsG+fsk344vjT9lgs/NNm48KOywU0NHAtyubNvB1QVi0PlNk4WmmKCYIIKyT4EASRGHg8kqZHjgjh1nIEFoJOfT3/nD9f22Q0fz6fv3Ur/3S7gfZ2HibudgPbtvEIqp07pfnBpikm7RBBxAUk+BBEIrJrF9d0dCf0jleUEfjnP5XtjY2SoAME1s7IlxPfRTLAAQO4gNW3r3K+UUQ+nokTpWsnosdIIOo2/O9//4PJZEJzc3OsuxI0gwYNwiOPPBLrboQFEnwIItFISQGKi3kYdl5erHsTPbQce3NzeXtNDQ9TF+Tnx0+ot9wMt2SJdO1ycrhpLT2dl6AQJjuRXyhSfQk3Bop4hhO73Q6TyYR//OMfivbXXnvNW4E8XGzduhUmkwnfffddWLdLxBYSfAgikdi1S1l/af9+Pvh3B7KzuUOynP37lfW4BE1N0etXIPxVkxcsWMCFIVF0VJ6DSJ5oUXyGgjz7dFdpb+fT998D337LP6NIZmYm/vnPf4a1KnlXcLvdse4CEQQk+BBEIqGlxXC5gNLS7mEyWbPGt00tCNhs8ed0vHgxLy0RDHV1SkFI/mm1cuFO1CprbZUmgbgfhMCkLsvR0SFNgfB4gLY2pbDz7be8DZDmRYmxY8eiT58+mDVrlt/lPv30U5x++unIyspC//79MW3aNLhcLu98k8nkk7CvsLAQdZ213UQR0WOOOQYmkwlnnHEGAK51uuSSS3DvvfeiuLgYRx55JABg4cKFOP7445GXl4c+ffqgoqICe/fuNXxcjDHMnDkTAwYMQEZGBoqLizFt2jTv/EDbF6a0d955B8cccwyysrJw1llnYe/evXj77bcxePBg5Ofno6KiQlFp/owzzsDUqVMxdepUFBQUoGfPnvjrX/8Kf2n+mpubcc0116CoqAj5+fk466yzsHr1au/81atX48wzz0ReXh7y8/Nx3HHH4euvvzZ8LiIJCT4EkUjoOfFu2SKZTLo7s2fHugfaeDySg3RzMxdYx48PbVsNDdy0l56uzEQthKLqaj4vP5+3HX64tK7VClxwAfDTT8C6dcCqVTyyTWhx2tu5MCQcvL/+Gli9WhJ4hLAjJyMDSE0N7VhCIDU1Fffddx8ef/xx7NixQ3OZTZs24dxzz8Xll1+ONWvW4Pnnn8enn36KqVOnGt7PV199BQB47733sGvXLrzyyiveee+//z42bNiA5cuX44033gAAeDwe/P3vf8fq1avx2muvYevWrbCrs3774eWXX8a//vUvPPPMM6ivr8drr72G4cOHe+cb3f7MmTPxxBNP4PPPP8dPP/2E8ePH45FHHsGSJUvw5ptv4t1338Xjjz+uWGf+/PlIS0vDV199hUcffRQPP/wwnnvuOd2+XnnllV6B6ptvvsGxxx6Ls88+G7/++isAXq2+X79+WLlyJb755hvccccdMMfLCwkjFDidTgaAOZ3OWHeFIPRxuRjjRi/fyWKJde8ih9vte6zNzcq25uZY9zI43G5+PZubpe92u/71DcN0YOBAtu7tt9mBlSsZC8d06FDUTldVVRW7+OKLGWOMnXzyyczhcDDGGHv11VeZfEirqalh1113nWLdTz75hKWkpLADBw4wxhgDwF599VXFMgUFBWzevHmMMca2bNnCALBvv/3Wpw+9e/dmbW1tfvu6cuVKBoDt27ePMcbYhx9+yACw3377TXP5hx56iJWXlzO32+13u4G2/95773mXmTVrFgPANm3a5G27/vrr2bhx47y/x4wZwwYPHsw6Ojq8bdOnT2eDBw/2/h44cOD/t3fvcVGV+R/AP8N9gOEiDAg2AoKQGuClJEwxE0NfyobruqYooKhrQprmNUvM/RnUrmmahbUCsmqWtV66aYJhrqgBCV5AboJowqKlIAKC8P39Mc2R4wCiAsMw3/frNa/hPOfMOd9zPDXfeZ7nPA9t2LCBiJTX0cLCgmpra0XxuLq60tatW4mISCaTUUJCQpvO42HU1NRQdna28G/YVFu/v7nGhzFt1HQ28vsVFHTfJ75aqvHSZqrH61UTjapmlL99+96rK/fjEmp7Or+p9d1338X27duRk5Ojti4rKwsJCQkwNzcXXgEBAWhsbERRUdFjH9vT0xNGRkaisoyMDAQGBqJ3796QyWQYOXIkAKCkpKRN+5w8eTJqamrQp08fzJkzB3v37sXdu3cfev9eXl7C3/b29jA1NUWfPn1EZfc3wT377LOizuG+vr7Iz89HQzNNmFlZWaiqqoKNjY3o+hYVFaGwsBAAsHjxYsyePRv+/v6IiYkRyrsCTnwY01aq2cibY2XVfZu9mlbRFxQACxYom3QA5bs2zlReX3+v87GRkXLARVXTlZeXshN3c5o+1RcScm8gRuDeoI33dwh/lCcBjY0BT897TWY2NsDgwcCgQcpyhAMw+uO98/j5+SEgIAArV65UW1dVVYW//e1vyMzMFF5ZWVnIz8+H6x/XRCKRqPVjqW9jXzkzMzPR8u3btxEQEAALCwvs3LkTaWlp2Lt3L4C2d35WKBTIzc3FRx99BKlUivnz58PPzw/19fUPtf+mTUoSiUStiUkikaCxLX27WlBVVQUHBwfRtc3MzERubi6WLl0KQNncdv78eYwfPx5HjhxB//79hXg17SF72zHGuhRDQ2XjhYGBeufSxEQgNVU5eF93Ymqq/FIvKFAuJyYqE8Dqau1MepqbWLXpr+PWfinfuqXsL2Rqeq9Dt6pfhmqmetW76gvd1BT4o6YAANCjh/L999+VCc6dO8rEpleve/12VO8uLspH8EWjWtcDUMUfByAWQOf15YiJicHAgQOFDsYqgwcPRnZ2NtxUCWAz5HI5SktLheX8/HxRp19VjU5ztR73u3DhAn777TfExMRAoVAAwCN15pVKpQgMDERgYCAiIiLw5JNP4uzZsyCidtl/S06dOiVaPnnyJPr27Qv9ZvpuDR48GGVlZTAwMICzs3OL+3R3d4e7uzsWLVqEqVOnIj4+HhMnTmy3mB8V1/gw1h3cvSuebkGluzZ7nTghXg4L086kpy0Tq/btq3y/r4ZBWKcaZFGl6QCLTd9NTe+NhXToEKBQAP37K58I7NNHWYPj6al8d3FR1jzp66t3WlabysMQgKr5cRY6M+kBlE1OwcHB2LRpk6h8+fLlSE1NRWRkJDIzM5Gfn4/9+/eLOje/8MIL+PDDD3H69Gmkp6dj3rx5otoROzs7SKVSHDx4EP/73/9Q0cp/S71794aRkRE2b96Mixcv4sCBA/j73//+UOeSkJCAbdu24dy5c7h48SJ27NgBqVQKJyendtl/a0pKSrB48WLk5ubis88+w+bNm7Fw4cJmt/X394evry+CgoLwww8/oLi4GKmpqVi1ahXS09NRU1ODyMhIpKSk4NKlSzh+/DjS0tLQr1+/dov3cXDiw1h3UVzc/JM13bHZ6/7BDHftEtdqaAtDQ2D69ObXmZsra7Ly8pTvVVXK/j6qKTNu31aue1R6euIkRvX3g+Yoa9Y2AHV/vHe+tWvXqjXdeHl54ejRo8jLy8OIESMwaNAgrF69Go6OjsI269evh0KhwIgRIzBt2jQsWbIEpk3uLQMDA2zatAlbt26Fo6MjXnrppRZjkMvlSEhIwJ49e9C/f3/ExMTgn//850Odh5WVFT799FM899xz8PLyQlJSEr7++mvY2Ni0y/5bExISgpqaGgwdOhQRERFYuHAh5s6d2+y2EokE3333Hfz8/DBz5ky4u7vj5ZdfxqVLl2Bvbw99fX389ttvCAkJgbu7O/76179i3LhxePvtt9st3schofsbOHVcZWUlLC0tUVFRAQtVvwHGtIlM1nyfEDe37tPsVV2tXgNiYKCs+Zo16+Hn0dI0Cwvx5Kt9+rTexPWYamtrUVRUBBcXF5iYmHTYcZh2eP755zFw4ECtmJKitXu3rd/fXOPDWHdz61bztQgFBcqRnwHtqxm5X3Pxq55+UQ3Qp00qK5V9dVTj+3ShJ2AY62448WGsO/r3v5XNIb17i8sdHZU1I6qpCx51+gNNqK9vW38lN7euN3JzW1haKl/NzUnGGGs3nPgw1l0ZGgKXLimbTZpSPaESF3dvpN+uTvWot5XVvQShpceyCwq0r8aHMQ1KSUnRimau9sKJD2PdXWGh+lguTRUUdO3Oz/c/+VRZqaz5qaxsvkkvLEw7a3wYY52CEx/GdEEzI9uKJCZ2zVqS69cBa2txmUx279F1VZOeauC+sDDlqMeMMdYCTnwY0wVtmeph1qyuk/xUVytjlsuVnX1VnJ2VNT1NGRoC27crEyBOehhjD8CJD2O6QjXFRUvjtOzYca/TM9C2js/tmShVVyv35+6u7HvUZI4iAMqy1uZY4uYtxlgbcOLDmC4xNFR2bp42reVt4uKUHZ7NzJRPSLWUAKk6HIeHP3oCpEp2VMczMmp5rKEbNx7tGIwx1oTWJD55eXl46aWXYGtrCwsLCwwfPhw//vijaJuSkhKMHz8epqamsLOzw9KlS0Uz2zLG/rBz570RgF1cxOtCQu7Ng1VYqExIXF2V/W1UCU7TDsdxceqPx1dXKzsgq0ZTrqhQlqkSnYoKcbKjOl5Lpk/nGh3GWLvQmsRnwoQJuHv3Lo4cOYKMjAx4e3tjwoQJKCsrA6CcRG78+PGoq6tDamoqtm/fjoSEBKxevVrDkTPWRanmdLp4UdmPRjUdwvr16ttevKjsb2NkBMycqfzc/bVGqsfjDQ2V71ZW92Ybt7K6N9u4avlByY6KTKbsxMyYFnF2dtapR8Sbev755/Haa69pOowWaUXic/36deTn52PFihXw8vJC3759ERMTg+rqapw7dw4A8MMPPyA7Oxs7duzAwIEDMW7cOPz973/Hli1bUFdXp+EzYKyLU01gaWgI2NoqBzlsSUKCsp/Qrl3Nr2/vWtY/ftwwBgBhYWGQSCSIiYkRle/btw8SiaTT40lISICVlZVaeVpaWotzXTHN0orEx8bGBh4eHkhMTMTt27dx9+5dbN26FXZ2dhgyZAgA4MSJE/D09IS9vb3wuYCAAFRWVuL8+fMt7vvOnTuorKwUvRjTefX1rfcDau8p/mQy4OWX1cvd3HgkY6bGxMQE7777Lm504X5fcrlcNOEp6zq0IvGRSCRISkrC6dOnIZPJYGJigvfffx8HDx6E9R9jfJSVlYmSHgDCclkrvxijo6NhaWkpvBQKRcedCGPapGk/oGvXlK+wMOW6+39Zt+WXdnODDU6frpyfigjYvVu87i9/6T6TqrJ25e/vj549eyI6OrrV7f773/9ixIgRkEqlUCgUWLBgAW43GR6htLQU48ePh1QqhYuLC3bt2qXWRPX+++/D09MTZmZmUCgUmD9/Pqr+mAQ4JSUFM2fOREVFBSQSCSQSCdasWQNA3NQ1bdo0TJkyRRRbfX09bG1tkZiYCABobGxEdHQ0XFxcIJVK4e3tjS+//LLV8/voo4/Qt29fmJiYwN7eHn/5y1+EdQcPHsTw4cNhZWUFGxsbTJgwAYVN5oArLi6GRCLBF198IVyjZ555Bnl5eUhLS8PTTz8Nc3NzjBs3DteuXRM+FxYWhqCgILz99tuQy+WwsLDAvHnzWm1ZuXPnDpYsWYJevXrBzMwMPj4+SElJEdZfunQJgYGBsLa2hpmZGQYMGIDvvvuu1XN/HBpNfFasWCHcLC29Lly4ACJCREQE7OzscOzYMfz8888ICgpCYGAgSlWTLj6ilStXoqKiQnhdvny5nc6OsW5A1Q/I1lb5io9XJkKNjcpESDWxZltqgHbsuJc4Acq///1vIDJSfTZ5iQTYs6f9zoN1K/r6+njnnXewefNmXLlypdltCgsLMXbsWEyaNAlnzpzB559/jv/+97+IjIwUtgkJCcHVq1eRkpKCr776Cp988gnKy8tF+9HT08OmTZtw/vx5bN++HUeOHMGyZcsAAMOGDcPGjRthYWGB0tJSlJaWYsmSJWqxBAcH4+uvvxYSJgA4dOgQqqurMXHiRADKH+GJiYmIjY3F+fPnsWjRIkyfPh1Hjx5t9vzS09OxYMECrF27Frm5uTh48CD8/PyE9bdv38bixYuRnp6O5ORk6OnpYeLEiWhsbBTtJyoqCm+++SZ++eUXGBgYYNq0aVi2bBk++OADHDt2DAUFBWp9ZZOTk5GTk4OUlBR89tln+M9//oO333672TgBIDIyEidOnMDu3btx5swZTJ48GWPHjkX+Hz9sIiIicOfOHfz00084e/Ys3n33XZibm7e4v8dGGlReXk45OTmtvu7cuUNJSUmkp6dHFRUVos+7ublRdHQ0ERG99dZb5O3tLVp/8eJFAkC//PJLm2OqqKggAGrHYoy1YtYsIoCob1/le3OvWbOU29bVKV+qv+/fTiLR3HnoiJqaGsrOzqaamhpNh/LQQkND6aWXXiIiomeffZZm/XFf7d27l5p+pYWHh9PcuXNFnz127Bjp6elRTU0N5eTkEABKS0sT1ufn5xMA2rBhQ4vH37NnD9nY2AjL8fHxZGlpqbadk5OTsJ/6+nqytbWlxMREYf3UqVNpypQpRERUW1tLpqamlJqaKtpHeHg4TZ06tdk4vvrqK7KwsKDKysoWY23q2rVrBIDOnj1LRERFRUUEgP71r38J23z22WcEgJKTk4Wy6Oho8vDwEJZDQ0OpR48edPv2baHs448/JnNzc2poaCAiopEjR9LChQuJiOjSpUukr69Pv/76qyie0aNH08qVK4mIyNPTk9asWdOm82jt3m3r93crPRg7nlwuh1wuf+B21X88Iqt338Brenp6Qvbq6+uLdevWoby8HHZ2dgCAw4cPw8LCAv3792/nyBljItu2AbGxytqh+nrlo++2tsrH1lXTS6geR2/6WLpqROm4OGWz14YNys8x7VNf3+lDDrz77rt44YUXmq1lycrKwpkzZ7Bz506hjIjQ2NiIoqIi5OXlwcDAAIMHDxbWu7m5Cd0nVJKSkhAdHY0LFy6gsrISd+/eRW1tLaqrq9vch8fAwAB//etfsXPnTsyYMQO3b9/G/v37sfuP5t2CggJUV1djzJgxos/V1dVh0KBBze5zzJgxcHJyQp8+fTB27FiMHTsWEydOFGLKz8/H6tWrcerUKVy/fl34riwpKcFTTz0l7MfLy0v4W9U9xNPTU1R2fy2Yt7e36Nx9fX1RVVWFy5cvw8nJSbTt2bNn0dDQAHd3d1H5nTt3YGNjAwBYsGABXnnlFfzwww/w9/fHpEmTRHG1N63o4+Pr6wtra2uEhoYiKysLeXl5WLp0KYqKijB+/HgAwIsvvoj+/ftjxowZyMrKwqFDh/Dmm28iIiICxsbGGj4DxnRA0y89S8t7TWSq5rKWqEaU/ve/OenRVk0Hs+xEfn5+CAgIwMqVK9XWVVVV4W9/+xsyMzOFV1ZWFvLz8+Ha2qS9TRQXF2PChAnw8vLCV199hYyMDGzZsgUAHvpp4eDgYCQnJ6O8vBz79u2DVCrF2LFjhVgB4NtvvxXFm52d3WI/H5lMhl9++QWfffYZHBwcsHr1anh7e+PmzZsAgMDAQPz+++/49NNPcerUKZw6darZuA2b/Lepeiru/rL7m8ceRlVVFfT19ZGRkSE6t5ycHHzwwQcAgNmzZ+PixYuYMWMGzp49i6effhqbN29+5GM+iEZrfNrK1tYWBw8exKpVq/DCCy+gvr4eAwYMwP79++Ht7Q1A2eb7zTff4JVXXoGvry/MzMwQGhqKtWvXajh6xrqxwsJ7SY6lJRAcfO8x9759gby8tu2HByfUXvcPZqmq+eskMTExGDhwIDw8PETlgwcPRnZ2Ntzc3Jr9nIeHB+7evYvTp08LTwcXFBSInhTLyMhAY2Mj1q9fL7Q4fPHFF6L9GBkZoaGh4YFxDhs2DAqFAp9//jm+//57TJ48WUgw+vfvD2NjY5SUlGDkyJFtPncDAwP4+/vD398fUVFRsLKywpEjRzBy5Ejk5ubi008/xYgRIwAoO3q3l6ysLNTU1EAqlQIATp48CXNz82YfDho0aBAaGhpQXl4uxNIchUKBefPmYd68eVi5ciU+/fRTvPrqq+0Wc1NakfgAwNNPP41Dhw61uo2Tk1OH9gRnjDXxoCe58vOVIzXzI73dW9PmylmzOj2J9fT0RHBwMDZt2iQqX758OZ599llERkZi9uzZMDMzQ3Z2Ng4fPowPP/wQTz75JPz9/TF37lx8/PHHMDQ0xOuvvw6pVCrUfLi5uaG+vh6bN29GYGAgjh8/jtjYWNFxnJ2dUVVVheTkZKEJqKUmsGnTpiE2NhZ5eXmimQdkMhmWLFmCRYsWobGxEcOHD0dFRQWOHz8OCwsLhIaGqu3rm2++wcWLF+Hn5wdra2t89913aGxshIeHB6ytrWFjY4NPPvkEDg4OKCkpwYoVKx73Ugvq6uoQHh6ON998E8XFxYiKikJkZKRadxQAcHd3R3BwMEJCQrB+/XoMGjQI165dQ3JyMry8vDB+/Hi89tprGDduHNzd3XHjxg38+OOP6NevX7vFq6ZNvYl0CHduZqwNCgpa7sSserm6ajpK1oIO6dys6rDewZp2blYpKioiIyMjuv8r7eeff6YxY8aQubk5mZmZkZeXF61bt05Yf/XqVRo3bhwZGxuTk5MT7dq1i+zs7Cg2NlbY5v333ycHBweSSqUUEBBAiYmJBIBu3LghbDNv3jyysbEhABQVFUVE4s7NKtnZ2QSAnJycqLGxUbSusbGRNm7cSB4eHmRoaEhyuZwCAgLo6NGjzV6HY8eO0ciRI8na2pqkUil5eXnR559/Lqw/fPgw9evXj4yNjcnLy4tSUlIIAO3du1e4ZgDo9OnTwmd+/PFHtXO7v/O26vqvXr2abGxsyNzcnObMmUO1tbXCNk07NxMR1dXV0erVq8nZ2ZkMDQ3JwcGBJk6cSGfOnCEiosjISHJ1dSVjY2OSy+U0Y8YMun79erPn3R6dmyVE7T0SmXarrKyEpaUlKioqYGFhoelwGOu6WqvxkckAHgy0y6qtrUVRURFcXFxgYmKi6XC6jCtXrkChUCApKQmjR4/WdDhdUlhYGG7evIl9+/Zp5Pit3btt/f7WmqYuxlgXQ6Tex+f69Xt/M9bFHTlyBFVVVfD09ERpaSmWLVsGZ2dn0Xg4rPvhxIcx9ujufzqGn8piWqS+vh5vvPEGLl68CJlMhmHDhmHnzp2ip5pY98OJD2OMMZ0UEBCAgIAATYehVRISEjQdwmPTinF8GGOMMcbaAyc+jDHGGNMZnPgwxpiO4od6mbZpj3uWEx/GGNMxqs67qnkQGdMWqnv2cTqgc+dmxhjTMfr6+rCyshImnzQ1NRVGK2asKyIiVFdXo7y8HFZWVtDX13/kfXHiwxhjOqhnz54AoDbzNmNdmZWVlXDvPipOfBhjTAdJJBI4ODjAzs4O9fX1mg6HsQcyNDR8rJoeFU58GGNMh+nr67fLlwlj2oI7NzPGGGNMZ3DiwxhjjDGdwYkPY4wxxnQG9/G5j2pwpMrKSg1HwhhjjLG2Un1vP2iQQ0587nPr1i0AgEKh0HAkjDHGGHtYt27dgqWlZYvrJcRjlos0Njbi6tWrkMlkWjOgV2VlJRQKBS5fvgwLCwtNh9Ml8DUR4+uhjq+JOr4mYnw91HXla0JEuHXrFhwdHaGn13JPHq7xuY+enh6eeOIJTYfxSCwsLLrcjahpfE3E+Hqo42uijq+JGF8PdV31mrRW06PCnZsZY4wxpjM48WGMMcaYzuDEpxswNjZGVFQUjI2NNR1Kl8HXRIyvhzq+Jur4mojx9VDXHa4Jd25mjDHGmM7gGh/GGGOM6QxOfBhjjDGmMzjxYYwxxpjO4MSHMcYYYzqDEx8tlpKSAolE0uwrLS0NAFBcXNzs+pMnT2o4+o7j7Oysdr4xMTGibc6cOYMRI0bAxMQECoUC7733noai7VjFxcUIDw+Hi4sLpFIpXF1dERUVhbq6OtE2unaPbNmyBc7OzjAxMYGPjw9+/vlnTYfUaaKjo/HMM89AJpPBzs4OQUFByM3NFW3z/PPPq90P8+bN01DEHW/NmjVq5/vkk08K62traxEREQEbGxuYm5tj0qRJ+N///qfBiDtWc/8PlUgkiIiIAKD99weP3KzFhg0bhtLSUlHZW2+9heTkZDz99NOi8qSkJAwYMEBYtrGx6ZQYNWXt2rWYM2eOsCyTyYS/Kysr8eKLL8Lf3x+xsbE4e/YsZs2aBSsrK8ydO1cT4XaYCxcuoLGxEVu3boWbmxvOnTuHOXPm4Pbt2/jnP/8p2lZX7pHPP/8cixcvRmxsLHx8fLBx40YEBAQgNzcXdnZ2mg6vwx09ehQRERF45plncPfuXbzxxht48cUXkZ2dDTMzM2G7OXPmYO3atcKyqampJsLtNAMGDEBSUpKwbGBw7+tx0aJF+Pbbb7Fnzx5YWloiMjISf/7zn3H8+HFNhNrh0tLS0NDQICyfO3cOY8aMweTJk4Uyrb4/iHUbdXV1JJfLae3atUJZUVERAaDTp09rLrBO5uTkRBs2bGhx/UcffUTW1tZ0584doWz58uXk4eHRCdFp3nvvvUcuLi7Csq7dI0OHDqWIiAhhuaGhgRwdHSk6OlqDUWlOeXk5AaCjR48KZSNHjqSFCxdqLqhOFhUVRd7e3s2uu3nzJhkaGtKePXuEspycHAJAJ06c6KQINWvhwoXk6upKjY2NRKT99wc3dXUjBw4cwG+//YaZM2eqrfvTn/4EOzs7DB8+HAcOHNBAdJ0rJiYGNjY2GDRoEP7xj3/g7t27wroTJ07Az88PRkZGQpnqF/+NGzc0EW6nqqioQI8ePdTKdeEeqaurQ0ZGBvz9/YUyPT09+Pv748SJExqMTHMqKioAQO2e2LlzJ2xtbfHUU09h5cqVqK6u1kR4nSY/Px+Ojo7o06cPgoODUVJSAgDIyMhAfX296J558skn0bt3b524Z+rq6rBjxw7MmjVLNHG3Nt8f3NTVjWzbtg0BAQGiSVbNzc2xfv16PPfcc9DT08NXX32FoKAg7Nu3D3/60580GG3HWbBgAQYPHowePXogNTUVK1euRGlpKd5//30AQFlZGVxcXESfsbe3F9ZZW1t3esydpaCgAJs3bxY1c+nSPXL9+nU0NDQI/94q9vb2uHDhgoai0pzGxka89tpreO655/DUU08J5dOmTYOTkxMcHR1x5swZLF++HLm5ufjPf/6jwWg7jo+PDxISEuDh4YHS0lK8/fbbGDFiBM6dO4eysjIYGRnByspK9Bl7e3uUlZVpJuBOtG/fPty8eRNhYWFCmdbfH5qucmLqli9fTgBafeXk5Ig+c/nyZdLT06Mvv/zygfufMWMGDR8+vKPC7xCPck1Utm3bRgYGBlRbW0tERGPGjKG5c+eKtjl//jwBoOzs7A4/l/bwKNfjypUr5OrqSuHh4Q/cvzbeI23x66+/EgBKTU0VlS9dupSGDh2qoag0Z968eeTk5ESXL19udbvk5GQCQAUFBZ0UmWbduHGDLCws6F//+hft3LmTjIyM1LZ55plnaNmyZRqIrnO9+OKLNGHChFa30bb7g2t8uqDXX39dlF03p0+fPqLl+Ph42NjYtOkXuo+PDw4fPvw4IXa6R7kmKj4+Prh79y6Ki4vh4eGBnj17qj2RoVru2bNnu8Tb0R72ely9ehWjRo3CsGHD8Mknnzxw/9p4j7SFra0t9PX1m/3315Z/+/YSGRmJb775Bj/99JOolrg5Pj4+AJQ1hq6urp0RnkZZWVnB3d0dBQUFGDNmDOrq6nDz5k1RrY8u3DOXLl1CUlLSA2tytO3+4MSnC5LL5ZDL5W3enogQHx+PkJAQGBoaPnD7zMxMODg4PE6Ine5hr0lTmZmZ0NPTE57Y8fX1xapVq1BfXy9cr8OHD8PDw0Nrmrke5nr8+uuvGDVqFIYMGYL4+Hjo6T24a5823iNtYWRkhCFDhiA5ORlBQUEAlM09ycnJiIyM1GxwnYSI8Oqrr2Lv3r1ISUlRa/ZtTmZmJgB0y3uiOVVVVSgsLMSMGTMwZMgQGBoaIjk5GZMmTQIA5ObmoqSkBL6+vhqOtGPFx8fDzs4O48ePb3U7rbs/NF3lxB5fUlJSi009CQkJtGvXLsrJyaGcnBxat24d6enpUVxcnAYi7Xipqam0YcMGyszMpMLCQtqxYwfJ5XIKCQkRtrl58ybZ29vTjBkz6Ny5c7R7924yNTWlrVu3ajDyjnHlyhVyc3Oj0aNH05UrV6i0tFR4qejaPbJ7924yNjamhIQEys7Oprlz55KVlRWVlZVpOrRO8corr5ClpSWlpKSI7ofq6moiIiooKKC1a9dSeno6FRUV0f79+6lPnz7k5+en4cg7zuuvv04pKSlUVFREx48fJ39/f7K1taXy8nIiUjYJ9u7dm44cOULp6enk6+tLvr6+Go66YzU0NFDv3r1p+fLlovLucH9w4tMNTJ06lYYNG9bsuoSEBOrXrx+ZmpqShYUFDR06VPRYZneTkZFBPj4+ZGlpSSYmJtSvXz965513hP49KllZWTR8+HAyNjamXr16UUxMjIYi7ljx8fEt9gFS0bV7hIho8+bN1Lt3bzIyMqKhQ4fSyZMnNR1Sp2npfoiPjyciopKSEvLz86MePXqQsbExubm50dKlS6miokKzgXegKVOmkIODAxkZGVGvXr1oypQpov4qNTU1NH/+fLK2tiZTU1OaOHGi6MdDd3To0CECQLm5uaLy7nB/SIiINFHTxBhjjDHW2XgcH8YYY4zpDE58GGOMMaYzOPFhjDHGmM7gxIcxxhhjOoMTH8YYY4zpDE58GGOMMaYzOPFhjDHGmM7gxIcx1uFSUlIgkUhw8+ZNjcaxZs0aDBw4sEOPkZCQoDaTN2Os6+DEhzEmCAsLg0QigUQigaGhIVxcXLBs2TLU1tZqOjStMWXKFOTl5XXoMX766ScEBgbC0dEREokE+/bt69DjMdadcOLDGBMZO3YsSktLcfHiRWzYsAFbt25FVFSUpsPSGlKpVJgQt6Pcvn0b3t7e2LJlS4ceh7HuiBMfxpiIsbExevbsCYVCgaCgIPj7++Pw4cPC+sbGRkRHR8PFxQVSqRTe3t748ssvRfv47rvv4O7uDqlUilGjRqG4uFi0vrkmp40bN8LZ2VlUFhcXhwEDBsDY2BgODg6iGdRv3ryJ2bNnQy6Xw8LCAi+88AKysrJEn4+JiYG9vT1kMhnCw8MfWHPV0NCA8PBw4dw8PDzwwQcfCOtra2sxYMAAzJ07VygrLCyETCZDXFwcAPWmrqysLIwaNQoymQwWFhYYMmQI0tPTW43jQcaNG4f/+7//w8SJEx9rP4zpIk58GGMtOnfuHFJTU2FkZCSURUdHIzExEbGxsTh//jwWLVqE6dOn4+jRowCAy5cv489//jMCAwORmZmJ2bNnY8WKFQ997I8//hgRERGYO3cuzp49iwMHDsDNzU1YP3nyZJSXl+P7779HRkYGBg8ejNGjR+P3338HAHzxxRdYs2YN3nnnHaSnp8PBwQEfffRRq8dsbGzEE088gT179iA7OxurV6/GG2+8gS+++AIAYGJigp07d2L79u3Yv38/GhoaMH36dIwZMwazZs1qdp/BwcF44oknkJaWhoyMDKxYsQKGhoYPfT0YY+1E07OkMsa6jtDQUNLX1yczMzMyNjYmAKSnp0dffvklERHV1taSqakppaamij4XHh5OU6dOJSKilStXUv/+/UXrly9fTgDoxo0bREQUFRVF3t7eom02bNhATk5OwrKjoyOtWrWq2TiPHTtGFhYWVFtbKyp3dXWlrVu3EhGRr68vzZ8/X7Tex8dH7bgPEhERQZMmTRKVvffee2Rra0uRkZHk4OBA169fF9bFx8eTpaWlsCyTySghIeGhjvkwANDevXs7bP+MdTdc48MYExk1ahQyMzNx6tQphIaGYubMmZg0aRIAoKCgANXV1RgzZgzMzc2FV2JiIgoLCwEAOTk58PHxEe3T19f3oWIoLy/H1atXMXr06GbXZ2VloaqqCjY2NqI4ioqKHjuOLVu2YMiQIZDL5TA3N8cnn3yCkpIS0Tavv/463N3d8eGHHyIuLg42NjYt7m/x4sWYPXs2/P39ERMTI8TXnHnz5onOhzHW/gw0HQBjrGsxMzMTmpTi4uLg7e2Nbdu2ITw8HFVVVQCAb7/9Fr169RJ9ztjYuM3H0NPTAxGJyurr64W/pVJpq5+vqqqCg4MDUlJS1NY9zqPku3fvxpIlS7B+/Xr4+vpCJpPhH//4B06dOiXarry8HHl5edDX10d+fj7Gjh3b4j7XrFmDadOm4dtvv8X333+PqKgo7N69u9n+OWvXrsWSJUseOX7G2INx4sMYa5Genh7eeOMNLF68GNOmTUP//v1hbGyMkpISjBw5stnP9OvXDwcOHBCVnTx5UrQsl8tRVlYGIoJEIgEAZGZmCutlMhmcnZ2RnJyMUaNGqR1j8ODBKCsrg4GBgVqH6KZxnDp1CiEhIS3Gcb/jx49j2LBhmD9/vlDWXA3NrFmz4OnpifDwcMyZMwf+/v7o169fi/t1d3eHu7s7Fi1ahKlTpyI+Pr7ZxMfOzq7DnwhjTNdxUxdjrFWTJ0+Gvr4+tmzZAplMhiVLlmDRokXYvn07CgsL8csvv2Dz5s3Yvn07AGVzTX5+PpYuXYrc3Fzs2rULCQkJon0+//zzuHbtGt577z0UFhZiy5Yt+P7770XbrFmzBuvXr8emTZuQn58vHAcA/P394evri6CgIPzwww8oLi5GamoqVq1aJTwxtXDhQsTFxSE+Ph55eXmIiorC+fPnWz3Xvn37Ij09HYcOHUJeXh7eeustpKWlibbZsmULTpw4ge3btyM4OBhBQUEIDg5GXV2d2v5qamoQGRmJlJQUXLp0CcePH0daWlqrSVJbVFVVITMzU0gWi4qKkJmZqdYkxxhrhqY7GTHGuo7Q0FB66aWX1Mqjo6NJLpdTVVUVNTY20saNG8nDw4MMDQ1JLpdTQEAAHT16VNj+66+/Jjc3NzI2NqYRI0ZQXFycqHMzEdHHH39MCoWCzMzMKCQkhNatWyfq3ExEFBsbKxzHwcGBXn31VWFdZWUlvfrqq+To6EiGhoakUCgoODiYSkpKhG3WrVtHtra2ZG5uTqGhobRs2bJWOzfX1tZSWFgYWVpakpWVFb3yyiu0YsUK4TM5OTkklUpp165dwmdu3LhBCoWCli1bRkTizs137tyhl19+mRQKBRkZGZGjoyNFRkZSTU3NA/4lWvfjjz8SALVXaGjoY+2XMV0gIbqvoZ0xxhhjrJvipi7GGGOM6QxOfBhjjDGmMzjxYYwxxpjO4MSHMcYYYzqDEx/GGGOM6QxOfBhjjDGmMzjxYYwxxpjO4MSHMcYYYzqDEx/GGGOM6QxOfBhjjDGmMzjxYYwxxpjO4MSHMcYYYzrj/wHcoK80QZkzTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "98affd2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Acc : 74.58    Train Loss : 0.54,    Test Acc : 65.5,    Test Loss :0.5,    Total Acc : 70.04\n",
      "Epoch 20 - Train Acc : 77.08    Train Loss : 0.48,    Test Acc : 67.65,    Test Loss :0.5,    Total Acc : 72.36\n",
      "Epoch 30 - Train Acc : 70.83    Train Loss : 0.65,    Test Acc : 74.79,    Test Loss :0.53,    Total Acc : 72.81\n",
      "Epoch 40 - Train Acc : 83.33    Train Loss : 0.44,    Test Acc : 73.94,    Test Loss :0.46,    Total Acc : 78.64\n",
      "Epoch 50 - Train Acc : 84.58    Train Loss : 0.38,    Test Acc : 76.5,    Test Loss :0.41,    Total Acc : 80.54\n",
      "Epoch 60 - Train Acc : 91.25    Train Loss : 0.31,    Test Acc : 85.73,    Test Loss :0.33,    Total Acc : 88.49\n",
      "Epoch 70 - Train Acc : 90.83    Train Loss : 0.35,    Test Acc : 83.44,    Test Loss :0.37,    Total Acc : 87.14\n",
      "Epoch 80 - Train Acc : 88.33    Train Loss : 0.32,    Test Acc : 83.44,    Test Loss :0.35,    Total Acc : 85.89\n",
      "Epoch 90 - Train Acc : 90.42    Train Loss : 0.3,    Test Acc : 81.88,    Test Loss :0.4,    Total Acc : 86.15\n",
      "Epoch 100 - Train Acc : 90.42    Train Loss : 0.3,    Test Acc : 78.27,    Test Loss :0.48,    Total Acc : 84.34\n",
      "Epoch 110 - Train Acc : 90.0    Train Loss : 0.28,    Test Acc : 78.02,    Test Loss :0.44,    Total Acc : 84.01\n",
      "Epoch 120 - Train Acc : 90.0    Train Loss : 0.28,    Test Acc : 86.5,    Test Loss :0.3,    Total Acc : 88.25\n",
      "Epoch 130 - Train Acc : 90.0    Train Loss : 0.27,    Test Acc : 78.44,    Test Loss :0.35,    Total Acc : 84.22\n",
      "Epoch 140 - Train Acc : 87.5    Train Loss : 0.3,    Test Acc : 77.23,    Test Loss :0.44,    Total Acc : 82.36\n",
      "Epoch 150 - Train Acc : 91.67    Train Loss : 0.26,    Test Acc : 87.19,    Test Loss :0.33,    Total Acc : 89.43\n",
      "Epoch 160 - Train Acc : 89.58    Train Loss : 0.28,    Test Acc : 88.48,    Test Loss :0.31,    Total Acc : 89.03\n",
      "Epoch 170 - Train Acc : 92.5    Train Loss : 0.25,    Test Acc : 84.65,    Test Loss :0.35,    Total Acc : 88.57\n",
      "Epoch 180 - Train Acc : 90.83    Train Loss : 0.29,    Test Acc : 87.02,    Test Loss :0.33,    Total Acc : 88.93\n",
      "Epoch 190 - Train Acc : 91.67    Train Loss : 0.22,    Test Acc : 89.52,    Test Loss :0.28,    Total Acc : 90.59\n",
      "Epoch 200 - Train Acc : 82.5    Train Loss : 0.35,    Test Acc : 81.69,    Test Loss :0.38,    Total Acc : 82.09\n",
      "Epoch 210 - Train Acc : 92.08    Train Loss : 0.23,    Test Acc : 86.38,    Test Loss :0.35,    Total Acc : 89.23\n",
      "Epoch 220 - Train Acc : 91.67    Train Loss : 0.25,    Test Acc : 84.98,    Test Loss :0.4,    Total Acc : 88.32\n",
      "Epoch 230 - Train Acc : 91.25    Train Loss : 0.24,    Test Acc : 81.38,    Test Loss :0.37,    Total Acc : 86.31\n",
      "Epoch 240 - Train Acc : 92.08    Train Loss : 0.23,    Test Acc : 81.06,    Test Loss :0.37,    Total Acc : 86.57\n",
      "Epoch 250 - Train Acc : 93.33    Train Loss : 0.22,    Test Acc : 82.38,    Test Loss :0.44,    Total Acc : 87.85\n",
      "Epoch 260 - Train Acc : 92.5    Train Loss : 0.22,    Test Acc : 87.1,    Test Loss :0.37,    Total Acc : 89.8\n",
      "Epoch 270 - Train Acc : 92.08    Train Loss : 0.23,    Test Acc : 88.6,    Test Loss :0.33,    Total Acc : 90.34\n",
      "Epoch 280 - Train Acc : 94.58    Train Loss : 0.18,    Test Acc : 89.27,    Test Loss :0.39,    Total Acc : 91.93\n",
      "Epoch 290 - Train Acc : 94.58    Train Loss : 0.2,    Test Acc : 86.0,    Test Loss :0.38,    Total Acc : 90.29\n",
      "Epoch 300 - Train Acc : 93.33    Train Loss : 0.2,    Test Acc : 89.9,    Test Loss :0.39,    Total Acc : 91.61\n",
      "Epoch 310 - Train Acc : 87.08    Train Loss : 0.26,    Test Acc : 85.35,    Test Loss :0.33,    Total Acc : 86.22\n",
      "Epoch 320 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 80.92,    Test Loss :0.44,    Total Acc : 85.46\n",
      "Epoch 330 - Train Acc : 92.5    Train Loss : 0.2,    Test Acc : 89.31,    Test Loss :0.38,    Total Acc : 90.91\n",
      "Epoch 340 - Train Acc : 92.92    Train Loss : 0.23,    Test Acc : 86.81,    Test Loss :0.4,    Total Acc : 89.86\n",
      "Epoch 350 - Train Acc : 95.83    Train Loss : 0.18,    Test Acc : 84.79,    Test Loss :0.51,    Total Acc : 90.31\n",
      "Epoch 360 - Train Acc : 91.25    Train Loss : 0.24,    Test Acc : 81.42,    Test Loss :0.64,    Total Acc : 86.33\n",
      "Epoch 370 - Train Acc : 93.75    Train Loss : 0.2,    Test Acc : 82.75,    Test Loss :0.58,    Total Acc : 88.25\n",
      "Epoch 380 - Train Acc : 92.92    Train Loss : 0.21,    Test Acc : 83.0,    Test Loss :0.59,    Total Acc : 87.96\n",
      "Epoch 390 - Train Acc : 96.25    Train Loss : 0.17,    Test Acc : 87.35,    Test Loss :0.6,    Total Acc : 91.8\n",
      "Epoch 400 - Train Acc : 94.58    Train Loss : 0.18,    Test Acc : 83.5,    Test Loss :0.65,    Total Acc : 89.04\n",
      "Epoch 410 - Train Acc : 97.08    Train Loss : 0.15,    Test Acc : 88.85,    Test Loss :0.57,    Total Acc : 92.97\n",
      "Epoch 420 - Train Acc : 95.83    Train Loss : 0.2,    Test Acc : 85.4,    Test Loss :0.57,    Total Acc : 90.61\n",
      "Epoch 430 - Train Acc : 95.42    Train Loss : 0.17,    Test Acc : 85.92,    Test Loss :0.7,    Total Acc : 90.67\n",
      "Epoch 440 - Train Acc : 97.5    Train Loss : 0.13,    Test Acc : 87.65,    Test Loss :0.59,    Total Acc : 92.57\n",
      "Epoch 450 - Train Acc : 95.42    Train Loss : 0.22,    Test Acc : 87.9,    Test Loss :0.62,    Total Acc : 91.66\n",
      "Epoch 460 - Train Acc : 94.58    Train Loss : 0.18,    Test Acc : 85.29,    Test Loss :0.49,    Total Acc : 89.94\n",
      "Epoch 470 - Train Acc : 96.25    Train Loss : 0.15,    Test Acc : 87.25,    Test Loss :0.46,    Total Acc : 91.75\n",
      "Epoch 480 - Train Acc : 95.83    Train Loss : 0.15,    Test Acc : 88.46,    Test Loss :0.55,    Total Acc : 92.15\n",
      "Epoch 490 - Train Acc : 84.58    Train Loss : 0.34,    Test Acc : 84.15,    Test Loss :0.39,    Total Acc : 84.36\n",
      "Epoch 500 - Train Acc : 91.67    Train Loss : 0.25,    Test Acc : 81.79,    Test Loss :0.61,    Total Acc : 86.73\n",
      "Epoch 510 - Train Acc : 95.42    Train Loss : 0.18,    Test Acc : 85.04,    Test Loss :0.43,    Total Acc : 90.23\n",
      "Epoch 520 - Train Acc : 95.42    Train Loss : 0.16,    Test Acc : 88.1,    Test Loss :0.45,    Total Acc : 91.76\n",
      "Epoch 530 - Train Acc : 92.5    Train Loss : 0.23,    Test Acc : 79.81,    Test Loss :0.65,    Total Acc : 86.16\n",
      "Epoch 540 - Train Acc : 95.42    Train Loss : 0.17,    Test Acc : 85.17,    Test Loss :0.5,    Total Acc : 90.29\n",
      "Epoch 550 - Train Acc : 95.42    Train Loss : 0.17,    Test Acc : 83.4,    Test Loss :0.67,    Total Acc : 89.41\n",
      "Epoch 560 - Train Acc : 95.42    Train Loss : 0.18,    Test Acc : 87.42,    Test Loss :0.53,    Total Acc : 91.42\n",
      "Epoch 570 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 86.19,    Test Loss :0.57,    Total Acc : 91.01\n",
      "Epoch 580 - Train Acc : 97.08    Train Loss : 0.14,    Test Acc : 85.15,    Test Loss :0.55,    Total Acc : 91.11\n",
      "Epoch 590 - Train Acc : 97.5    Train Loss : 0.13,    Test Acc : 85.33,    Test Loss :0.64,    Total Acc : 91.42\n",
      "Epoch 600 - Train Acc : 98.33    Train Loss : 0.12,    Test Acc : 86.69,    Test Loss :0.61,    Total Acc : 92.51\n",
      "Epoch 610 - Train Acc : 93.33    Train Loss : 0.25,    Test Acc : 87.12,    Test Loss :0.59,    Total Acc : 90.23\n",
      "Epoch 620 - Train Acc : 90.0    Train Loss : 0.26,    Test Acc : 85.27,    Test Loss :0.43,    Total Acc : 87.64\n",
      "Epoch 630 - Train Acc : 96.25    Train Loss : 0.14,    Test Acc : 87.62,    Test Loss :0.54,    Total Acc : 91.94\n",
      "Epoch 640 - Train Acc : 98.33    Train Loss : 0.13,    Test Acc : 90.1,    Test Loss :0.59,    Total Acc : 94.22\n",
      "Epoch 650 - Train Acc : 99.17    Train Loss : 0.11,    Test Acc : 88.71,    Test Loss :0.6,    Total Acc : 93.94\n",
      "Epoch 660 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 86.31,    Test Loss :0.81,    Total Acc : 91.07\n",
      "Epoch 670 - Train Acc : 98.75    Train Loss : 0.11,    Test Acc : 88.35,    Test Loss :0.76,    Total Acc : 93.55\n",
      "Epoch 680 - Train Acc : 98.75    Train Loss : 0.12,    Test Acc : 87.81,    Test Loss :0.72,    Total Acc : 93.28\n",
      "Epoch 690 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 87.08,    Test Loss :0.86,    Total Acc : 93.12\n",
      "Epoch 700 - Train Acc : 98.33    Train Loss : 0.12,    Test Acc : 88.17,    Test Loss :0.77,    Total Acc : 93.25\n",
      "Epoch 710 - Train Acc : 95.83    Train Loss : 0.19,    Test Acc : 84.33,    Test Loss :0.95,    Total Acc : 90.08\n",
      "Epoch 720 - Train Acc : 97.92    Train Loss : 0.11,    Test Acc : 85.85,    Test Loss :1.0,    Total Acc : 91.89\n",
      "Epoch 730 - Train Acc : 97.92    Train Loss : 0.12,    Test Acc : 89.19,    Test Loss :0.74,    Total Acc : 93.55\n",
      "Epoch 740 - Train Acc : 98.75    Train Loss : 0.12,    Test Acc : 84.6,    Test Loss :0.91,    Total Acc : 91.68\n",
      "Epoch 750 - Train Acc : 97.08    Train Loss : 0.15,    Test Acc : 84.71,    Test Loss :0.89,    Total Acc : 90.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760 - Train Acc : 98.33    Train Loss : 0.12,    Test Acc : 86.0,    Test Loss :0.75,    Total Acc : 92.17\n",
      "Epoch 770 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 89.35,    Test Loss :0.84,    Total Acc : 94.26\n",
      "Epoch 780 - Train Acc : 98.75    Train Loss : 0.12,    Test Acc : 89.6,    Test Loss :0.78,    Total Acc : 94.18\n",
      "Epoch 790 - Train Acc : 98.75    Train Loss : 0.1,    Test Acc : 90.58,    Test Loss :0.76,    Total Acc : 94.67\n",
      "Epoch 800 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 90.92,    Test Loss :0.65,    Total Acc : 95.04\n",
      "Epoch 810 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 89.81,    Test Loss :0.79,    Total Acc : 94.7\n",
      "Epoch 820 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 89.02,    Test Loss :0.77,    Total Acc : 94.09\n",
      "Epoch 830 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 89.29,    Test Loss :0.75,    Total Acc : 94.65\n",
      "Epoch 840 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 90.52,    Test Loss :0.81,    Total Acc : 94.84\n",
      "Epoch 850 - Train Acc : 97.08    Train Loss : 0.16,    Test Acc : 85.52,    Test Loss :1.05,    Total Acc : 91.3\n",
      "Epoch 860 - Train Acc : 98.33    Train Loss : 0.12,    Test Acc : 90.23,    Test Loss :0.75,    Total Acc : 94.28\n",
      "Epoch 870 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 87.79,    Test Loss :0.95,    Total Acc : 93.9\n",
      "Epoch 880 - Train Acc : 98.75    Train Loss : 0.1,    Test Acc : 89.21,    Test Loss :0.86,    Total Acc : 93.98\n",
      "Epoch 890 - Train Acc : 99.17    Train Loss : 0.11,    Test Acc : 86.52,    Test Loss :1.04,    Total Acc : 92.84\n",
      "Epoch 900 - Train Acc : 97.92    Train Loss : 0.13,    Test Acc : 86.54,    Test Loss :0.84,    Total Acc : 92.23\n",
      "Epoch 910 - Train Acc : 98.75    Train Loss : 0.11,    Test Acc : 88.33,    Test Loss :0.79,    Total Acc : 93.54\n",
      "Epoch 920 - Train Acc : 97.92    Train Loss : 0.13,    Test Acc : 88.96,    Test Loss :0.74,    Total Acc : 93.44\n",
      "Epoch 930 - Train Acc : 98.75    Train Loss : 0.11,    Test Acc : 89.48,    Test Loss :0.66,    Total Acc : 94.11\n",
      "Epoch 940 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 88.35,    Test Loss :0.84,    Total Acc : 93.76\n",
      "Epoch 950 - Train Acc : 98.33    Train Loss : 0.1,    Test Acc : 89.15,    Test Loss :0.69,    Total Acc : 93.74\n",
      "Epoch 960 - Train Acc : 100.0    Train Loss : 0.09,    Test Acc : 90.75,    Test Loss :0.77,    Total Acc : 95.38\n",
      "Epoch 970 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 88.04,    Test Loss :0.96,    Total Acc : 93.6\n",
      "Epoch 980 - Train Acc : 98.75    Train Loss : 0.09,    Test Acc : 90.67,    Test Loss :0.83,    Total Acc : 94.71\n",
      "Epoch 990 - Train Acc : 97.92    Train Loss : 0.12,    Test Acc : 89.38,    Test Loss :0.72,    Total Acc : 93.65\n",
      "Epoch 1000 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 88.98,    Test Loss :0.75,    Total Acc : 94.07\n",
      "Epoch 1010 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.04,    Test Loss :0.69,    Total Acc : 95.02\n",
      "Epoch 1020 - Train Acc : 98.33    Train Loss : 0.1,    Test Acc : 89.19,    Test Loss :0.75,    Total Acc : 93.76\n",
      "Epoch 1030 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 91.04,    Test Loss :0.51,    Total Acc : 95.31\n",
      "Epoch 1040 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 90.21,    Test Loss :0.72,    Total Acc : 94.9\n",
      "Epoch 1050 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 88.94,    Test Loss :0.75,    Total Acc : 94.26\n",
      "Epoch 1060 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 89.38,    Test Loss :0.83,    Total Acc : 94.27\n",
      "Epoch 1070 - Train Acc : 98.75    Train Loss : 0.13,    Test Acc : 90.98,    Test Loss :0.66,    Total Acc : 94.86\n",
      "Epoch 1080 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.71,    Test Loss :0.74,    Total Acc : 95.35\n",
      "Epoch 1090 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.08,    Test Loss :0.79,    Total Acc : 95.54\n",
      "Epoch 1100 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 91.42,    Test Loss :0.72,    Total Acc : 95.5\n",
      "Epoch 1110 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.15,    Test Loss :0.75,    Total Acc : 95.07\n",
      "Epoch 1120 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.44,    Test Loss :0.75,    Total Acc : 95.72\n",
      "Epoch 1130 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 89.02,    Test Loss :0.87,    Total Acc : 94.51\n",
      "Epoch 1140 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 91.02,    Test Loss :0.85,    Total Acc : 95.09\n",
      "Epoch 1150 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 90.98,    Test Loss :0.77,    Total Acc : 95.28\n",
      "Epoch 1160 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 89.25,    Test Loss :0.94,    Total Acc : 94.42\n",
      "Epoch 1170 - Train Acc : 98.75    Train Loss : 0.1,    Test Acc : 86.83,    Test Loss :0.97,    Total Acc : 92.79\n",
      "Epoch 1180 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 89.44,    Test Loss :0.87,    Total Acc : 94.3\n",
      "Epoch 1190 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 90.12,    Test Loss :0.99,    Total Acc : 94.65\n",
      "Epoch 1200 - Train Acc : 97.5    Train Loss : 0.13,    Test Acc : 92.56,    Test Loss :0.49,    Total Acc : 95.03\n",
      "Epoch 1210 - Train Acc : 99.58    Train Loss : 0.1,    Test Acc : 89.52,    Test Loss :0.47,    Total Acc : 94.55\n",
      "Epoch 1220 - Train Acc : 98.33    Train Loss : 0.11,    Test Acc : 92.67,    Test Loss :0.48,    Total Acc : 95.5\n",
      "Epoch 1230 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 90.33,    Test Loss :0.52,    Total Acc : 94.96\n",
      "Epoch 1240 - Train Acc : 99.58    Train Loss : 0.1,    Test Acc : 89.29,    Test Loss :0.7,    Total Acc : 94.44\n",
      "Epoch 1250 - Train Acc : 99.58    Train Loss : 0.1,    Test Acc : 92.08,    Test Loss :0.57,    Total Acc : 95.83\n",
      "Epoch 1260 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 92.56,    Test Loss :0.6,    Total Acc : 96.07\n",
      "Epoch 1270 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 91.9,    Test Loss :0.72,    Total Acc : 95.74\n",
      "Epoch 1280 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.1,    Test Loss :0.7,    Total Acc : 95.55\n",
      "Epoch 1290 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 90.23,    Test Loss :0.69,    Total Acc : 94.91\n",
      "Epoch 1300 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 91.98,    Test Loss :0.61,    Total Acc : 95.57\n",
      "Epoch 1310 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.27,    Test Loss :0.66,    Total Acc : 96.14\n",
      "Epoch 1320 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.27,    Test Loss :0.66,    Total Acc : 95.64\n",
      "Epoch 1330 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.06,    Test Loss :0.56,    Total Acc : 96.03\n",
      "Epoch 1340 - Train Acc : 98.33    Train Loss : 0.12,    Test Acc : 88.9,    Test Loss :0.68,    Total Acc : 93.61\n",
      "Epoch 1350 - Train Acc : 98.75    Train Loss : 0.11,    Test Acc : 89.65,    Test Loss :0.55,    Total Acc : 94.2\n",
      "Epoch 1360 - Train Acc : 97.92    Train Loss : 0.12,    Test Acc : 90.4,    Test Loss :0.56,    Total Acc : 94.16\n",
      "Epoch 1370 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 92.44,    Test Loss :0.54,    Total Acc : 96.01\n",
      "Epoch 1380 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.23,    Test Loss :0.57,    Total Acc : 95.61\n",
      "Epoch 1390 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 92.6,    Test Loss :0.47,    Total Acc : 96.09\n",
      "Epoch 1400 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 90.67,    Test Loss :0.57,    Total Acc : 94.92\n",
      "Epoch 1410 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.73,    Test Loss :0.52,    Total Acc : 96.36\n",
      "Epoch 1420 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.79,    Test Loss :0.63,    Total Acc : 95.4\n",
      "Epoch 1430 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 89.83,    Test Loss :0.77,    Total Acc : 94.5\n",
      "Epoch 1440 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 92.67,    Test Loss :0.59,    Total Acc : 96.12\n",
      "Epoch 1450 - Train Acc : 98.75    Train Loss : 0.09,    Test Acc : 92.73,    Test Loss :0.6,    Total Acc : 95.74\n",
      "Epoch 1460 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.04,    Test Loss :0.59,    Total Acc : 96.02\n",
      "Epoch 1470 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.83,    Test Loss :0.73,    Total Acc : 95.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1480 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 89.77,    Test Loss :0.74,    Total Acc : 94.47\n",
      "Epoch 1490 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.44,    Test Loss :0.67,    Total Acc : 95.72\n",
      "Epoch 1500 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.98,    Test Loss :0.69,    Total Acc : 95.99\n",
      "Epoch 1510 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 91.58,    Test Loss :0.68,    Total Acc : 95.58\n",
      "Epoch 1520 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 91.27,    Test Loss :0.71,    Total Acc : 95.22\n",
      "Epoch 1530 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 90.9,    Test Loss :0.76,    Total Acc : 95.24\n",
      "Epoch 1540 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 88.96,    Test Loss :0.93,    Total Acc : 94.48\n",
      "Epoch 1550 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 90.25,    Test Loss :0.66,    Total Acc : 94.71\n",
      "Epoch 1560 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 89.52,    Test Loss :0.78,    Total Acc : 94.34\n",
      "Epoch 1570 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 90.65,    Test Loss :0.7,    Total Acc : 94.91\n",
      "Epoch 1580 - Train Acc : 100.0    Train Loss : 0.09,    Test Acc : 92.6,    Test Loss :0.56,    Total Acc : 96.3\n",
      "Epoch 1590 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 87.77,    Test Loss :0.77,    Total Acc : 93.47\n",
      "Epoch 1600 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 92.21,    Test Loss :0.66,    Total Acc : 95.69\n",
      "Epoch 1610 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 91.46,    Test Loss :0.68,    Total Acc : 95.52\n",
      "Epoch 1620 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.9,    Test Loss :0.75,    Total Acc : 95.45\n",
      "Epoch 1630 - Train Acc : 98.75    Train Loss : 0.12,    Test Acc : 91.67,    Test Loss :0.76,    Total Acc : 95.21\n",
      "Epoch 1640 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 89.77,    Test Loss :0.73,    Total Acc : 94.68\n",
      "Epoch 1650 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.5,    Test Loss :0.67,    Total Acc : 96.25\n",
      "Epoch 1660 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 91.92,    Test Loss :0.75,    Total Acc : 95.75\n",
      "Epoch 1670 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.62,    Test Loss :0.78,    Total Acc : 95.31\n",
      "Epoch 1680 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.6,    Test Loss :0.64,    Total Acc : 95.8\n",
      "Epoch 1690 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 93.17,    Test Loss :0.69,    Total Acc : 96.58\n",
      "Epoch 1700 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 91.96,    Test Loss :0.74,    Total Acc : 95.56\n",
      "Epoch 1710 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.06,    Test Loss :0.76,    Total Acc : 96.03\n",
      "Epoch 1720 - Train Acc : 99.17    Train Loss : 0.11,    Test Acc : 92.5,    Test Loss :0.67,    Total Acc : 95.83\n",
      "Epoch 1730 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.38,    Test Loss :0.72,    Total Acc : 96.19\n",
      "Epoch 1740 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.48,    Test Loss :0.81,    Total Acc : 95.74\n",
      "Epoch 1750 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 92.08,    Test Loss :0.75,    Total Acc : 95.83\n",
      "Epoch 1760 - Train Acc : 99.58    Train Loss : 0.17,    Test Acc : 89.44,    Test Loss :0.97,    Total Acc : 94.51\n",
      "Epoch 1770 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.92,    Test Loss :1.06,    Total Acc : 95.96\n",
      "Epoch 1780 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 93.29,    Test Loss :0.91,    Total Acc : 96.44\n",
      "Epoch 1790 - Train Acc : 97.92    Train Loss : 0.13,    Test Acc : 92.19,    Test Loss :1.4,    Total Acc : 95.05\n",
      "Epoch 1800 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.33,    Test Loss :1.37,    Total Acc : 95.67\n",
      "Epoch 1810 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 92.04,    Test Loss :1.13,    Total Acc : 95.81\n",
      "Epoch 1820 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 90.69,    Test Loss :1.52,    Total Acc : 94.93\n",
      "Epoch 1830 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 90.12,    Test Loss :1.1,    Total Acc : 94.85\n",
      "Epoch 1840 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 94.0,    Test Loss :0.7,    Total Acc : 96.79\n",
      "Epoch 1850 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 90.46,    Test Loss :0.87,    Total Acc : 95.02\n",
      "Epoch 1860 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 92.62,    Test Loss :0.7,    Total Acc : 96.1\n",
      "Epoch 1870 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 92.88,    Test Loss :0.64,    Total Acc : 96.23\n",
      "Epoch 1880 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 92.17,    Test Loss :0.81,    Total Acc : 95.88\n",
      "Epoch 1890 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 92.08,    Test Loss :0.84,    Total Acc : 95.83\n",
      "Epoch 1900 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.81,    Test Loss :0.91,    Total Acc : 95.91\n",
      "Epoch 1910 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 93.17,    Test Loss :0.76,    Total Acc : 96.58\n",
      "Epoch 1920 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 93.31,    Test Loss :0.83,    Total Acc : 96.66\n",
      "Epoch 1930 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.02,    Test Loss :0.97,    Total Acc : 96.01\n",
      "Epoch 1940 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.25,    Test Loss :0.87,    Total Acc : 96.12\n",
      "Epoch 1950 - Train Acc : 98.75    Train Loss : 0.1,    Test Acc : 90.9,    Test Loss :0.95,    Total Acc : 94.82\n",
      "Epoch 1960 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.81,    Test Loss :1.06,    Total Acc : 95.41\n",
      "Epoch 1970 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 92.33,    Test Loss :0.79,    Total Acc : 95.96\n",
      "Epoch 1980 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 93.48,    Test Loss :0.77,    Total Acc : 96.74\n",
      "Epoch 1990 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.85,    Test Loss :0.91,    Total Acc : 95.93\n",
      "Epoch 2000 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.44,    Test Loss :0.85,    Total Acc : 96.22\n",
      "Epoch 2010 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 90.23,    Test Loss :0.96,    Total Acc : 94.91\n",
      "Epoch 2020 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 91.83,    Test Loss :0.97,    Total Acc : 95.71\n",
      "Epoch 2030 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 89.27,    Test Loss :1.1,    Total Acc : 94.22\n",
      "Epoch 2040 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 90.85,    Test Loss :0.97,    Total Acc : 95.22\n",
      "Epoch 2050 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.04,    Test Loss :0.97,    Total Acc : 95.52\n",
      "Epoch 2060 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.98,    Test Loss :0.75,    Total Acc : 96.49\n",
      "Epoch 2070 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 91.67,    Test Loss :0.89,    Total Acc : 95.62\n",
      "Epoch 2080 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.17,    Test Loss :0.85,    Total Acc : 95.58\n",
      "Epoch 2090 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.25,    Test Loss :1.17,    Total Acc : 95.12\n",
      "Epoch 2100 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.83,    Test Loss :0.97,    Total Acc : 95.92\n",
      "Epoch 2110 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 90.46,    Test Loss :1.06,    Total Acc : 95.02\n",
      "Epoch 2120 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 90.83,    Test Loss :0.99,    Total Acc : 95.21\n",
      "Epoch 2130 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 93.46,    Test Loss :0.9,    Total Acc : 96.31\n",
      "Epoch 2140 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 90.12,    Test Loss :1.32,    Total Acc : 94.65\n",
      "Epoch 2150 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.56,    Test Loss :1.17,    Total Acc : 95.78\n",
      "Epoch 2160 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 91.94,    Test Loss :0.94,    Total Acc : 95.76\n",
      "Epoch 2170 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 93.08,    Test Loss :1.02,    Total Acc : 96.12\n",
      "Epoch 2180 - Train Acc : 98.33    Train Loss : 0.1,    Test Acc : 90.62,    Test Loss :1.11,    Total Acc : 94.48\n",
      "Epoch 2190 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 92.0,    Test Loss :1.08,    Total Acc : 95.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2200 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.23,    Test Loss :0.99,    Total Acc : 95.61\n",
      "Epoch 2210 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.54,    Test Loss :0.94,    Total Acc : 96.27\n",
      "Epoch 2220 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.9,    Test Loss :1.05,    Total Acc : 95.95\n",
      "Epoch 2230 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 91.9,    Test Loss :1.12,    Total Acc : 95.95\n",
      "Epoch 2240 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 92.17,    Test Loss :0.96,    Total Acc : 96.08\n",
      "Epoch 2250 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.85,    Test Loss :1.03,    Total Acc : 95.93\n",
      "Epoch 2260 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.69,    Test Loss :1.03,    Total Acc : 95.84\n",
      "Epoch 2270 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 90.31,    Test Loss :1.17,    Total Acc : 94.95\n",
      "Epoch 2280 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 89.88,    Test Loss :1.33,    Total Acc : 94.73\n",
      "Epoch 2290 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.98,    Test Loss :1.13,    Total Acc : 96.49\n",
      "Epoch 2300 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 92.56,    Test Loss :0.96,    Total Acc : 96.28\n",
      "Epoch 2310 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.65,    Test Loss :0.94,    Total Acc : 95.82\n",
      "Epoch 2320 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 91.31,    Test Loss :1.06,    Total Acc : 95.45\n",
      "Epoch 2330 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 91.4,    Test Loss :1.04,    Total Acc : 95.7\n",
      "Epoch 2340 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 91.31,    Test Loss :1.08,    Total Acc : 95.24\n",
      "Epoch 2350 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.88,    Test Loss :1.07,    Total Acc : 95.44\n",
      "Epoch 2360 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 92.54,    Test Loss :1.07,    Total Acc : 96.06\n",
      "Epoch 2370 - Train Acc : 99.17    Train Loss : 0.1,    Test Acc : 90.25,    Test Loss :1.25,    Total Acc : 94.71\n",
      "Epoch 2380 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 93.06,    Test Loss :0.92,    Total Acc : 96.32\n",
      "Epoch 2390 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 91.81,    Test Loss :1.11,    Total Acc : 95.91\n",
      "Epoch 2400 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.79,    Test Loss :1.01,    Total Acc : 96.4\n",
      "Epoch 2410 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 90.94,    Test Loss :1.13,    Total Acc : 95.47\n",
      "Epoch 2420 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.54,    Test Loss :1.12,    Total Acc : 95.77\n",
      "Epoch 2430 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.96,    Test Loss :0.95,    Total Acc : 96.48\n",
      "Epoch 2440 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 91.54,    Test Loss :1.08,    Total Acc : 95.77\n",
      "Epoch 2450 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 92.75,    Test Loss :1.1,    Total Acc : 96.17\n",
      "Epoch 2460 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.06,    Test Loss :1.07,    Total Acc : 96.03\n",
      "Epoch 2470 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 92.44,    Test Loss :1.06,    Total Acc : 96.01\n",
      "Epoch 2480 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 91.83,    Test Loss :1.07,    Total Acc : 95.92\n",
      "Epoch 2490 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 91.71,    Test Loss :1.08,    Total Acc : 95.65\n",
      "Epoch 2500 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.25,    Test Loss :1.07,    Total Acc : 95.62\n",
      "Epoch 2510 - Train Acc : 99.58    Train Loss : 0.08,    Test Acc : 91.19,    Test Loss :1.05,    Total Acc : 95.39\n",
      "Epoch 2520 - Train Acc : 99.58    Train Loss : 0.09,    Test Acc : 92.04,    Test Loss :0.87,    Total Acc : 95.81\n",
      "Epoch 2530 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 90.56,    Test Loss :1.12,    Total Acc : 95.28\n",
      "Epoch 2540 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 92.77,    Test Loss :0.97,    Total Acc : 95.97\n",
      "Epoch 2550 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.06,    Test Loss :1.08,    Total Acc : 95.53\n",
      "Epoch 2560 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 91.69,    Test Loss :1.07,    Total Acc : 95.43\n",
      "Epoch 2570 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.75,    Test Loss :0.93,    Total Acc : 96.38\n",
      "Epoch 2580 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.81,    Test Loss :1.1,    Total Acc : 96.41\n",
      "Epoch 2590 - Train Acc : 99.17    Train Loss : 0.08,    Test Acc : 91.79,    Test Loss :1.14,    Total Acc : 95.48\n",
      "Epoch 2600 - Train Acc : 99.17    Train Loss : 0.09,    Test Acc : 91.42,    Test Loss :1.17,    Total Acc : 95.29\n",
      "Epoch 2610 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 92.1,    Test Loss :1.13,    Total Acc : 96.05\n",
      "Epoch 2620 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 92.0,    Test Loss :1.15,    Total Acc : 96.0\n",
      "Epoch 2630 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 91.25,    Test Loss :1.13,    Total Acc : 95.62\n",
      "Epoch 2640 - Train Acc : 100.0    Train Loss : 0.08,    Test Acc : 91.81,    Test Loss :1.17,    Total Acc : 95.91\n",
      "Epoch 2650 - Train Acc : 99.58    Train Loss : 0.11,    Test Acc : 90.92,    Test Loss :1.46,    Total Acc : 95.25\n",
      "Epoch 2660 - Train Acc : 100.0    Train Loss : 0.07,    Test Acc : 91.75,    Test Loss :1.42,    Total Acc : 95.88\n",
      "Epoch 2670 - Train Acc : 86.25    Train Loss : 1.1,    Test Acc : 83.17,    Test Loss :1.85,    Total Acc : 84.71\n",
      "Epoch 2680 - Train Acc : 79.17    Train Loss : 3.55,    Test Acc : 70.85,    Test Loss :4.11,    Total Acc : 75.01\n",
      "Epoch 2690 - Train Acc : 83.33    Train Loss : 0.76,    Test Acc : 83.56,    Test Loss :1.47,    Total Acc : 83.45\n",
      "Epoch 2700 - Train Acc : 82.5    Train Loss : 0.54,    Test Acc : 74.04,    Test Loss :0.88,    Total Acc : 78.27\n",
      "Epoch 2710 - Train Acc : 83.33    Train Loss : 0.39,    Test Acc : 74.79,    Test Loss :0.75,    Total Acc : 79.06\n",
      "Epoch 2720 - Train Acc : 83.75    Train Loss : 0.4,    Test Acc : 75.92,    Test Loss :0.72,    Total Acc : 79.83\n",
      "Epoch 2730 - Train Acc : 84.58    Train Loss : 0.33,    Test Acc : 76.23,    Test Loss :0.9,    Total Acc : 80.41\n",
      "Epoch 2740 - Train Acc : 86.25    Train Loss : 0.3,    Test Acc : 78.96,    Test Loss :1.17,    Total Acc : 82.6\n",
      "Epoch 2750 - Train Acc : 88.33    Train Loss : 0.3,    Test Acc : 83.15,    Test Loss :1.01,    Total Acc : 85.74\n",
      "Epoch 2760 - Train Acc : 93.33    Train Loss : 0.23,    Test Acc : 80.88,    Test Loss :1.26,    Total Acc : 87.1\n",
      "Epoch 2770 - Train Acc : 88.75    Train Loss : 0.29,    Test Acc : 81.08,    Test Loss :1.14,    Total Acc : 84.92\n",
      "Epoch 2780 - Train Acc : 91.67    Train Loss : 0.27,    Test Acc : 80.58,    Test Loss :1.02,    Total Acc : 86.12\n",
      "Epoch 2790 - Train Acc : 90.42    Train Loss : 0.25,    Test Acc : 79.44,    Test Loss :1.18,    Total Acc : 84.93\n",
      "Epoch 2800 - Train Acc : 92.08    Train Loss : 0.25,    Test Acc : 81.67,    Test Loss :1.08,    Total Acc : 86.88\n",
      "Epoch 2810 - Train Acc : 89.58    Train Loss : 0.28,    Test Acc : 78.56,    Test Loss :1.15,    Total Acc : 84.07\n",
      "Epoch 2820 - Train Acc : 93.33    Train Loss : 0.22,    Test Acc : 81.31,    Test Loss :1.1,    Total Acc : 87.32\n",
      "Epoch 2830 - Train Acc : 92.5    Train Loss : 0.23,    Test Acc : 82.92,    Test Loss :1.0,    Total Acc : 87.71\n",
      "Epoch 2840 - Train Acc : 92.92    Train Loss : 0.22,    Test Acc : 80.44,    Test Loss :0.94,    Total Acc : 86.68\n",
      "Epoch 2850 - Train Acc : 94.17    Train Loss : 0.19,    Test Acc : 82.96,    Test Loss :1.23,    Total Acc : 88.56\n",
      "Epoch 2860 - Train Acc : 92.5    Train Loss : 0.22,    Test Acc : 86.94,    Test Loss :1.13,    Total Acc : 89.72\n",
      "Epoch 2870 - Train Acc : 95.0    Train Loss : 0.2,    Test Acc : 86.17,    Test Loss :1.01,    Total Acc : 90.58\n",
      "Epoch 2880 - Train Acc : 91.67    Train Loss : 0.26,    Test Acc : 84.92,    Test Loss :1.04,    Total Acc : 88.29\n",
      "Epoch 2890 - Train Acc : 92.08    Train Loss : 0.25,    Test Acc : 86.4,    Test Loss :1.16,    Total Acc : 89.24\n",
      "Epoch 2900 - Train Acc : 90.42    Train Loss : 0.29,    Test Acc : 85.83,    Test Loss :1.32,    Total Acc : 88.12\n",
      "Epoch 2910 - Train Acc : 92.08    Train Loss : 0.25,    Test Acc : 85.33,    Test Loss :0.97,    Total Acc : 88.71\n",
      "Epoch 2920 - Train Acc : 93.75    Train Loss : 0.21,    Test Acc : 85.88,    Test Loss :0.68,    Total Acc : 89.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2930 - Train Acc : 92.5    Train Loss : 0.25,    Test Acc : 86.96,    Test Loss :0.73,    Total Acc : 89.73\n",
      "Epoch 2940 - Train Acc : 95.83    Train Loss : 0.21,    Test Acc : 86.52,    Test Loss :1.0,    Total Acc : 91.18\n",
      "Epoch 2950 - Train Acc : 93.75    Train Loss : 0.2,    Test Acc : 86.15,    Test Loss :0.91,    Total Acc : 89.95\n",
      "Epoch 2960 - Train Acc : 96.67    Train Loss : 0.17,    Test Acc : 86.83,    Test Loss :0.83,    Total Acc : 91.75\n",
      "Epoch 2970 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 86.88,    Test Loss :0.85,    Total Acc : 91.35\n",
      "Epoch 2980 - Train Acc : 94.17    Train Loss : 0.21,    Test Acc : 83.77,    Test Loss :0.9,    Total Acc : 88.97\n",
      "Epoch 2990 - Train Acc : 95.0    Train Loss : 0.19,    Test Acc : 84.88,    Test Loss :1.0,    Total Acc : 89.94\n",
      "Epoch 3000 - Train Acc : 95.83    Train Loss : 0.16,    Test Acc : 84.94,    Test Loss :0.84,    Total Acc : 90.39\n",
      "*** Best ACC : 94.38 ***\n"
     ]
    }
   ],
   "source": [
    "activation = get_activation('celu')\n",
    "gcn = GraphConvolution\n",
    "\n",
    "encoder = Encoder(args.feature_dimension, args.gcn_hid_channels, args.gcn_out_channels, activation, args.seed, base_model = gcn).to(device)\n",
    "model = GRACE(encoder, args.feature_dimension, args.gcn_out_channels, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "model, best_acc, best_epoch, best_model, best_z, result = GCA_train(model, optimizer, feature, adj, vlc_label,\n",
    "                                                                    vlc_train_identifier, vlc_test_identifier,\n",
    "                                                                    args,device,date,sub_idx, isdeap=True)\n",
    "print(\"*** Best ACC : {} ***\".format(round(best_acc.item(), 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e4de6ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_scatter_deap(result.detach().cpu().numpy(), vlc_label, best_acc, sub_idx, date, args.figure_save_path, visualization_type, vlc_train_identifier, cf_name, fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0c3434e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neuroai/anaconda3/envs/py39_dh/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/neuroai/anaconda3/envs/py39_dh/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dr_result = feature.cpu().numpy()\n",
    "visualization_type = 1\n",
    "if visualization_type == 0:\n",
    "    sample = result.cpu().detach().numpy().copy()\n",
    "    drmodel = PCA(n_components = 2)\n",
    "    pca_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "    dr_result = drmodel.fit_transform(pca_sample)\n",
    "    \n",
    "elif visualization_type == 1:\n",
    "    sample = result.cpu().detach().numpy().copy()\n",
    "    drmodel = TSNE(n_components = 2, n_iter_without_progress = 2000)\n",
    "    tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "    dr_result = drmodel.fit_transform(tsne_sample)\n",
    "    \n",
    "cf_name = 'Valence'\n",
    "fig_name = 'Output'\n",
    "save_scatter_deap(result, vlc_label, best_acc, sub_idx, date, args.figure_save_path, visualization_type, vlc_train_identifier, cf_name, fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159996e2",
   "metadata": {},
   "source": [
    "# Adaptive method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd6e65e",
   "metadata": {},
   "source": [
    "# Edge drop hyperparameter validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d9ed1eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9799, 0.9831, 0.9841, 0.9768, 0.9771, 0.9678, 0.9316, 0.9309, 0.8962,\n",
      "        0.9055, 0.9393, 0.9465, 0.9641, 0.9234, 0.9590, 0.9240, 0.9305, 0.9317,\n",
      "        0.9401, 0.9515, 0.9146, 0.9384, 0.9289, 0.9477, 0.9246, 0.9270, 0.9475,\n",
      "        0.9976, 0.9988, 0.9267, 0.9059, 0.9225, 0.9338, 0.9253, 0.9638, 0.9094,\n",
      "        0.9854, 0.9458, 0.9430, 0.9387, 0.9164, 0.9092, 0.9189, 0.9381, 0.9749,\n",
      "        0.9880, 0.9062, 0.9382, 0.9212, 0.9268, 0.9095, 0.9084, 0.8920, 0.8948,\n",
      "        0.8015, 0.9425, 0.9427, 0.9326, 0.9401, 0.9608, 0.9495, 0.9430, 0.9884,\n",
      "        0.9848, 0.9785, 0.9740, 0.9787, 0.9720, 0.9536, 0.9524, 0.9413, 0.9656,\n",
      "        0.8708, 0.8938, 0.9526, 0.9325, 0.9652, 0.9113, 0.9163, 0.9148, 0.9691,\n",
      "        0.9783, 0.9197, 0.9212, 0.8937, 0.9526, 0.9406, 0.9471, 0.9419, 0.9970,\n",
      "        1.0000, 0.9359, 0.9276, 0.9060, 0.9805, 0.9285, 0.9575, 0.9126, 0.9775,\n",
      "        0.9644, 0.9618, 0.9385, 0.9209, 0.9199, 0.9463, 0.9716, 0.9474, 0.9438,\n",
      "        0.9317, 0.9781, 0.9592, 0.9558, 0.9204, 0.9172, 0.9226, 0.8403, 0.8293,\n",
      "        0.9624, 0.9624, 0.9687, 0.9714, 0.9802, 0.9680, 0.9608, 0.9464, 0.9429,\n",
      "        0.9389, 0.9509, 0.9310, 0.9576, 0.9148, 0.9159, 0.8939, 0.8872, 0.9261,\n",
      "        0.9448, 0.9371, 0.9329, 0.9408, 0.9505, 0.9128, 0.9050, 0.9201, 0.9034,\n",
      "        0.9403, 0.9384, 0.9421, 0.9479, 0.9478, 0.9291, 0.9352, 0.9949, 0.9956,\n",
      "        0.9081, 0.9206, 0.9176, 0.8096, 0.9545, 0.9429, 0.9479, 0.9706, 0.9615,\n",
      "        0.8806, 0.9133, 0.9042, 0.9285, 0.9258, 0.9330, 0.9627, 0.9621, 0.9482,\n",
      "        0.9337, 0.8842, 0.8790, 0.9277, 0.9284, 0.9148, 0.9280, 0.8965, 0.8563,\n",
      "        0.8567, 0.8017, 0.8171, 0.7980, 0.8902, 0.8726, 0.9513, 0.9146, 0.9686,\n",
      "        0.9640, 0.9293, 0.9705, 0.9802, 0.9804, 0.9784, 0.9770, 0.9582, 0.9730,\n",
      "        0.9833, 0.9459, 0.9858, 0.9356, 0.9689, 0.9843, 0.9831, 0.9753, 0.9656,\n",
      "        0.9651, 0.9541, 0.9677, 0.9544, 0.9486, 0.9705, 0.9977, 0.9907, 0.9683,\n",
      "        0.9578, 0.9626, 0.9222, 0.9363, 0.9130, 0.9457, 0.9683, 0.9712, 0.9514,\n",
      "        0.9317, 0.8898, 0.9405, 0.9206, 0.9008, 0.9057, 0.9015, 0.8770, 0.8362,\n",
      "        0.8897, 0.9037, 0.9428, 0.9419, 0.9117, 0.8704, 0.8853, 0.9282, 0.9283,\n",
      "        0.8876, 0.8845, 0.8368, 0.9059, 0.9110, 0.9415, 0.9364, 0.9704, 0.8952,\n",
      "        0.9721, 0.9647, 0.9415, 0.9408, 0.9183, 0.9079, 0.9187, 0.9429, 0.9418,\n",
      "        0.9383, 0.9640, 0.9396, 0.9411, 0.9365, 0.9338, 0.9038, 0.9410, 0.9465,\n",
      "        0.9434, 0.9793, 0.9672, 0.9064, 0.9002, 0.9953, 0.9937, 0.9337, 0.9543,\n",
      "        0.9718, 0.9536, 0.9366, 0.9294, 0.9129, 0.9606, 0.9426, 0.9309, 0.9203,\n",
      "        0.9240, 0.9443, 0.9406, 0.9424, 0.8834, 0.8906, 0.8682, 0.9119, 0.9614,\n",
      "        0.9640, 0.9448, 0.9449, 0.9328, 0.8999, 0.9421, 0.9802, 0.9801, 0.8927,\n",
      "        0.9394, 0.9052, 0.9382, 0.9299, 0.8977, 0.9269, 0.9453, 0.9130, 0.9307,\n",
      "        0.9361, 0.9154, 0.9147, 0.9264, 0.9003, 0.6567, 0.9202, 0.9328, 0.9001,\n",
      "        0.9186, 0.8993, 0.8950, 0.9257, 0.8246, 0.8940, 0.4237, 0.9261, 0.8856,\n",
      "        0.7435, 0.8859, 0.9119, 0.8503, 0.9717, 0.9246, 0.8583, 0.8946, 0.7754,\n",
      "        0.8158, 0.8826, 0.8868, 0.6945, 0.9331, 0.9113, 0.9057, 0.6944, 0.8698,\n",
      "        0.7691, 0.8858, 0.8909, 0.9507, 0.4730, 0.6318, 0.8948, 0.8942, 0.9090,\n",
      "        0.7656, 0.7579, 0.9103, 0.6106, 0.7059, 0.8915, 0.8927, 0.6303, 0.8514,\n",
      "        0.8720, 0.7547, 0.7795, 0.9291, 0.9451, 0.9516, 0.9507, 0.9534, 0.9407,\n",
      "        0.9281, 0.9276, 0.8968, 0.9475, 0.7686, 0.8440, 0.9174, 0.8965, 0.9360,\n",
      "        0.9037, 0.9200, 0.9072, 0.9474, 0.9588, 0.4237, 0.8995, 0.8576, 0.9546,\n",
      "        0.9394, 0.9396, 0.8425, 0.9811, 0.9605, 0.9339, 0.9209, 0.8813, 0.9778,\n",
      "        0.9158, 0.9596, 0.8985, 0.9434, 0.9303, 0.9693, 0.9137, 0.8994, 0.9267,\n",
      "        0.9416, 0.9587, 0.9556, 0.5094, 0.9245, 0.9636, 0.9536, 0.9402, 0.9273,\n",
      "        0.9226, 0.9222, 0.8161, 0.7515, 0.9361, 0.9367, 0.6058, 0.8547, 0.9745,\n",
      "        0.9613, 0.9565, 0.8558, 0.8607, 0.8694, 0.9312, 0.9095, 0.9576, 0.9027,\n",
      "        0.9029, 0.8820, 0.8792, 0.9042, 0.9176, 0.8941, 0.9271, 0.9385, 0.9440,\n",
      "        0.8953, 0.8802, 0.8821, 0.8808, 0.4237, 0.9270, 0.9350, 0.9444, 0.9401,\n",
      "        0.9140, 0.9211, 0.9553, 0.9375, 0.8725, 0.9055, 0.9251, 0.7208, 0.9350,\n",
      "        0.9214, 0.9278, 0.9171, 0.9637, 0.8693, 0.9056, 0.8327, 0.9195, 0.9121,\n",
      "        0.9250, 0.9524, 0.6825, 0.9472, 0.9292, 0.8001, 0.7799, 0.9167, 0.9194,\n",
      "        0.9049, 0.9075, 0.7810, 0.7290, 0.7293, 0.6715, 0.8472, 0.6363, 0.8033,\n",
      "        0.7842, 0.9335, 0.8866, 0.9499, 0.9716, 0.8747, 0.9533, 0.9668, 0.9685,\n",
      "        0.9808, 0.9756, 0.9690, 0.9718, 0.9262, 0.9245, 0.9584, 0.9013, 0.9613,\n",
      "        0.9841, 0.9802, 0.9717, 0.4237, 0.9312, 0.9267, 0.9273, 0.9272, 0.9345,\n",
      "        0.9727, 0.9944, 0.9538, 0.9576, 0.9121, 0.9117, 0.7811, 0.8626, 0.8526,\n",
      "        0.9217, 0.9266, 0.9836, 0.8932, 0.8455, 0.8117, 0.7952, 0.7996, 0.7972,\n",
      "        0.8606, 0.5654, 0.7576, 0.7561, 0.7666, 0.7769, 0.7955, 0.7965, 0.8221,\n",
      "        0.7337, 0.7552, 0.8054, 0.8057, 0.7591, 0.8027, 0.6712, 0.7473, 0.7317,\n",
      "        0.9152, 0.8828, 0.9272, 0.8650, 0.9020, 0.9024, 0.8827, 0.8803, 0.8750,\n",
      "        0.8538, 0.8751, 0.8900, 0.8911, 0.8996, 0.9038, 0.8486, 0.8467, 0.8967,\n",
      "        0.8996, 0.8811, 0.4237, 0.8876, 0.8968, 0.9202, 0.8727, 0.7961, 0.8195,\n",
      "        0.9871, 0.9367, 0.8824, 0.8764, 0.8957, 0.8243, 0.8482, 0.8242, 0.8679,\n",
      "        0.9521, 0.8796, 0.8126, 0.8316, 0.8081, 0.7918, 0.7969, 0.7994, 0.8093,\n",
      "        0.5379, 0.7683, 0.7736, 0.7809, 0.7859, 0.7936, 0.7937, 0.8426, 0.7719,\n",
      "        0.7712, 0.8164, 0.8165, 0.7727, 0.8047, 0.6904, 0.7556, 0.7394],\n",
      "       device='cuda:1')\n",
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False, False, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True, False,  True, False,  True,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "        False,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False, False,  True,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "        False,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True, False, False,  True, False,\n",
      "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False, False,  True,  True,  True, False, False,\n",
      "         True,  True,  True, False,  True,  True,  True,  True,  True,  True],\n",
      "       device='cuda:1')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9299, -0.9922, -1.3947,  ..., -0.1198,  0.6016,  0.5215],\n",
       "        [-0.9305, -0.9918, -1.3938,  ..., -0.1196,  0.6023,  0.5221],\n",
       "        [-0.9314, -0.9922, -1.3941,  ..., -0.1192,  0.6038,  0.5234],\n",
       "        ...,\n",
       "        [-1.7059, -1.4937, -1.3851,  ...,  0.7166,  1.0864,  1.0704],\n",
       "        [-1.7075, -1.4946, -1.3852,  ...,  0.7163,  1.0861,  1.0702],\n",
       "        [-1.7081, -1.4952, -1.3858,  ...,  0.7161,  1.0858,  1.0699]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_features(feature, adj, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "2707a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drop_edges(edge_weights, p: float, threshold: float = 1.):\n",
    "#     alleviated_weights = torch.log(edge_weights)\n",
    "    weight_max = edge_weights.max()\n",
    "    weights = (weight_max-edge_weights)/(weight_max-edge_weights.mean())\n",
    "\n",
    "    probability_weights = weights / weights.mean() * p\n",
    "    probability_weights = probability_weights.where(probability_weights < threshold, torch.ones_like(probability_weights) * threshold)\n",
    "    drop_mask = torch.bernoulli(1. - probability_weights).to(torch.bool)\n",
    "   \n",
    "    edge_weights_view = edge_weights.where(drop_mask == True, torch.zeros_like(edge_weights))\n",
    "    \n",
    "    return edge_weights_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c27606",
   "metadata": {},
   "source": [
    "# Feature drop hyperparameter validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a0ee929c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drop_features(features, edges, p: float, threshold: float = 0.7):\n",
    "    x = torch.abs(features)\n",
    "    row_sum = torch.sum(edges, axis=0)\n",
    "    feature_weights = x.t() @ row_sum\n",
    "    feature_weights = feature_weights.log()\n",
    "    weight_max = feature_weights.max()\n",
    "    w = (weight_max-feature_weights)/(weight_max-feature_weights.mean())\n",
    "\n",
    "    probability_weights = w / w.mean() * p\n",
    "    probability_weights = probability_weights.where(probability_weights < threshold, torch.ones_like(probability_weights) * threshold) \n",
    "    drop_mask = torch.bernoulli(probability_weights).to(torch.bool)\n",
    "    \n",
    "    features_view = features.clone()\n",
    "    features_view[:,drop_mask] = 0.\n",
    "\n",
    "    return features_view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb71be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features2(probability_weights, features, threshold: float = 1.):\n",
    "\n",
    "    probability_weights = probability_weights.where(probability_weights < threshold, torch.ones_like(probability_weights) * threshold) \n",
    "    drop_mask = torch.bernoulli(probability_weights).to(torch.bool)\n",
    "    \n",
    "    features_view = features.clone()\n",
    "    features_view[:,drop_mask] = 0.\n",
    "\n",
    "    return features_view\n",
    "\n",
    "def edge_rank(edge_weights):\n",
    "    weight_max = edge_weights.max(axis=1).values\n",
    "    weight_mean = edge_weights.sum(axis=1)/(edge_weights!=0).sum(axis=1)\n",
    "    weights = (weight_max-edge_weights)/(weight_max-edge_weights.mean())\n",
    "    return weights\n",
    "\n",
    "def drop_edges2(probability_weights, edge_weights, threshold: float = 1.):\n",
    "#     alleviated_weights = torch.log(edge_weights\n",
    "\n",
    "    probability_weights = probability_weights.where(probability_weights < threshold, torch.ones_like(probability_weights) * threshold)\n",
    "    drop_mask = torch.bernoulli(1. - probability_weights).to(torch.bool)\n",
    "   \n",
    "    edge_weights_view = edge_weights.where(drop_mask == True, torch.zeros_like(edge_weights))\n",
    "\n",
    "    return edge_weights_view\n",
    "\n",
    "\n",
    "def GCA_train2(model, otimizer, feature, orig_adj, label, train_identifier, test_identifier, args, device,date = None,sub_idx = None, isdeap=False ):\n",
    "#     save_path = args.model_save_path+'subject_dependent/'+date+'/'+sub_idx+'.pt'\n",
    "#     early_stopping = EarlyStopping(patience = args.patience, verbose = False, path=save_path)\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_model = None\n",
    "    best_z = None\n",
    "#     w = 0.5\n",
    "\n",
    "    rankf = disc_rank(feature, label,train_identifier, args.out_channels)\n",
    "    rankf1 = rankf*args.pf1\n",
    "    rankf2 = rankf*args.pf2\n",
    "    ranke = edge_rank(adj)\n",
    "    ranke1 = ranke*args.pe1\n",
    "    ranke2 = ranke*args.pe2\n",
    "    \n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x1 = drop_features2(rankf1, feature, threshold = args.tpf1)\n",
    "        x2 = drop_features2(rankf2, feature, threshold = args.tpf2)\n",
    "        e1 = drop_edges2(ranke1,orig_adj, threshold = args.tpe1)\n",
    "        e2 = drop_edges2(ranke2,orig_adj, threshold = args.tpe2)\n",
    "\n",
    "#         x1 = drop_features(feature, adj, p = 0.1, threshold = args.tpf1)\n",
    "#         x2 = drop_features(feature, adj, p = 0.2, threshold = args.tpf2)\n",
    "#         e1 = drop_edges(adj, p = 0.1, threshold = args.tpe1)\n",
    "#         e2 = drop_edges(adj, p = 0.2, threshold = args.tpe2)\n",
    "        \n",
    "        z1 = model(x1,e1) #,bias = True)\n",
    "#         z1 = model(feature,adj)\n",
    "        z1 = model.projection(z1)\n",
    "        z2 = model(x2,e2)\n",
    "        z2 = model.projection(z2)   \n",
    "        \n",
    "#         ne1 = model.decoder(z1)\n",
    "#         ne2 = model.decoder(z2)\n",
    " \n",
    "#         ne1 = (ne1-ne1.min())/(ne1.max()-ne1.min())\n",
    "#         ne2 = (ne2-ne2.min())/(ne2.max()-ne2.min())\n",
    "#         nadj1 = w*adj + (1.-w)*ne1\n",
    "#         nadj2 = w*adj + (1.-w)*ne2\n",
    "#         nadj = 0.5*(nadj1+nadj2)\n",
    "#         print(nadj)\n",
    " \n",
    "        r1 = model.classification(z1)\n",
    "        r1_pred = r1[train_identifier]\n",
    "        r1_y = label[train_identifier]\n",
    "        # L2 regularization is not implemented yet\n",
    "        labeled_loss1 = criterion(r1_pred, r1_y)\n",
    "        r1_acc = accuracy(r1_pred, r1_y, isdeap)\n",
    "\n",
    "        r2 = model.classification(z2)\n",
    "        r2_pred = r2[train_identifier]\n",
    "        r2_y = label[train_identifier]\n",
    "        # L2 regularization is not implemented yet\n",
    "        labeled_loss2 = criterion(r2_pred, r2_y)\n",
    "        r2_acc = accuracy(r2_pred, r2_y, isdeap)\n",
    "\n",
    "        \n",
    "        contrastive_loss = model.loss(z1,z2)\n",
    "#         print(contrastive_loss)\n",
    "        loss = (labeled_loss1 + labeled_loss2)/2. + contrastive_loss*args.loss_lambda\n",
    "#         loss = labeled_loss1 + contrastive_loss*args.loss_lambda\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         orig_adj = nadj.detach().clone().to(device)\n",
    "#         print(orig_adj)\n",
    "#         adj = nadj.detach().clone().cuda()\n",
    "        acc = (r1_acc + r2_acc)/2.\n",
    "#         acc = r1_acc\n",
    "        \n",
    "        tr1_pred = r1[test_identifier]\n",
    "        tr1_y = label[test_identifier]\n",
    "        tr1_loss = criterion(tr1_pred, tr1_y)\n",
    "        tr1_acc = accuracy(tr1_pred, tr1_y, isdeap)\n",
    "        \n",
    "        tr2_pred = r2[test_identifier]\n",
    "        tr2_y = label[test_identifier]\n",
    "        tr2_acc = accuracy(tr2_pred, tr2_y, isdeap)\n",
    "        tr2_loss = criterion(tr2_pred, tr2_y)\n",
    "        \n",
    "#         tr_acc = (tr1_acc + tr2_acc)/2.\n",
    "        if tr1_acc > tr2_acc:\n",
    "            result = r1\n",
    "            tr_acc = tr1_acc\n",
    "        else:\n",
    "            result = r2\n",
    "            tr_acc = tr2_acc\n",
    "        \n",
    "        tr_loss = (tr1_loss + tr2_loss)/2.\n",
    "        total_acc = (tr_acc + acc)/2.\n",
    "        \n",
    "        if tr_acc > best_acc :\n",
    "            best_acc = tr_acc\n",
    "            best_epoch = epoch\n",
    "            best_model = model\n",
    "            \n",
    "            best_result = result\n",
    "            best_z = z1 if tr1_acc > tr2_acc else z2\n",
    "\n",
    "\n",
    "#         if epoch % 10 == 0:\n",
    "#             print(\"Epoch {} - Train Acc : {}    Train Loss : {},    Test Acc : {},    Test Loss :{},    Total Acc : {}\".format(epoch, round(acc.item(), 2), round(loss.item(),2), round(tr_acc.item(),2), round(tr_loss.item(),2), round(total_acc.item(), 2)))\n",
    "\n",
    "#         early_stopping(vloss, model)\n",
    "#         if early_stopping.early_stop:\n",
    "#             print('Epoch : {} - Ealry Stopping'.format(epoch))\n",
    "#             break\n",
    "#     model.load_state_dict(torch.load(save_path))\n",
    "    return model, best_acc, best_epoch, best_model, best_z, best_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3794120b",
   "metadata": {},
   "source": [
    "# Row max, mean with Self-similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c37dbbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bus_id': 'PCI_BUS_ID',\n",
       " 'cuda_id': ['0', '1', '2'],\n",
       " 'os_path': '/home/neuroai/users/dhkim/eer/SSLGCN',\n",
       " 'feature_name1': 'DE_LDS_data',\n",
       " 'feature_name2': 'PSD_LDS_data',\n",
       " 'deap_label_dir_path': 'dataset/deap/data_preprocessed_matlab/',\n",
       " 'deap_data_dir_path': 'dataset/deap/extractedfeatures/de_psd_lds/',\n",
       " 'figure_save_path': 'store_deap/figure/',\n",
       " 'tensor_save_path': 'store_deap/tensor/',\n",
       " 'model_save_path': 'store_deap/model/',\n",
       " 'valence': 'Valence',\n",
       " 'arousal': 'Arousal',\n",
       " 'n_subjects': 32,\n",
       " 'n_trials': 40,\n",
       " 'n_nodes': 32,\n",
       " 'n_features': 4,\n",
       " 'n_samples': 2520,\n",
       " 'n_labels_by_class1': 60,\n",
       " 'n_labels_by_class2': 90,\n",
       " 'n_labels_by_class3': 120,\n",
       " 'n_labels': 2,\n",
       " 'seed': 2023,\n",
       " 'EEG_band': None,\n",
       " 'pca_components1': 9,\n",
       " 'pca_components2': 6,\n",
       " 'essm_lambda': 0.9,\n",
       " 'de_k': 1200,\n",
       " 'psd_k': 1200,\n",
       " 'k1': 30,\n",
       " 'k2': 130,\n",
       " 't1': 1,\n",
       " 't2': 1,\n",
       " 'feature_dimension': 256,\n",
       " 'gcn_hid_channels': 128,\n",
       " 'gcn_out_channels': 64,\n",
       " 'out_channels': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'l2_lambda': 0.001,\n",
       " 'epochs': 3000,\n",
       " 'proj_hid_channels': 16,\n",
       " 'ptau': 0.7,\n",
       " 'pf1': 0.1,\n",
       " 'pf2': 0.2,\n",
       " 'pe1': 0.1,\n",
       " 'pe2': 0.2,\n",
       " 'tpf1': 0.3,\n",
       " 'tpf2': 0.3,\n",
       " 'tpe1': 0.3,\n",
       " 'tpe2': 0.3,\n",
       " 'loss_lambda': 0.01,\n",
       " 'patience': 10,\n",
       " 'val_split': 0.2}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26c812d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 2\n",
      "Count of using GPUs: 3\n",
      "========================================== SEED_IV Protocol 15 ==========================================\n",
      "+++++++++++++++++++++++++++ Pe: 0.1, Pf:0.1 +++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "3.5422 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 82.49 , Best Epoch : 1258***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 2 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3239 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 88.51 , Best Epoch : 432***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 3 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2769 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5080/4212163399.py:59: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.matshow(matrix)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Best ACC : 83.03 , Best Epoch : 1380***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 4 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2886 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 87.2 , Best Epoch : 1439***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 5 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3023 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 83.6 , Best Epoch : 344***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 6 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2943 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 89.41 , Best Epoch : 1536***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 7 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2853 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 88.83 , Best Epoch : 2159***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 8 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2865 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 86.75 , Best Epoch : 57***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 9 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2945 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 88.14 , Best Epoch : 260***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 10 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3015 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 89.53 , Best Epoch : 225***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 11 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2933 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 84.42 , Best Epoch : 1195***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 12 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2973 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 77.75 , Best Epoch : 12***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 13 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2932 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 85.64 , Best Epoch : 1193***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 14 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3007 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 85.07 , Best Epoch : 2982***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 15 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2820 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 93.01 , Best Epoch : 59***\n",
      "\n",
      "**************** Best acc by subject *********************\n",
      "** Best ACC : [82.49, 88.51, 83.03, 87.2, 83.6, 89.41, 88.83, 86.75, 88.14, 89.53, 84.42, 77.75, 85.64, 85.07, 93.01] **\n",
      " ** Avearge acc : 86.22,    std : 3.58 **\n",
      "\n",
      "\n",
      " Best Epochs : [1258, 432, 1380, 1439, 344, 1536, 2159, 57, 260, 225, 1195, 12, 1193, 2982, 59]\n",
      "directory already exists\n",
      "protocol 15_best_acc_list_230405 is saved successfully\n",
      "+++++++++++++++++++++++++++ Pe: 0.1, Pf:0.2 +++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "******************* SUBJECT : 1 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2889 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 81.88 , Best Epoch : 2504***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 2 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2783 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 86.67 , Best Epoch : 188***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 3 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2785 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 82.99 , Best Epoch : 479***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 4 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2815 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 85.24 , Best Epoch : 76***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 5 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2857 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 81.31 , Best Epoch : 1081***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 6 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2861 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 89.94 , Best Epoch : 415***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 7 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2831 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 87.28 , Best Epoch : 269***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 8 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2887 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 90.55 , Best Epoch : 2168***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 9 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.3017 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 88.88 , Best Epoch : 227***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 10 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n",
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2839 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n",
      "*** Best ACC : 90.51 , Best Epoch : 2621***\n",
      "\n",
      "\n",
      "******************* SUBJECT : 11 *********************\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "\n",
      "********** SSM construction start ***********\n",
      "\n",
      "Distance matrix construction start...\n",
      "Done\n",
      "\n",
      "Sparse ssm and normalized sparse ssm construction start...\n",
      "Done\n",
      "\n",
      "directory already exists\n",
      "de_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "de_nssm_230405 is saved successfully\n",
      "directory already exists\n",
      "psd_nssm_230405 is saved successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** SSM fusion start ***********\n",
      "sparse kernel matrix construction start...\n",
      "1st feature based skm has been completed\n",
      "2nd feature based skm has been completed\n",
      "\n",
      "fused ssm construction start...\n",
      "time step :  0\n",
      "0.2793 sec\n",
      "Done\n",
      "**********************************************\n",
      "directory already exists\n",
      "fused_ssm_230405 is saved successfully\n",
      "directory already exists\n",
      "adjacency_matrix_230405 is saved successfully\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m model \u001b[38;5;241m=\u001b[39m GRACE(encoder, args\u001b[38;5;241m.\u001b[39mfeature_dimension, args\u001b[38;5;241m.\u001b[39mgcn_out_channels, args\u001b[38;5;241m.\u001b[39mproj_hid_channels, args\u001b[38;5;241m.\u001b[39mout_channels, args\u001b[38;5;241m.\u001b[39mptau)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     97\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[0;32m---> 99\u001b[0m model, best_acc, best_epoch, best_model, best_z, result \u001b[38;5;241m=\u001b[39m \u001b[43mGCA_train2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43mtrain_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43msub_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misdeap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m experiment_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject_dependent\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    104\u001b[0m model_save_name \u001b[38;5;241m=\u001b[39m sub_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn [10], line 93\u001b[0m, in \u001b[0;36mGCA_train2\u001b[0;34m(model, otimizer, feature, orig_adj, label, train_identifier, test_identifier, args, device, date, sub_idx, isdeap)\u001b[0m\n\u001b[1;32m     90\u001b[0m         loss \u001b[38;5;241m=\u001b[39m (labeled_loss1 \u001b[38;5;241m+\u001b[39m labeled_loss2)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m+\u001b[39m contrastive_loss\u001b[38;5;241m*\u001b[39margs\u001b[38;5;241m.\u001b[39mloss_lambda\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m#         loss = labeled_loss1 + contrastive_loss*args.loss_lambda\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m#         orig_adj = nadj.detach().clone().to(device)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#         print(orig_adj)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#         adj = nadj.detach().clone().cuda()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x1600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "method\n",
    "cp.cuda.Device(2).use()\n",
    "\n",
    "args = get_seedIV_args()\n",
    "\n",
    "device = get_device(args.bus_id, args.cuda_id[2])\n",
    "setting_os_path(args.os_path)\n",
    "# fix_random_variables(args.seed)\n",
    "\n",
    "args.tpe1 = 1.\n",
    "args.tpe2 = 1.\n",
    "args.tpf1 = 1.\n",
    "args.tpf2 = 1.\n",
    "\n",
    "subject_de, subject_psd, subject_label, subject_sample_counts = load_subject_data(args.tensor_save_path, isdeap=False)\n",
    "\n",
    "visualization_type = 1\n",
    "for p in range(1):\n",
    "    if p == 0:\n",
    "        n_labels_by_class = args.n_labels_by_class1\n",
    "    elif p == 1:\n",
    "        n_labels_by_class = args.n_labels_by_class2\n",
    "    else:\n",
    "        n_labels_by_class = args.n_labels_by_class1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    print(\"========================================== SEED_IV Protocol {} ==========================================\".format(int(n_labels_by_class)))\n",
    "    Best_EF_acc = [[0 for _ in range(9)] for _ in range(9)]\n",
    "    Best_EF_std = [[0 for _ in range(9)] for _ in range(9)]\n",
    "    for e in range(1,10):\n",
    "        for f in range(1,10):\n",
    "            print(\"+++++++++++++++++++++++++++ Pe: {}, Pf:{} +++++++++++++++++++++++++++++++++++\".format(e/10,f/10))\n",
    "        \n",
    "            best_epoch_list = []\n",
    "            best_acc_list = []\n",
    "            orig_acc_list = []\n",
    "            args.pe1 = e/10\n",
    "            args.pe2 = e/10\n",
    "            args.pf1 = f/10\n",
    "            args.pf2 = f/10\n",
    "            for i in range(15):\n",
    "                print(\"\\n\\n******************* SUBJECT : {} *********************\".format(i+1))\n",
    "                sub_idx = 'sub'+str(i+1)\n",
    "                date = '230405'\n",
    "\n",
    "                sub_de = subject_de[i]\n",
    "                sub_psd = subject_psd[i]\n",
    "                sub_label = subject_label[i]\n",
    "                sub_sample_counts = subject_sample_counts[i]\n",
    "\n",
    "                de, psd, identifier = other_preprocessing(sub_de,sub_psd,sub_label, n_labels_by_class, args.out_channels, args.seed)\n",
    "\n",
    "                de = normalization(de, axis = 0, ntype='standardization')\n",
    "                psd = normalization(psd, axis = 0, ntype='standardization')\n",
    "\n",
    "                de_ssm, de_nssm = ssm_construction(de, args.n_samples, args.de_k)\n",
    "                psd_ssm, psd_nssm = ssm_construction(psd, args.n_samples, args.psd_k)\n",
    "\n",
    "                save_np(args.tensor_save_path+sub_idx, 'de_ssm_'+date, de_ssm)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'psd_ssm_'+date, psd_ssm)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'de_nssm_'+date, de_nssm)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'psd_nssm_'+date, psd_nssm)\n",
    "                save_heatmap(de_ssm, \"DE SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/DE_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "                save_heatmap(psd_ssm, \"PSD SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/PSD_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "                save_heatmap(de_nssm, \"DE NSSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/DE_NSSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "                save_heatmap(psd_nssm, \"PSD NSSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/ssm/PSD_NSSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "\n",
    "                fsm = ssm_fusion(de_ssm,psd_ssm, de_nssm, psd_nssm, args.k1, args.t1)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'fused_ssm_'+date, fsm)\n",
    "                save_heatmap(fsm, \"Fused SSM\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/fused_ssm/Fused_SSM_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "\n",
    "                adj = normalize_adj(fsm)\n",
    "                save_np(args.tensor_save_path+sub_idx, 'adjacency_matrix_'+date, adj)\n",
    "                save_heatmap(adj, \"Normalized Adjacecy Matrix\", \"Sample indices (axis i)\", \"Sample indices (axis i)\", args.figure_save_path+'heatmap/'+sub_idx+'/adjacency_matrix/Adjacecny_Matrix_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight')\n",
    "\n",
    "                feature = input_feature(de, psd)\n",
    "                label = sub_label\n",
    "\n",
    "                save_heatmap(feature, \"Feature matrix\", \"Feature dimensions\", \"Sample index\", args.figure_save_path+'heatmap/'+sub_idx+'/feature/feature_matrix_'+date+'.png',clim_min =None, clim_max =None, _dpi=300, _facecolor=\"#eeeeee\", _bbox_inches = 'tight') \n",
    "\n",
    "                feature = torch.from_numpy(feature).to(torch.float32).to(device)\n",
    "                adj = torch.from_numpy(adj).to(torch.float32).to(device)\n",
    "                label = torch.from_numpy(label).to(torch.long).to(device)\n",
    "\n",
    "                identifier = torch.from_numpy(identifier).bool()\n",
    "                train_identifier = identifier.to(device)\n",
    "                isunlabeled = ~identifier\n",
    "\n",
    "                test_identifier = isunlabeled.to(device)\n",
    "\n",
    "                activation = get_activation('celu')\n",
    "                gcn = GraphConvolution\n",
    "\n",
    "                encoder = Encoder(args.feature_dimension, args.gcn_hid_channels, args.gcn_out_channels, activation, args.seed, base_model = gcn).to(device)\n",
    "                model = GRACE(encoder, args.feature_dimension, args.gcn_out_channels, args.proj_hid_channels, args.out_channels, args.ptau).to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr = args.learning_rate)\n",
    "\n",
    "                model, best_acc, best_epoch, best_model, best_z, result = GCA_train2(model, optimizer, feature, adj, label,\n",
    "                                                                                    train_identifier, test_identifier,\n",
    "                                                                                    args,device,date,sub_idx, isdeap=False)\n",
    "\n",
    "                experiment_type = 'subject_dependent'\n",
    "                model_save_name = sub_idx+'_model'\n",
    "                model_path = args.model_save_path+experiment_type+'/'+date+'/'+model_save_name\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "\n",
    "                print(\"*** Best ACC : {} , Best Epoch : {}***\".format(round(best_acc.item(), 2), best_epoch))\n",
    "                best_epoch_list.append(best_epoch)\n",
    "                best_acc_list.append(round(best_acc.item(), 2))\n",
    "                orig_acc_list.append(best_acc.item())\n",
    "\n",
    "\n",
    "            #     sample = best_z.cpu().detach().numpy().copy()\n",
    "            #     drmodel = TSNE(n_components = 2, perplexity = 50., n_iter_without_progress = 4000)\n",
    "            #     tsne_sample = StandardScaler().fit_transform(sample) # standardization\n",
    "            #     dr_result = drmodel.fit_transform(tsne_sample)\n",
    "\n",
    "            #     save_scatter(dr_result, label, best_acc.item(),sub_idx, date, args.figure_save_path, visualization_type, identifier)\n",
    "\n",
    "            print(\"\\n**************** Best acc by subject *********************\")\n",
    "            print(\"** Best ACC : {} **\\n ** Avearge acc : {},    std : {} **\\n\".format(best_acc_list, round(np.mean(orig_acc_list),2), round(np.std(orig_acc_list),2)))\n",
    "\n",
    "            Best_EF_acc[e-1][f-1] = round(np.mean(orig_acc_list),2)\n",
    "            Best_EF_std[e-1][f-1] = round(np.std(orig_acc_list),2)\n",
    "            print(\"\\n Best Epochs : {}\".format(best_epoch_list))\n",
    "            best_acc_list = np.array(best_acc_list)\n",
    "            save_np(args.tensor_save_path+sub_idx, 'protocol '+str(n_labels_by_class)+'_best_acc_list_'+date, best_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc00b277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[95.96, 96.44, 96.51, 96.59, 96.37, 96.71, 96.62, 96.7, 96.45],\n",
       " [95.35, 95.99, 96.32, 96.51, 96.59, 96.78, 96.7, 96.57, 96.42],\n",
       " [95.85, 96.28, 96.53, 96.44, 96.52, 96.59, 96.37, 96.57, 96.49],\n",
       " [95.79, 96.31, 96.38, 96.53, 96.74, 96.6, 96.86, 96.67, 96.39],\n",
       " [95.97, 96.45, 96.74, 96.73, 96.62, 96.79, 96.57, 96.5, 96.6],\n",
       " [96.01, 96.35, 96.27, 96.64, 96.52, 96.54, 96.4, 96.62, 96.55],\n",
       " [95.75, 96.23, 96.57, 96.54, 96.65, 96.44, 96.5, 96.37, 96.52],\n",
       " [96.08, 96.17, 96.68, 96.57, 96.6, 96.63, 96.63, 96.55, 96.55],\n",
       " [95.96, 96.06, 96.67, 96.65, 96.66, 96.59, 96.68, 96.37, 96.44]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_EF_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc603ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_dh",
   "language": "python",
   "name": "py39_dh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
