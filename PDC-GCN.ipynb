{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce3f247",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mget_device_name(\u001B[38;5;241m2\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.get_device_name(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0b3ba4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from torch_geometric.nn import ChebConv, GCNConv\n",
    "from torch_geometric.transforms import LaplacianLambdaMax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c04921",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# EEG_band : delta, theta, alpha, beta, gamma, all = 1,2,3,4,5,None\n",
    "# Feature_name : de_LDS, PSD_LDS, etc.\n",
    "def load_data(data_dir_path,label_dir_path, trial:int, feature_name, EEG_band=None):  \n",
    "    subject_data_list, session_list = [], []\n",
    "    file_list = os.listdir(data_dir_path)\n",
    "    \n",
    "    for idx, file in enumerate(file_list):\n",
    "        trial_list = []\n",
    "        data = io.loadmat(data_dir_path + file)\n",
    "        if EEG_band is None:\n",
    "            for trial_idx in range(1, trial+1):\n",
    "                trial_list.append(data[feature_name + str(trial_idx)][:, :, :])  # EEG all bands\n",
    "\n",
    "        else:\n",
    "            for trial_idx in range(1, trial+1):\n",
    "                trial_list.append(data[feature_name + str(trial_idx)][:, :, EEG_band])\n",
    "\n",
    "        session_list.append(trial_list)\n",
    "\n",
    "        if (idx + 1) % 3 == 0:\n",
    "            subject_data_list.append(session_list)\n",
    "            session_list = []\n",
    "\n",
    "    label = io.loadmat(label_dir_path + 'label.mat')['label']\n",
    "    label = [1 + label[0][i] for i in range(trial)]\n",
    "    #label [-1, 1] --> [0, 2]\n",
    "\n",
    "    # subject_data_list : num_subjects(15) × num_sessions(3) × num_trials(15)\n",
    "    return subject_data_list, label\n",
    "\n",
    "\n",
    "# edge attributes are composed of edge weights, the distance between all EEG channel pairs\n",
    "def load_edge_information(pdc_dir_path, sub_name, pdc_var_name, n_channels, n_trials, n_sessions, n_subjects):\n",
    "\n",
    "    file_list = os.listdir(pdc_dir_path)\n",
    "    \n",
    "    edge_index_list = []\n",
    "    for i in range(n_channels):\n",
    "        for j in range(n_channels):\n",
    "            edge_index_list.append([i,j])\n",
    "            \n",
    "    edge_attr_list = []\n",
    "    session_edge_attr_list = []\n",
    "    sub_idx = 0\n",
    "    for i, file in enumerate(file_list):\n",
    "        trial_edge_attr_list = []\n",
    "        pdcs = io.loadmat(pdc_dir_path + file)\n",
    "        pdc_name = sub_name[sub_idx]+pdc_var_name\n",
    "        for trial_idx in range(1, n_trials+1):\n",
    "            edge_attr = []\n",
    "            pdc = pdcs[pdc_name+str(trial_idx)][:,:]\n",
    "            for k in range(n_channels):\n",
    "                for l in range(n_channels):\n",
    "                    if k == l:\n",
    "                        edge_attr.append(0)\n",
    "                    else:\n",
    "                        edge_attr.append(pdc[k][l])\n",
    "        \n",
    "            trial_edge_attr_list.append(edge_attr)\n",
    "        session_edge_attr_list.append(trial_edge_attr_list)\n",
    "        if (i+1) % 3 == 0:\n",
    "            sub_idx+=1\n",
    "            edge_attr_list.append(session_edge_attr_list)\n",
    "            session_edge_attr_list = []\n",
    "\n",
    "    return edge_index_list, edge_attr_list\n",
    "\n",
    "\n",
    "#Graph Representation\n",
    "def get_graph_data(subject_data, subject_label, edge_index_list, edge_attr_list, num_train_trials , batch_size):\n",
    "    edge_index = torch.tensor(edge_index_list, dtype=torch.long)\n",
    "    train_loader, test_loader = [], []\n",
    "\n",
    "    num_subjects = len(subject_data)\n",
    "    num_sessions = len(subject_data[0])\n",
    "    num_trials = len(subject_data[0][0])\n",
    "\n",
    "    for subject in range(num_subjects):\n",
    "        train_dataset, test_dataset = [], []\n",
    "        for session in range(num_sessions):\n",
    "            for trial in range(num_trials):\n",
    "                data_list = []\n",
    "                trial_data = subject_data[subject][session][trial] # trial_data = [62][about 240][1or5] = [nodes][trial time][EEG band(s)]\n",
    "                blocks = len(trial_data[1]) # about 240(240 sec, 4minutes), 'blocks' is number of blocks which is the same as a trial time\n",
    "                edge_attr = torch.tensor(edge_attr_list[subject][session][trial], dtype=torch.float)\n",
    "                for block_idx in range(blocks):\n",
    "                    # if using features of all frequency bands,\n",
    "                    # node_feature = [delta, theta, alpha, beta, gamma]\n",
    "                    data_sample = torch.tensor(trial_data[:, block_idx, :], dtype=torch.float)#data_sample = [62][5] = [nodes, node_features(EEG band(s)]\n",
    "                    data_label = torch.tensor(subject_label[trial], dtype=torch.long) # data_label [0,2]\n",
    "                    data_list.append(Data(x=data_sample, edge_index=edge_index.t().contiguous(), edge_attr=edge_attr, y=data_label))\n",
    "                if trial < num_train_trials:\n",
    "                    train_dataset.extend(data_list)\n",
    "                else: \n",
    "                    test_dataset.extend(data_list)\n",
    "            \n",
    "        random.shuffle(train_dataset)\n",
    "        random.shuffle(test_dataset)\n",
    "        \n",
    "        batch_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "        batch_test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        train_loader.append(batch_train_loader)\n",
    "        test_loader.append(batch_test_loader)\n",
    "        print('loading' + str(subject))\n",
    "    print(\"\\nTrain dataset length: {}, \\tTest dataset legnth: {}\".format(len(train_dataset), len(test_dataset)))\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6b48c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def criterion(loss, label, model, L1_regularization_scaler):\n",
    "    l1_regularization = torch.tensor(0., device=device)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        l1_regularization += torch.norm(param, 1)\n",
    "\n",
    "    loss += L1_regularization_scaler * l1_regularization\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train(loader, model, optimizer, L1_regularization_scaler, epoch, batch_size):\n",
    "    model.train()\n",
    "    train_acc, train_loss, count = 0., 0., 0.\n",
    "\n",
    "    dataset_length = len(loader.dataset)\n",
    "    loader_length = len(loader)\n",
    "    for batch_idx, data in enumerate(loader):\n",
    "        if len(data.y) == batch_size: # dataset size가 batch size로 안나눠지면 버림\n",
    "            count += 1.\n",
    "            data = data.to(device)\n",
    "            loss,result = model(data, 'train')\n",
    "            loss = criterion(loss, data.y, model, L1_regularization_scaler)\n",
    "            loss.backward()\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 for p in model.parameters():\n",
    "#                     #p = (1-lr)*p + lr*p.grad\n",
    "#                     print(p.requires_grad,\" row : \", p)\n",
    "#                     p = p.grad\n",
    "#                     print(p.requires_grad, \" copy : \",p)\n",
    "#                     break\n",
    "#             for p in model.parameters():\n",
    "#                 print(p.requires_grad, \" update: \", p)\n",
    "#                 break\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss += loss.item()\n",
    "            pred = result.max(1, keepdim = True)[1]\n",
    "            acc = pred.eq(data.y.view_as(pred)).sum().item()\n",
    "            acc = 100. * acc / batch_size\n",
    "\n",
    "            train_acc += acc\n",
    "\n",
    "    train_acc /= count\n",
    "    train_loss /= count\n",
    "    return train_acc, train_loss\n",
    "\n",
    "\n",
    "def test(loader, model, L1_regularization_scaler, batch_size):\n",
    "    model.eval()\n",
    "\n",
    "    count, test_loss, test_acc = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            if len(data.y) == batch_size:\n",
    "                count += 1\n",
    "                data = data.to(device)\n",
    "                output, result = model(data)\n",
    "                loss = output.item()\n",
    "                test_loss += loss\n",
    "                \n",
    "                pred = result.max(1, keepdim = True)[1]\n",
    "                acc = pred.eq(data.y.view_as(pred)).sum().item()\n",
    "                acc = 100. * acc / batch_size\n",
    "                test_acc += acc\n",
    "\n",
    "    test_acc /= count\n",
    "    test_loss /= count\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b9503c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SSLGCN(nn.Module):\n",
    "    def __init__(self, num_nodes,num_features, gcn1_channels, gcn2_channels, gcn3_channels, fc1_channels, out_channels, edge_weight, batch_size, learnable=False):\n",
    "        super(SSLGCN, self).__init__()\n",
    "        self.in_channels = num_features\n",
    "        self.gcn1_out_channels = gcn1_channels\n",
    "        self.gcn2_out_channels = gcn2_channels\n",
    "        self.gcn3_out_channels = gcn3_channels\n",
    "#         self.fc1_in_channels = (gcn1_channels + gcn2_channels) * num_nodes\n",
    "        self.fc1_in_channels = gcn3_channels * num_nodes\n",
    "        self.fc1_out_channels = fc1_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.lambdamax = LaplacianLambdaMax(None)\n",
    "        self.edge_weight = nn.Parameter(edge_weight, requires_grad=learnable)\n",
    "        self.batch_size = batch_size\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.crossentropy = nn.CrossEntropyLoss()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.leakyrelu = nn.LeakyReLU(0.15)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.bn1d = nn.BatchNorm1d(self.in_channels)\n",
    "        self.gcn1 = GCNConv(self.in_channels, self.gcn1_out_channels)\n",
    "        self.gcn2 = GCNConv(self.gcn1_out_channels, self.gcn2_out_channels)\n",
    "        self.gcn3 = GCNConv(self.gcn2_out_channels, self.gcn3_out_channels)\n",
    "        self.fc1 = nn.Linear(self.fc1_in_channels, self.fc1_out_channels)\n",
    "        self.fc2 = nn.Linear(self.fc1_out_channels, self.out_channels)\n",
    "        self.fc_module = nn.Sequential(self.fc1, self.dropout, self.leakyrelu, self.fc2)\n",
    "        \n",
    "    def forward(self, data, _type=None):\n",
    "        data.edge_attr = self.edge_weight.data.repeat(self.batch_size)\n",
    "        data = self.lambdamax(data)\n",
    "\n",
    "        if data.x.dim() == 1:\n",
    "            data.x = data.x.unsqueeze(dim=1)\n",
    "        \n",
    "        bn = self.leakyrelu(self.bn1d(data.x))\n",
    "        gcn1 = self.gcn1(bn, data.edge_index, self.leakyrelu(data.edge_attr))\n",
    "        gcn2 = self.gcn2(self.leakyrelu(gcn1), data.edge_index, self.leakyrelu(data.edge_attr))\n",
    "        gcn3 = self.gcn3(self.leakyrelu(gcn2), data.edge_index, self.leakyrelu(data.edge_attr))\n",
    "        \n",
    "        \"\"\"need to be checked\"\"\"\n",
    "#         gcn = torch.cat((gcn1, gcn2), 0)\n",
    "        gcn = self.leakyrelu(gcn3).reshape(self.batch_size, -1)\n",
    "\n",
    "        fc = self.fc_module(gcn)\n",
    "#         print(\"edge: \", data.edge_attr)\n",
    "#         print(\"data: \", data.x)\n",
    "#         print(\"BN: \", bn)\n",
    "#         print(\"gcn1: \", gcn1)\n",
    "#         print(\"gcn2: \", gcn2)\n",
    "#         print(\"gcn3: \", gcn3, gcn3.shape)\n",
    "#         print(\"flatten: \", gcn, gcn.shape)\n",
    "#         print(\"fc: \", fc)\n",
    "        loss = self.crossentropy(fc.view(-1, self.out_channels), data.y.view(-1))\n",
    "        result = self.softmax(fc)\n",
    "        \n",
    "        return loss, result\n",
    "\n",
    "class DGCNN6(nn.Module): # Two GCN with Batch Normalization and LeakyReLU\n",
    "    def __init__(self, num_nodes,num_features, hid_channels, out_channels, k,  edge_weight, batch_size, learnable=False):\n",
    "        super(DGCNN6, self).__init__()\n",
    "\n",
    "        self.lambdamax = LaplacianLambdaMax(None)\n",
    "\n",
    "        self.in_channels = num_features\n",
    "        self.cheb_out_channels = hid_channels\n",
    "\n",
    "        self.fc1_in_channels = 1240\n",
    "        self.fc1_out_channels = 128 # \n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.edge_weight = nn.Parameter(edge_weight, requires_grad=learnable)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_nodes = num_nodes\n",
    "        \n",
    "        self.chebconv1 = ChebConv(self.in_channels, self.cheb_out_channels, K=k, normalization = None)\n",
    "        # batch normalization\n",
    "        \n",
    "        self.BN1d1 = nn.BatchNorm1d(self.in_channels)\n",
    "        #self.BN1d1 = nn.BatchNorm1d(self.cheb_out_channels)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.leakyrelu = nn.LeakyReLU(0.15)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.fc1_in_channels, self.fc1_out_channels)\n",
    "        self.fc2 = nn.Linear(self.fc1_out_channels, self.out_channels)\n",
    "        self.fc_module = nn.Sequential(self.fc1, self.leakyrelu, self.fc2)\n",
    "\n",
    "        \n",
    "                                      \n",
    "    def forward(self, data, _type=None):\n",
    "        data.edge_attr = self.edge_weight.data.repeat(self.batch_size)\n",
    "        data = self.lambdamax(data)\n",
    "\n",
    "        if data.x.dim() == 1:\n",
    "            data.x = data.x.unsqueeze(dim=1)\n",
    "#         print(len(data.x), data.x.shape)\n",
    "        \n",
    "#         print(\"chebconv1: \",repr(self.chebconv1.lins[0].weight))\n",
    "#         print(\"chebconv2: \",repr(self.chebconv1.lins[1].weight))\n",
    "#         print(\"chebconv3: \",repr(self.chebconv1.lins[2].weight))\n",
    "#         print(\"fc1: \", repr(self.fc1.weight))\n",
    "#         print(\"fc2: \", repr(self.fc2.weight))\n",
    "\n",
    "#         print(\"data: {} , size:{}\".format(data.x, data.x.shape))\n",
    "#         print(\"Edge: {}\".format(data.edge_attr))\n",
    "#         print(\"SEdge: {}\".format(self.edge_weight))\n",
    "#         print(\"BN data: {}\".format(self.BN1d1(data.x)))\n",
    "        data.x = self.leakyrelu(self.BN1d1(data.x))\n",
    "#         print(\"BN data: {}\".format(data.x))\n",
    "        cheb_layer = self.chebconv1(data.x, data.edge_index, self.leakyrelu(data.edge_attr), lambda_max=data.lambda_max)\n",
    "        #print(\"CHEB: {}\".format(cheb_layer.shape))\n",
    "        #print(\"CHEB: {}\".format(cheb_layer))\n",
    "        #print(\"BN: {}\".format(cheb_layer.shape))\n",
    "        #print(\"BN: {}\".format(cheb_layer))\n",
    "        cheb_layer = self.leakyrelu(cheb_layer).reshape(self.batch_size, -1)\n",
    "        fc_layer = self.fc_module(cheb_layer)\n",
    "        \n",
    "        if _type == 'train':\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "#             print(fc_layer.shape, data.y.shape, fc_layer[0])\n",
    "            loss = loss_fct(fc_layer.view(-1, self.out_channels), data.y.view(-1))\n",
    "#             print(loss)\n",
    "            logits = self.softmax(fc_layer)\n",
    "            return loss, logits\n",
    "        else:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "#             print(fc_layer.shape, data.y.shape, fc_layer[0])\n",
    "            loss = loss_fct(fc_layer.view(-1, self.out_channels), data.y.view(-1))\n",
    "#             print(loss)\n",
    "            logits = self.softmax(fc_layer)\n",
    "            return loss, logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70cb69bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/neuroai/dh/test.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/media/neuroai/dh/test.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m f\u001B[38;5;241m.\u001B[39mclose()\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/media/neuroai/dh/test.txt'"
     ]
    }
   ],
   "source": [
    "f = open('/media/neuroai/dh/test.txt')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2f3453",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "data_dir_path = '/media/neuroai/Samsung USB/data/'\n",
    "feature_name = 'de_LDS'\n",
    "# data_dir_path = 'C:/Users/daehyeon/Desktop/GCN_implement/GCN_implement/dataset/SEED/SEED/ExtractedFeatures/data/'\n",
    "# feature_name = 'de_LDS'\n",
    "label_dir_path = '/media/neuroai/Samsung USB/label/'\n",
    "channels_dir_path = '/media/neuroai/Samsung USB/requirements'\n",
    "\n",
    "pdc_dir_path = '/media/neuroai/Samsung USB/pdcs_nodiag/'\n",
    "sub_name = ['djc', 'jl', 'jj', 'lqj', 'ly', 'mhw', 'phl', 'sxy', 'wk', 'ww', 'wsf', 'wyw', 'xyl', 'ys', 'zjy'];\n",
    "pdc_var_name = '_PDC_mean'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42151066",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/neuroai/Samsung USB/pdcs_nodiag/'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [14], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m EEG_band \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m      5\u001B[0m subject_data, subject_label \u001B[38;5;241m=\u001B[39m load_data(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSSLGCN/dataset/seed/SEED_EEG/ExtractedFeatures/data/\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSSLGCN/dataset/seed/SEED_EEG/ExtractedFeatures/label/\u001B[39m\u001B[38;5;124m'\u001B[39m, trials, feature_name, EEG_band)\n\u001B[0;32m----> 6\u001B[0m edge_index_list, edge_attr_list \u001B[38;5;241m=\u001B[39m \u001B[43mload_edge_information\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpdc_dir_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpdc_var_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msessions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubjects\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m train_loader, test_loader \u001B[38;5;241m=\u001B[39m get_graph_data(subject_data, subject_label,\n\u001B[1;32m      8\u001B[0m                                  edge_index_list, edge_attr_list,\n\u001B[1;32m      9\u001B[0m                                  train_trials , batch_size)\n",
      "Cell \u001B[0;32mIn [3], line 35\u001B[0m, in \u001B[0;36mload_edge_information\u001B[0;34m(pdc_dir_path, sub_name, pdc_var_name, n_channels, n_trials, n_sessions, n_subjects)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_edge_information\u001B[39m(pdc_dir_path, sub_name, pdc_var_name, n_channels, n_trials, n_sessions, n_subjects):\n\u001B[0;32m---> 35\u001B[0m     file_list \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpdc_dir_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m     edge_index_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_channels):\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/media/neuroai/Samsung USB/pdcs_nodiag/'"
     ]
    }
   ],
   "source": [
    "sessions, subjects, trials, num_nodes, num_classes, train_trials = 3, 15, 15, 62, 3, 9  # 논문과 데이터셋에서 명시된 값\n",
    "epochs, freq_bands, random_seed = 100, 5, 42  # training 할 때 변경이 가능한 hyper-parameter\n",
    "k, batch_size, learning_rate, lambda1 = 3, 32, 0.01, 0.001  # training 할 때 변경이 가능한 parameter\n",
    "EEG_band = None\n",
    "subject_data, subject_label = load_data('SSLGCN/dataset/seed/SEED_EEG/ExtractedFeatures/data/','SSLGCN/dataset/seed/SEED_EEG/ExtractedFeatures/label/', trials, feature_name, EEG_band)\n",
    "edge_index_list, edge_attr_list = load_edge_information(pdc_dir_path, sub_name, pdc_var_name, num_nodes, trials, sessions, subjects)\n",
    "train_loader, test_loader = get_graph_data(subject_data, subject_label,\n",
    "                                 edge_index_list, edge_attr_list,\n",
    "                                 train_trials , batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7622a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "edge_attr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a09888dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sub_train_loader_pdc = train_loader[4]\n",
    "sub_edge_attr_pdc = sub_train_loader_dsma.dataset[4].edge_attr\n",
    "sub_test_loader_pdc = test_loader[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b945211",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdc_dir_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m edge_index_list, edge_attr_list \u001B[38;5;241m=\u001B[39m load_edge_information(\u001B[43mpdc_dir_path\u001B[49m,sub_name, pdc_var_name,num_nodes, trials, sessions, subjects)\n\u001B[1;32m      2\u001B[0m train_loader, test_loader \u001B[38;5;241m=\u001B[39m get_graph_data(subject_data, subject_label,\n\u001B[1;32m      3\u001B[0m                                  edge_index_list, edge_attr_list,\n\u001B[1;32m      4\u001B[0m                                  train_trials , batch_size)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pdc_dir_path' is not defined"
     ]
    }
   ],
   "source": [
    "edge_index_list, edge_attr_list = load_edge_information(pdc_dir_path,sub_name, pdc_var_name,num_nodes, trials, sessions, subjects)\n",
    "train_loader, test_loader = get_graph_data(subject_data, subject_label,\n",
    "                                 edge_index_list, edge_attr_list,\n",
    "                                 train_trials , batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad32706c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efd30dda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 53.69%,Train Loss: 1.1889\n",
      "Epoch:1, Model6 Evaluation Result: Test Accuracy: 36.17%,\tTest Loss: 1.1193\n",
      "Train Accuracy: 64.53%,Train Loss: 0.9002\n",
      "Epoch:2, Model6 Evaluation Result: Test Accuracy: 39.87%,\tTest Loss: 1.1119\n",
      "Train Accuracy: 66.59%,Train Loss: 0.8272\n",
      "Epoch:3, Model6 Evaluation Result: Test Accuracy: 38.18%,\tTest Loss: 1.1747\n",
      "Train Accuracy: 67.77%,Train Loss: 0.7804\n",
      "Epoch:4, Model6 Evaluation Result: Test Accuracy: 40.75%,\tTest Loss: 1.2428\n",
      "Train Accuracy: 69.55%,Train Loss: 0.7393\n",
      "Epoch:5, Model6 Evaluation Result: Test Accuracy: 34.74%,\tTest Loss: 1.2678\n",
      "Train Accuracy: 70.79%,Train Loss: 0.7099\n",
      "Epoch:6, Model6 Evaluation Result: Test Accuracy: 35.22%,\tTest Loss: 1.3820\n",
      "Train Accuracy: 72.64%,Train Loss: 0.6825\n",
      "Epoch:7, Model6 Evaluation Result: Test Accuracy: 44.36%,\tTest Loss: 1.3399\n",
      "Train Accuracy: 73.39%,Train Loss: 0.6575\n",
      "Epoch:8, Model6 Evaluation Result: Test Accuracy: 34.57%,\tTest Loss: 1.3024\n",
      "Train Accuracy: 75.03%,Train Loss: 0.6317\n",
      "Epoch:9, Model6 Evaluation Result: Test Accuracy: 39.63%,\tTest Loss: 1.3587\n",
      "Train Accuracy: 76.21%,Train Loss: 0.6143\n",
      "Epoch:10, Model6 Evaluation Result: Test Accuracy: 37.40%,\tTest Loss: 1.4459\n",
      "Train Accuracy: 76.94%,Train Loss: 0.6008\n",
      "Epoch:11, Model6 Evaluation Result: Test Accuracy: 42.34%,\tTest Loss: 1.5255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m200\u001B[39m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m---> 10\u001B[0m     train_acc, train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43msub_train_loader_pdc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel6\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer6\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain Accuracy: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m,Train Loss: \u001B[39m\u001B[38;5;132;01m{:.4f}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     13\u001B[0m               \u001B[38;5;241m.\u001B[39mformat(train_acc, train_loss))\n\u001B[0;32m     14\u001B[0m     test_acc, test_loss \u001B[38;5;241m=\u001B[39m test(sub_test_loader_pdc, model6, lambda1, batch_size)\n",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(loader, model, optimizer, L1_regularization_scaler, epoch, batch_size)\u001B[0m\n\u001B[0;32m     19\u001B[0m count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.\u001B[39m\n\u001B[0;32m     20\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 21\u001B[0m loss,result \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(loss, data\u001B[38;5;241m.\u001B[39my, model, L1_regularization_scaler)\n\u001B[0;32m     23\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MScourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36mSSLGCN.forward\u001B[1;34m(self, data, _type)\u001B[0m\n\u001B[0;32m     38\u001B[0m         gcn1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgcn1(bn, data\u001B[38;5;241m.\u001B[39medge_index, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleakyrelu(data\u001B[38;5;241m.\u001B[39medge_attr))\n\u001B[0;32m     39\u001B[0m         gcn2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgcn2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleakyrelu(gcn1), data\u001B[38;5;241m.\u001B[39medge_index, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleakyrelu(data\u001B[38;5;241m.\u001B[39medge_attr))\n\u001B[1;32m---> 40\u001B[0m         gcn3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgcn3\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mleakyrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgcn2\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mleakyrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m         \u001B[38;5;124;03m\"\"\"need to be checked\"\"\"\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m#         gcn = torch.cat((gcn1, gcn2), 0)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MScourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MScourse\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:175\u001B[0m, in \u001B[0;36mGCNConv.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m    173\u001B[0m cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_edge_index\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 175\u001B[0m     edge_index, edge_weight \u001B[38;5;241m=\u001B[39m \u001B[43mgcn_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# yapf: disable\u001B[39;49;00m\n\u001B[0;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimproved\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_self_loops\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    178\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcached:\n\u001B[0;32m    179\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_edge_index \u001B[38;5;241m=\u001B[39m (edge_index, edge_weight)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MScourse\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:60\u001B[0m, in \u001B[0;36mgcn_norm\u001B[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001B[0m\n\u001B[0;32m     56\u001B[0m     edge_weight \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones((edge_index\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m), ), dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m     57\u001B[0m                              device\u001B[38;5;241m=\u001B[39medge_index\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m add_self_loops:\n\u001B[1;32m---> 60\u001B[0m     edge_index, tmp_edge_weight \u001B[38;5;241m=\u001B[39m \u001B[43madd_remaining_self_loops\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m        \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_nodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m tmp_edge_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m     edge_weight \u001B[38;5;241m=\u001B[39m tmp_edge_weight\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MScourse\\lib\\site-packages\\torch_geometric\\utils\\loop.py:226\u001B[0m, in \u001B[0;36madd_remaining_self_loops\u001B[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001B[0m\n\u001B[0;32m    223\u001B[0m     inv_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m~\u001B[39mmask\n\u001B[0;32m    224\u001B[0m     loop_attr[edge_index[\u001B[38;5;241m0\u001B[39m][inv_mask]] \u001B[38;5;241m=\u001B[39m edge_attr[inv_mask]\n\u001B[1;32m--> 226\u001B[0m     edge_attr \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloop_attr\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    228\u001B[0m edge_index \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([edge_index[:, mask], loop_index], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m edge_index, edge_attr\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "lambda1 = 0.0001\n",
    "wd = learning_rate / 10\n",
    "model6 = SSLGCN(num_nodes, freq_bands, 16, 32, 64, 128, num_classes, sub_edge_attr_pdc, batch_size, False).to(device)\n",
    "#odel6 = DGCNN6(num_nodes, freq_bands, 20, num_classes, k, sub_edge_attr_pdc, batch_size, True).to(device)\n",
    "optimizer6 = torch.optim.Adam(model6.parameters(), lr=learning_rate, weight_decay= wd)\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_acc, train_loss = train(sub_train_loader_pdc, model6, optimizer6, lambda1, epoch, batch_size)\n",
    "    \n",
    "    print(\"Train Accuracy: {:.2f}%,Train Loss: {:.4f}\"\n",
    "              .format(train_acc, train_loss))\n",
    "    test_acc, test_loss = test(sub_test_loader_pdc.to(device), model6, lambda1, batch_size)\n",
    "    print(\"Epoch:{}, Model6 Evaluation Result: Test Accuracy: {:.2f}%,\\tTest Loss: {:.4f}\"\n",
    "              .format(epoch, test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5cd2a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open(\"E:/pdc_result/22-08-31_PDCGCN_epoch200.txt\", 'w')\n",
    "f.write(\"DGCNN6 lr : {0.01 ~ 0.000001}, ld : {0.01, 0.0000001}\\n\\n\")\n",
    "\n",
    "epochs = 200\n",
    "cnt = 0\n",
    "learning_rate = 0.01\n",
    "# prev = 0\n",
    "sub_train_loader_pdc = train_loader[4]\n",
    "sub_edge_attr_pdc = sub_train_loader_pdc.dataset[4].edge_attr\n",
    "sub_test_loader_pdc = test_loader[4]\n",
    "\n",
    "for lr in range (5):\n",
    "    lambda1 = 0.001\n",
    "    for ld in range(5):\n",
    "#         learning_check = 0\n",
    "        cnt+=1\n",
    "        print(\"OK {}\".format(cnt))\n",
    "        w = \"lr: \"+str(learning_rate) + \"  ld: \"+str(lambda1) + \"\\n--------------------------------------------------------------------\\n\"\n",
    "        f.write(w)\n",
    "        model6 = SSLGCN(num_nodes, freq_bands, 16, 32, 64, 128, num_classes, sub_edge_attr_pdc, batch_size, False).to(device)\n",
    "        optimizer6 = torch.optim.Adam(model6.parameters(), lr=learning_rate)#, weight_decay=5e-3)\n",
    "        for epoch in range(1, epochs+1):\n",
    "            train_acc, train_loss = train(sub_train_loader_pdc, model6, optimizer6, lambda1, epoch, batch_size)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                a = \"Epoch: \"+str(epoch)+\", Train Acc: \" + str(round(train_acc,2)) + \",Train Loss: \" + str(round(train_loss,4)) + \"\\n\"\n",
    "                f.write(a)\n",
    "            test_acc, test_loss = test(sub_test_loader_pdc, model6, lambda1, batch_size)\n",
    "            b = \"Epoch: \"+str(epoch)+\", SSLGCN Evaluation Result -  Test Accuracy: \" + str(round(test_acc,2)) + \",\\tTest Loss: \" + str(round(test_loss,4)) + \"\\n\\n\"\n",
    "            f.write(b)\n",
    "            \n",
    "#             if str(test_acc)[:5] == str(prev)[:5]:\n",
    "#                 learning_check += 1\n",
    "#             else:\n",
    "#                 learning_check = 0\n",
    "#             if learning_check == 8:\n",
    "#                 break\n",
    "                \n",
    "#             prev = test_acc\n",
    "        lambda1 /= 10\n",
    "        f.write(\"------------------------------------------------------------------\\n\\n\")\n",
    "    f.write(\"------------------------------------------------------------------\\n\\n\\n\")\n",
    "    learning_rate /= 10\n",
    "    \n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fcc514",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open(\"E:/pdc_result/22-08-31_DGCNN_PDC_epoch200_wd.txt\", 'w')\n",
    "f.write(\"DGCNN6 lr : {0.01 ~ 0.000001}, ld : {0.01, 0.0000001}\\n\\n\")\n",
    "\n",
    "epochs = 200\n",
    "cnt = 0\n",
    "learning_rate = 0.01\n",
    "\n",
    "model6 = DGCNN6(num_nodes, freq_bands, 20, num_classes, k, sub_edge_attr_pdc, batch_size, True).to(device)\n",
    "optimizer6 = torch.optim.Adam(model6.parameters(), lr=learning_rate, weight_decay= wd)\n",
    "\n",
    "sub_train_loader_pdc = train_loader[4]\n",
    "sub_edge_attr_pdc = sub_train_loader_pdc.dataset[4].edge_attr\n",
    "sub_test_loader_pdc = test_loader[4]\n",
    "for lr in range (5):\n",
    "    lambda1 = 0.001\n",
    "    wd = learning_rate / 10\n",
    "    for ld in range(5):\n",
    "#         learning_check = 0\n",
    "        cnt+=1\n",
    "        print(\"OK {}\".format(cnt))\n",
    "        w = \"lr: \"+str(learning_rate) + \"  ld: \"+str(lambda1) + \"\\n--------------------------------------------------------------------\\n\"\n",
    "        f.write(w)\n",
    "        model6 = DGCNN6(num_nodes, freq_bands, 20, num_classes, k, sub_edge_attr_pdc, batch_size, True).to(device)\n",
    "        optimizer6 = torch.optim.Adam(model6.parameters(), lr=learning_rate, weight_decay=wd)\n",
    "        for epoch in range(1, epochs+1):\n",
    "            train_acc, train_loss = train(sub_train_loader_pdc, model6, optimizer6, lambda1, epoch, batch_size)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                a = \"Epoch: \"+str(epoch)+\", Train Acc: \" + str(round(train_acc,2)) + \",Train Loss: \" + str(round(train_loss,4)) + \"\\n\"\n",
    "                f.write(a)\n",
    "            test_acc, test_loss = test(sub_test_loader_pdc, model6, lambda1, batch_size)\n",
    "            b = \"Epoch: \"+str(epoch)+\", SSLGCN Evaluation Result -  Test Accuracy: \" + str(round(test_acc,2)) + \",\\tTest Loss: \" + str(round(test_loss,4)) + \"\\n\\n\"\n",
    "            f.write(b)\n",
    "            \n",
    "#             if str(test_acc)[:5] == str(prev)[:5]:\n",
    "#                 learning_check += 1\n",
    "#             else:\n",
    "#                 learning_check = 0\n",
    "#             if learning_check == 8:\n",
    "#                 break\n",
    "                \n",
    "#             prev = test_acc\n",
    "        lambda1 /= 10\n",
    "        f.write(\"------------------------------------------------------------------\\n\\n\")\n",
    "    f.write(\"------------------------------------------------------------------\\n\\n\\n\")\n",
    "    learning_rate /= 10\n",
    "    \n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea23798b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open('E:/pdc_result/test.txt', 'w')\n",
    "f.write(str(best_acc[0]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b216650",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open('E:/pdc_result/test.txt', 'w')\n",
    "f.write(\"!!! BEST ACCURACY !!!\\n   \")\n",
    "f.write(str(best_acc[1]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01d9980f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "734d5a1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"  # Set the GPU 2 to use\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97f16590",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_acc = np.zeros((15,),float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74cd7198",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , 84.44767442,  0.        , 97.02034884])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.close()\n",
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83a2340d",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK 1\n",
      "OK 2\n",
      "OK 3\n",
      "OK 4\n",
      "OK 5\n",
      "OK 6\n",
      "OK 7\n",
      "OK 8\n",
      "OK 9\n",
      "OK 10\n",
      "OK 11\n",
      "OK 12\n",
      "OK 13\n",
      "OK 14\n",
      "OK 15\n",
      "OK 16\n",
      "OK 17\n",
      "OK 18\n",
      "OK 19\n",
      "OK 20\n",
      "OK 21\n",
      "OK 22\n",
      "OK 23\n",
      "OK 24\n",
      "OK 25\n",
      "OK 1\n",
      "OK 2\n",
      "OK 3\n",
      "OK 4\n",
      "OK 5\n",
      "OK 6\n",
      "OK 7\n",
      "OK 8\n",
      "OK 9\n",
      "OK 10\n",
      "OK 11\n",
      "OK 12\n",
      "OK 13\n",
      "OK 14\n",
      "OK 15\n",
      "OK 16\n",
      "OK 17\n",
      "OK 18\n",
      "OK 19\n",
      "OK 20\n",
      "OK 21\n",
      "OK 22\n",
      "OK 23\n",
      "OK 24\n",
      "OK 25\n",
      "OK 1\n",
      "OK 2\n",
      "OK 3\n",
      "OK 4\n",
      "OK 5\n",
      "OK 6\n",
      "OK 7\n",
      "OK 8\n",
      "OK 9\n",
      "OK 10\n",
      "OK 11\n",
      "OK 12\n",
      "OK 13\n",
      "OK 14\n",
      "OK 15\n",
      "OK 16\n",
      "OK 17\n",
      "OK 18\n",
      "OK 19\n",
      "OK 20\n",
      "OK 21\n",
      "OK 22\n",
      "OK 23\n",
      "OK 24\n",
      "OK 25\n",
      "\n",
      "-------- Best Acc ---------------\n",
      "[  0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.          93.84689922  88.2751938  100.        ]\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "# prev = 0\n",
    "# best_acc = np.zeros((15), float)\n",
    "\n",
    "for sub in range (12,15):\n",
    "    cnt = 0\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    sub_train_loader_pdc = train_loader[sub]\n",
    "    sub_edge_attr_pdc = sub_train_loader_pdc.dataset[sub].edge_attr\n",
    "    sub_test_loader_pdc = test_loader[sub]\n",
    "    len_lr = 5;\n",
    "    len_ld = 5;\n",
    "    f = open(\"/media/neuroai/Samsung USB/continue_22-08-31_sub12_DGCNN_PDC_epoch200.txt\", 'w')\n",
    "    \n",
    "    for lr in range (len_lr):\n",
    "        lambda1 = 0.001\n",
    "        \n",
    "        for ld in range(len_ld):\n",
    "    #         learning_check = 0\n",
    "            cnt+=1\n",
    "            print(\"OK {}\".format(cnt))\n",
    "            w = \"lr: \"+str(learning_rate) + \"  ld: \"+str(lambda1) + \"\\n--------------------------------------------------------------------\\n\"\n",
    "            f.write(w)\n",
    "            model6 = DGCNN6(num_nodes, freq_bands, 20, num_classes, k, sub_edge_attr_pdc, batch_size, True).to(device)\n",
    "            optimizer6 = torch.optim.Adam(model6.parameters(), lr=learning_rate)#, weight_decay=5e-3)\n",
    "            for epoch in range(1, epochs+1):\n",
    "                \n",
    "                train_acc, train_loss = train(sub_train_loader_pdc, model6, optimizer6, lambda1, epoch, batch_size)\n",
    "\n",
    "#                 if epoch % 10 == 0:\n",
    "#                     a = \"Epoch: \"+str(epoch)+\", Train Acc: \" + str(round(train_acc,2)) + \",Train Loss: \" + str(round(train_loss,4)) + \"\\n\"\n",
    "#                     f.write(a)\n",
    "                test_acc, test_loss = test(sub_test_loader_pdc, model6, lambda1, batch_size)\n",
    "                if test_acc > best_acc[sub]:\n",
    "                    best_acc[sub] = test_acc\n",
    "                b = \"Epoch: \"+str(epoch)+\", Model6 Evaluation Result -  Test Accuracy: \" + str(round(test_acc,2)) + \",\\tTest Loss: \" + str(round(test_loss,4)) + \"\\n\\n\"\n",
    "                f.write(b)\n",
    "\n",
    "    #             if str(test_acc)[:5] == str(prev)[:5]:\n",
    "    #                 learning_check += 1\n",
    "    #             else:\n",
    "    #                 learning_check = 0\n",
    "    #             if learning_check == 8:\n",
    "    #                 break\n",
    "\n",
    "    #             prev = test_acc\n",
    "            lambda1 /= 10\n",
    "            f.write(\"------------------------------------------------------------------\\n\\n\")\n",
    "        f.write(\"------------------------------------------------------------------\\n\\n\\n\")\n",
    "        learning_rate /= 10\n",
    "    f.write(\"!!! BEST ACCURACY !!!\\n\")\n",
    "    f.write(str(best_acc[sub]))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "print(\"\\n-------- Best Acc ---------------\")\n",
    "print(best_acc)\n",
    "\n",
    "# f = open('E:/pdc_result/all_sub_dgcnn/22-08-31 sub_acc_mean_std', 'w')\n",
    "# mean_acc = best_acc.mean()\n",
    "# std_acc = best_acc.std()\n",
    "# f.write(\"mean_acc : \")\n",
    "# f.write(str(mean_acc))\n",
    "# f.write(\"std_acc: \")\n",
    "# f.write(str(std_acc))\n",
    "# f.close()\n",
    "\n",
    "# print(\"\\n-------------------------------\")\n",
    "# print(\"mean_acc : \", mean_acc)\n",
    "# print(\"std_acc: \", std_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2c417ce",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK 12\n",
      "OK 13\n",
      "OK 14\n",
      "OK 15\n",
      "OK 16\n",
      "OK 17\n",
      "OK 18\n",
      "OK 19\n",
      "OK 20\n",
      "OK 21\n",
      "OK 22\n",
      "OK 23\n",
      "\n",
      "-------- Best Acc ---------------\n",
      "[  0.           0.           0.          82.17054264   0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.          93.84689922  88.2751938  100.        ]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:/pdc_result/all_sub_dgcnn/22-08-31 sub_acc_mean_std'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [58], line 67\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-------- Best Acc ---------------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28mprint\u001B[39m(best_acc)\n\u001B[0;32m---> 67\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mE:/pdc_result/all_sub_dgcnn/22-08-31 sub_acc_mean_std\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mw\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m mean_acc \u001B[38;5;241m=\u001B[39m best_acc\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m     69\u001B[0m std_acc \u001B[38;5;241m=\u001B[39m best_acc\u001B[38;5;241m.\u001B[39mstd()\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'E:/pdc_result/all_sub_dgcnn/22-08-31 sub_acc_mean_std'"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "# prev = 0\n",
    "# best_acc = np.zeros((15), float)\n",
    "\n",
    "for sub in range (3,4):\n",
    "    cnt = 11\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    sub_train_loader_pdc = train_loader[sub]\n",
    "    sub_edge_attr_pdc = sub_train_loader_pdc.dataset[sub].edge_attr\n",
    "    sub_test_loader_pdc = test_loader[sub]\n",
    "    len_lr = 3;\n",
    "    len_ld = 5;\n",
    "    f = open('/media/neuroai/Samsung USB/continue_22-08-31_sub'+str(sub+1)+'_DGCNN_PDC_epoch200.txt', 'w')\n",
    "\n",
    "#     else:\n",
    "#         f = open('E:/pdc_result/all_sub_dgcnn/22-08-31 sub' + str(sub+1) + '_DGCNN_PDC_epoch200.txt', 'w')\n",
    "#         f.write(\"DGCNN lr : {0.01 ~ 0.000001}, ld : {0.01, 0.0000001}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    for lr in range (len_lr):\n",
    "        lambda1 = 0.001      \n",
    "        if lr == 0:\n",
    "            lambda1 = 0.0001\n",
    "            len_ld = 4\n",
    "        for ld in range(len_ld):\n",
    "    #         learning_check = 0\n",
    "            cnt+=1\n",
    "            print(\"OK {}\".format(cnt))\n",
    "            w = \"lr: \"+str(learning_rate) + \"  ld: \"+str(lambda1) + \"\\n--------------------------------------------------------------------\\n\"\n",
    "            f.write(w)\n",
    "            model6 = DGCNN6(num_nodes, freq_bands, 20, num_classes, k, sub_edge_attr_pdc, batch_size, True).to(device)\n",
    "            optimizer6 = torch.optim.Adam(model6.parameters(), lr=learning_rate)#, weight_decay=5e-3)\n",
    "            for epoch in range(1, epochs+1):\n",
    "                train_acc, train_loss = train(sub_train_loader_pdc, model6, optimizer6, lambda1, epoch, batch_size)\n",
    "\n",
    "                if epoch % 10 == 0:\n",
    "                    a = \"Epoch: \"+str(epoch)+\", Train Acc: \" + str(round(train_acc,2)) + \",Train Loss: \" + str(round(train_loss,4)) + \"\\n\"\n",
    "                    f.write(a)\n",
    "                test_acc, test_loss = test(sub_test_loader_pdc, model6, lambda1, batch_size)\n",
    "                if test_acc > best_acc[sub]:\n",
    "                    best_acc[sub] = test_acc\n",
    "                b = \"Epoch: \"+str(epoch)+\", Model6 Evaluation Result -  Test Accuracy: \" + str(round(test_acc,2)) + \",\\tTest Loss: \" + str(round(test_loss,4)) + \"\\n\\n\"\n",
    "                f.write(b)\n",
    "\n",
    "    #             if str(test_acc)[:5] == str(prev)[:5]:\n",
    "    #                 learning_check += 1\n",
    "    #             else:\n",
    "    #                 learning_check = 0\n",
    "    #             if learning_check == 8:\n",
    "    #                 break\n",
    "\n",
    "    #             prev = test_acc\n",
    "            lambda1 /= 10\n",
    "            f.write(\"------------------------------------------------------------------\\n\\n\")\n",
    "        f.write(\"------------------------------------------------------------------\\n\\n\\n\")\n",
    "        learning_rate /= 10\n",
    "    f.write(\"!!! BEST ACCURACY !!!\\n\")\n",
    "    f.write(str(best_acc[sub]))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "print(\"\\n-------- Best Acc ---------------\")\n",
    "print(best_acc)\n",
    "\n",
    "f = open('E:/pdc_result/all_sub_dgcnn/22-08-31 sub_acc_mean_std', 'w')\n",
    "mean_acc = best_acc.mean()\n",
    "std_acc = best_acc.std()\n",
    "f.write(\"mean_acc : \", str(mean_acc))\n",
    "f.write(\"std_acc: \", str(std_acc))\n",
    "f.close()\n",
    "\n",
    "print(\"\\n-------------------------------\")\n",
    "print(\"mean_acc : \", mean_acc)\n",
    "print(\"std_acc: \", std_acc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9c4aecd",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK 1\n",
      "\n",
      "-------- Best Acc ---------------\n",
      "[  0.           0.           0.          82.17054264  80.42635659\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.          93.84689922  88.2751938  100.        ]\n",
      "OK 1\n",
      "OK 2\n",
      "OK 3\n",
      "OK 4\n",
      "OK 5\n",
      "OK 6\n",
      "OK 7\n",
      "OK 8\n",
      "OK 9\n",
      "OK 10\n",
      "OK 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [59], line 90\u001B[0m\n\u001B[1;32m     88\u001B[0m optimizer6 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model6\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlearning_rate)\u001B[38;5;66;03m#, weight_decay=5e-3)\u001B[39;00m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m---> 90\u001B[0m     train_acc, train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43msub_train_loader_pdc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel6\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer6\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     93\u001B[0m         a \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mstr\u001B[39m(epoch)\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, Train Acc: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mround\u001B[39m(train_acc,\u001B[38;5;241m2\u001B[39m)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,Train Loss: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mround\u001B[39m(train_loss,\u001B[38;5;241m4\u001B[39m)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "Cell \u001B[0;32mIn [4], line 21\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(loader, model, optimizer, L1_regularization_scaler, epoch, batch_size)\u001B[0m\n\u001B[1;32m     19\u001B[0m count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.\u001B[39m\n\u001B[1;32m     20\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 21\u001B[0m loss,result \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(loss, data\u001B[38;5;241m.\u001B[39my, model, L1_regularization_scaler)\n\u001B[1;32m     23\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn [6], line 95\u001B[0m, in \u001B[0;36mDGCNN6.forward\u001B[0;34m(self, data, _type)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, data, _type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     94\u001B[0m     data\u001B[38;5;241m.\u001B[39medge_attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39medge_weight\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mrepeat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size)\n\u001B[0;32m---> 95\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlambdamax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data\u001B[38;5;241m.\u001B[39mx\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     98\u001B[0m         data\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mx\u001B[38;5;241m.\u001B[39munsqueeze(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/torch_geometric/transforms/laplacian_lambda_max.py:51\u001B[0m, in \u001B[0;36mLaplacianLambdaMax.__call__\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_undirected \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalization \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrw\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     49\u001B[0m     eig_fn \u001B[38;5;241m=\u001B[39m eigsh\n\u001B[0;32m---> 51\u001B[0m lambda_max \u001B[38;5;241m=\u001B[39m \u001B[43meig_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhich\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mLM\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_eigenvectors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m data\u001B[38;5;241m.\u001B[39mlambda_max \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(lambda_max\u001B[38;5;241m.\u001B[39mreal)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1345\u001B[0m, in \u001B[0;36meigs\u001B[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, OPpart)\u001B[0m\n\u001B[1;32m   1343\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _ARPACK_LOCK:\n\u001B[1;32m   1344\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m params\u001B[38;5;241m.\u001B[39mconverged:\n\u001B[0;32m-> 1345\u001B[0m         \u001B[43mparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m params\u001B[38;5;241m.\u001B[39mextract(return_eigenvectors)\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:741\u001B[0m, in \u001B[0;36m_UnsymmetricArpackParams.iterate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    738\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mido \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    739\u001B[0m     \u001B[38;5;66;03m# compute y = Op*x\u001B[39;00m\n\u001B[1;32m    740\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m):\n\u001B[0;32m--> 741\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworkd[yslice] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOP\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mworkd\u001B[49m\u001B[43m[\u001B[49m\u001B[43mxslice\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    742\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    743\u001B[0m         Bxslice \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mslice\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mipntr[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mipntr[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn)\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/scipy/sparse/linalg/_interface.py:232\u001B[0m, in \u001B[0;36mLinearOperator.matvec\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m (N,) \u001B[38;5;129;01mand\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m (N,\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdimension mismatch\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 232\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_matvec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, np\u001B[38;5;241m.\u001B[39mmatrix):\n\u001B[1;32m    235\u001B[0m     y \u001B[38;5;241m=\u001B[39m asmatrix(y)\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/scipy/sparse/linalg/_interface.py:199\u001B[0m, in \u001B[0;36mLinearOperator._matvec\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_matvec\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;124;03m\"\"\"Default matrix-vector multiplication handler.\u001B[39;00m\n\u001B[1;32m    191\u001B[0m \n\u001B[1;32m    192\u001B[0m \u001B[38;5;124;03m    If self is a linear operator of shape (M, N), then this method will\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;124;03m    will define matrix-vector multiplication as well.\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/scipy/sparse/linalg/_interface.py:337\u001B[0m, in \u001B[0;36mLinearOperator.matmat\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m    334\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdimension mismatch: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    335\u001B[0m                      \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape, X\u001B[38;5;241m.\u001B[39mshape))\n\u001B[0;32m--> 337\u001B[0m Y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_matmat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(Y, np\u001B[38;5;241m.\u001B[39mmatrix):\n\u001B[1;32m    340\u001B[0m     Y \u001B[38;5;241m=\u001B[39m asmatrix(Y)\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/scipy/sparse/linalg/_interface.py:731\u001B[0m, in \u001B[0;36mMatrixLinearOperator._matmat\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    730\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_matmat\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m--> 731\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mA\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/scipy/sparse/_base.py:416\u001B[0m, in \u001B[0;36mspmatrix.dot\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    414\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m*\u001B[39m other\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/scipy/sparse/_base.py:630\u001B[0m, in \u001B[0;36mspmatrix.__matmul__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m isscalarlike(other):\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mScalar operands are not allowed, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    629\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m instead\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 630\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mul_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/scipy/sparse/_base.py:530\u001B[0m, in \u001B[0;36mspmatrix._mul_dispatch\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    528\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mul_vector(other)\n\u001B[1;32m    529\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m other\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m (N, \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m--> 530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mul_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(M, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m other\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m other\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m N:\n\u001B[1;32m    532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mul_multivector(other)\n",
      "File \u001B[0;32m~/anaconda3/envs/py39_dh/lib/python3.9/site-packages/scipy/sparse/_coo.py:578\u001B[0m, in \u001B[0;36mcoo_matrix._mul_vector\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    574\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_mul_vector\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;66;03m#output array\u001B[39;00m\n\u001B[1;32m    576\u001B[0m     result \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mupcast_char(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mchar,\n\u001B[1;32m    577\u001B[0m                                                         other\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mchar))\n\u001B[0;32m--> 578\u001B[0m     \u001B[43mcoo_matvec\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnnz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    579\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "# prev = 0\n",
    "# best_acc = np.zeros((15), float)\n",
    "for sub in range (4,5):\n",
    "    cnt = 0\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    sub_train_loader_pdc = train_loader[sub]\n",
    "    sub_edge_attr_pdc = sub_train_loader_pdc.dataset[sub].edge_attr\n",
    "    sub_test_loader_pdc = test_loader[sub]\n",
    "    len_lr = 1;\n",
    "    len_ld = 1;\n",
    "    f = open('/media/neuroai/Samsung USB/continue_22-08-31_sub'+str(sub+1)+'_DGCNN_PDC_epoch200.txt', 'w')\n",
    "\n",
    "#     else:\n",
    "#         f = open('E:/pdc_result/all_sub_dgcnn/22-08-31 sub' + str(sub+1) + '_DGCNN_PDC_epoch200.txt', 'w')\n",
    "#         f.write(\"DGCNN lr : {0.01 ~ 0.000001}, ld : {0.01, 0.0000001}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    for lr in range (len_lr):\n",
    "        lambda1 = 0.0000001      \n",
    "        for ld in range(len_ld):\n",
    "    #         learning_check = 0\n",
    "            cnt+=1\n",
    "            print(\"OK {}\".format(cnt))\n",
    "            w = \"lr: \"+str(learning_rate) + \"  ld: \"+str(lambda1) + \"\\n--------------------------------------------------------------------\\n\"\n",
    "            f.write(w)\n",
    "            model6 = DGCNN6(num_nodes, freq_bands, 20, num_classes, k, sub_edge_attr_pdc, batch_size, True).to(device)\n",
    "            optimizer6 = torch.optim.Adam(model6.parameters(), lr=learning_rate)#, weight_decay=5e-3)\n",
    "            for epoch in range(1, epochs+1):\n",
    "                train_acc, train_loss = train(sub_train_loader_pdc, model6, optimizer6, lambda1, epoch, batch_size)\n",
    "\n",
    "                if epoch % 10 == 0:\n",
    "                    a = \"Epoch: \"+str(epoch)+\", Train Acc: \" + str(round(train_acc,2)) + \",Train Loss: \" + str(round(train_loss,4)) + \"\\n\"\n",
    "                    f.write(a)\n",
    "                test_acc, test_loss = test(sub_test_loader_pdc, model6, lambda1, batch_size)\n",
    "                if test_acc > best_acc[sub]:\n",
    "                    best_acc[sub] = test_acc\n",
    "                b = \"Epoch: \"+str(epoch)+\", Model6 Evaluation Result -  Test Accuracy: \" + str(round(test_acc,2)) + \",\\tTest Loss: \" + str(round(test_loss,4)) + \"\\n\\n\"\n",
    "                f.write(b)\n",
    "\n",
    "    #             if str(test_acc)[:5] == str(prev)[:5]:\n",
    "    #                 learning_check += 1\n",
    "    #             else:\n",
    "    #                 learning_check = 0\n",
    "    #             if learning_check == 8:\n",
    "    #                 break\n",
    "\n",
    "    #             prev = test_acc\n",
    "            lambda1 /= 10\n",
    "            f.write(\"------------------------------------------------------------------\\n\\n\")\n",
    "        f.write(\"------------------------------------------------------------------\\n\\n\\n\")\n",
    "        learning_rate /= 10\n",
    "    f.write(\"!!! BEST ACCURACY !!!\\n\")\n",
    "    f.write(str(best_acc[sub]))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "print(\"\\n-------- Best Acc ---------------\")\n",
    "print(best_acc)\n",
    "\n",
    "for sub in range (4,5):\n",
    "    cnt = 0\n",
    "    learning_rate = 0.00001\n",
    "\n",
    "    sub_train_loader_pdc = train_loader[sub]\n",
    "    sub_edge_attr_pdc = sub_train_loader_pdc.dataset[sub].edge_attr\n",
    "    sub_test_loader_pdc = test_loader[sub]\n",
    "    len_lr = 3;\n",
    "    len_ld = 5;\n",
    "    f = open('/media/neuroai/Samsung USB/continue_22-08-31_sub'+str(sub+1)+'_DGCNN_PDC_epoch200.txt', 'w')\n",
    "\n",
    "#     else:\n",
    "#         f = open('E:/pdc_result/all_sub_dgcnn/22-08-31 sub' + str(sub+1) + '_DGCNN_PDC_epoch200.txt', 'w')\n",
    "#         f.write(\"DGCNN lr : {0.01 ~ 0.000001}, ld : {0.01, 0.0000001}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    for lr in range (len_lr):\n",
    "        lambda1 = 0.001      \n",
    "        for ld in range(len_ld):\n",
    "    #         learning_check = 0\n",
    "            cnt+=1\n",
    "            print(\"OK {}\".format(cnt))\n",
    "            w = \"lr: \"+str(learning_rate) + \"  ld: \"+str(lambda1) + \"\\n--------------------------------------------------------------------\\n\"\n",
    "            f.write(w)\n",
    "            model6 = DGCNN6(num_nodes, freq_bands, 20, num_classes, k, sub_edge_attr_pdc, batch_size, True).to(device)\n",
    "            optimizer6 = torch.optim.Adam(model6.parameters(), lr=learning_rate)#, weight_decay=5e-3)\n",
    "            for epoch in range(1, epochs+1):\n",
    "                train_acc, train_loss = train(sub_train_loader_pdc, model6, optimizer6, lambda1, epoch, batch_size)\n",
    "\n",
    "                if epoch % 10 == 0:\n",
    "                    a = \"Epoch: \"+str(epoch)+\", Train Acc: \" + str(round(train_acc,2)) + \",Train Loss: \" + str(round(train_loss,4)) + \"\\n\"\n",
    "                    f.write(a)\n",
    "                test_acc, test_loss = test(sub_test_loader_pdc, model6, lambda1, batch_size)\n",
    "                if test_acc > best_acc[sub]:\n",
    "                    best_acc[sub] = test_acc\n",
    "                b = \"Epoch: \"+str(epoch)+\", Model6 Evaluation Result -  Test Accuracy: \" + str(round(test_acc,2)) + \",\\tTest Loss: \" + str(round(test_loss,4)) + \"\\n\\n\"\n",
    "                f.write(b)\n",
    "\n",
    "    #             if str(test_acc)[:5] == str(prev)[:5]:\n",
    "    #                 learning_check += 1\n",
    "    #             else:\n",
    "    #                 learning_check = 0\n",
    "    #             if learning_check == 8:\n",
    "    #                 break\n",
    "\n",
    "    #             prev = test_acc\n",
    "            lambda1 /= 10\n",
    "            f.write(\"------------------------------------------------------------------\\n\\n\")\n",
    "        f.write(\"------------------------------------------------------------------\\n\\n\\n\")\n",
    "        learning_rate /= 10\n",
    "    f.write(\"!!! BEST ACCURACY !!!\\n\")\n",
    "    f.write(str(best_acc[sub]))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "print(\"\\n-------- Best Acc ---------------\")\n",
    "print(best_acc)\n",
    "\n",
    "f = open('E:/pdc_result/all_sub_dgcnn/22-08-31 sub_acc_mean_std', 'w')\n",
    "mean_acc = best_acc.mean()\n",
    "std_acc = best_acc.std()\n",
    "f.write(\"mean_acc : \", str(mean_acc))\n",
    "f.write(\"std_acc: \", str(std_acc))\n",
    "f.close()\n",
    "\n",
    "print(\"\\n-------------------------------\")\n",
    "print(\"mean_acc : \", mean_acc)\n",
    "print(\"std_acc: \", std_acc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e97c413",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        ,   0.        ,  82.17054264,\n",
       "        83.96317829,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "        93.84689922,  88.2751938 , 100.        ])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ed0c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bbee780",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"DE and DDE, or DE and PSD, or DE, PSD, and DDE\"\"\"\n",
    "\"\"\"SSM construction, fusion, and enhancement\"\"\"\n",
    "\"\"\"-Parallel- concatenation of two EEG features\"\"\"\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler as stds\n",
    "from sklearn.neighbors import NearestNeighbors as knn\n",
    "import math\n",
    "\n",
    "def Sum_Neighbor_Value(matrix, n_nbrs=2, return_indices = False):#, agrtm='auto'):\n",
    "#     dt = type(matrix)\n",
    "#     if dt == 'pandas.core.frame.DataFrame':\n",
    "#         matrix = np.array(matrix).tolist()\n",
    "#     elif dt == 'torch.Tensor' or 'numpy.ndarray':\n",
    "#         matrix = matrix.tolist()\n",
    "#     else:\n",
    "#         print(\"***** ERROR ***** \\n   \"\" Unsupported data type ** \\n support\\n 1. list\\n2. numpy.ndarray\\n3. pandas.core.fram.DataFrame\\n4. torch.Tensor\\n recommended data type: 'list' \")\n",
    "    \n",
    "    \"\"\"수정해야댐 i = 1일 때 1번째 행에서 62개의 열, 즉 길이가 62인 벡터에서 네이버 찾고\n",
    "        i = 2일 때 2번째 행에서 62개의 열에서 찾고 ....\n",
    "        총 62 x 2의 인덱스 매트릭스가 만들어져야 함\n",
    "        나중에 i = 1일 때 네이버와 4일 때 네이버를 찾고 싶다면\n",
    "        그 인덱스 값은 indices[1][:], indices[4][:]가 됨\n",
    "        그리고 해당 값들은 matrix[1][indices[1][x]], matrix[4][indices[4][y]]가 됨\"\"\"\n",
    "    \n",
    "    n_channels = matrix.shape[0]\n",
    "    sum_neighbor_value = np.zeros((n_channels), float)\n",
    "    \n",
    "    if return_indices == False:        \n",
    "        for i in range(n_channels):\n",
    "            similarities_to_ith_node = matrix[i]\n",
    "            sorted_values = sorted(similarities_to_ith_node, reverse=False)\n",
    "            sum_neighbor_value[i] = sum(sorted_values[:n_nbrs])\n",
    "            for j in range(n_nbrs):\n",
    "                neighbor_indices[j] = sorted_values[j]\n",
    "        return sum_neighbor_value\n",
    "    \n",
    "    else:\n",
    "        neighbor_indices = np.zeros((n_channels, n_nbrs), float)\n",
    "        \n",
    "        for i in range(n_channels):\n",
    "            similarities_to_ith_node = matrix[i]\n",
    "            for j in range(n_nbrs):\n",
    "                min_index = similarities_to_ith_node.argmin()\n",
    "                neighbor_indices[i][j] = min_index\n",
    "                sum_neighbor_value[i] += similarities_to_ith_node[min_index]\n",
    "                similarities_to_ith_node[min_index] = float('inf')\n",
    "\n",
    "        return sum_neighbor_value, neighbor_indices\n",
    "    \n",
    "\n",
    "#     values = matrix.reshape(matrix.size)\n",
    "#     nbrs = knn(n_neighbors = n_nbrs, algorithm = agrtm).fit(values)\n",
    "#     indices = nbrs.kneighbors(values,return_distance=false)\n",
    "    \n",
    "#     return values, indices\n",
    "\n",
    "    \n",
    "\n",
    "def SSM_Construction(data, n_channels):\n",
    "    ssm = np.zeros((n_channels,n_channels), dtype = float)\n",
    "    data_len = len(data[0])\n",
    "    data = np.array(data)\n",
    "    \n",
    "    for i in range(n_channels):\n",
    "        for j in range(n_channels):\n",
    "            if i == j: continue\n",
    "            euclidean_distance = 0\n",
    "            euclidean_distance = sum((data[j]-data[i])**2)**0.5\n",
    "            sum_euclidean_distances += euclidean_distance\n",
    "            ssm[i][j] = euclidean_distance\n",
    "    mean_euclidean_distances = sum_euclidean_distances(n_channels*(n_channels-1))\n",
    "    ssm /= -(0.05*mean_euclidean_distances)\n",
    "    ssm = np.exp(ssm)\n",
    "\n",
    "    pssm = np.zeros((n_channels, n_channels), dtype = float) #ssm probablity matrix\n",
    "    for k in range(n_channels):\n",
    "        sum_row = sum(ssm[k][:])\n",
    "        pssm[k][:] = ssm[k][:] / sum_row\n",
    "    \n",
    "    \"\"\"need to get a feedback from professor\"\"\"\n",
    "    n_nbrs = 2\n",
    "    values = Sum_Neighbor_Value(ssm, n_nbrs, return_indices = False) # n_channels X n_nbrs matrix\n",
    "    skm = np.zeros((n_channels, n_channels), dtype = float) #sparse kernel matrix\n",
    "    for k in range(n_channels):\n",
    "        for l in range(n_channels):\n",
    "            skm[k][l] = ssm[k][l] / values[k]\n",
    "    \n",
    "    return pssm, skm\n",
    "\n",
    "def SSM_Fusion(p1,p2,sk1,sk2,iterator): # p: pssm, sk: skm    \n",
    "    for i in range(iterator):\n",
    "        p1 = sk1*p1*sk1.T\n",
    "        p2 = sk2*p2*sk2.T\n",
    "    return (p1+p2)/2\n",
    "\n",
    "def SSM_Enhancement(fwm, n_channels, weight, iterator): # fwm : fused weight matrix\n",
    "    \"\"\"need to get a feedback from professor\"\"\"\n",
    "    n_nbrs = 3\n",
    "    values = Sum_Neighbor_Value(fwm, n_nbrs, return_indices)\n",
    "    k2ssm = np.zeros((n_channels, n_channels), dtype = float) #ssm normalized with k2-based knn\n",
    "    for i in range(n_channels):\n",
    "        for j in range(n_channels):\n",
    "            k2ssm[i][j] = ssm[i][j] / values[i]\n",
    "            \n",
    "    lnm = np.zeors((n_channels,n_channels), dtype = float) # localized network matrix\n",
    "    for k in range(n_channels):\n",
    "        for l in range(n_channels):\n",
    "            for m in range(n_channels):\n",
    "                lnm[k][l] += k2ssm[k][m]*k2ssm[l][m]/sum(k2ssm[:][m])\n",
    "    \n",
    "    values, indices = Sum_Neighbor_Value(ssm, n_nbrs = 3, return_indices = True)\n",
    "    for t in range(iterator):\n",
    "        essm = np.zeros((n_channels, n_channels), dtype = float)\n",
    "        for i in range(n_channels):\n",
    "            for j in range(n_channels):\n",
    "                for q in indices[i]:\n",
    "                    q1 = lnm[i][q]\n",
    "                    for p in indices[j]:\n",
    "                        q2 = lnm[p][j]\n",
    "                        essm[i][j] += q1*ssm[q][p]*q2\n",
    "            essm[i][j] = weight*essm[i][j] + (1-weight)*lnm[i][j]\n",
    "        ssm = essm\n",
    "    \n",
    "    return essm\n",
    "\n",
    "def Input_Generator(fm1, fm2, num_components): # fm means feature matrix\n",
    "    \"\"\"fm1 and fm2 need to be flatten\"\"\"\n",
    "    # fv means feature vector\n",
    "    \n",
    "    # The large scale variable affects the principal components more\n",
    "    # if the difference of scale among variables is larger\n",
    "    # , so they need to be normalized as standard normal distribution, etc.\n",
    "    fm1 = stds().fit_transform(fm1) # stds means standardscaler\n",
    "    fm2 = stds().fit_transform(fm2)\n",
    "    \n",
    "    pca = PCA(n_components = num_components)\n",
    "    f1_pca = pca.fit_transform(fv1) # pca result of feature1\n",
    "    f2_pca = pca.fit_transform(fv2)\n",
    "    \n",
    "    result_fm = torch.cat((f1_pca, f2_pca), 0)\n",
    "    result_ssm = SSM(f1_pca, f2_pca) # ssm means Sample-by-Sample Similarity Matrix\n",
    "    \n",
    "    return result_fm, result_ssm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28b91a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Implements Partial Directed Coherence and Direct Transfer Function\n",
    "using MVAR processes.\n",
    "Reference\n",
    "---------\n",
    "Luiz A. Baccala and Koichi Sameshima. Partial directed coherence:\n",
    "a new concept in neural structure determination.\n",
    "Biological Cybernetics, 84(6):463:474, 2001.\n",
    "\"\"\"\n",
    "\n",
    "# Authors: Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import linalg, fftpack\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def mvar_generate(A, n, sigma, burnin=500):\n",
    "    \"\"\"Simulate MVAR process\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray, shape (p, N, N)\n",
    "        The AR coefficients where N is the number of signals\n",
    "        and p the order of the model.\n",
    "    n : int\n",
    "        The number of time samples.\n",
    "    sigma : array, shape (N,)\n",
    "        The noise for each time series\n",
    "    burnin : int\n",
    "        The length of the burnin period (in samples).\n",
    "    Returns\n",
    "    -------\n",
    "    X : ndarray, shape (N, n)\n",
    "        The N time series of length n\n",
    "    \"\"\"\n",
    "    p, N, N = A.shape\n",
    "    A_2d = np.concatenate(A, axis=1)\n",
    "    Y = np.zeros((n + burnin, N))\n",
    "\n",
    "    sigma = np.diag(sigma)\n",
    "    mu = np.zeros(N)\n",
    "\n",
    "    # itération du processus\n",
    "    for i in range(p, n):\n",
    "        w = np.random.multivariate_normal(mu, sigma)\n",
    "        Y[i] = np.dot(A_2d, Y[i - p:i][::-1, :].ravel()) + w\n",
    "\n",
    "    return Y[burnin:].T\n",
    "\n",
    "\n",
    "def cov(X, p):\n",
    "    \"\"\"vector autocovariance up to order p\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (N, n)\n",
    "        The N time series of length n\n",
    "    Returns\n",
    "    -------\n",
    "    R : ndarray, shape (p + 1, N, N)\n",
    "        The autocovariance up to order p\n",
    "    \"\"\"\n",
    "    N, n = X.shape\n",
    "    R = np.zeros((p + 1, N, N))\n",
    "    for k in range(p + 1):\n",
    "        R[k] = (1. / float(n - k)) * np.dot(X[:, :n - k], X[:, k:].T)\n",
    "    return R\n",
    "\n",
    "\n",
    "def mvar_fit(X, p):\n",
    "    \"\"\"Fit MVAR model of order p using Yule Walker\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (N, n)\n",
    "        The N time series of length n\n",
    "    n_fft : int\n",
    "        The length of the FFT\n",
    "    Returns\n",
    "    -------\n",
    "    A : ndarray, shape (p, N, N)\n",
    "        The AR coefficients where N is the number of signals\n",
    "        and p the order of the model.\n",
    "    sigma : array, shape (N,)\n",
    "        The noise for each time series\n",
    "    \"\"\"\n",
    "    N, n = X.shape\n",
    "    gamma = cov(X, p)  # gamma(r,i,j) cov between X_i(0) et X_j(r)\n",
    "    G = np.zeros((p * N, p * N))\n",
    "    gamma2 = np.concatenate(gamma, axis=0)\n",
    "    gamma2[:N, :N] /= 2.\n",
    "\n",
    "    for i in range(p):\n",
    "        G[N * i:, N * i:N * (i + 1)] = gamma2[:N * (p - i)]\n",
    "\n",
    "    G = G + G.T  # big block matrix\n",
    "\n",
    "    gamma4 = np.concatenate(gamma[1:], axis=0)\n",
    "\n",
    "    phi = linalg.solve(G, gamma4)  # solve Yule Walker\n",
    "\n",
    "    tmp = np.dot(gamma4[:N * p].T, phi)\n",
    "    sigma = gamma[0] - tmp - tmp.T + np.dot(phi.T, np.dot(G, phi))\n",
    "\n",
    "    phi = np.reshape(phi, (p, N, N))\n",
    "    for k in range(p):\n",
    "        phi[k] = phi[k].T\n",
    "\n",
    "    return phi, sigma\n",
    "\n",
    "\n",
    "def compute_order(X, p_max):\n",
    "    \"\"\"Estimate AR order with BIC\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (N, n)\n",
    "        The N time series of length n\n",
    "    p_max : int\n",
    "        The maximum model order to test\n",
    "    Returns\n",
    "    -------\n",
    "    p : int\n",
    "        Estimated order\n",
    "    bic : ndarray, shape (p_max + 1,)\n",
    "        The BIC for the orders from 0 to p_max.\n",
    "    \"\"\"\n",
    "    N, n = X.shape\n",
    "\n",
    "    bic = np.empty(p_max + 1)\n",
    "    bic[0] = np.inf # XXX\n",
    "\n",
    "    Y = X.T\n",
    "\n",
    "    for p in range(1, p_max + 1):\n",
    "        A, sigma = mvar_fit(X, p)\n",
    "        A_2d = np.concatenate(A, axis=1)\n",
    "\n",
    "        n_samples = n - p\n",
    "        bic[p] = n_samples * N * math.log(2. * math.pi)\n",
    "        bic[p] += n_samples * np.log(linalg.det(sigma))\n",
    "        bic[p] += p * (N ** 2) * math.log(n_samples)\n",
    "\n",
    "        sigma_inv = linalg.inv(sigma)\n",
    "        S = 0.\n",
    "        for i in range(p, n):\n",
    "            res = Y[i] - np.dot(A_2d, Y[i - p:i][::-1, :].ravel())\n",
    "            S += np.dot(res, sigma_inv.dot(res))\n",
    "\n",
    "        bic[p] += S\n",
    "\n",
    "    p = np.argmin(bic)\n",
    "    return p, bic\n",
    "\n",
    "\n",
    "def spectral_density(A, n_fft=None):\n",
    "    \"\"\"Estimate PSD from AR coefficients\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray, shape (p, N, N)\n",
    "        The AR coefficients where N is the number of signals\n",
    "        and p the order of the model.\n",
    "    n_fft : int\n",
    "        The length of the FFT\n",
    "    Returns\n",
    "    -------\n",
    "    fA : ndarray, shape (n_fft, N, N)\n",
    "        The estimated spectral density.\n",
    "    \"\"\"\n",
    "    p, N, N = A.shape\n",
    "    if n_fft is None:\n",
    "        n_fft = max(int(2 ** math.ceil(np.log2(p))), 512)\n",
    "    A2 = np.zeros((n_fft, N, N))\n",
    "    A2[1:p + 1, :, :] = A  # start at 1 !\n",
    "    fA = fftpack.fft(A2, axis=0)\n",
    "    freqs = fftpack.fftfreq(n_fft)\n",
    "    I = np.eye(N)\n",
    "\n",
    "    for i in range(n_fft):\n",
    "        fA[i] = linalg.inv(I - fA[i])\n",
    "\n",
    "    return fA, freqs\n",
    "\n",
    "\n",
    "def DTF(A, sigma=None, n_fft=None):\n",
    "    \"\"\"Direct Transfer Function (DTF)\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray, shape (p, N, N)\n",
    "        The AR coefficients where N is the number of signals\n",
    "        and p the order of the model.\n",
    "    sigma : array, shape (N, )\n",
    "        The noise for each time series\n",
    "    n_fft : int\n",
    "        The length of the FFT\n",
    "    Returns\n",
    "    -------\n",
    "    D : ndarray, shape (n_fft, N, N)\n",
    "        The estimated DTF\n",
    "    \"\"\"\n",
    "    p, N, N = A.shape\n",
    "\n",
    "    if n_fft is None:\n",
    "        n_fft = max(int(2 ** math.ceil(np.log2(p))), 512)\n",
    "\n",
    "    H, freqs = spectral_density(A, n_fft)\n",
    "    D = np.zeros((n_fft, N, N))\n",
    "\n",
    "    if sigma is None:\n",
    "        sigma = np.ones(N)\n",
    "\n",
    "    for i in range(n_fft):\n",
    "        S = H[i]\n",
    "        V = (S * sigma[None, :]).dot(S.T.conj())\n",
    "        V = np.abs(np.diag(V))\n",
    "        D[i] = np.abs(S * np.sqrt(sigma[None, :])) / np.sqrt(V)[:, None]\n",
    "\n",
    "    return D, freqs\n",
    "\n",
    "\n",
    "def PDC(A, sigma=None, n_fft=None):\n",
    "    \"\"\"Partial directed coherence (PDC)\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray, shape (p, N, N)\n",
    "        The AR coefficients where N is the number of signals\n",
    "        and p the order of the model.\n",
    "    sigma : array, shape (N,)\n",
    "        The noise for each time series.\n",
    "    n_fft : int\n",
    "        The length of the FFT.\n",
    "    Returns\n",
    "    -------\n",
    "    P : ndarray, shape (n_fft, N, N)\n",
    "        The estimated PDC.\n",
    "    \"\"\"\n",
    "    p, N, N = A.shape\n",
    "\n",
    "    if n_fft is None:\n",
    "        n_fft = max(int(2 ** math.ceil(np.log2(p))), 512)\n",
    "\n",
    "    H, freqs = spectral_density(A, n_fft)\n",
    "    P = np.zeros((n_fft, N, N))\n",
    "\n",
    "    if sigma is None:\n",
    "        sigma = np.ones(N)\n",
    "\n",
    "    for i in range(n_fft):\n",
    "        B = H[i]\n",
    "        B = linalg.inv(B)\n",
    "        V = np.abs(np.dot(B.T.conj(), B * (1. / sigma[:, None])))\n",
    "        V = np.diag(V)  # denominator squared\n",
    "        P[i] = np.abs(B * (1. / np.sqrt(sigma))[None, :]) / np.sqrt(V)[None, :]\n",
    "\n",
    "    return P, freqs\n",
    "\n",
    "\n",
    "def plot_all(freqs, P, name):\n",
    "    \"\"\"Plot grid of subplots\n",
    "    \"\"\"\n",
    "    m, N, N = P.shape\n",
    "    pos_freqs = freqs[freqs >= 0]\n",
    "\n",
    "    f, axes = plt.subplots(N, N)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            axes[i, j].fill_between(pos_freqs, P[freqs >= 0, i, j], 0)\n",
    "            axes[i, j].set_xlim([0, np.max(pos_freqs)])\n",
    "            axes[i, j].set_ylim([0, 1])\n",
    "    plt.suptitle(name)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plt.close('all')\n",
    "\n",
    "    # example from the paper\n",
    "    A = np.zeros((3, 5, 5))\n",
    "    A[0, 0, 0] = 0.95 * math.sqrt(2)\n",
    "    A[1, 0, 0] = -0.9025\n",
    "    A[1, 1, 0] = 0.5\n",
    "    A[2, 2, 0] = -0.4\n",
    "    A[1, 3, 0] = -0.5\n",
    "    A[0, 3, 3] = 0.25 * math.sqrt(2)\n",
    "    A[0, 3, 4] = 0.25 * math.sqrt(2)\n",
    "    A[0, 4, 3] = -0.25 * math.sqrt(2)\n",
    "    A[0, 4, 4] = 0.25 * math.sqrt(2)\n",
    "\n",
    "    # simulate processes\n",
    "    n = 10 ** 4\n",
    "    # sigma = np.array([0.0001, 1, 1, 1, 1])\n",
    "    # sigma = np.array([0.01, 1, 1, 1, 1])\n",
    "    sigma = np.array([1., 1., 1., 1., 1.])\n",
    "    Y = mvar_generate(A, n, sigma)\n",
    "\n",
    "    mu = np.mean(Y, axis=1)\n",
    "    X = Y - mu[:, None]\n",
    "\n",
    "    # estimate AR order with BIC\n",
    "    if 1:\n",
    "        p_max = 20\n",
    "        p, bic = compute_order(X, p_max=p_max)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(p_max + 1), bic)\n",
    "        plt.xlabel('order')\n",
    "        plt.ylabel('BIC')\n",
    "        plt.show()\n",
    "    else:\n",
    "        p = 3\n",
    "\n",
    "    A_est, sigma = mvar_fit(X, p)\n",
    "    sigma = np.diag(sigma)  # DTF + PDC support diagonal noise\n",
    "    # sigma = None\n",
    "\n",
    "    # compute DTF\n",
    "    D, freqs = DTF(A_est, sigma)\n",
    "    plot_all(freqs, D, 'DTF')\n",
    "\n",
    "    # compute PDC\n",
    "    P, freqs = PDC(A_est, sigma)\n",
    "    plot_all(freqs, P, 'PDC')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "808ba9f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 8]\n",
      " [8 1]]\n",
      "[[1 8]\n",
      " [8 1]]\n",
      "[[ 1 32]\n",
      " [32  1]]\n",
      "[[ 1 32]\n",
      " [32  1]]\n",
      "[[  1 128]\n",
      " [128   1]]\n",
      "[[  1 128]\n",
      " [128   1]]\n",
      "[[  1 512]\n",
      " [512   1]]\n",
      "[[  1 512]\n",
      " [512   1]]\n",
      "[[   1 2048]\n",
      " [2048    1]]\n",
      "[[   1 2048]\n",
      " [2048    1]]\n"
     ]
    }
   ],
   "source": [
    "p1 = np.array([[1,2,],[2,1]])\n",
    "p2 = np.array([[1,2,],[2,1]])\n",
    "k1 = np.array([[1,2,],[2,1]])\n",
    "k2= np.array([[1,2,],[2,1]])\n",
    "SSM_Fusion(p1,p2,k1,k2,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_dh",
   "language": "python",
   "name": "py39_dh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}